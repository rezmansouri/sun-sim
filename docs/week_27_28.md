---
layout: default
title: First Paper 7
---

### Methods

#### Cross-validation:

- for finding # Layers and # Channels
- MSE as the metric

#### Other metrics

- ACC, PSNR, MS-SSIM, Earth Mover's

### Results

- 8 layer x 256 hidden channel SFNO is the best since has lowest MSE
  - box and whisker plot for cross validation folds {fig:mse_cv}
- Optimal SFNO is doing better than HUX both overall and in edge-specific areas
  - box and whisker plot {fig:mse_sfno_hux}
- Based on MSE, the error increases as the radius becomes larger in both
  - Scatter plots {fig:mse_per_slice}
- Based on Masked MSE, as the radius becomes larger SFNO has matching variance with HUX
  - Scatter plots {fig:mse_per_slice}
- Optimal SFNO is more accurate in high-speed areas (near poles)
  - Easiest case and hard case plots {fig:best} {fig:worst}
  - Ask pete why is HUX bad in polar regions❓ (Leave this one as a question in red)
- Based on MSE, SFNO is more accurate in high gradient areas too
  - box and whisker plot for all the instances {fig:mse_sfno_hux}
  - Still, due to its ability to capture high-speed areas? elaborate based on your knowledge
- Based on visual inspection, HUX's estimates are still agreeing more with the MAS
  - MSE, ACC, PSNR, MS-SSIM and Earth Mover's results tell us the opposite or show almost no difference
  - A table {tab:metrics}
  - Better metrics are required
- Regardless, SFNO is data-driven, HUX is numeric, in terms of surrogates, it is still beneficial



<!-- - Modeling pipeline
  - Intro SFNO
  - Model parameters
    - 110 modes in latitude. max possible based on polynomial quadrature rules (Gauss-Legendre)
    - 64 modes in longitude since its periodic [0, 2pi] to be captured which is the max possible based on Shannon Nyquist Sampling Theorem
    - 1 input channel (r_0, inner boundary, at 30 R_\odot)
    - 139 output channels (from r_1 (\approx 31 R_\odot) to r_139 (1 AU))
    - dense tensor factorization (i.e., none) in the SFNO layers for maxiumum learning capability
    - number of sfno layers is to be tuned
    - number of hidden channels in the sfno layers is to be tuned

- Evaluation metrics
  - Mean Squared Error is the common one for regression ML tasks, employed in our cross validation step to choose the best hyperparams.
  - As the pattern in high gradient (i.e., sudden transition between slow wind to fast wind) is more important to be captured because that's where the dynamics are and Fast wind hitting slow wind produces shocks for example \cite{riley1, riley2}, we used a variation of MSE and call it edge-specific MSE which only considers the edge regions in radial slices detected by a $3\times3$ sobel filter. See fig~\ref{fig:edges} for this detection demonstration.
  - We also evaluate the estimates from the optimal models using the earth mover distance (aka wasserstein distance), multiscale ssim (MS-SSIM)~\cite{mssim}, peak signal to noise ration (PSNR), and ACC (which requires a climatology and in our case it was the mean of the training data across the samples to acquire a climatology datacube).

- Training Strategy
  - Loss function and optimization: The objective is a layer-wise two-dimensional \(L_{2}\) loss,
  defined as
  \begin{align}
  \mathcal{L}_{2}^{(2\mathrm{D})}
  &= \frac{1}{BCR} \sum_{b,c,r}
  \left(
  \sum_{i,j}
  \lvert x_{bcrij} - y_{bcrij} \rvert^2
  \right)^{1/2}
  \label{eq:l2_2d_short}
  \end{align}

  where \(B\) is the batch size, \(C\) the number of
  velocity components, \(R\) the radial shells, and
  \(H\times W\) the latitude–longitude grid.
  We optimize the network with the Adam optimiser
  using a fixed learning rate of \(\boldsymbol{8\times10^{-4}}\)
  and a batch size of 32 velocity cubes per step.
  Training for each experiment continues for 150 epochs and the model's state with the least validation loss will be retained as the optimal model.

  - Cross validation and final model training : using MSE as the metric to choose the number of layers and hidden channels. our candidates for the number of layers were 4 and 8 and hidden channels as 64, 128, and 256. This was done to find the sweet spot between best performance and overfitting. Once the best combination is found, the model will be trained from scratch on the training split and the results are reported on the hold out test set. table~\ref{tab:dataset} shows the details of this splitting strategy.

  - System specifications: We used PyTorch \cite{torch} version 2.2.1, the NeuralOperator package version 1.0.2 in Python 3.10.12. The experiments were run on an NVIDIA A40 48Gb GPU, 22.04.3 Ubuntu system with $\sim$500Gb memory. Since HUX-f is implemented for CPU-Only we'll report the resource/time consumption results of the SFNO on the CPU as well for the sake of "comparing apples to apples" comparison. -->