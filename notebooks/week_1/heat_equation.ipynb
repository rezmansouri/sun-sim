{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_1, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(2, 5)\n",
    "        self.hidden_layer2 = nn.Linear(5, 5)\n",
    "        self.hidden_layer3 = nn.Linear(5, 5)\n",
    "        self.hidden_layer4 = nn.Linear(5, 5)\n",
    "        self.hidden_layer5 = nn.Linear(5, 5)\n",
    "        self.output_layer = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        inputs = torch.cat([x, t], axis=1)\n",
    "        layer1_out = torch.sigmoid(self.hidden_layer1(inputs))\n",
    "        layer2_out = torch.sigmoid(self.hidden_layer2(layer1_out))\n",
    "        layer3_out = torch.sigmoid(self.hidden_layer3(layer2_out))\n",
    "        layer4_out = torch.sigmoid(self.hidden_layer4(layer3_out))\n",
    "        layer5_out = torch.sigmoid(self.hidden_layer5(layer4_out))\n",
    "        output = self.output_layer(layer5_out)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, t, net):\n",
    "    u = net(x, t)\n",
    "    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u.sum(), t, create_graph=True)[0]\n",
    "    pde = u_x - 2 * u_t - u\n",
    "    return pde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(low=0.0, high=2.0, size=(500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:400]\n",
    "val_indices = indices[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bc = x[train_indices, :]\n",
    "t_bc = np.zeros((400,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_bc = 6 * np.exp(-3 * x_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x[val_indices, :]\n",
    "t_val = np.random.uniform(low=0.0, high=0.1, size=(100,1))\n",
    "u_val = 6 * np.exp(-3 * x_val - 2 * t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_x_val = Variable(torch.from_numpy(x_val).float(), requires_grad=True).to(device)\n",
    "pt_t_val = Variable(torch.from_numpy(t_val).float(), requires_grad=True).to(device)\n",
    "pt_u_val = Variable(torch.from_numpy(u_val).float(), requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model_1()\n",
    "net = net.to(device)\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Training Loss: 3.9808855056762695 Validation Loss: 3.2671167850494385\n",
      "1 Training Loss: 3.9623196125030518 Validation Loss: 3.2499122619628906\n",
      "2 Training Loss: 3.9438512325286865 Validation Loss: 3.2328014373779297\n",
      "3 Training Loss: 3.925469160079956 Validation Loss: 3.2157857418060303\n",
      "4 Training Loss: 3.907186508178711 Validation Loss: 3.198866367340088\n",
      "5 Training Loss: 3.8889987468719482 Validation Loss: 3.1820456981658936\n",
      "6 Training Loss: 3.870908260345459 Validation Loss: 3.1653242111206055\n",
      "7 Training Loss: 3.852918863296509 Validation Loss: 3.1487035751342773\n",
      "8 Training Loss: 3.8350307941436768 Validation Loss: 3.132185459136963\n",
      "9 Training Loss: 3.817242383956909 Validation Loss: 3.1157705783843994\n",
      "10 Training Loss: 3.799560308456421 Validation Loss: 3.0994598865509033\n",
      "11 Training Loss: 3.7819814682006836 Validation Loss: 3.083254814147949\n",
      "12 Training Loss: 3.764512538909912 Validation Loss: 3.06715726852417\n",
      "13 Training Loss: 3.7471485137939453 Validation Loss: 3.0511670112609863\n",
      "14 Training Loss: 3.7298946380615234 Validation Loss: 3.035285711288452\n",
      "15 Training Loss: 3.712747097015381 Validation Loss: 3.0195140838623047\n",
      "16 Training Loss: 3.6957132816314697 Validation Loss: 3.0038528442382812\n",
      "17 Training Loss: 3.678792715072632 Validation Loss: 2.9883034229278564\n",
      "18 Training Loss: 3.6619796752929688 Validation Loss: 2.9728665351867676\n",
      "19 Training Loss: 3.6452841758728027 Validation Loss: 2.9575419425964355\n",
      "20 Training Loss: 3.628706216812134 Validation Loss: 2.9423320293426514\n",
      "21 Training Loss: 3.6122357845306396 Validation Loss: 2.927236318588257\n",
      "22 Training Loss: 3.5958871841430664 Validation Loss: 2.9122555255889893\n",
      "23 Training Loss: 3.5796520709991455 Validation Loss: 2.897390127182007\n",
      "24 Training Loss: 3.563537359237671 Validation Loss: 2.8826406002044678\n",
      "25 Training Loss: 3.5475375652313232 Validation Loss: 2.8680081367492676\n",
      "26 Training Loss: 3.5316543579101562 Validation Loss: 2.85349178314209\n",
      "27 Training Loss: 3.5158934593200684 Validation Loss: 2.83909273147583\n",
      "28 Training Loss: 3.5002503395080566 Validation Loss: 2.8248114585876465\n",
      "29 Training Loss: 3.484727621078491 Validation Loss: 2.810647487640381\n",
      "30 Training Loss: 3.469322919845581 Validation Loss: 2.7966010570526123\n",
      "31 Training Loss: 3.4540388584136963 Validation Loss: 2.782672882080078\n",
      "32 Training Loss: 3.4388768672943115 Validation Loss: 2.768862724304199\n",
      "33 Training Loss: 3.4238333702087402 Validation Loss: 2.7551703453063965\n",
      "34 Training Loss: 3.408909797668457 Validation Loss: 2.7415964603424072\n",
      "35 Training Loss: 3.3941071033477783 Validation Loss: 2.728140354156494\n",
      "36 Training Loss: 3.379425048828125 Validation Loss: 2.7148027420043945\n",
      "37 Training Loss: 3.3648619651794434 Validation Loss: 2.701582431793213\n",
      "38 Training Loss: 3.3504207134246826 Validation Loss: 2.6884801387786865\n",
      "39 Training Loss: 3.336099624633789 Validation Loss: 2.6754958629608154\n",
      "40 Training Loss: 3.3219003677368164 Validation Loss: 2.662628173828125\n",
      "41 Training Loss: 3.307817220687866 Validation Loss: 2.649878740310669\n",
      "42 Training Loss: 3.293858051300049 Validation Loss: 2.6372463703155518\n",
      "43 Training Loss: 3.2800183296203613 Validation Loss: 2.624730348587036\n",
      "44 Training Loss: 3.266296148300171 Validation Loss: 2.6123311519622803\n",
      "45 Training Loss: 3.2526938915252686 Validation Loss: 2.600048303604126\n",
      "46 Training Loss: 3.2392094135284424 Validation Loss: 2.587881088256836\n",
      "47 Training Loss: 3.225846529006958 Validation Loss: 2.5758297443389893\n",
      "48 Training Loss: 3.21260142326355 Validation Loss: 2.5638935565948486\n",
      "49 Training Loss: 3.1994731426239014 Validation Loss: 2.552072525024414\n",
      "50 Training Loss: 3.1864633560180664 Validation Loss: 2.5403661727905273\n",
      "51 Training Loss: 3.173570394515991 Validation Loss: 2.528773546218872\n",
      "52 Training Loss: 3.1607980728149414 Validation Loss: 2.5172948837280273\n",
      "53 Training Loss: 3.148139238357544 Validation Loss: 2.505929708480835\n",
      "54 Training Loss: 3.1355950832366943 Validation Loss: 2.4946775436401367\n",
      "55 Training Loss: 3.1231703758239746 Validation Loss: 2.4835379123687744\n",
      "56 Training Loss: 3.110860824584961 Validation Loss: 2.472510576248169\n",
      "57 Training Loss: 3.0986642837524414 Validation Loss: 2.461594820022583\n",
      "58 Training Loss: 3.086582899093628 Validation Loss: 2.4507904052734375\n",
      "59 Training Loss: 3.074618101119995 Validation Loss: 2.440096855163574\n",
      "60 Training Loss: 3.0627658367156982 Validation Loss: 2.4295129776000977\n",
      "61 Training Loss: 3.0510270595550537 Validation Loss: 2.419039487838745\n",
      "62 Training Loss: 3.0394022464752197 Validation Loss: 2.408674955368042\n",
      "63 Training Loss: 3.027888536453247 Validation Loss: 2.3984198570251465\n",
      "64 Training Loss: 3.0164871215820312 Validation Loss: 2.388272762298584\n",
      "65 Training Loss: 3.005197763442993 Validation Loss: 2.3782336711883545\n",
      "66 Training Loss: 2.9940202236175537 Validation Loss: 2.3683018684387207\n",
      "67 Training Loss: 2.9829516410827637 Validation Loss: 2.3584768772125244\n",
      "68 Training Loss: 2.9719936847686768 Validation Loss: 2.3487582206726074\n",
      "69 Training Loss: 2.9611454010009766 Validation Loss: 2.3391458988189697\n",
      "70 Training Loss: 2.950406551361084 Validation Loss: 2.3296384811401367\n",
      "71 Training Loss: 2.939777374267578 Validation Loss: 2.3202359676361084\n",
      "72 Training Loss: 2.9292545318603516 Validation Loss: 2.3109378814697266\n",
      "73 Training Loss: 2.918840169906616 Validation Loss: 2.3017430305480957\n",
      "74 Training Loss: 2.9085333347320557 Validation Loss: 2.292651653289795\n",
      "75 Training Loss: 2.898333787918091 Validation Loss: 2.283663272857666\n",
      "76 Training Loss: 2.8882386684417725 Validation Loss: 2.2747769355773926\n",
      "77 Training Loss: 2.878248691558838 Validation Loss: 2.265991687774658\n",
      "78 Training Loss: 2.8683652877807617 Validation Loss: 2.257308006286621\n",
      "79 Training Loss: 2.858586311340332 Validation Loss: 2.248724937438965\n",
      "80 Training Loss: 2.8489110469818115 Validation Loss: 2.240241289138794\n",
      "81 Training Loss: 2.8393402099609375 Validation Loss: 2.2318575382232666\n",
      "82 Training Loss: 2.8298699855804443 Validation Loss: 2.223572254180908\n",
      "83 Training Loss: 2.8205037117004395 Validation Loss: 2.2153854370117188\n",
      "84 Training Loss: 2.811239719390869 Validation Loss: 2.207296133041382\n",
      "85 Training Loss: 2.8020763397216797 Validation Loss: 2.1993041038513184\n",
      "86 Training Loss: 2.793013572692871 Validation Loss: 2.191409111022949\n",
      "87 Training Loss: 2.784050941467285 Validation Loss: 2.1836092472076416\n",
      "88 Training Loss: 2.77518892288208 Validation Loss: 2.175905466079712\n",
      "89 Training Loss: 2.766425609588623 Validation Loss: 2.1682963371276855\n",
      "90 Training Loss: 2.757760524749756 Validation Loss: 2.1607813835144043\n",
      "91 Training Loss: 2.7491939067840576 Validation Loss: 2.153360366821289\n",
      "92 Training Loss: 2.7407240867614746 Validation Loss: 2.1460323333740234\n",
      "93 Training Loss: 2.732351064682007 Validation Loss: 2.13879656791687\n",
      "94 Training Loss: 2.7240748405456543 Validation Loss: 2.13165283203125\n",
      "95 Training Loss: 2.7158937454223633 Validation Loss: 2.124600887298584\n",
      "96 Training Loss: 2.707808494567871 Validation Loss: 2.1176393032073975\n",
      "97 Training Loss: 2.699817419052124 Validation Loss: 2.1107680797576904\n",
      "98 Training Loss: 2.691920280456543 Validation Loss: 2.1039862632751465\n",
      "99 Training Loss: 2.6841166019439697 Validation Loss: 2.0972931385040283\n",
      "100 Training Loss: 2.676406145095825 Validation Loss: 2.090688943862915\n",
      "101 Training Loss: 2.668787717819214 Validation Loss: 2.084172487258911\n",
      "102 Training Loss: 2.6612610816955566 Validation Loss: 2.0777428150177\n",
      "103 Training Loss: 2.653825283050537 Validation Loss: 2.071399688720703\n",
      "104 Training Loss: 2.646480083465576 Validation Loss: 2.0651426315307617\n",
      "105 Training Loss: 2.6392247676849365 Validation Loss: 2.0589709281921387\n",
      "106 Training Loss: 2.63205885887146 Validation Loss: 2.052884340286255\n",
      "107 Training Loss: 2.62498140335083 Validation Loss: 2.0468811988830566\n",
      "108 Training Loss: 2.617992639541626 Validation Loss: 2.0409622192382812\n",
      "109 Training Loss: 2.611090898513794 Validation Loss: 2.035125494003296\n",
      "110 Training Loss: 2.604276180267334 Validation Loss: 2.0293710231781006\n",
      "111 Training Loss: 2.597548007965088 Validation Loss: 2.023698568344116\n",
      "112 Training Loss: 2.59090518951416 Validation Loss: 2.0181071758270264\n",
      "113 Training Loss: 2.58434796333313 Validation Loss: 2.0125958919525146\n",
      "114 Training Loss: 2.5778748989105225 Validation Loss: 2.00716495513916\n",
      "115 Training Loss: 2.571486234664917 Validation Loss: 2.00181245803833\n",
      "116 Training Loss: 2.5651803016662598 Validation Loss: 1.996538758277893\n",
      "117 Training Loss: 2.558957576751709 Validation Loss: 1.9913429021835327\n",
      "118 Training Loss: 2.552816867828369 Validation Loss: 1.9862242937088013\n",
      "119 Training Loss: 2.546757459640503 Validation Loss: 1.9811824560165405\n",
      "120 Training Loss: 2.540778636932373 Validation Loss: 1.976216435432434\n",
      "121 Training Loss: 2.5348808765411377 Validation Loss: 1.9713261127471924\n",
      "122 Training Loss: 2.529061794281006 Validation Loss: 1.9665101766586304\n",
      "123 Training Loss: 2.523322820663452 Validation Loss: 1.9617685079574585\n",
      "124 Training Loss: 2.5176610946655273 Validation Loss: 1.9571001529693604\n",
      "125 Training Loss: 2.512078046798706 Validation Loss: 1.9525048732757568\n",
      "126 Training Loss: 2.5065717697143555 Validation Loss: 1.947981595993042\n",
      "127 Training Loss: 2.5011417865753174 Validation Loss: 1.943529725074768\n",
      "128 Training Loss: 2.49578857421875 Validation Loss: 1.9391489028930664\n",
      "129 Training Loss: 2.490508556365967 Validation Loss: 1.9348382949829102\n",
      "130 Training Loss: 2.4853053092956543 Validation Loss: 1.9305973052978516\n",
      "131 Training Loss: 2.4801764488220215 Validation Loss: 1.9264254570007324\n",
      "132 Training Loss: 2.4751200675964355 Validation Loss: 1.9223216772079468\n",
      "133 Training Loss: 2.4701366424560547 Validation Loss: 1.9182859659194946\n",
      "134 Training Loss: 2.465224266052246 Validation Loss: 1.9143167734146118\n",
      "135 Training Loss: 2.4603841304779053 Validation Loss: 1.910414218902588\n",
      "136 Training Loss: 2.455615520477295 Validation Loss: 1.906577467918396\n",
      "137 Training Loss: 2.450918197631836 Validation Loss: 1.9028055667877197\n",
      "138 Training Loss: 2.4462878704071045 Validation Loss: 1.8990983963012695\n",
      "139 Training Loss: 2.4417262077331543 Validation Loss: 1.8954548835754395\n",
      "140 Training Loss: 2.4372363090515137 Validation Loss: 1.8918746709823608\n",
      "141 Training Loss: 2.432811975479126 Validation Loss: 1.8883569240570068\n",
      "142 Training Loss: 2.4284539222717285 Validation Loss: 1.8849008083343506\n",
      "143 Training Loss: 2.424164295196533 Validation Loss: 1.8815059661865234\n",
      "144 Training Loss: 2.419938564300537 Validation Loss: 1.8781719207763672\n",
      "145 Training Loss: 2.4157795906066895 Validation Loss: 1.8748974800109863\n",
      "146 Training Loss: 2.411684989929199 Validation Loss: 1.8716824054718018\n",
      "147 Training Loss: 2.407654285430908 Validation Loss: 1.8685261011123657\n",
      "148 Training Loss: 2.403686046600342 Validation Loss: 1.8654277324676514\n",
      "149 Training Loss: 2.3997819423675537 Validation Loss: 1.8623865842819214\n",
      "150 Training Loss: 2.39593768119812 Validation Loss: 1.8594021797180176\n",
      "151 Training Loss: 2.3921566009521484 Validation Loss: 1.8564738035202026\n",
      "152 Training Loss: 2.3884360790252686 Validation Loss: 1.8536008596420288\n",
      "153 Training Loss: 2.3847744464874268 Validation Loss: 1.8507826328277588\n",
      "154 Training Loss: 2.3811733722686768 Validation Loss: 1.8480184078216553\n",
      "155 Training Loss: 2.3776321411132812 Validation Loss: 1.84530770778656\n",
      "156 Training Loss: 2.374147415161133 Validation Loss: 1.8426498174667358\n",
      "157 Training Loss: 2.3707187175750732 Validation Loss: 1.8400442600250244\n",
      "158 Training Loss: 2.3673505783081055 Validation Loss: 1.8374900817871094\n",
      "159 Training Loss: 2.3640382289886475 Validation Loss: 1.8349868059158325\n",
      "160 Training Loss: 2.360780954360962 Validation Loss: 1.8325337171554565\n",
      "161 Training Loss: 2.3575775623321533 Validation Loss: 1.8301305770874023\n",
      "162 Training Loss: 2.3544294834136963 Validation Loss: 1.827776312828064\n",
      "163 Training Loss: 2.351335287094116 Validation Loss: 1.8254703283309937\n",
      "164 Training Loss: 2.3482933044433594 Validation Loss: 1.8232121467590332\n",
      "165 Training Loss: 2.3453071117401123 Validation Loss: 1.8210011720657349\n",
      "166 Training Loss: 2.342369318008423 Validation Loss: 1.8188366889953613\n",
      "167 Training Loss: 2.339484453201294 Validation Loss: 1.8167179822921753\n",
      "168 Training Loss: 2.3366518020629883 Validation Loss: 1.8146448135375977\n",
      "169 Training Loss: 2.333867073059082 Validation Loss: 1.8126158714294434\n",
      "170 Training Loss: 2.3311328887939453 Validation Loss: 1.810631275177002\n",
      "171 Training Loss: 2.3284449577331543 Validation Loss: 1.808690071105957\n",
      "172 Training Loss: 2.3258090019226074 Validation Loss: 1.8067911863327026\n",
      "173 Training Loss: 2.3232197761535645 Validation Loss: 1.8049352169036865\n",
      "174 Training Loss: 2.320674419403076 Validation Loss: 1.803120493888855\n",
      "175 Training Loss: 2.3181798458099365 Validation Loss: 1.8013466596603394\n",
      "176 Training Loss: 2.315730094909668 Validation Loss: 1.799613356590271\n",
      "177 Training Loss: 2.313323497772217 Validation Loss: 1.797919750213623\n",
      "178 Training Loss: 2.3109614849090576 Validation Loss: 1.7962653636932373\n",
      "179 Training Loss: 2.3086483478546143 Validation Loss: 1.794649600982666\n",
      "180 Training Loss: 2.306375741958618 Validation Loss: 1.793071985244751\n",
      "181 Training Loss: 2.304147243499756 Validation Loss: 1.7915315628051758\n",
      "182 Training Loss: 2.3019590377807617 Validation Loss: 1.7900280952453613\n",
      "183 Training Loss: 2.2998127937316895 Validation Loss: 1.7885609865188599\n",
      "184 Training Loss: 2.297708511352539 Validation Loss: 1.7871294021606445\n",
      "185 Training Loss: 2.2956438064575195 Validation Loss: 1.7857332229614258\n",
      "186 Training Loss: 2.293618679046631 Validation Loss: 1.7843711376190186\n",
      "187 Training Loss: 2.2916362285614014 Validation Loss: 1.783043384552002\n",
      "188 Training Loss: 2.2896878719329834 Validation Loss: 1.78174889087677\n",
      "189 Training Loss: 2.2877838611602783 Validation Loss: 1.7804875373840332\n",
      "190 Training Loss: 2.2859132289886475 Validation Loss: 1.7792584896087646\n",
      "191 Training Loss: 2.2840805053710938 Validation Loss: 1.778061032295227\n",
      "192 Training Loss: 2.282283306121826 Validation Loss: 1.7768948078155518\n",
      "193 Training Loss: 2.2805261611938477 Validation Loss: 1.7757594585418701\n",
      "194 Training Loss: 2.2787997722625732 Validation Loss: 1.7746542692184448\n",
      "195 Training Loss: 2.277111768722534 Validation Loss: 1.7735785245895386\n",
      "196 Training Loss: 2.275458812713623 Validation Loss: 1.7725319862365723\n",
      "197 Training Loss: 2.2738380432128906 Validation Loss: 1.7715142965316772\n",
      "198 Training Loss: 2.2722532749176025 Validation Loss: 1.770524501800537\n",
      "199 Training Loss: 2.270697593688965 Validation Loss: 1.7695621252059937\n",
      "200 Training Loss: 2.269176483154297 Validation Loss: 1.7686270475387573\n",
      "201 Training Loss: 2.2676846981048584 Validation Loss: 1.7677185535430908\n",
      "202 Training Loss: 2.266228675842285 Validation Loss: 1.7668356895446777\n",
      "203 Training Loss: 2.264800786972046 Validation Loss: 1.7659788131713867\n",
      "204 Training Loss: 2.2634005546569824 Validation Loss: 1.7651469707489014\n",
      "205 Training Loss: 2.262035608291626 Validation Loss: 1.764339566230774\n",
      "206 Training Loss: 2.2606959342956543 Validation Loss: 1.7635562419891357\n",
      "207 Training Loss: 2.2593884468078613 Validation Loss: 1.7627966403961182\n",
      "208 Training Loss: 2.2581064701080322 Validation Loss: 1.7620604038238525\n",
      "209 Training Loss: 2.256854772567749 Validation Loss: 1.7613465785980225\n",
      "210 Training Loss: 2.255631923675537 Validation Loss: 1.7606549263000488\n",
      "211 Training Loss: 2.2544307708740234 Validation Loss: 1.759985327720642\n",
      "212 Training Loss: 2.2532598972320557 Validation Loss: 1.7593371868133545\n",
      "213 Training Loss: 2.2521116733551025 Validation Loss: 1.7587097883224487\n",
      "214 Training Loss: 2.2509920597076416 Validation Loss: 1.7581027746200562\n",
      "215 Training Loss: 2.24989914894104 Validation Loss: 1.7575159072875977\n",
      "216 Training Loss: 2.2488276958465576 Validation Loss: 1.7569483518600464\n",
      "217 Training Loss: 2.2477807998657227 Validation Loss: 1.7564005851745605\n",
      "218 Training Loss: 2.246758460998535 Validation Loss: 1.7558711767196655\n",
      "219 Training Loss: 2.2457611560821533 Validation Loss: 1.7553598880767822\n",
      "220 Training Loss: 2.2447822093963623 Validation Loss: 1.7548669576644897\n",
      "221 Training Loss: 2.2438297271728516 Validation Loss: 1.7543911933898926\n",
      "222 Training Loss: 2.2428972721099854 Validation Loss: 1.7539329528808594\n",
      "223 Training Loss: 2.2419862747192383 Validation Loss: 1.7534914016723633\n",
      "224 Training Loss: 2.2410995960235596 Validation Loss: 1.753066062927246\n",
      "225 Training Loss: 2.24023175239563 Validation Loss: 1.7526568174362183\n",
      "226 Training Loss: 2.239384412765503 Validation Loss: 1.752263069152832\n",
      "227 Training Loss: 2.2385568618774414 Validation Loss: 1.7518848180770874\n",
      "228 Training Loss: 2.2377498149871826 Validation Loss: 1.751521348953247\n",
      "229 Training Loss: 2.236961603164673 Validation Loss: 1.7511723041534424\n",
      "230 Training Loss: 2.236192464828491 Validation Loss: 1.7508374452590942\n",
      "231 Training Loss: 2.235440254211426 Validation Loss: 1.7505162954330444\n",
      "232 Training Loss: 2.234707832336426 Validation Loss: 1.750208854675293\n",
      "233 Training Loss: 2.2339928150177 Validation Loss: 1.749914526939392\n",
      "234 Training Loss: 2.2332985401153564 Validation Loss: 1.7496329545974731\n",
      "235 Training Loss: 2.2326161861419678 Validation Loss: 1.7493637800216675\n",
      "236 Training Loss: 2.23195481300354 Validation Loss: 1.7491068840026855\n",
      "237 Training Loss: 2.2313051223754883 Validation Loss: 1.7488616704940796\n",
      "238 Training Loss: 2.2306747436523438 Validation Loss: 1.7486283779144287\n",
      "239 Training Loss: 2.230059862136841 Validation Loss: 1.7484060525894165\n",
      "240 Training Loss: 2.229458808898926 Validation Loss: 1.7481945753097534\n",
      "241 Training Loss: 2.2288718223571777 Validation Loss: 1.74799382686615\n",
      "242 Training Loss: 2.2283029556274414 Validation Loss: 1.7478035688400269\n",
      "243 Training Loss: 2.227750062942505 Validation Loss: 1.7476232051849365\n",
      "244 Training Loss: 2.2272069454193115 Validation Loss: 1.7474524974822998\n",
      "245 Training Loss: 2.2266783714294434 Validation Loss: 1.7472914457321167\n",
      "246 Training Loss: 2.2261648178100586 Validation Loss: 1.7471399307250977\n",
      "247 Training Loss: 2.2256667613983154 Validation Loss: 1.7469968795776367\n",
      "248 Training Loss: 2.225175380706787 Validation Loss: 1.7468626499176025\n",
      "249 Training Loss: 2.2246999740600586 Validation Loss: 1.7467368841171265\n",
      "250 Training Loss: 2.2242414951324463 Validation Loss: 1.746619462966919\n",
      "251 Training Loss: 2.223787307739258 Validation Loss: 1.7465097904205322\n",
      "252 Training Loss: 2.2233493328094482 Validation Loss: 1.7464081048965454\n",
      "253 Training Loss: 2.222921371459961 Validation Loss: 1.7463136911392212\n",
      "254 Training Loss: 2.2225074768066406 Validation Loss: 1.74622642993927\n",
      "255 Training Loss: 2.222102642059326 Validation Loss: 1.746146321296692\n",
      "256 Training Loss: 2.2217085361480713 Validation Loss: 1.7460730075836182\n",
      "257 Training Loss: 2.221327066421509 Validation Loss: 1.7460062503814697\n",
      "258 Training Loss: 2.220951557159424 Validation Loss: 1.745945930480957\n",
      "259 Training Loss: 2.2205846309661865 Validation Loss: 1.7458915710449219\n",
      "260 Training Loss: 2.2202351093292236 Validation Loss: 1.7458432912826538\n",
      "261 Training Loss: 2.2198903560638428 Validation Loss: 1.7458007335662842\n",
      "262 Training Loss: 2.219557285308838 Validation Loss: 1.7457640171051025\n",
      "263 Training Loss: 2.219235420227051 Validation Loss: 1.745732307434082\n",
      "264 Training Loss: 2.218916654586792 Validation Loss: 1.7457058429718018\n",
      "265 Training Loss: 2.2186129093170166 Validation Loss: 1.745684266090393\n",
      "266 Training Loss: 2.218308687210083 Validation Loss: 1.7456676959991455\n",
      "267 Training Loss: 2.218022346496582 Validation Loss: 1.7456557750701904\n",
      "268 Training Loss: 2.217738151550293 Validation Loss: 1.7456483840942383\n",
      "269 Training Loss: 2.2174630165100098 Validation Loss: 1.7456451654434204\n",
      "270 Training Loss: 2.2171945571899414 Validation Loss: 1.7456459999084473\n",
      "271 Training Loss: 2.21693754196167 Validation Loss: 1.7456507682800293\n",
      "272 Training Loss: 2.216684579849243 Validation Loss: 1.7456597089767456\n",
      "273 Training Loss: 2.2164413928985596 Validation Loss: 1.7456718683242798\n",
      "274 Training Loss: 2.216200590133667 Validation Loss: 1.7456878423690796\n",
      "275 Training Loss: 2.2159714698791504 Validation Loss: 1.7457071542739868\n",
      "276 Training Loss: 2.215744972229004 Validation Loss: 1.745729923248291\n",
      "277 Training Loss: 2.2155277729034424 Validation Loss: 1.7457551956176758\n",
      "278 Training Loss: 2.215315580368042 Validation Loss: 1.745784044265747\n",
      "279 Training Loss: 2.2151060104370117 Validation Loss: 1.7458152770996094\n",
      "280 Training Loss: 2.2149083614349365 Validation Loss: 1.7458494901657104\n",
      "281 Training Loss: 2.2147138118743896 Validation Loss: 1.745886206626892\n",
      "282 Training Loss: 2.2145283222198486 Validation Loss: 1.7459255456924438\n",
      "283 Training Loss: 2.2143430709838867 Validation Loss: 1.745966911315918\n",
      "284 Training Loss: 2.2141671180725098 Validation Loss: 1.7460107803344727\n",
      "285 Training Loss: 2.2139952182769775 Validation Loss: 1.7460567951202393\n",
      "286 Training Loss: 2.2138242721557617 Validation Loss: 1.7461047172546387\n",
      "287 Training Loss: 2.213665723800659 Validation Loss: 1.7461546659469604\n",
      "288 Training Loss: 2.213507652282715 Validation Loss: 1.7462061643600464\n",
      "289 Training Loss: 2.213355779647827 Validation Loss: 1.7462594509124756\n",
      "290 Training Loss: 2.2132036685943604 Validation Loss: 1.7463144063949585\n",
      "291 Training Loss: 2.2130627632141113 Validation Loss: 1.7463711500167847\n",
      "292 Training Loss: 2.2129201889038086 Validation Loss: 1.7464290857315063\n",
      "293 Training Loss: 2.212785243988037 Validation Loss: 1.746488332748413\n",
      "294 Training Loss: 2.2126543521881104 Validation Loss: 1.7465488910675049\n",
      "295 Training Loss: 2.212523937225342 Validation Loss: 1.7466108798980713\n",
      "296 Training Loss: 2.212406873703003 Validation Loss: 1.7466734647750854\n",
      "297 Training Loss: 2.212287664413452 Validation Loss: 1.7467375993728638\n",
      "298 Training Loss: 2.2121684551239014 Validation Loss: 1.7468024492263794\n",
      "299 Training Loss: 2.212055206298828 Validation Loss: 1.7468680143356323\n",
      "300 Training Loss: 2.211947441101074 Validation Loss: 1.7469346523284912\n",
      "301 Training Loss: 2.2118377685546875 Validation Loss: 1.7470020055770874\n",
      "302 Training Loss: 2.2117388248443604 Validation Loss: 1.7470698356628418\n",
      "303 Training Loss: 2.211642026901245 Validation Loss: 1.7471383810043335\n",
      "304 Training Loss: 2.211544990539551 Validation Loss: 1.7472074031829834\n",
      "305 Training Loss: 2.2114522457122803 Validation Loss: 1.747277021408081\n",
      "306 Training Loss: 2.211359977722168 Validation Loss: 1.747347116470337\n",
      "307 Training Loss: 2.2112700939178467 Validation Loss: 1.7474174499511719\n",
      "308 Training Loss: 2.211189031600952 Validation Loss: 1.747488260269165\n",
      "309 Training Loss: 2.211103916168213 Validation Loss: 1.7475593090057373\n",
      "310 Training Loss: 2.21102237701416 Validation Loss: 1.7476304769515991\n",
      "311 Training Loss: 2.2109460830688477 Validation Loss: 1.7477020025253296\n",
      "312 Training Loss: 2.2108731269836426 Validation Loss: 1.7477734088897705\n",
      "313 Training Loss: 2.2107999324798584 Validation Loss: 1.747844934463501\n",
      "314 Training Loss: 2.2107279300689697 Validation Loss: 1.747916579246521\n",
      "315 Training Loss: 2.2106592655181885 Validation Loss: 1.747987985610962\n",
      "316 Training Loss: 2.2105963230133057 Validation Loss: 1.7480599880218506\n",
      "317 Training Loss: 2.210528612136841 Validation Loss: 1.7481313943862915\n",
      "318 Training Loss: 2.2104709148406982 Validation Loss: 1.7482028007507324\n",
      "319 Training Loss: 2.210411548614502 Validation Loss: 1.7482740879058838\n",
      "320 Training Loss: 2.210348606109619 Validation Loss: 1.7483452558517456\n",
      "321 Training Loss: 2.210297107696533 Validation Loss: 1.7484161853790283\n",
      "322 Training Loss: 2.2102458477020264 Validation Loss: 1.748486876487732\n",
      "323 Training Loss: 2.2101919651031494 Validation Loss: 1.7485573291778564\n",
      "324 Training Loss: 2.2101333141326904 Validation Loss: 1.7486271858215332\n",
      "325 Training Loss: 2.2100894451141357 Validation Loss: 1.74869704246521\n",
      "326 Training Loss: 2.2100422382354736 Validation Loss: 1.7487664222717285\n",
      "327 Training Loss: 2.209993600845337 Validation Loss: 1.748835563659668\n",
      "328 Training Loss: 2.209946870803833 Validation Loss: 1.7489042282104492\n",
      "329 Training Loss: 2.209904432296753 Validation Loss: 1.7489725351333618\n",
      "330 Training Loss: 2.2098631858825684 Validation Loss: 1.749040126800537\n",
      "331 Training Loss: 2.209824562072754 Validation Loss: 1.7491075992584229\n",
      "332 Training Loss: 2.2097830772399902 Validation Loss: 1.7491743564605713\n",
      "333 Training Loss: 2.209747314453125 Validation Loss: 1.749240756034851\n",
      "334 Training Loss: 2.2097110748291016 Validation Loss: 1.7493066787719727\n",
      "335 Training Loss: 2.209672451019287 Validation Loss: 1.7493717670440674\n",
      "336 Training Loss: 2.2096362113952637 Validation Loss: 1.749436616897583\n",
      "337 Training Loss: 2.2096049785614014 Validation Loss: 1.7495008707046509\n",
      "338 Training Loss: 2.209571361541748 Validation Loss: 1.749564528465271\n",
      "339 Training Loss: 2.209538459777832 Validation Loss: 1.7496274709701538\n",
      "340 Training Loss: 2.2095112800598145 Validation Loss: 1.749690055847168\n",
      "341 Training Loss: 2.209482431411743 Validation Loss: 1.7497518062591553\n",
      "342 Training Loss: 2.2094521522521973 Validation Loss: 1.749813437461853\n",
      "343 Training Loss: 2.2094225883483887 Validation Loss: 1.7498739957809448\n",
      "344 Training Loss: 2.2093968391418457 Validation Loss: 1.7499338388442993\n",
      "345 Training Loss: 2.209371566772461 Validation Loss: 1.7499933242797852\n",
      "346 Training Loss: 2.209341287612915 Validation Loss: 1.7500520944595337\n",
      "347 Training Loss: 2.2093210220336914 Validation Loss: 1.7501100301742554\n",
      "348 Training Loss: 2.2092976570129395 Validation Loss: 1.7501676082611084\n",
      "349 Training Loss: 2.209275007247925 Validation Loss: 1.7502244710922241\n",
      "350 Training Loss: 2.209252119064331 Validation Loss: 1.7502806186676025\n",
      "351 Training Loss: 2.209228754043579 Validation Loss: 1.750335931777954\n",
      "352 Training Loss: 2.20920991897583 Validation Loss: 1.7503907680511475\n",
      "353 Training Loss: 2.2091891765594482 Validation Loss: 1.7504448890686035\n",
      "354 Training Loss: 2.2091710567474365 Validation Loss: 1.7504982948303223\n",
      "355 Training Loss: 2.209153175354004 Validation Loss: 1.7505509853363037\n",
      "356 Training Loss: 2.2091333866119385 Validation Loss: 1.7506030797958374\n",
      "357 Training Loss: 2.2091097831726074 Validation Loss: 1.7506544589996338\n",
      "358 Training Loss: 2.209092855453491 Validation Loss: 1.7507052421569824\n",
      "359 Training Loss: 2.2090768814086914 Validation Loss: 1.7507550716400146\n",
      "360 Training Loss: 2.2090611457824707 Validation Loss: 1.7508044242858887\n",
      "361 Training Loss: 2.209044933319092 Validation Loss: 1.750853180885315\n",
      "362 Training Loss: 2.209029197692871 Validation Loss: 1.750901222229004\n",
      "363 Training Loss: 2.2090163230895996 Validation Loss: 1.7509483098983765\n",
      "364 Training Loss: 2.2090003490448 Validation Loss: 1.75099515914917\n",
      "365 Training Loss: 2.208984613418579 Validation Loss: 1.7510409355163574\n",
      "366 Training Loss: 2.208972930908203 Validation Loss: 1.7510861158370972\n",
      "367 Training Loss: 2.2089579105377197 Validation Loss: 1.7511305809020996\n",
      "368 Training Loss: 2.208946943283081 Validation Loss: 1.7511746883392334\n",
      "369 Training Loss: 2.208932876586914 Validation Loss: 1.7512179613113403\n",
      "370 Training Loss: 2.208918333053589 Validation Loss: 1.7512602806091309\n",
      "371 Training Loss: 2.208908796310425 Validation Loss: 1.7513025999069214\n",
      "372 Training Loss: 2.2088940143585205 Validation Loss: 1.7513437271118164\n",
      "373 Training Loss: 2.20888614654541 Validation Loss: 1.7513842582702637\n",
      "374 Training Loss: 2.208874225616455 Validation Loss: 1.7514243125915527\n",
      "375 Training Loss: 2.2088630199432373 Validation Loss: 1.751463532447815\n",
      "376 Training Loss: 2.208853244781494 Validation Loss: 1.7515021562576294\n",
      "377 Training Loss: 2.20883846282959 Validation Loss: 1.7515403032302856\n",
      "378 Training Loss: 2.2088301181793213 Validation Loss: 1.751577615737915\n",
      "379 Training Loss: 2.2088205814361572 Validation Loss: 1.7516143321990967\n",
      "380 Training Loss: 2.2088117599487305 Validation Loss: 1.751650333404541\n",
      "381 Training Loss: 2.208803653717041 Validation Loss: 1.7516859769821167\n",
      "382 Training Loss: 2.2087883949279785 Validation Loss: 1.7517210245132446\n",
      "383 Training Loss: 2.208784341812134 Validation Loss: 1.7517551183700562\n",
      "384 Training Loss: 2.208773136138916 Validation Loss: 1.7517889738082886\n",
      "385 Training Loss: 2.208767890930176 Validation Loss: 1.7518219947814941\n",
      "386 Training Loss: 2.208759307861328 Validation Loss: 1.751854658126831\n",
      "387 Training Loss: 2.2087490558624268 Validation Loss: 1.7518864870071411\n",
      "388 Training Loss: 2.208742618560791 Validation Loss: 1.751918077468872\n",
      "389 Training Loss: 2.208735227584839 Validation Loss: 1.751948595046997\n",
      "390 Training Loss: 2.2087225914001465 Validation Loss: 1.751978874206543\n",
      "391 Training Loss: 2.208714485168457 Validation Loss: 1.7520086765289307\n",
      "392 Training Loss: 2.208710193634033 Validation Loss: 1.7520376443862915\n",
      "393 Training Loss: 2.2087042331695557 Validation Loss: 1.7520661354064941\n",
      "394 Training Loss: 2.20869517326355 Validation Loss: 1.7520943880081177\n",
      "395 Training Loss: 2.208686113357544 Validation Loss: 1.7521218061447144\n",
      "396 Training Loss: 2.2086873054504395 Validation Loss: 1.7521487474441528\n",
      "397 Training Loss: 2.2086751461029053 Validation Loss: 1.7521750926971436\n",
      "398 Training Loss: 2.2086691856384277 Validation Loss: 1.7522010803222656\n",
      "399 Training Loss: 2.2086589336395264 Validation Loss: 1.7522265911102295\n",
      "400 Training Loss: 2.2086546421051025 Validation Loss: 1.752251386642456\n",
      "401 Training Loss: 2.2086493968963623 Validation Loss: 1.7522757053375244\n",
      "402 Training Loss: 2.2086379528045654 Validation Loss: 1.7522995471954346\n",
      "403 Training Loss: 2.208639621734619 Validation Loss: 1.752323031425476\n",
      "404 Training Loss: 2.208629846572876 Validation Loss: 1.752346158027649\n",
      "405 Training Loss: 2.208621025085449 Validation Loss: 1.7523683309555054\n",
      "406 Training Loss: 2.20862078666687 Validation Loss: 1.7523903846740723\n",
      "407 Training Loss: 2.2086102962493896 Validation Loss: 1.752411961555481\n",
      "408 Training Loss: 2.208606004714966 Validation Loss: 1.7524328231811523\n",
      "409 Training Loss: 2.2085978984832764 Validation Loss: 1.7524536848068237\n",
      "410 Training Loss: 2.2085907459259033 Validation Loss: 1.7524735927581787\n",
      "411 Training Loss: 2.208590269088745 Validation Loss: 1.7524936199188232\n",
      "412 Training Loss: 2.2085814476013184 Validation Loss: 1.752512812614441\n",
      "413 Training Loss: 2.2085764408111572 Validation Loss: 1.7525315284729004\n",
      "414 Training Loss: 2.2085704803466797 Validation Loss: 1.7525502443313599\n",
      "415 Training Loss: 2.208566904067993 Validation Loss: 1.752568006515503\n",
      "416 Training Loss: 2.2085602283477783 Validation Loss: 1.752586007118225\n",
      "417 Training Loss: 2.20855450630188 Validation Loss: 1.75260329246521\n",
      "418 Training Loss: 2.2085471153259277 Validation Loss: 1.752619981765747\n",
      "419 Training Loss: 2.2085447311401367 Validation Loss: 1.7526365518569946\n",
      "420 Training Loss: 2.2085392475128174 Validation Loss: 1.752652645111084\n",
      "421 Training Loss: 2.208534002304077 Validation Loss: 1.7526682615280151\n",
      "422 Training Loss: 2.208530902862549 Validation Loss: 1.7526836395263672\n",
      "423 Training Loss: 2.2085230350494385 Validation Loss: 1.7526988983154297\n",
      "424 Training Loss: 2.2085163593292236 Validation Loss: 1.7527130842208862\n",
      "425 Training Loss: 2.2085132598876953 Validation Loss: 1.7527273893356323\n",
      "426 Training Loss: 2.2085084915161133 Validation Loss: 1.7527413368225098\n",
      "427 Training Loss: 2.208503007888794 Validation Loss: 1.7527549266815186\n",
      "428 Training Loss: 2.2084972858428955 Validation Loss: 1.7527680397033691\n",
      "429 Training Loss: 2.2084908485412598 Validation Loss: 1.7527809143066406\n",
      "430 Training Loss: 2.2084879875183105 Validation Loss: 1.7527936697006226\n",
      "431 Training Loss: 2.2084827423095703 Validation Loss: 1.7528060674667358\n",
      "432 Training Loss: 2.208477258682251 Validation Loss: 1.7528177499771118\n",
      "433 Training Loss: 2.2084712982177734 Validation Loss: 1.7528293132781982\n",
      "434 Training Loss: 2.208467721939087 Validation Loss: 1.7528406381607056\n",
      "435 Training Loss: 2.2084624767303467 Validation Loss: 1.7528517246246338\n",
      "436 Training Loss: 2.2084567546844482 Validation Loss: 1.7528624534606934\n",
      "437 Training Loss: 2.208451986312866 Validation Loss: 1.7528730630874634\n",
      "438 Training Loss: 2.208449125289917 Validation Loss: 1.7528831958770752\n",
      "439 Training Loss: 2.2084426879882812 Validation Loss: 1.7528929710388184\n",
      "440 Training Loss: 2.2084386348724365 Validation Loss: 1.7529027462005615\n",
      "441 Training Loss: 2.2084336280822754 Validation Loss: 1.7529118061065674\n",
      "442 Training Loss: 2.208427667617798 Validation Loss: 1.7529208660125732\n",
      "443 Training Loss: 2.208422899246216 Validation Loss: 1.7529298067092896\n",
      "444 Training Loss: 2.20841383934021 Validation Loss: 1.7529382705688477\n",
      "445 Training Loss: 2.2084100246429443 Validation Loss: 1.7529467344284058\n",
      "446 Training Loss: 2.208409070968628 Validation Loss: 1.7529547214508057\n",
      "447 Training Loss: 2.208400249481201 Validation Loss: 1.752962350845337\n",
      "448 Training Loss: 2.2084004878997803 Validation Loss: 1.7529702186584473\n",
      "449 Training Loss: 2.2083933353424072 Validation Loss: 1.7529776096343994\n",
      "450 Training Loss: 2.208386182785034 Validation Loss: 1.7529845237731934\n",
      "451 Training Loss: 2.2083852291107178 Validation Loss: 1.7529914379119873\n",
      "452 Training Loss: 2.208375930786133 Validation Loss: 1.7529981136322021\n",
      "453 Training Loss: 2.2083728313446045 Validation Loss: 1.753004550933838\n",
      "454 Training Loss: 2.2083733081817627 Validation Loss: 1.753010869026184\n",
      "455 Training Loss: 2.208364486694336 Validation Loss: 1.753016710281372\n",
      "456 Training Loss: 2.2083585262298584 Validation Loss: 1.7530224323272705\n",
      "457 Training Loss: 2.2083520889282227 Validation Loss: 1.753028154373169\n",
      "458 Training Loss: 2.2083473205566406 Validation Loss: 1.7530333995819092\n",
      "459 Training Loss: 2.2083449363708496 Validation Loss: 1.7530386447906494\n",
      "460 Training Loss: 2.208340883255005 Validation Loss: 1.753043532371521\n",
      "461 Training Loss: 2.2083330154418945 Validation Loss: 1.7530484199523926\n",
      "462 Training Loss: 2.2083277702331543 Validation Loss: 1.753053069114685\n",
      "463 Training Loss: 2.208325147628784 Validation Loss: 1.7530574798583984\n",
      "464 Training Loss: 2.208319902420044 Validation Loss: 1.7530617713928223\n",
      "465 Training Loss: 2.2083115577697754 Validation Loss: 1.753065824508667\n",
      "466 Training Loss: 2.2083091735839844 Validation Loss: 1.7530697584152222\n",
      "467 Training Loss: 2.2083029747009277 Validation Loss: 1.7530736923217773\n",
      "468 Training Loss: 2.2082953453063965 Validation Loss: 1.7530772686004639\n",
      "469 Training Loss: 2.2082901000976562 Validation Loss: 1.7530806064605713\n",
      "470 Training Loss: 2.2082912921905518 Validation Loss: 1.7530839443206787\n",
      "471 Training Loss: 2.2082839012145996 Validation Loss: 1.7530869245529175\n",
      "472 Training Loss: 2.208278179168701 Validation Loss: 1.7530899047851562\n",
      "473 Training Loss: 2.2082748413085938 Validation Loss: 1.753092885017395\n",
      "474 Training Loss: 2.2082667350769043 Validation Loss: 1.7530953884124756\n",
      "475 Training Loss: 2.208261251449585 Validation Loss: 1.7530978918075562\n",
      "476 Training Loss: 2.2082571983337402 Validation Loss: 1.7531002759933472\n",
      "477 Training Loss: 2.2082512378692627 Validation Loss: 1.7531025409698486\n",
      "478 Training Loss: 2.2082436084747314 Validation Loss: 1.7531046867370605\n",
      "479 Training Loss: 2.2082438468933105 Validation Loss: 1.7531065940856934\n",
      "480 Training Loss: 2.2082359790802 Validation Loss: 1.753108263015747\n",
      "481 Training Loss: 2.2082314491271973 Validation Loss: 1.7531101703643799\n",
      "482 Training Loss: 2.2082250118255615 Validation Loss: 1.753111720085144\n",
      "483 Training Loss: 2.208221197128296 Validation Loss: 1.7531132698059082\n",
      "484 Training Loss: 2.208219051361084 Validation Loss: 1.7531144618988037\n",
      "485 Training Loss: 2.208216667175293 Validation Loss: 1.7531157732009888\n",
      "486 Training Loss: 2.2082090377807617 Validation Loss: 1.7531167268753052\n",
      "487 Training Loss: 2.2081992626190186 Validation Loss: 1.7531176805496216\n",
      "488 Training Loss: 2.208193778991699 Validation Loss: 1.7531187534332275\n",
      "489 Training Loss: 2.2081868648529053 Validation Loss: 1.7531192302703857\n",
      "490 Training Loss: 2.208185911178589 Validation Loss: 1.753119945526123\n",
      "491 Training Loss: 2.2081780433654785 Validation Loss: 1.7531204223632812\n",
      "492 Training Loss: 2.208174228668213 Validation Loss: 1.753121018409729\n",
      "493 Training Loss: 2.2081656455993652 Validation Loss: 1.753121018409729\n",
      "494 Training Loss: 2.208165168762207 Validation Loss: 1.7531213760375977\n",
      "495 Training Loss: 2.2081568241119385 Validation Loss: 1.7531214952468872\n",
      "496 Training Loss: 2.2081518173217773 Validation Loss: 1.7531214952468872\n",
      "497 Training Loss: 2.2081449031829834 Validation Loss: 1.7531214952468872\n",
      "498 Training Loss: 2.208146810531616 Validation Loss: 1.753121018409729\n",
      "499 Training Loss: 2.208134889602661 Validation Loss: 1.753121018409729\n",
      "500 Training Loss: 2.208131790161133 Validation Loss: 1.7531205415725708\n",
      "501 Training Loss: 2.2081186771392822 Validation Loss: 1.7531200647354126\n",
      "502 Training Loss: 2.2081193923950195 Validation Loss: 1.7531195878982544\n",
      "503 Training Loss: 2.2081077098846436 Validation Loss: 1.7531189918518066\n",
      "504 Training Loss: 2.2081079483032227 Validation Loss: 1.7531183958053589\n",
      "505 Training Loss: 2.2081029415130615 Validation Loss: 1.753117561340332\n",
      "506 Training Loss: 2.208096981048584 Validation Loss: 1.7531166076660156\n",
      "507 Training Loss: 2.20809006690979 Validation Loss: 1.7531155347824097\n",
      "508 Training Loss: 2.2080905437469482 Validation Loss: 1.7531144618988037\n",
      "509 Training Loss: 2.2080769538879395 Validation Loss: 1.7531133890151978\n",
      "510 Training Loss: 2.208073139190674 Validation Loss: 1.7531120777130127\n",
      "511 Training Loss: 2.208061695098877 Validation Loss: 1.7531108856201172\n",
      "512 Training Loss: 2.2080562114715576 Validation Loss: 1.7531094551086426\n",
      "513 Training Loss: 2.2080583572387695 Validation Loss: 1.753108263015747\n",
      "514 Training Loss: 2.20805025100708 Validation Loss: 1.753106713294983\n",
      "515 Training Loss: 2.2080488204956055 Validation Loss: 1.7531051635742188\n",
      "516 Training Loss: 2.208043336868286 Validation Loss: 1.7531033754348755\n",
      "517 Training Loss: 2.2080252170562744 Validation Loss: 1.7531018257141113\n",
      "518 Training Loss: 2.208026170730591 Validation Loss: 1.7531001567840576\n",
      "519 Training Loss: 2.2080206871032715 Validation Loss: 1.7530982494354248\n",
      "520 Training Loss: 2.2080166339874268 Validation Loss: 1.7530964612960815\n",
      "521 Training Loss: 2.2080068588256836 Validation Loss: 1.7530944347381592\n",
      "522 Training Loss: 2.2079989910125732 Validation Loss: 1.7530921697616577\n",
      "523 Training Loss: 2.207993984222412 Validation Loss: 1.753090262413025\n",
      "524 Training Loss: 2.2079851627349854 Validation Loss: 1.753088116645813\n",
      "525 Training Loss: 2.207984209060669 Validation Loss: 1.7530858516693115\n",
      "526 Training Loss: 2.207974433898926 Validation Loss: 1.7530837059020996\n",
      "527 Training Loss: 2.2079710960388184 Validation Loss: 1.7530814409255981\n",
      "528 Training Loss: 2.207962989807129 Validation Loss: 1.7530791759490967\n",
      "529 Training Loss: 2.2079532146453857 Validation Loss: 1.7530769109725952\n",
      "530 Training Loss: 2.2079458236694336 Validation Loss: 1.753074288368225\n",
      "531 Training Loss: 2.2079410552978516 Validation Loss: 1.7530717849731445\n",
      "532 Training Loss: 2.2079460620880127 Validation Loss: 1.7530691623687744\n",
      "533 Training Loss: 2.2079312801361084 Validation Loss: 1.7530665397644043\n",
      "534 Training Loss: 2.2079226970672607 Validation Loss: 1.7530639171600342\n",
      "535 Training Loss: 2.207916259765625 Validation Loss: 1.753061294555664\n",
      "536 Training Loss: 2.2079131603240967 Validation Loss: 1.7530587911605835\n",
      "537 Training Loss: 2.207908868789673 Validation Loss: 1.7530559301376343\n",
      "538 Training Loss: 2.2079031467437744 Validation Loss: 1.753053069114685\n",
      "539 Training Loss: 2.207892656326294 Validation Loss: 1.7530500888824463\n",
      "540 Training Loss: 2.2078795433044434 Validation Loss: 1.7530473470687866\n",
      "541 Training Loss: 2.2078909873962402 Validation Loss: 1.7530442476272583\n",
      "542 Training Loss: 2.2078776359558105 Validation Loss: 1.753041386604309\n",
      "543 Training Loss: 2.2078616619110107 Validation Loss: 1.7530381679534912\n",
      "544 Training Loss: 2.207855701446533 Validation Loss: 1.753035068511963\n",
      "545 Training Loss: 2.207862377166748 Validation Loss: 1.7530317306518555\n",
      "546 Training Loss: 2.207852602005005 Validation Loss: 1.7530286312103271\n",
      "547 Training Loss: 2.207836627960205 Validation Loss: 1.7530252933502197\n",
      "548 Training Loss: 2.207836866378784 Validation Loss: 1.7530219554901123\n",
      "549 Training Loss: 2.2078258991241455 Validation Loss: 1.7530187368392944\n",
      "550 Training Loss: 2.207826852798462 Validation Loss: 1.753015398979187\n",
      "551 Training Loss: 2.2078158855438232 Validation Loss: 1.75301194190979\n",
      "552 Training Loss: 2.2078096866607666 Validation Loss: 1.7530086040496826\n",
      "553 Training Loss: 2.207805871963501 Validation Loss: 1.753005027770996\n",
      "554 Training Loss: 2.207793712615967 Validation Loss: 1.7530014514923096\n",
      "555 Training Loss: 2.2077841758728027 Validation Loss: 1.7529979944229126\n",
      "556 Training Loss: 2.207785129547119 Validation Loss: 1.752994418144226\n",
      "557 Training Loss: 2.2077739238739014 Validation Loss: 1.75299072265625\n",
      "558 Training Loss: 2.207770824432373 Validation Loss: 1.752987027168274\n",
      "559 Training Loss: 2.2077488899230957 Validation Loss: 1.752983570098877\n",
      "560 Training Loss: 2.207747220993042 Validation Loss: 1.7529797554016113\n",
      "561 Training Loss: 2.2077388763427734 Validation Loss: 1.7529761791229248\n",
      "562 Training Loss: 2.2077314853668213 Validation Loss: 1.7529723644256592\n",
      "563 Training Loss: 2.207730293273926 Validation Loss: 1.7529687881469727\n",
      "564 Training Loss: 2.207721710205078 Validation Loss: 1.752964973449707\n",
      "565 Training Loss: 2.2077057361602783 Validation Loss: 1.7529611587524414\n",
      "566 Training Loss: 2.2077128887176514 Validation Loss: 1.7529572248458862\n",
      "567 Training Loss: 2.2076961994171143 Validation Loss: 1.7529534101486206\n",
      "568 Training Loss: 2.207695484161377 Validation Loss: 1.7529492378234863\n",
      "569 Training Loss: 2.2076783180236816 Validation Loss: 1.7529455423355103\n",
      "570 Training Loss: 2.2076714038848877 Validation Loss: 1.7529414892196655\n",
      "571 Training Loss: 2.207674741744995 Validation Loss: 1.7529376745224\n",
      "572 Training Loss: 2.2076587677001953 Validation Loss: 1.752933382987976\n",
      "573 Training Loss: 2.2076544761657715 Validation Loss: 1.7529292106628418\n",
      "574 Training Loss: 2.20766019821167 Validation Loss: 1.7529252767562866\n",
      "575 Training Loss: 2.207634925842285 Validation Loss: 1.7529206275939941\n",
      "576 Training Loss: 2.207636833190918 Validation Loss: 1.752916693687439\n",
      "577 Training Loss: 2.207627773284912 Validation Loss: 1.752912163734436\n",
      "578 Training Loss: 2.2076191902160645 Validation Loss: 1.7529077529907227\n",
      "579 Training Loss: 2.207601308822632 Validation Loss: 1.7529034614562988\n",
      "580 Training Loss: 2.2076027393341064 Validation Loss: 1.7528988122940063\n",
      "581 Training Loss: 2.207585334777832 Validation Loss: 1.7528941631317139\n",
      "582 Training Loss: 2.207577705383301 Validation Loss: 1.752889633178711\n",
      "583 Training Loss: 2.2075788974761963 Validation Loss: 1.752885103225708\n",
      "584 Training Loss: 2.2075698375701904 Validation Loss: 1.7528804540634155\n",
      "585 Training Loss: 2.207562208175659 Validation Loss: 1.752875804901123\n",
      "586 Training Loss: 2.2075512409210205 Validation Loss: 1.7528711557388306\n",
      "587 Training Loss: 2.207547903060913 Validation Loss: 1.752866506576538\n",
      "588 Training Loss: 2.2075347900390625 Validation Loss: 1.752861738204956\n",
      "589 Training Loss: 2.2075295448303223 Validation Loss: 1.7528570890426636\n",
      "590 Training Loss: 2.2075297832489014 Validation Loss: 1.752852201461792\n",
      "591 Training Loss: 2.207524538040161 Validation Loss: 1.75284743309021\n",
      "592 Training Loss: 2.2075088024139404 Validation Loss: 1.7528424263000488\n",
      "593 Training Loss: 2.2074902057647705 Validation Loss: 1.7528376579284668\n",
      "594 Training Loss: 2.2074880599975586 Validation Loss: 1.7528327703475952\n",
      "595 Training Loss: 2.2074859142303467 Validation Loss: 1.7528276443481445\n",
      "596 Training Loss: 2.2074761390686035 Validation Loss: 1.7528226375579834\n",
      "597 Training Loss: 2.2074592113494873 Validation Loss: 1.7528176307678223\n",
      "598 Training Loss: 2.2074553966522217 Validation Loss: 1.7528125047683716\n",
      "599 Training Loss: 2.207456111907959 Validation Loss: 1.7528072595596313\n",
      "600 Training Loss: 2.2074289321899414 Validation Loss: 1.7528022527694702\n",
      "601 Training Loss: 2.2074286937713623 Validation Loss: 1.75279700756073\n",
      "602 Training Loss: 2.2074146270751953 Validation Loss: 1.7527920007705688\n",
      "603 Training Loss: 2.2074134349823 Validation Loss: 1.7527871131896973\n",
      "604 Training Loss: 2.2073919773101807 Validation Loss: 1.752781867980957\n",
      "605 Training Loss: 2.207385540008545 Validation Loss: 1.752776861190796\n",
      "606 Training Loss: 2.207390785217285 Validation Loss: 1.7527718544006348\n",
      "607 Training Loss: 2.20737886428833 Validation Loss: 1.7527666091918945\n",
      "608 Training Loss: 2.2073588371276855 Validation Loss: 1.752761721611023\n",
      "609 Training Loss: 2.2073612213134766 Validation Loss: 1.7527563571929932\n",
      "610 Training Loss: 2.2073638439178467 Validation Loss: 1.752751111984253\n",
      "611 Training Loss: 2.2073333263397217 Validation Loss: 1.7527458667755127\n",
      "612 Training Loss: 2.207317352294922 Validation Loss: 1.752740740776062\n",
      "613 Training Loss: 2.207329034805298 Validation Loss: 1.7527356147766113\n",
      "614 Training Loss: 2.2073206901550293 Validation Loss: 1.7527304887771606\n",
      "615 Training Loss: 2.2073171138763428 Validation Loss: 1.7527254819869995\n",
      "616 Training Loss: 2.207285165786743 Validation Loss: 1.7527198791503906\n",
      "617 Training Loss: 2.207296371459961 Validation Loss: 1.7527146339416504\n",
      "618 Training Loss: 2.2072720527648926 Validation Loss: 1.7527093887329102\n",
      "619 Training Loss: 2.207273006439209 Validation Loss: 1.7527039051055908\n",
      "620 Training Loss: 2.207273006439209 Validation Loss: 1.7526981830596924\n",
      "621 Training Loss: 2.207244634628296 Validation Loss: 1.752692699432373\n",
      "622 Training Loss: 2.2072317600250244 Validation Loss: 1.7526872158050537\n",
      "623 Training Loss: 2.207223653793335 Validation Loss: 1.7526817321777344\n",
      "624 Training Loss: 2.2072219848632812 Validation Loss: 1.752676010131836\n",
      "625 Training Loss: 2.2072091102600098 Validation Loss: 1.7526705265045166\n",
      "626 Training Loss: 2.207202434539795 Validation Loss: 1.7526646852493286\n",
      "627 Training Loss: 2.2071964740753174 Validation Loss: 1.7526589632034302\n",
      "628 Training Loss: 2.2071831226348877 Validation Loss: 1.7526531219482422\n",
      "629 Training Loss: 2.207181215286255 Validation Loss: 1.7526471614837646\n",
      "630 Training Loss: 2.207153558731079 Validation Loss: 1.752641201019287\n",
      "631 Training Loss: 2.207155227661133 Validation Loss: 1.75263512134552\n",
      "632 Training Loss: 2.207144260406494 Validation Loss: 1.7526288032531738\n",
      "633 Training Loss: 2.207120180130005 Validation Loss: 1.7526226043701172\n",
      "634 Training Loss: 2.20711350440979 Validation Loss: 1.7526164054870605\n",
      "635 Training Loss: 2.207092761993408 Validation Loss: 1.7526100873947144\n",
      "636 Training Loss: 2.2070910930633545 Validation Loss: 1.7526040077209473\n",
      "637 Training Loss: 2.207092523574829 Validation Loss: 1.7525978088378906\n",
      "638 Training Loss: 2.2070794105529785 Validation Loss: 1.7525914907455444\n",
      "639 Training Loss: 2.207071542739868 Validation Loss: 1.7525852918624878\n",
      "640 Training Loss: 2.2070600986480713 Validation Loss: 1.7525787353515625\n",
      "641 Training Loss: 2.207059621810913 Validation Loss: 1.7525726556777954\n",
      "642 Training Loss: 2.2070395946502686 Validation Loss: 1.7525660991668701\n",
      "643 Training Loss: 2.2070319652557373 Validation Loss: 1.7525596618652344\n",
      "644 Training Loss: 2.2070140838623047 Validation Loss: 1.7525532245635986\n",
      "645 Training Loss: 2.207003593444824 Validation Loss: 1.7525469064712524\n",
      "646 Training Loss: 2.207019805908203 Validation Loss: 1.7525404691696167\n",
      "647 Training Loss: 2.20698881149292 Validation Loss: 1.7525339126586914\n",
      "648 Training Loss: 2.206975221633911 Validation Loss: 1.752526879310608\n",
      "649 Training Loss: 2.2069664001464844 Validation Loss: 1.7525203227996826\n",
      "650 Training Loss: 2.2069478034973145 Validation Loss: 1.7525134086608887\n",
      "651 Training Loss: 2.2069151401519775 Validation Loss: 1.7525064945220947\n",
      "652 Training Loss: 2.206935405731201 Validation Loss: 1.7524996995925903\n",
      "653 Training Loss: 2.2069389820098877 Validation Loss: 1.752492904663086\n",
      "654 Training Loss: 2.2069098949432373 Validation Loss: 1.7524861097335815\n",
      "655 Training Loss: 2.206904888153076 Validation Loss: 1.752479076385498\n",
      "656 Training Loss: 2.20689058303833 Validation Loss: 1.752471923828125\n",
      "657 Training Loss: 2.2068684101104736 Validation Loss: 1.752464771270752\n",
      "658 Training Loss: 2.206864356994629 Validation Loss: 1.7524573802947998\n",
      "659 Training Loss: 2.206859588623047 Validation Loss: 1.7524502277374268\n",
      "660 Training Loss: 2.206848621368408 Validation Loss: 1.752442717552185\n",
      "661 Training Loss: 2.206826686859131 Validation Loss: 1.7524356842041016\n",
      "662 Training Loss: 2.2068021297454834 Validation Loss: 1.752428412437439\n",
      "663 Training Loss: 2.2068052291870117 Validation Loss: 1.7524213790893555\n",
      "664 Training Loss: 2.206787109375 Validation Loss: 1.752414345741272\n",
      "665 Training Loss: 2.2067766189575195 Validation Loss: 1.7524070739746094\n",
      "666 Training Loss: 2.20676326751709 Validation Loss: 1.7524001598358154\n",
      "667 Training Loss: 2.206740617752075 Validation Loss: 1.7523932456970215\n",
      "668 Training Loss: 2.206740617752075 Validation Loss: 1.7523860931396484\n",
      "669 Training Loss: 2.2067534923553467 Validation Loss: 1.7523788213729858\n",
      "670 Training Loss: 2.206723213195801 Validation Loss: 1.7523717880249023\n",
      "671 Training Loss: 2.2067015171051025 Validation Loss: 1.7523643970489502\n",
      "672 Training Loss: 2.2066898345947266 Validation Loss: 1.7523568868637085\n",
      "673 Training Loss: 2.206681966781616 Validation Loss: 1.7523494958877563\n",
      "674 Training Loss: 2.2066774368286133 Validation Loss: 1.752341866493225\n",
      "675 Training Loss: 2.206625461578369 Validation Loss: 1.7523343563079834\n",
      "676 Training Loss: 2.2066454887390137 Validation Loss: 1.7523267269134521\n",
      "677 Training Loss: 2.206615686416626 Validation Loss: 1.752319097518921\n",
      "678 Training Loss: 2.206632137298584 Validation Loss: 1.7523114681243896\n",
      "679 Training Loss: 2.2066144943237305 Validation Loss: 1.7523033618927002\n",
      "680 Training Loss: 2.2065911293029785 Validation Loss: 1.7522954940795898\n",
      "681 Training Loss: 2.2065818309783936 Validation Loss: 1.7522871494293213\n",
      "682 Training Loss: 2.2065677642822266 Validation Loss: 1.7522790431976318\n",
      "683 Training Loss: 2.2065563201904297 Validation Loss: 1.7522706985473633\n",
      "684 Training Loss: 2.2065351009368896 Validation Loss: 1.7522623538970947\n",
      "685 Training Loss: 2.206509590148926 Validation Loss: 1.7522544860839844\n",
      "686 Training Loss: 2.206482410430908 Validation Loss: 1.7522468566894531\n",
      "687 Training Loss: 2.206496238708496 Validation Loss: 1.7522388696670532\n",
      "688 Training Loss: 2.2064943313598633 Validation Loss: 1.7522307634353638\n",
      "689 Training Loss: 2.2064743041992188 Validation Loss: 1.7522225379943848\n",
      "690 Training Loss: 2.2064850330352783 Validation Loss: 1.7522138357162476\n",
      "691 Training Loss: 2.2064599990844727 Validation Loss: 1.7522056102752686\n",
      "692 Training Loss: 2.2064380645751953 Validation Loss: 1.7521964311599731\n",
      "693 Training Loss: 2.206408739089966 Validation Loss: 1.7521878480911255\n",
      "694 Training Loss: 2.206408977508545 Validation Loss: 1.7521789073944092\n",
      "695 Training Loss: 2.2063848972320557 Validation Loss: 1.7521698474884033\n",
      "696 Training Loss: 2.2063839435577393 Validation Loss: 1.7521601915359497\n",
      "697 Training Loss: 2.2063486576080322 Validation Loss: 1.7521510124206543\n",
      "698 Training Loss: 2.206367015838623 Validation Loss: 1.7521411180496216\n",
      "699 Training Loss: 2.206313371658325 Validation Loss: 1.7521313428878784\n",
      "700 Training Loss: 2.206301212310791 Validation Loss: 1.752121925354004\n",
      "701 Training Loss: 2.2062883377075195 Validation Loss: 1.752112627029419\n",
      "702 Training Loss: 2.206280469894409 Validation Loss: 1.7521032094955444\n",
      "703 Training Loss: 2.2062785625457764 Validation Loss: 1.7520934343338013\n",
      "704 Training Loss: 2.2062385082244873 Validation Loss: 1.7520840167999268\n",
      "705 Training Loss: 2.2062368392944336 Validation Loss: 1.7520742416381836\n",
      "706 Training Loss: 2.206216812133789 Validation Loss: 1.7520643472671509\n",
      "707 Training Loss: 2.2062079906463623 Validation Loss: 1.7520540952682495\n",
      "708 Training Loss: 2.2061891555786133 Validation Loss: 1.7520438432693481\n",
      "709 Training Loss: 2.2061800956726074 Validation Loss: 1.7520334720611572\n",
      "710 Training Loss: 2.2061524391174316 Validation Loss: 1.7520233392715454\n",
      "711 Training Loss: 2.20613956451416 Validation Loss: 1.7520129680633545\n",
      "712 Training Loss: 2.206111431121826 Validation Loss: 1.7520028352737427\n",
      "713 Training Loss: 2.2061071395874023 Validation Loss: 1.7519925832748413\n",
      "714 Training Loss: 2.2060751914978027 Validation Loss: 1.7519820928573608\n",
      "715 Training Loss: 2.2060816287994385 Validation Loss: 1.7519716024398804\n",
      "716 Training Loss: 2.2060511112213135 Validation Loss: 1.7519608736038208\n",
      "717 Training Loss: 2.2060341835021973 Validation Loss: 1.7519503831863403\n",
      "718 Training Loss: 2.206021308898926 Validation Loss: 1.7519402503967285\n",
      "719 Training Loss: 2.2060296535491943 Validation Loss: 1.7519299983978271\n",
      "720 Training Loss: 2.205998659133911 Validation Loss: 1.7519199848175049\n",
      "721 Training Loss: 2.2059762477874756 Validation Loss: 1.751909852027893\n",
      "722 Training Loss: 2.2059340476989746 Validation Loss: 1.7518998384475708\n",
      "723 Training Loss: 2.2059288024902344 Validation Loss: 1.751889944076538\n",
      "724 Training Loss: 2.2059226036071777 Validation Loss: 1.7518794536590576\n",
      "725 Training Loss: 2.2058775424957275 Validation Loss: 1.751870036125183\n",
      "726 Training Loss: 2.205906867980957 Validation Loss: 1.7518600225448608\n",
      "727 Training Loss: 2.2058842182159424 Validation Loss: 1.7518495321273804\n",
      "728 Training Loss: 2.205854892730713 Validation Loss: 1.751839280128479\n",
      "729 Training Loss: 2.2058122158050537 Validation Loss: 1.7518287897109985\n",
      "730 Training Loss: 2.2058095932006836 Validation Loss: 1.751818299293518\n",
      "731 Training Loss: 2.205796003341675 Validation Loss: 1.7518078088760376\n",
      "732 Training Loss: 2.2057909965515137 Validation Loss: 1.751796841621399\n",
      "733 Training Loss: 2.2057621479034424 Validation Loss: 1.7517856359481812\n",
      "734 Training Loss: 2.2057254314422607 Validation Loss: 1.751774549484253\n",
      "735 Training Loss: 2.205698013305664 Validation Loss: 1.7517635822296143\n",
      "736 Training Loss: 2.2056772708892822 Validation Loss: 1.7517530918121338\n",
      "737 Training Loss: 2.2056925296783447 Validation Loss: 1.7517420053482056\n",
      "738 Training Loss: 2.205634117126465 Validation Loss: 1.7517311573028564\n",
      "739 Training Loss: 2.20565128326416 Validation Loss: 1.7517199516296387\n",
      "740 Training Loss: 2.205610990524292 Validation Loss: 1.751708984375\n",
      "741 Training Loss: 2.2055914402008057 Validation Loss: 1.7516975402832031\n",
      "742 Training Loss: 2.2055931091308594 Validation Loss: 1.7516863346099854\n",
      "743 Training Loss: 2.2055492401123047 Validation Loss: 1.7516745328903198\n",
      "744 Training Loss: 2.2055294513702393 Validation Loss: 1.7516627311706543\n",
      "745 Training Loss: 2.2055368423461914 Validation Loss: 1.751650333404541\n",
      "746 Training Loss: 2.2055277824401855 Validation Loss: 1.751637578010559\n",
      "747 Training Loss: 2.2054834365844727 Validation Loss: 1.751624345779419\n",
      "748 Training Loss: 2.2054877281188965 Validation Loss: 1.751611351966858\n",
      "749 Training Loss: 2.2054221630096436 Validation Loss: 1.7515983581542969\n",
      "750 Training Loss: 2.2054178714752197 Validation Loss: 1.7515854835510254\n",
      "751 Training Loss: 2.2053537368774414 Validation Loss: 1.751572847366333\n",
      "752 Training Loss: 2.2054007053375244 Validation Loss: 1.751560091972351\n",
      "753 Training Loss: 2.205348014831543 Validation Loss: 1.7515472173690796\n",
      "754 Training Loss: 2.2053158283233643 Validation Loss: 1.7515348196029663\n",
      "755 Training Loss: 2.205324649810791 Validation Loss: 1.7515218257904053\n",
      "756 Training Loss: 2.205275297164917 Validation Loss: 1.7515082359313965\n",
      "757 Training Loss: 2.205240249633789 Validation Loss: 1.7514946460723877\n",
      "758 Training Loss: 2.2052619457244873 Validation Loss: 1.7514809370040894\n",
      "759 Training Loss: 2.2052230834960938 Validation Loss: 1.751466989517212\n",
      "760 Training Loss: 2.2052011489868164 Validation Loss: 1.7514528036117554\n",
      "761 Training Loss: 2.2051868438720703 Validation Loss: 1.7514387369155884\n",
      "762 Training Loss: 2.205134868621826 Validation Loss: 1.7514245510101318\n",
      "763 Training Loss: 2.2050888538360596 Validation Loss: 1.751410722732544\n",
      "764 Training Loss: 2.205101251602173 Validation Loss: 1.7513972520828247\n",
      "765 Training Loss: 2.205098867416382 Validation Loss: 1.7513833045959473\n",
      "766 Training Loss: 2.205059766769409 Validation Loss: 1.7513688802719116\n",
      "767 Training Loss: 2.2050087451934814 Validation Loss: 1.7513548135757446\n",
      "768 Training Loss: 2.2049970626831055 Validation Loss: 1.7513405084609985\n",
      "769 Training Loss: 2.204930067062378 Validation Loss: 1.751326560974121\n",
      "770 Training Loss: 2.2049734592437744 Validation Loss: 1.751312494277954\n",
      "771 Training Loss: 2.2049529552459717 Validation Loss: 1.7512977123260498\n",
      "772 Training Loss: 2.204904079437256 Validation Loss: 1.751283049583435\n",
      "773 Training Loss: 2.2048230171203613 Validation Loss: 1.751268982887268\n",
      "774 Training Loss: 2.2048604488372803 Validation Loss: 1.7512544393539429\n",
      "775 Training Loss: 2.204834222793579 Validation Loss: 1.7512390613555908\n",
      "776 Training Loss: 2.2048020362854004 Validation Loss: 1.7512235641479492\n",
      "777 Training Loss: 2.2048373222351074 Validation Loss: 1.7512075901031494\n",
      "778 Training Loss: 2.2047717571258545 Validation Loss: 1.7511913776397705\n",
      "779 Training Loss: 2.2047383785247803 Validation Loss: 1.7511746883392334\n",
      "780 Training Loss: 2.2047476768493652 Validation Loss: 1.7511578798294067\n",
      "781 Training Loss: 2.204636812210083 Validation Loss: 1.751141905784607\n",
      "782 Training Loss: 2.2046895027160645 Validation Loss: 1.7511253356933594\n",
      "783 Training Loss: 2.2046122550964355 Validation Loss: 1.7511093616485596\n",
      "784 Training Loss: 2.2046051025390625 Validation Loss: 1.7510931491851807\n",
      "785 Training Loss: 2.2045459747314453 Validation Loss: 1.7510766983032227\n",
      "786 Training Loss: 2.2045187950134277 Validation Loss: 1.7510606050491333\n",
      "787 Training Loss: 2.2044970989227295 Validation Loss: 1.751044511795044\n",
      "788 Training Loss: 2.2044427394866943 Validation Loss: 1.751028299331665\n",
      "789 Training Loss: 2.204429864883423 Validation Loss: 1.751011848449707\n",
      "790 Training Loss: 2.204430341720581 Validation Loss: 1.750995397567749\n",
      "791 Training Loss: 2.204373598098755 Validation Loss: 1.7509785890579224\n",
      "792 Training Loss: 2.2044050693511963 Validation Loss: 1.7509615421295166\n",
      "793 Training Loss: 2.2043354511260986 Validation Loss: 1.7509441375732422\n",
      "794 Training Loss: 2.2042694091796875 Validation Loss: 1.7509270906448364\n",
      "795 Training Loss: 2.204273223876953 Validation Loss: 1.750909686088562\n",
      "796 Training Loss: 2.204233407974243 Validation Loss: 1.7508915662765503\n",
      "797 Training Loss: 2.2042336463928223 Validation Loss: 1.7508728504180908\n",
      "798 Training Loss: 2.204129695892334 Validation Loss: 1.7508544921875\n",
      "799 Training Loss: 2.2041449546813965 Validation Loss: 1.7508360147476196\n",
      "800 Training Loss: 2.204096794128418 Validation Loss: 1.750818133354187\n",
      "801 Training Loss: 2.2040984630584717 Validation Loss: 1.750799298286438\n",
      "802 Training Loss: 2.2040600776672363 Validation Loss: 1.7507799863815308\n",
      "803 Training Loss: 2.204024076461792 Validation Loss: 1.7507600784301758\n",
      "804 Training Loss: 2.203998327255249 Validation Loss: 1.7507401704788208\n",
      "805 Training Loss: 2.2039103507995605 Validation Loss: 1.750720739364624\n",
      "806 Training Loss: 2.2039248943328857 Validation Loss: 1.7507009506225586\n",
      "807 Training Loss: 2.203890323638916 Validation Loss: 1.7506802082061768\n",
      "808 Training Loss: 2.203900098800659 Validation Loss: 1.7506589889526367\n",
      "809 Training Loss: 2.2038159370422363 Validation Loss: 1.7506372928619385\n",
      "810 Training Loss: 2.2037460803985596 Validation Loss: 1.7506167888641357\n",
      "811 Training Loss: 2.203788995742798 Validation Loss: 1.7505954504013062\n",
      "812 Training Loss: 2.203711748123169 Validation Loss: 1.7505736351013184\n",
      "813 Training Loss: 2.2037353515625 Validation Loss: 1.7505507469177246\n",
      "814 Training Loss: 2.2036454677581787 Validation Loss: 1.7505279779434204\n",
      "815 Training Loss: 2.2036335468292236 Validation Loss: 1.7505042552947998\n",
      "816 Training Loss: 2.2035603523254395 Validation Loss: 1.7504805326461792\n",
      "817 Training Loss: 2.2035396099090576 Validation Loss: 1.750457525253296\n",
      "818 Training Loss: 2.2034873962402344 Validation Loss: 1.7504347562789917\n",
      "819 Training Loss: 2.2034366130828857 Validation Loss: 1.7504122257232666\n",
      "820 Training Loss: 2.2034637928009033 Validation Loss: 1.7503896951675415\n",
      "821 Training Loss: 2.203399658203125 Validation Loss: 1.750366449356079\n",
      "822 Training Loss: 2.20334792137146 Validation Loss: 1.750342607498169\n",
      "823 Training Loss: 2.2033443450927734 Validation Loss: 1.750318169593811\n",
      "824 Training Loss: 2.2033166885375977 Validation Loss: 1.7502930164337158\n",
      "825 Training Loss: 2.2032101154327393 Validation Loss: 1.7502682209014893\n",
      "826 Training Loss: 2.203174591064453 Validation Loss: 1.7502434253692627\n",
      "827 Training Loss: 2.2031264305114746 Validation Loss: 1.750219702720642\n",
      "828 Training Loss: 2.203157663345337 Validation Loss: 1.750195026397705\n",
      "829 Training Loss: 2.2030625343322754 Validation Loss: 1.7501708269119263\n",
      "830 Training Loss: 2.203035354614258 Validation Loss: 1.750146746635437\n",
      "831 Training Loss: 2.2030019760131836 Validation Loss: 1.7501225471496582\n",
      "832 Training Loss: 2.202950954437256 Validation Loss: 1.7500989437103271\n",
      "833 Training Loss: 2.2028648853302 Validation Loss: 1.750075340270996\n",
      "834 Training Loss: 2.202871799468994 Validation Loss: 1.7500511407852173\n",
      "835 Training Loss: 2.2028775215148926 Validation Loss: 1.7500267028808594\n",
      "836 Training Loss: 2.202752113342285 Validation Loss: 1.7500019073486328\n",
      "837 Training Loss: 2.202749252319336 Validation Loss: 1.7499771118164062\n",
      "838 Training Loss: 2.2026774883270264 Validation Loss: 1.7499525547027588\n",
      "839 Training Loss: 2.2026257514953613 Validation Loss: 1.7499277591705322\n",
      "840 Training Loss: 2.202672004699707 Validation Loss: 1.749900221824646\n",
      "841 Training Loss: 2.2025012969970703 Validation Loss: 1.7498739957809448\n",
      "842 Training Loss: 2.202488422393799 Validation Loss: 1.7498481273651123\n",
      "843 Training Loss: 2.2024600505828857 Validation Loss: 1.7498220205307007\n",
      "844 Training Loss: 2.2024059295654297 Validation Loss: 1.7497950792312622\n",
      "845 Training Loss: 2.2024073600769043 Validation Loss: 1.7497673034667969\n",
      "846 Training Loss: 2.202253818511963 Validation Loss: 1.7497397661209106\n",
      "847 Training Loss: 2.202268123626709 Validation Loss: 1.7497105598449707\n",
      "848 Training Loss: 2.202202558517456 Validation Loss: 1.7496806383132935\n",
      "849 Training Loss: 2.2021913528442383 Validation Loss: 1.7496496438980103\n",
      "850 Training Loss: 2.2021055221557617 Validation Loss: 1.7496193647384644\n",
      "851 Training Loss: 2.202061891555786 Validation Loss: 1.7495887279510498\n",
      "852 Training Loss: 2.201988697052002 Validation Loss: 1.749558448791504\n",
      "853 Training Loss: 2.2020018100738525 Validation Loss: 1.7495272159576416\n",
      "854 Training Loss: 2.2019591331481934 Validation Loss: 1.7494949102401733\n",
      "855 Training Loss: 2.2018630504608154 Validation Loss: 1.7494633197784424\n",
      "856 Training Loss: 2.2018043994903564 Validation Loss: 1.7494308948516846\n",
      "857 Training Loss: 2.2017858028411865 Validation Loss: 1.7493985891342163\n",
      "858 Training Loss: 2.201716184616089 Validation Loss: 1.749367117881775\n",
      "859 Training Loss: 2.201704740524292 Validation Loss: 1.7493351697921753\n",
      "860 Training Loss: 2.201648235321045 Validation Loss: 1.7493001222610474\n",
      "861 Training Loss: 2.201503038406372 Validation Loss: 1.749266266822815\n",
      "862 Training Loss: 2.201511859893799 Validation Loss: 1.7492319345474243\n",
      "863 Training Loss: 2.2014389038085938 Validation Loss: 1.7491964101791382\n",
      "864 Training Loss: 2.201359987258911 Validation Loss: 1.7491612434387207\n",
      "865 Training Loss: 2.2013041973114014 Validation Loss: 1.74912691116333\n",
      "866 Training Loss: 2.201327085494995 Validation Loss: 1.7490923404693604\n",
      "867 Training Loss: 2.2012341022491455 Validation Loss: 1.7490555047988892\n",
      "868 Training Loss: 2.201141834259033 Validation Loss: 1.7490191459655762\n",
      "869 Training Loss: 2.201083183288574 Validation Loss: 1.7489829063415527\n",
      "870 Training Loss: 2.201046943664551 Validation Loss: 1.7489466667175293\n",
      "871 Training Loss: 2.2009804248809814 Validation Loss: 1.7489093542099\n",
      "872 Training Loss: 2.200876235961914 Validation Loss: 1.748871922492981\n",
      "873 Training Loss: 2.200873613357544 Validation Loss: 1.7488343715667725\n",
      "874 Training Loss: 2.200805187225342 Validation Loss: 1.748798131942749\n",
      "875 Training Loss: 2.200639009475708 Validation Loss: 1.7487623691558838\n",
      "876 Training Loss: 2.20066237449646 Validation Loss: 1.748726487159729\n",
      "877 Training Loss: 2.200613498687744 Validation Loss: 1.748687505722046\n",
      "878 Training Loss: 2.2004992961883545 Validation Loss: 1.7486481666564941\n",
      "879 Training Loss: 2.2004613876342773 Validation Loss: 1.7486077547073364\n",
      "880 Training Loss: 2.200547933578491 Validation Loss: 1.7485655546188354\n",
      "881 Training Loss: 2.2003490924835205 Validation Loss: 1.7485231161117554\n",
      "882 Training Loss: 2.2003214359283447 Validation Loss: 1.7484797239303589\n",
      "883 Training Loss: 2.200265884399414 Validation Loss: 1.7484335899353027\n",
      "884 Training Loss: 2.2001585960388184 Validation Loss: 1.748386025428772\n",
      "885 Training Loss: 2.2001383304595947 Validation Loss: 1.7483367919921875\n",
      "886 Training Loss: 2.200000286102295 Validation Loss: 1.7482868432998657\n",
      "887 Training Loss: 2.1998817920684814 Validation Loss: 1.7482362985610962\n",
      "888 Training Loss: 2.1998438835144043 Validation Loss: 1.7481874227523804\n",
      "889 Training Loss: 2.1998648643493652 Validation Loss: 1.7481356859207153\n",
      "890 Training Loss: 2.1996631622314453 Validation Loss: 1.7480865716934204\n",
      "891 Training Loss: 2.199681520462036 Validation Loss: 1.7480350732803345\n",
      "892 Training Loss: 2.199535846710205 Validation Loss: 1.747984528541565\n",
      "893 Training Loss: 2.1995627880096436 Validation Loss: 1.7479346990585327\n",
      "894 Training Loss: 2.199479818344116 Validation Loss: 1.7478822469711304\n",
      "895 Training Loss: 2.1993775367736816 Validation Loss: 1.7478299140930176\n",
      "896 Training Loss: 2.199267625808716 Validation Loss: 1.7477766275405884\n",
      "897 Training Loss: 2.199197292327881 Validation Loss: 1.7477235794067383\n",
      "898 Training Loss: 2.199050188064575 Validation Loss: 1.747673511505127\n",
      "899 Training Loss: 2.199021577835083 Validation Loss: 1.7476248741149902\n",
      "900 Training Loss: 2.198965549468994 Validation Loss: 1.7475756406784058\n",
      "901 Training Loss: 2.198824644088745 Validation Loss: 1.7475286722183228\n",
      "902 Training Loss: 2.1987578868865967 Validation Loss: 1.7474815845489502\n",
      "903 Training Loss: 2.198746919631958 Validation Loss: 1.7474325895309448\n",
      "904 Training Loss: 2.198606491088867 Validation Loss: 1.7473838329315186\n",
      "905 Training Loss: 2.1985409259796143 Validation Loss: 1.7473350763320923\n",
      "906 Training Loss: 2.198516607284546 Validation Loss: 1.747285008430481\n",
      "907 Training Loss: 2.198387622833252 Validation Loss: 1.74723482131958\n",
      "908 Training Loss: 2.19828462600708 Validation Loss: 1.7471845149993896\n",
      "909 Training Loss: 2.1980392932891846 Validation Loss: 1.747138500213623\n",
      "910 Training Loss: 2.198030471801758 Validation Loss: 1.7470927238464355\n",
      "911 Training Loss: 2.1978588104248047 Validation Loss: 1.747050166130066\n",
      "912 Training Loss: 2.1979191303253174 Validation Loss: 1.7470067739486694\n",
      "913 Training Loss: 2.1977715492248535 Validation Loss: 1.746962308883667\n",
      "914 Training Loss: 2.1976101398468018 Validation Loss: 1.7469165325164795\n",
      "915 Training Loss: 2.1975409984588623 Validation Loss: 1.7468700408935547\n",
      "916 Training Loss: 2.19744873046875 Validation Loss: 1.7468245029449463\n",
      "917 Training Loss: 2.197514295578003 Validation Loss: 1.7467734813690186\n",
      "918 Training Loss: 2.1973977088928223 Validation Loss: 1.7467185258865356\n",
      "919 Training Loss: 2.1972432136535645 Validation Loss: 1.7466598749160767\n",
      "920 Training Loss: 2.1971514225006104 Validation Loss: 1.7466001510620117\n",
      "921 Training Loss: 2.196951389312744 Validation Loss: 1.74654221534729\n",
      "922 Training Loss: 2.196854591369629 Validation Loss: 1.7464830875396729\n",
      "923 Training Loss: 2.1969289779663086 Validation Loss: 1.7464185953140259\n",
      "924 Training Loss: 2.196565628051758 Validation Loss: 1.7463520765304565\n",
      "925 Training Loss: 2.1966185569763184 Validation Loss: 1.7462849617004395\n",
      "926 Training Loss: 2.196507453918457 Validation Loss: 1.7462148666381836\n",
      "927 Training Loss: 2.1963212490081787 Validation Loss: 1.746144413948059\n",
      "928 Training Loss: 2.196216344833374 Validation Loss: 1.7460713386535645\n",
      "929 Training Loss: 2.1962499618530273 Validation Loss: 1.745993971824646\n",
      "930 Training Loss: 2.1960079669952393 Validation Loss: 1.7459139823913574\n",
      "931 Training Loss: 2.1959071159362793 Validation Loss: 1.7458317279815674\n",
      "932 Training Loss: 2.1958515644073486 Validation Loss: 1.745751142501831\n",
      "933 Training Loss: 2.1955928802490234 Validation Loss: 1.7456681728363037\n",
      "934 Training Loss: 2.1955997943878174 Validation Loss: 1.7455850839614868\n",
      "935 Training Loss: 2.1953656673431396 Validation Loss: 1.7455030679702759\n",
      "936 Training Loss: 2.195319175720215 Validation Loss: 1.7454191446304321\n",
      "937 Training Loss: 2.1951563358306885 Validation Loss: 1.7453380823135376\n",
      "938 Training Loss: 2.194960117340088 Validation Loss: 1.7452616691589355\n",
      "939 Training Loss: 2.194964647293091 Validation Loss: 1.7451856136322021\n",
      "940 Training Loss: 2.194908380508423 Validation Loss: 1.745105504989624\n",
      "941 Training Loss: 2.194730043411255 Validation Loss: 1.7450217008590698\n",
      "942 Training Loss: 2.1944515705108643 Validation Loss: 1.7449395656585693\n",
      "943 Training Loss: 2.1945037841796875 Validation Loss: 1.744853138923645\n",
      "944 Training Loss: 2.194314479827881 Validation Loss: 1.7447642087936401\n",
      "945 Training Loss: 2.194080352783203 Validation Loss: 1.7446792125701904\n",
      "946 Training Loss: 2.1938724517822266 Validation Loss: 1.7445944547653198\n",
      "947 Training Loss: 2.193796396255493 Validation Loss: 1.744510531425476\n",
      "948 Training Loss: 2.1936309337615967 Validation Loss: 1.7444218397140503\n",
      "949 Training Loss: 2.193540334701538 Validation Loss: 1.7443329095840454\n",
      "950 Training Loss: 2.193410873413086 Validation Loss: 1.7442426681518555\n",
      "951 Training Loss: 2.1931443214416504 Validation Loss: 1.7441521883010864\n",
      "952 Training Loss: 2.1929121017456055 Validation Loss: 1.7440612316131592\n",
      "953 Training Loss: 2.1928417682647705 Validation Loss: 1.7439699172973633\n",
      "954 Training Loss: 2.1926937103271484 Validation Loss: 1.7438803911209106\n",
      "955 Training Loss: 2.192565441131592 Validation Loss: 1.7437896728515625\n",
      "956 Training Loss: 2.192194700241089 Validation Loss: 1.7437007427215576\n",
      "957 Training Loss: 2.192389488220215 Validation Loss: 1.743607521057129\n",
      "958 Training Loss: 2.191798448562622 Validation Loss: 1.7435178756713867\n",
      "959 Training Loss: 2.191866159439087 Validation Loss: 1.7434289455413818\n",
      "960 Training Loss: 2.1917130947113037 Validation Loss: 1.7433393001556396\n",
      "961 Training Loss: 2.1917319297790527 Validation Loss: 1.7432427406311035\n",
      "962 Training Loss: 2.1913001537323 Validation Loss: 1.743147611618042\n",
      "963 Training Loss: 2.191192865371704 Validation Loss: 1.7430490255355835\n",
      "964 Training Loss: 2.1908891201019287 Validation Loss: 1.7429530620574951\n",
      "965 Training Loss: 2.190887212753296 Validation Loss: 1.742853045463562\n",
      "966 Training Loss: 2.1906800270080566 Validation Loss: 1.7427470684051514\n",
      "967 Training Loss: 2.1904356479644775 Validation Loss: 1.7426360845565796\n",
      "968 Training Loss: 2.1902081966400146 Validation Loss: 1.7425272464752197\n",
      "969 Training Loss: 2.1902267932891846 Validation Loss: 1.74241042137146\n",
      "970 Training Loss: 2.1899633407592773 Validation Loss: 1.7422935962677002\n",
      "971 Training Loss: 2.1895151138305664 Validation Loss: 1.742175579071045\n",
      "972 Training Loss: 2.1894876956939697 Validation Loss: 1.7420529127120972\n",
      "973 Training Loss: 2.1891050338745117 Validation Loss: 1.7419265508651733\n",
      "974 Training Loss: 2.189234495162964 Validation Loss: 1.7417984008789062\n",
      "975 Training Loss: 2.188748359680176 Validation Loss: 1.7416741847991943\n",
      "976 Training Loss: 2.188920021057129 Validation Loss: 1.7415409088134766\n",
      "977 Training Loss: 2.188570976257324 Validation Loss: 1.741402268409729\n",
      "978 Training Loss: 2.1881985664367676 Validation Loss: 1.7412654161453247\n",
      "979 Training Loss: 2.188009023666382 Validation Loss: 1.741127371788025\n",
      "980 Training Loss: 2.187558650970459 Validation Loss: 1.7409923076629639\n",
      "981 Training Loss: 2.187394142150879 Validation Loss: 1.74085533618927\n",
      "982 Training Loss: 2.18723726272583 Validation Loss: 1.7407190799713135\n",
      "983 Training Loss: 2.1870181560516357 Validation Loss: 1.7405736446380615\n",
      "984 Training Loss: 2.18681263923645 Validation Loss: 1.740425944328308\n",
      "985 Training Loss: 2.1865687370300293 Validation Loss: 1.7402710914611816\n",
      "986 Training Loss: 2.1861860752105713 Validation Loss: 1.7401177883148193\n",
      "987 Training Loss: 2.1863129138946533 Validation Loss: 1.7399569749832153\n",
      "988 Training Loss: 2.1858489513397217 Validation Loss: 1.7397944927215576\n",
      "989 Training Loss: 2.185570001602173 Validation Loss: 1.739632487297058\n",
      "990 Training Loss: 2.1851978302001953 Validation Loss: 1.7394815683364868\n",
      "991 Training Loss: 2.1851093769073486 Validation Loss: 1.7393159866333008\n",
      "992 Training Loss: 2.184819221496582 Validation Loss: 1.7391397953033447\n",
      "993 Training Loss: 2.1846044063568115 Validation Loss: 1.738957405090332\n",
      "994 Training Loss: 2.1842381954193115 Validation Loss: 1.738775610923767\n",
      "995 Training Loss: 2.1840195655822754 Validation Loss: 1.7385900020599365\n",
      "996 Training Loss: 2.183816432952881 Validation Loss: 1.7384072542190552\n",
      "997 Training Loss: 2.183292865753174 Validation Loss: 1.7382221221923828\n",
      "998 Training Loss: 2.183091163635254 Validation Loss: 1.7380316257476807\n",
      "999 Training Loss: 2.1829440593719482 Validation Loss: 1.7378414869308472\n",
      "1000 Training Loss: 2.182710647583008 Validation Loss: 1.7376424074172974\n",
      "1001 Training Loss: 2.182468891143799 Validation Loss: 1.7374458312988281\n",
      "1002 Training Loss: 2.181978464126587 Validation Loss: 1.7372506856918335\n",
      "1003 Training Loss: 2.181650161743164 Validation Loss: 1.7370508909225464\n",
      "1004 Training Loss: 2.1811695098876953 Validation Loss: 1.7368522882461548\n",
      "1005 Training Loss: 2.181231737136841 Validation Loss: 1.736649990081787\n",
      "1006 Training Loss: 2.181016683578491 Validation Loss: 1.7364459037780762\n",
      "1007 Training Loss: 2.1804921627044678 Validation Loss: 1.736236810684204\n",
      "1008 Training Loss: 2.1800503730773926 Validation Loss: 1.736027717590332\n",
      "1009 Training Loss: 2.179556131362915 Validation Loss: 1.735823154449463\n",
      "1010 Training Loss: 2.179434061050415 Validation Loss: 1.7356257438659668\n",
      "1011 Training Loss: 2.17903995513916 Validation Loss: 1.7354319095611572\n",
      "1012 Training Loss: 2.1784512996673584 Validation Loss: 1.735241174697876\n",
      "1013 Training Loss: 2.1779627799987793 Validation Loss: 1.7350585460662842\n",
      "1014 Training Loss: 2.1779944896698 Validation Loss: 1.7348755598068237\n",
      "1015 Training Loss: 2.1775214672088623 Validation Loss: 1.7346863746643066\n",
      "1016 Training Loss: 2.177358865737915 Validation Loss: 1.7344903945922852\n",
      "1017 Training Loss: 2.176973581314087 Validation Loss: 1.7342844009399414\n",
      "1018 Training Loss: 2.1768155097961426 Validation Loss: 1.734079122543335\n",
      "1019 Training Loss: 2.17638897895813 Validation Loss: 1.7338614463806152\n",
      "1020 Training Loss: 2.175525426864624 Validation Loss: 1.7336565256118774\n",
      "1021 Training Loss: 2.1754441261291504 Validation Loss: 1.73343825340271\n",
      "1022 Training Loss: 2.1749866008758545 Validation Loss: 1.7332104444503784\n",
      "1023 Training Loss: 2.174400568008423 Validation Loss: 1.7329940795898438\n",
      "1024 Training Loss: 2.1742093563079834 Validation Loss: 1.7327828407287598\n",
      "1025 Training Loss: 2.173635721206665 Validation Loss: 1.7325572967529297\n",
      "1026 Training Loss: 2.1729798316955566 Validation Loss: 1.7323380708694458\n",
      "1027 Training Loss: 2.173001766204834 Validation Loss: 1.7320945262908936\n",
      "1028 Training Loss: 2.1726412773132324 Validation Loss: 1.7318487167358398\n",
      "1029 Training Loss: 2.172004222869873 Validation Loss: 1.7315970659255981\n",
      "1030 Training Loss: 2.171764612197876 Validation Loss: 1.7313214540481567\n",
      "1031 Training Loss: 2.171851396560669 Validation Loss: 1.731034517288208\n",
      "1032 Training Loss: 2.1708648204803467 Validation Loss: 1.7307326793670654\n",
      "1033 Training Loss: 2.1701126098632812 Validation Loss: 1.7304307222366333\n",
      "1034 Training Loss: 2.1700658798217773 Validation Loss: 1.7301260232925415\n",
      "1035 Training Loss: 2.1692302227020264 Validation Loss: 1.7298351526260376\n",
      "1036 Training Loss: 2.1690099239349365 Validation Loss: 1.7295341491699219\n",
      "1037 Training Loss: 2.1685569286346436 Validation Loss: 1.7292375564575195\n",
      "1038 Training Loss: 2.16799259185791 Validation Loss: 1.72895348072052\n",
      "1039 Training Loss: 2.167722463607788 Validation Loss: 1.7286723852157593\n",
      "1040 Training Loss: 2.1668803691864014 Validation Loss: 1.7283833026885986\n",
      "1041 Training Loss: 2.1667065620422363 Validation Loss: 1.7280741930007935\n",
      "1042 Training Loss: 2.165985345840454 Validation Loss: 1.7277913093566895\n",
      "1043 Training Loss: 2.165527582168579 Validation Loss: 1.7274937629699707\n",
      "1044 Training Loss: 2.1649177074432373 Validation Loss: 1.7271971702575684\n",
      "1045 Training Loss: 2.1645898818969727 Validation Loss: 1.7268978357315063\n",
      "1046 Training Loss: 2.163627862930298 Validation Loss: 1.7266089916229248\n",
      "1047 Training Loss: 2.1633639335632324 Validation Loss: 1.726320505142212\n",
      "1048 Training Loss: 2.162813663482666 Validation Loss: 1.7260401248931885\n",
      "1049 Training Loss: 2.1625022888183594 Validation Loss: 1.7257492542266846\n",
      "1050 Training Loss: 2.1619646549224854 Validation Loss: 1.725457787513733\n",
      "1051 Training Loss: 2.1605117321014404 Validation Loss: 1.7251794338226318\n",
      "1052 Training Loss: 2.1607346534729004 Validation Loss: 1.7248950004577637\n",
      "1053 Training Loss: 2.160048484802246 Validation Loss: 1.7246180772781372\n",
      "1054 Training Loss: 2.158904790878296 Validation Loss: 1.7243585586547852\n",
      "1055 Training Loss: 2.1587846279144287 Validation Loss: 1.7240904569625854\n",
      "1056 Training Loss: 2.158442258834839 Validation Loss: 1.7238292694091797\n",
      "1057 Training Loss: 2.157428026199341 Validation Loss: 1.7235605716705322\n",
      "1058 Training Loss: 2.1571381092071533 Validation Loss: 1.7232645750045776\n",
      "1059 Training Loss: 2.1559176445007324 Validation Loss: 1.7229794263839722\n",
      "1060 Training Loss: 2.1554174423217773 Validation Loss: 1.722686529159546\n",
      "1061 Training Loss: 2.155156135559082 Validation Loss: 1.722398042678833\n",
      "1062 Training Loss: 2.1548149585723877 Validation Loss: 1.722076416015625\n",
      "1063 Training Loss: 2.15381121635437 Validation Loss: 1.721738576889038\n",
      "1064 Training Loss: 2.1528866291046143 Validation Loss: 1.7214157581329346\n",
      "1065 Training Loss: 2.1529057025909424 Validation Loss: 1.7210711240768433\n",
      "1066 Training Loss: 2.151500940322876 Validation Loss: 1.7207303047180176\n",
      "1067 Training Loss: 2.1521952152252197 Validation Loss: 1.7203383445739746\n",
      "1068 Training Loss: 2.150458812713623 Validation Loss: 1.7199523448944092\n",
      "1069 Training Loss: 2.1495213508605957 Validation Loss: 1.7195544242858887\n",
      "1070 Training Loss: 2.149634838104248 Validation Loss: 1.7191457748413086\n",
      "1071 Training Loss: 2.1484670639038086 Validation Loss: 1.7187390327453613\n",
      "1072 Training Loss: 2.1487417221069336 Validation Loss: 1.7182953357696533\n",
      "1073 Training Loss: 2.1469485759735107 Validation Loss: 1.7178431749343872\n",
      "1074 Training Loss: 2.1461598873138428 Validation Loss: 1.7173969745635986\n",
      "1075 Training Loss: 2.1452934741973877 Validation Loss: 1.716956615447998\n",
      "1076 Training Loss: 2.145184278488159 Validation Loss: 1.7165112495422363\n",
      "1077 Training Loss: 2.1438093185424805 Validation Loss: 1.7160711288452148\n",
      "1078 Training Loss: 2.1435623168945312 Validation Loss: 1.7156223058700562\n",
      "1079 Training Loss: 2.14200496673584 Validation Loss: 1.7152000665664673\n",
      "1080 Training Loss: 2.1420419216156006 Validation Loss: 1.7147551774978638\n",
      "1081 Training Loss: 2.140965223312378 Validation Loss: 1.714280605316162\n",
      "1082 Training Loss: 2.1399800777435303 Validation Loss: 1.7137757539749146\n",
      "1083 Training Loss: 2.1387176513671875 Validation Loss: 1.7132726907730103\n",
      "1084 Training Loss: 2.138582706451416 Validation Loss: 1.7127355337142944\n",
      "1085 Training Loss: 2.1378467082977295 Validation Loss: 1.7121907472610474\n",
      "1086 Training Loss: 2.137159824371338 Validation Loss: 1.7116496562957764\n",
      "1087 Training Loss: 2.1355977058410645 Validation Loss: 1.7110940217971802\n",
      "1088 Training Loss: 2.1354713439941406 Validation Loss: 1.7105472087860107\n",
      "1089 Training Loss: 2.133789300918579 Validation Loss: 1.7100540399551392\n",
      "1090 Training Loss: 2.132758855819702 Validation Loss: 1.70962393283844\n",
      "1091 Training Loss: 2.133013963699341 Validation Loss: 1.7091621160507202\n",
      "1092 Training Loss: 2.13134503364563 Validation Loss: 1.7087130546569824\n",
      "1093 Training Loss: 2.1304402351379395 Validation Loss: 1.7082793712615967\n",
      "1094 Training Loss: 2.1294705867767334 Validation Loss: 1.707836627960205\n",
      "1095 Training Loss: 2.129319429397583 Validation Loss: 1.7073737382888794\n",
      "1096 Training Loss: 2.127976655960083 Validation Loss: 1.7069261074066162\n",
      "1097 Training Loss: 2.127213478088379 Validation Loss: 1.7064400911331177\n",
      "1098 Training Loss: 2.1259565353393555 Validation Loss: 1.7059853076934814\n",
      "1099 Training Loss: 2.1250481605529785 Validation Loss: 1.7055435180664062\n",
      "1100 Training Loss: 2.1232094764709473 Validation Loss: 1.7051258087158203\n",
      "1101 Training Loss: 2.123110771179199 Validation Loss: 1.704666018486023\n",
      "1102 Training Loss: 2.120954990386963 Validation Loss: 1.7042112350463867\n",
      "1103 Training Loss: 2.121929883956909 Validation Loss: 1.7037042379379272\n",
      "1104 Training Loss: 2.119493007659912 Validation Loss: 1.7030978202819824\n",
      "1105 Training Loss: 2.1188416481018066 Validation Loss: 1.702526569366455\n",
      "1106 Training Loss: 2.1183416843414307 Validation Loss: 1.7019426822662354\n",
      "1107 Training Loss: 2.1168711185455322 Validation Loss: 1.7013416290283203\n",
      "1108 Training Loss: 2.1162822246551514 Validation Loss: 1.7007315158843994\n",
      "1109 Training Loss: 2.113548517227173 Validation Loss: 1.700174331665039\n",
      "1110 Training Loss: 2.1137521266937256 Validation Loss: 1.6995469331741333\n",
      "1111 Training Loss: 2.112987518310547 Validation Loss: 1.698899269104004\n",
      "1112 Training Loss: 2.1114282608032227 Validation Loss: 1.698289394378662\n",
      "1113 Training Loss: 2.109622001647949 Validation Loss: 1.6977033615112305\n",
      "1114 Training Loss: 2.1099462509155273 Validation Loss: 1.6971254348754883\n",
      "1115 Training Loss: 2.1077470779418945 Validation Loss: 1.6965688467025757\n",
      "1116 Training Loss: 2.1064672470092773 Validation Loss: 1.6961181163787842\n",
      "1117 Training Loss: 2.1057651042938232 Validation Loss: 1.6957370042800903\n",
      "1118 Training Loss: 2.105238914489746 Validation Loss: 1.695285439491272\n",
      "1119 Training Loss: 2.1055099964141846 Validation Loss: 1.6946712732315063\n",
      "1120 Training Loss: 2.1027491092681885 Validation Loss: 1.6941126585006714\n",
      "1121 Training Loss: 2.1025989055633545 Validation Loss: 1.6935288906097412\n",
      "1122 Training Loss: 2.099454641342163 Validation Loss: 1.6929854154586792\n",
      "1123 Training Loss: 2.098986864089966 Validation Loss: 1.692444086074829\n",
      "1124 Training Loss: 2.0980544090270996 Validation Loss: 1.6918660402297974\n",
      "1125 Training Loss: 2.097376823425293 Validation Loss: 1.6912291049957275\n",
      "1126 Training Loss: 2.0950980186462402 Validation Loss: 1.6905637979507446\n",
      "1127 Training Loss: 2.0949676036834717 Validation Loss: 1.689874291419983\n",
      "1128 Training Loss: 2.0932393074035645 Validation Loss: 1.6891711950302124\n",
      "1129 Training Loss: 2.0918712615966797 Validation Loss: 1.6884119510650635\n",
      "1130 Training Loss: 2.0899882316589355 Validation Loss: 1.6876554489135742\n",
      "1131 Training Loss: 2.0879569053649902 Validation Loss: 1.686903476715088\n",
      "1132 Training Loss: 2.0887982845306396 Validation Loss: 1.6861639022827148\n",
      "1133 Training Loss: 2.087053060531616 Validation Loss: 1.685412049293518\n",
      "1134 Training Loss: 2.083731174468994 Validation Loss: 1.6847522258758545\n",
      "1135 Training Loss: 2.0833005905151367 Validation Loss: 1.6841413974761963\n",
      "1136 Training Loss: 2.0835659503936768 Validation Loss: 1.6835582256317139\n",
      "1137 Training Loss: 2.0805811882019043 Validation Loss: 1.68295156955719\n",
      "1138 Training Loss: 2.08015775680542 Validation Loss: 1.6822292804718018\n",
      "1139 Training Loss: 2.077122211456299 Validation Loss: 1.6815235614776611\n",
      "1140 Training Loss: 2.0755457878112793 Validation Loss: 1.680866003036499\n",
      "1141 Training Loss: 2.075406312942505 Validation Loss: 1.6801321506500244\n",
      "1142 Training Loss: 2.073094129562378 Validation Loss: 1.6794118881225586\n",
      "1143 Training Loss: 2.0707428455352783 Validation Loss: 1.6786775588989258\n",
      "1144 Training Loss: 2.071944236755371 Validation Loss: 1.677955150604248\n",
      "1145 Training Loss: 2.06893253326416 Validation Loss: 1.6772202253341675\n",
      "1146 Training Loss: 2.069366216659546 Validation Loss: 1.6765577793121338\n",
      "1147 Training Loss: 2.0665621757507324 Validation Loss: 1.6760475635528564\n",
      "1148 Training Loss: 2.0643162727355957 Validation Loss: 1.675521731376648\n",
      "1149 Training Loss: 2.0635151863098145 Validation Loss: 1.6749227046966553\n",
      "1150 Training Loss: 2.063915252685547 Validation Loss: 1.6741868257522583\n",
      "1151 Training Loss: 2.0605411529541016 Validation Loss: 1.6733757257461548\n",
      "1152 Training Loss: 2.059509515762329 Validation Loss: 1.6725237369537354\n",
      "1153 Training Loss: 2.058493137359619 Validation Loss: 1.671778917312622\n",
      "1154 Training Loss: 2.0544958114624023 Validation Loss: 1.671000361442566\n",
      "1155 Training Loss: 2.053772211074829 Validation Loss: 1.6700353622436523\n",
      "1156 Training Loss: 2.051523208618164 Validation Loss: 1.669079065322876\n",
      "1157 Training Loss: 2.05397891998291 Validation Loss: 1.668064832687378\n",
      "1158 Training Loss: 2.049436092376709 Validation Loss: 1.6670010089874268\n",
      "1159 Training Loss: 2.049283504486084 Validation Loss: 1.666074514389038\n",
      "1160 Training Loss: 2.0475258827209473 Validation Loss: 1.665239691734314\n",
      "1161 Training Loss: 2.0463130474090576 Validation Loss: 1.6646639108657837\n",
      "1162 Training Loss: 2.0433011054992676 Validation Loss: 1.6641623973846436\n",
      "1163 Training Loss: 2.0405216217041016 Validation Loss: 1.6635757684707642\n",
      "1164 Training Loss: 2.0402331352233887 Validation Loss: 1.6628468036651611\n",
      "1165 Training Loss: 2.0371034145355225 Validation Loss: 1.662279486656189\n",
      "1166 Training Loss: 2.039113759994507 Validation Loss: 1.6614326238632202\n",
      "1167 Training Loss: 2.036778688430786 Validation Loss: 1.6604256629943848\n",
      "1168 Training Loss: 2.0340378284454346 Validation Loss: 1.6593490839004517\n",
      "1169 Training Loss: 2.0351405143737793 Validation Loss: 1.6581193208694458\n",
      "1170 Training Loss: 2.0328307151794434 Validation Loss: 1.6568403244018555\n",
      "1171 Training Loss: 2.028654098510742 Validation Loss: 1.655533790588379\n",
      "1172 Training Loss: 2.0303165912628174 Validation Loss: 1.6539864540100098\n",
      "1173 Training Loss: 2.025071382522583 Validation Loss: 1.6525806188583374\n",
      "1174 Training Loss: 2.0237936973571777 Validation Loss: 1.6512689590454102\n",
      "1175 Training Loss: 2.023163080215454 Validation Loss: 1.6497725248336792\n",
      "1176 Training Loss: 2.0189826488494873 Validation Loss: 1.6482563018798828\n",
      "1177 Training Loss: 2.0163257122039795 Validation Loss: 1.6468745470046997\n",
      "1178 Training Loss: 2.0156123638153076 Validation Loss: 1.6455618143081665\n",
      "1179 Training Loss: 2.011479377746582 Validation Loss: 1.6444706916809082\n",
      "1180 Training Loss: 2.0213537216186523 Validation Loss: 1.6434125900268555\n",
      "1181 Training Loss: 2.012763261795044 Validation Loss: 1.6421645879745483\n",
      "1182 Training Loss: 2.010599136352539 Validation Loss: 1.6410166025161743\n",
      "1183 Training Loss: 2.0079057216644287 Validation Loss: 1.6397329568862915\n",
      "1184 Training Loss: 2.0071871280670166 Validation Loss: 1.638740062713623\n",
      "1185 Training Loss: 2.0073397159576416 Validation Loss: 1.6377253532409668\n",
      "1186 Training Loss: 2.003589153289795 Validation Loss: 1.6363966464996338\n",
      "1187 Training Loss: 2.00174880027771 Validation Loss: 1.6350678205490112\n",
      "1188 Training Loss: 2.0034677982330322 Validation Loss: 1.633692741394043\n",
      "1189 Training Loss: 1.9954441785812378 Validation Loss: 1.6325350999832153\n",
      "1190 Training Loss: 1.9963762760162354 Validation Loss: 1.6316652297973633\n",
      "1191 Training Loss: 1.9956865310668945 Validation Loss: 1.6309692859649658\n",
      "1192 Training Loss: 1.9914844036102295 Validation Loss: 1.6302690505981445\n",
      "1193 Training Loss: 1.9904354810714722 Validation Loss: 1.6296181678771973\n",
      "1194 Training Loss: 1.9879578351974487 Validation Loss: 1.6291465759277344\n",
      "1195 Training Loss: 1.9892958402633667 Validation Loss: 1.628358244895935\n",
      "1196 Training Loss: 1.9859328269958496 Validation Loss: 1.6275296211242676\n",
      "1197 Training Loss: 1.9858338832855225 Validation Loss: 1.6265360116958618\n",
      "1198 Training Loss: 1.983205795288086 Validation Loss: 1.6254541873931885\n",
      "1199 Training Loss: 1.9804646968841553 Validation Loss: 1.6243641376495361\n",
      "1200 Training Loss: 1.9798939228057861 Validation Loss: 1.6232852935791016\n",
      "1201 Training Loss: 1.9758068323135376 Validation Loss: 1.622132420539856\n",
      "1202 Training Loss: 1.9793580770492554 Validation Loss: 1.620993971824646\n",
      "1203 Training Loss: 1.9755635261535645 Validation Loss: 1.6192872524261475\n",
      "1204 Training Loss: 1.9708936214447021 Validation Loss: 1.6177959442138672\n",
      "1205 Training Loss: 1.9716004133224487 Validation Loss: 1.6160149574279785\n",
      "1206 Training Loss: 1.9657061100006104 Validation Loss: 1.6143717765808105\n",
      "1207 Training Loss: 1.9646157026290894 Validation Loss: 1.6132303476333618\n",
      "1208 Training Loss: 1.966710090637207 Validation Loss: 1.6122105121612549\n",
      "1209 Training Loss: 1.9635143280029297 Validation Loss: 1.6109001636505127\n",
      "1210 Training Loss: 1.9614005088806152 Validation Loss: 1.609363317489624\n",
      "1211 Training Loss: 1.9607937335968018 Validation Loss: 1.6079318523406982\n",
      "1212 Training Loss: 1.9566905498504639 Validation Loss: 1.6067981719970703\n",
      "1213 Training Loss: 1.954756498336792 Validation Loss: 1.605644941329956\n",
      "1214 Training Loss: 1.956357717514038 Validation Loss: 1.6045796871185303\n",
      "1215 Training Loss: 1.9507008790969849 Validation Loss: 1.603547215461731\n",
      "1216 Training Loss: 1.9514472484588623 Validation Loss: 1.6020081043243408\n",
      "1217 Training Loss: 1.9507428407669067 Validation Loss: 1.6005860567092896\n",
      "1218 Training Loss: 1.945770502090454 Validation Loss: 1.5993109941482544\n",
      "1219 Training Loss: 1.9410475492477417 Validation Loss: 1.598136305809021\n",
      "1220 Training Loss: 1.9431979656219482 Validation Loss: 1.5971070528030396\n",
      "1221 Training Loss: 1.940982460975647 Validation Loss: 1.5957577228546143\n",
      "1222 Training Loss: 1.9399539232254028 Validation Loss: 1.5940115451812744\n",
      "1223 Training Loss: 1.940265417098999 Validation Loss: 1.591969609260559\n",
      "1224 Training Loss: 1.9384701251983643 Validation Loss: 1.5900704860687256\n",
      "1225 Training Loss: 1.9372448921203613 Validation Loss: 1.588361382484436\n",
      "1226 Training Loss: 1.9333813190460205 Validation Loss: 1.5866153240203857\n",
      "1227 Training Loss: 1.9295841455459595 Validation Loss: 1.5851038694381714\n",
      "1228 Training Loss: 1.9309934377670288 Validation Loss: 1.5832674503326416\n",
      "1229 Training Loss: 1.9273192882537842 Validation Loss: 1.5812768936157227\n",
      "1230 Training Loss: 1.931240439414978 Validation Loss: 1.5789076089859009\n",
      "1231 Training Loss: 1.9246000051498413 Validation Loss: 1.5762476921081543\n",
      "1232 Training Loss: 1.9246950149536133 Validation Loss: 1.5738214254379272\n",
      "1233 Training Loss: 1.9270693063735962 Validation Loss: 1.5713887214660645\n",
      "1234 Training Loss: 1.922950029373169 Validation Loss: 1.5691943168640137\n",
      "1235 Training Loss: 1.919189214706421 Validation Loss: 1.5668480396270752\n",
      "1236 Training Loss: 1.9164705276489258 Validation Loss: 1.564294457435608\n",
      "1237 Training Loss: 1.9137173891067505 Validation Loss: 1.5620510578155518\n",
      "1238 Training Loss: 1.914013385772705 Validation Loss: 1.5598976612091064\n",
      "1239 Training Loss: 1.915845274925232 Validation Loss: 1.557847023010254\n",
      "1240 Training Loss: 1.9086037874221802 Validation Loss: 1.556057333946228\n",
      "1241 Training Loss: 1.9053459167480469 Validation Loss: 1.5543909072875977\n",
      "1242 Training Loss: 1.9082791805267334 Validation Loss: 1.5525249242782593\n",
      "1243 Training Loss: 1.9029361009597778 Validation Loss: 1.5507392883300781\n",
      "1244 Training Loss: 1.9035331010818481 Validation Loss: 1.5492064952850342\n",
      "1245 Training Loss: 1.9031288623809814 Validation Loss: 1.5476547479629517\n",
      "1246 Training Loss: 1.9047155380249023 Validation Loss: 1.5462346076965332\n",
      "1247 Training Loss: 1.903620719909668 Validation Loss: 1.5447843074798584\n",
      "1248 Training Loss: 1.898186206817627 Validation Loss: 1.543501615524292\n",
      "1249 Training Loss: 1.8998481035232544 Validation Loss: 1.5420887470245361\n",
      "1250 Training Loss: 1.894498348236084 Validation Loss: 1.5407905578613281\n",
      "1251 Training Loss: 1.8999396562576294 Validation Loss: 1.5394330024719238\n",
      "1252 Training Loss: 1.894570231437683 Validation Loss: 1.537761926651001\n",
      "1253 Training Loss: 1.8933066129684448 Validation Loss: 1.536399006843567\n",
      "1254 Training Loss: 1.8882193565368652 Validation Loss: 1.5348742008209229\n",
      "1255 Training Loss: 1.8878593444824219 Validation Loss: 1.5335675477981567\n",
      "1256 Training Loss: 1.885886549949646 Validation Loss: 1.5321693420410156\n",
      "1257 Training Loss: 1.8865725994110107 Validation Loss: 1.5305311679840088\n",
      "1258 Training Loss: 1.8886867761611938 Validation Loss: 1.5291242599487305\n",
      "1259 Training Loss: 1.8815001249313354 Validation Loss: 1.5271401405334473\n",
      "1260 Training Loss: 1.8780362606048584 Validation Loss: 1.5247654914855957\n",
      "1261 Training Loss: 1.8777176141738892 Validation Loss: 1.5223218202590942\n",
      "1262 Training Loss: 1.8830642700195312 Validation Loss: 1.5199484825134277\n",
      "1263 Training Loss: 1.8763878345489502 Validation Loss: 1.5171606540679932\n",
      "1264 Training Loss: 1.875758171081543 Validation Loss: 1.5143874883651733\n",
      "1265 Training Loss: 1.876746654510498 Validation Loss: 1.5114158391952515\n",
      "1266 Training Loss: 1.8714921474456787 Validation Loss: 1.5085793733596802\n",
      "1267 Training Loss: 1.8715895414352417 Validation Loss: 1.5059651136398315\n",
      "1268 Training Loss: 1.8683438301086426 Validation Loss: 1.5037541389465332\n",
      "1269 Training Loss: 1.8706642389297485 Validation Loss: 1.5016205310821533\n",
      "1270 Training Loss: 1.8628519773483276 Validation Loss: 1.4995681047439575\n",
      "1271 Training Loss: 1.8646482229232788 Validation Loss: 1.4974617958068848\n",
      "1272 Training Loss: 1.8616628646850586 Validation Loss: 1.4954873323440552\n",
      "1273 Training Loss: 1.861854076385498 Validation Loss: 1.493500828742981\n",
      "1274 Training Loss: 1.861802101135254 Validation Loss: 1.4915236234664917\n",
      "1275 Training Loss: 1.8637363910675049 Validation Loss: 1.48953378200531\n",
      "1276 Training Loss: 1.8578532934188843 Validation Loss: 1.4877761602401733\n",
      "1277 Training Loss: 1.8638403415679932 Validation Loss: 1.4859809875488281\n",
      "1278 Training Loss: 1.8510189056396484 Validation Loss: 1.483965516090393\n",
      "1279 Training Loss: 1.8477225303649902 Validation Loss: 1.4819223880767822\n",
      "1280 Training Loss: 1.8550002574920654 Validation Loss: 1.48013174533844\n",
      "1281 Training Loss: 1.853936791419983 Validation Loss: 1.4780144691467285\n",
      "1282 Training Loss: 1.8515461683273315 Validation Loss: 1.4757533073425293\n",
      "1283 Training Loss: 1.8480560779571533 Validation Loss: 1.473421573638916\n",
      "1284 Training Loss: 1.8517887592315674 Validation Loss: 1.4712616205215454\n",
      "1285 Training Loss: 1.8511854410171509 Validation Loss: 1.4688711166381836\n",
      "1286 Training Loss: 1.847155213356018 Validation Loss: 1.466809868812561\n",
      "1287 Training Loss: 1.8453799486160278 Validation Loss: 1.4648394584655762\n",
      "1288 Training Loss: 1.842191457748413 Validation Loss: 1.4630316495895386\n",
      "1289 Training Loss: 1.8381633758544922 Validation Loss: 1.4612689018249512\n",
      "1290 Training Loss: 1.8364378213882446 Validation Loss: 1.459639549255371\n",
      "1291 Training Loss: 1.8416163921356201 Validation Loss: 1.4580658674240112\n",
      "1292 Training Loss: 1.8348196744918823 Validation Loss: 1.4563266038894653\n",
      "1293 Training Loss: 1.8328170776367188 Validation Loss: 1.4547446966171265\n",
      "1294 Training Loss: 1.831613540649414 Validation Loss: 1.4531114101409912\n",
      "1295 Training Loss: 1.831845998764038 Validation Loss: 1.451658844947815\n",
      "1296 Training Loss: 1.8328888416290283 Validation Loss: 1.4498987197875977\n",
      "1297 Training Loss: 1.8327163457870483 Validation Loss: 1.4482465982437134\n",
      "1298 Training Loss: 1.830741047859192 Validation Loss: 1.446548581123352\n",
      "1299 Training Loss: 1.8274365663528442 Validation Loss: 1.444798469543457\n",
      "1300 Training Loss: 1.8296335935592651 Validation Loss: 1.443112850189209\n",
      "1301 Training Loss: 1.830756425857544 Validation Loss: 1.4413585662841797\n",
      "1302 Training Loss: 1.8217072486877441 Validation Loss: 1.439292550086975\n",
      "1303 Training Loss: 1.819475769996643 Validation Loss: 1.4371577501296997\n",
      "1304 Training Loss: 1.818324089050293 Validation Loss: 1.434861183166504\n",
      "1305 Training Loss: 1.816925048828125 Validation Loss: 1.4324308633804321\n",
      "1306 Training Loss: 1.8154540061950684 Validation Loss: 1.4299638271331787\n",
      "1307 Training Loss: 1.8112753629684448 Validation Loss: 1.4274955987930298\n",
      "1308 Training Loss: 1.8203661441802979 Validation Loss: 1.4251800775527954\n",
      "1309 Training Loss: 1.8128669261932373 Validation Loss: 1.422849416732788\n",
      "1310 Training Loss: 1.8094913959503174 Validation Loss: 1.4205790758132935\n",
      "1311 Training Loss: 1.811896800994873 Validation Loss: 1.4184753894805908\n",
      "1312 Training Loss: 1.805574893951416 Validation Loss: 1.4164241552352905\n",
      "1313 Training Loss: 1.8068828582763672 Validation Loss: 1.4142615795135498\n",
      "1314 Training Loss: 1.803072452545166 Validation Loss: 1.4121928215026855\n",
      "1315 Training Loss: 1.798490047454834 Validation Loss: 1.4100596904754639\n",
      "1316 Training Loss: 1.8078486919403076 Validation Loss: 1.408179759979248\n",
      "1317 Training Loss: 1.797986626625061 Validation Loss: 1.40629243850708\n",
      "1318 Training Loss: 1.8032941818237305 Validation Loss: 1.404349684715271\n",
      "1319 Training Loss: 1.8001422882080078 Validation Loss: 1.4024789333343506\n",
      "1320 Training Loss: 1.7905259132385254 Validation Loss: 1.4006236791610718\n",
      "1321 Training Loss: 1.7957814931869507 Validation Loss: 1.3987526893615723\n",
      "1322 Training Loss: 1.7932376861572266 Validation Loss: 1.39683997631073\n",
      "1323 Training Loss: 1.7892122268676758 Validation Loss: 1.394966721534729\n",
      "1324 Training Loss: 1.7931815385818481 Validation Loss: 1.3931419849395752\n",
      "1325 Training Loss: 1.7912378311157227 Validation Loss: 1.391436219215393\n",
      "1326 Training Loss: 1.7834551334381104 Validation Loss: 1.389752745628357\n",
      "1327 Training Loss: 1.782184362411499 Validation Loss: 1.3881306648254395\n",
      "1328 Training Loss: 1.7850806713104248 Validation Loss: 1.3864578008651733\n",
      "1329 Training Loss: 1.7824926376342773 Validation Loss: 1.3849568367004395\n",
      "1330 Training Loss: 1.7799049615859985 Validation Loss: 1.383311152458191\n",
      "1331 Training Loss: 1.7826305627822876 Validation Loss: 1.3818355798721313\n",
      "1332 Training Loss: 1.7762537002563477 Validation Loss: 1.38029944896698\n",
      "1333 Training Loss: 1.7754641771316528 Validation Loss: 1.378737211227417\n",
      "1334 Training Loss: 1.7786163091659546 Validation Loss: 1.3771097660064697\n",
      "1335 Training Loss: 1.7722651958465576 Validation Loss: 1.375618577003479\n",
      "1336 Training Loss: 1.7717982530593872 Validation Loss: 1.3743222951889038\n",
      "1337 Training Loss: 1.7660871744155884 Validation Loss: 1.3729358911514282\n",
      "1338 Training Loss: 1.7677850723266602 Validation Loss: 1.371444582939148\n",
      "1339 Training Loss: 1.7666707038879395 Validation Loss: 1.3698903322219849\n",
      "1340 Training Loss: 1.7642563581466675 Validation Loss: 1.3682076930999756\n",
      "1341 Training Loss: 1.7651952505111694 Validation Loss: 1.3665308952331543\n",
      "1342 Training Loss: 1.7586164474487305 Validation Loss: 1.3649486303329468\n",
      "1343 Training Loss: 1.7635166645050049 Validation Loss: 1.3633018732070923\n",
      "1344 Training Loss: 1.7640835046768188 Validation Loss: 1.3616496324539185\n",
      "1345 Training Loss: 1.75440514087677 Validation Loss: 1.3600469827651978\n",
      "1346 Training Loss: 1.7569681406021118 Validation Loss: 1.3583101034164429\n",
      "1347 Training Loss: 1.7528765201568604 Validation Loss: 1.356583595275879\n",
      "1348 Training Loss: 1.7567858695983887 Validation Loss: 1.354967474937439\n",
      "1349 Training Loss: 1.7514569759368896 Validation Loss: 1.3533753156661987\n",
      "1350 Training Loss: 1.7455759048461914 Validation Loss: 1.3517543077468872\n",
      "1351 Training Loss: 1.7483367919921875 Validation Loss: 1.3501033782958984\n",
      "1352 Training Loss: 1.7436738014221191 Validation Loss: 1.348488450050354\n",
      "1353 Training Loss: 1.7477226257324219 Validation Loss: 1.3469041585922241\n",
      "1354 Training Loss: 1.7414169311523438 Validation Loss: 1.3452794551849365\n",
      "1355 Training Loss: 1.7445112466812134 Validation Loss: 1.3435348272323608\n",
      "1356 Training Loss: 1.7378008365631104 Validation Loss: 1.3417598009109497\n",
      "1357 Training Loss: 1.7363389730453491 Validation Loss: 1.3401341438293457\n",
      "1358 Training Loss: 1.7362343072891235 Validation Loss: 1.338483452796936\n",
      "1359 Training Loss: 1.7297685146331787 Validation Loss: 1.3368616104125977\n",
      "1360 Training Loss: 1.7313705682754517 Validation Loss: 1.335103154182434\n",
      "1361 Training Loss: 1.7312791347503662 Validation Loss: 1.3332884311676025\n",
      "1362 Training Loss: 1.7243231534957886 Validation Loss: 1.3315584659576416\n",
      "1363 Training Loss: 1.7236244678497314 Validation Loss: 1.3299068212509155\n",
      "1364 Training Loss: 1.7239766120910645 Validation Loss: 1.3283569812774658\n",
      "1365 Training Loss: 1.7230147123336792 Validation Loss: 1.326821208000183\n",
      "1366 Training Loss: 1.721224069595337 Validation Loss: 1.3252322673797607\n",
      "1367 Training Loss: 1.7198477983474731 Validation Loss: 1.3237042427062988\n",
      "1368 Training Loss: 1.713789701461792 Validation Loss: 1.3222476243972778\n",
      "1369 Training Loss: 1.7153974771499634 Validation Loss: 1.3207905292510986\n",
      "1370 Training Loss: 1.716444969177246 Validation Loss: 1.3192648887634277\n",
      "1371 Training Loss: 1.709753155708313 Validation Loss: 1.3176360130310059\n",
      "1372 Training Loss: 1.710405707359314 Validation Loss: 1.3160274028778076\n",
      "1373 Training Loss: 1.7096002101898193 Validation Loss: 1.314538836479187\n",
      "1374 Training Loss: 1.7066185474395752 Validation Loss: 1.3130215406417847\n",
      "1375 Training Loss: 1.7006745338439941 Validation Loss: 1.3114674091339111\n",
      "1376 Training Loss: 1.7033898830413818 Validation Loss: 1.309973120689392\n",
      "1377 Training Loss: 1.699538230895996 Validation Loss: 1.3085675239562988\n",
      "1378 Training Loss: 1.691104531288147 Validation Loss: 1.3071402311325073\n",
      "1379 Training Loss: 1.6952005624771118 Validation Loss: 1.3057613372802734\n",
      "1380 Training Loss: 1.6924548149108887 Validation Loss: 1.3043493032455444\n",
      "1381 Training Loss: 1.6933971643447876 Validation Loss: 1.302931547164917\n",
      "1382 Training Loss: 1.6886365413665771 Validation Loss: 1.3014626502990723\n",
      "1383 Training Loss: 1.681834101676941 Validation Loss: 1.3000035285949707\n",
      "1384 Training Loss: 1.687513828277588 Validation Loss: 1.2985594272613525\n",
      "1385 Training Loss: 1.6823718547821045 Validation Loss: 1.2971158027648926\n",
      "1386 Training Loss: 1.6810663938522339 Validation Loss: 1.2956147193908691\n",
      "1387 Training Loss: 1.6832157373428345 Validation Loss: 1.2942100763320923\n",
      "1388 Training Loss: 1.6766492128372192 Validation Loss: 1.2928556203842163\n",
      "1389 Training Loss: 1.6742790937423706 Validation Loss: 1.2915294170379639\n",
      "1390 Training Loss: 1.6714192628860474 Validation Loss: 1.2900590896606445\n",
      "1391 Training Loss: 1.6761901378631592 Validation Loss: 1.2884968519210815\n",
      "1392 Training Loss: 1.675408959388733 Validation Loss: 1.2868413925170898\n",
      "1393 Training Loss: 1.6666009426116943 Validation Loss: 1.285256266593933\n",
      "1394 Training Loss: 1.6653966903686523 Validation Loss: 1.283851146697998\n",
      "1395 Training Loss: 1.6692835092544556 Validation Loss: 1.2824397087097168\n",
      "1396 Training Loss: 1.660365104675293 Validation Loss: 1.2809566259384155\n",
      "1397 Training Loss: 1.6656429767608643 Validation Loss: 1.2792893648147583\n",
      "1398 Training Loss: 1.6560016870498657 Validation Loss: 1.2776786088943481\n",
      "1399 Training Loss: 1.6516157388687134 Validation Loss: 1.27609384059906\n",
      "1400 Training Loss: 1.6574430465698242 Validation Loss: 1.2745654582977295\n",
      "1401 Training Loss: 1.6526870727539062 Validation Loss: 1.2730896472930908\n",
      "1402 Training Loss: 1.6485717296600342 Validation Loss: 1.271804690361023\n",
      "1403 Training Loss: 1.6543917655944824 Validation Loss: 1.2705668210983276\n",
      "1404 Training Loss: 1.6473188400268555 Validation Loss: 1.2693513631820679\n",
      "1405 Training Loss: 1.647081732749939 Validation Loss: 1.268192172050476\n",
      "1406 Training Loss: 1.6424517631530762 Validation Loss: 1.2669446468353271\n",
      "1407 Training Loss: 1.6413161754608154 Validation Loss: 1.2656669616699219\n",
      "1408 Training Loss: 1.6425070762634277 Validation Loss: 1.264519214630127\n",
      "1409 Training Loss: 1.6357691287994385 Validation Loss: 1.2633652687072754\n",
      "1410 Training Loss: 1.6350362300872803 Validation Loss: 1.2622965574264526\n",
      "1411 Training Loss: 1.637556552886963 Validation Loss: 1.2611504793167114\n",
      "1412 Training Loss: 1.632455825805664 Validation Loss: 1.2599902153015137\n",
      "1413 Training Loss: 1.625624656677246 Validation Loss: 1.2588564157485962\n",
      "1414 Training Loss: 1.6245379447937012 Validation Loss: 1.2576147317886353\n",
      "1415 Training Loss: 1.6219109296798706 Validation Loss: 1.2563973665237427\n",
      "1416 Training Loss: 1.6166400909423828 Validation Loss: 1.2551136016845703\n",
      "1417 Training Loss: 1.6113324165344238 Validation Loss: 1.2537592649459839\n",
      "1418 Training Loss: 1.6188706159591675 Validation Loss: 1.2523647546768188\n",
      "1419 Training Loss: 1.6118998527526855 Validation Loss: 1.2509667873382568\n",
      "1420 Training Loss: 1.6154048442840576 Validation Loss: 1.249627947807312\n",
      "1421 Training Loss: 1.6083683967590332 Validation Loss: 1.2482521533966064\n",
      "1422 Training Loss: 1.6114310026168823 Validation Loss: 1.2468196153640747\n",
      "1423 Training Loss: 1.6074355840682983 Validation Loss: 1.2452934980392456\n",
      "1424 Training Loss: 1.6092009544372559 Validation Loss: 1.2437275648117065\n",
      "1425 Training Loss: 1.6028600931167603 Validation Loss: 1.242113709449768\n",
      "1426 Training Loss: 1.5981396436691284 Validation Loss: 1.240522861480713\n",
      "1427 Training Loss: 1.5991442203521729 Validation Loss: 1.238940715789795\n",
      "1428 Training Loss: 1.6003977060317993 Validation Loss: 1.2372431755065918\n",
      "1429 Training Loss: 1.5905981063842773 Validation Loss: 1.235654592514038\n",
      "1430 Training Loss: 1.589005947113037 Validation Loss: 1.2339890003204346\n",
      "1431 Training Loss: 1.5935484170913696 Validation Loss: 1.2322468757629395\n",
      "1432 Training Loss: 1.5877147912979126 Validation Loss: 1.2305188179016113\n",
      "1433 Training Loss: 1.590306282043457 Validation Loss: 1.2287402153015137\n",
      "1434 Training Loss: 1.5874296426773071 Validation Loss: 1.2268939018249512\n",
      "1435 Training Loss: 1.5877844095230103 Validation Loss: 1.2250688076019287\n",
      "1436 Training Loss: 1.5771615505218506 Validation Loss: 1.2232918739318848\n",
      "1437 Training Loss: 1.5791206359863281 Validation Loss: 1.2215631008148193\n",
      "1438 Training Loss: 1.576723337173462 Validation Loss: 1.2199475765228271\n",
      "1439 Training Loss: 1.5704360008239746 Validation Loss: 1.2184126377105713\n",
      "1440 Training Loss: 1.5688612461090088 Validation Loss: 1.216801643371582\n",
      "1441 Training Loss: 1.5657795667648315 Validation Loss: 1.2152924537658691\n",
      "1442 Training Loss: 1.5651044845581055 Validation Loss: 1.213929533958435\n",
      "1443 Training Loss: 1.561901569366455 Validation Loss: 1.2126303911209106\n",
      "1444 Training Loss: 1.5559303760528564 Validation Loss: 1.2113091945648193\n",
      "1445 Training Loss: 1.5604435205459595 Validation Loss: 1.2099695205688477\n",
      "1446 Training Loss: 1.5543259382247925 Validation Loss: 1.2086158990859985\n",
      "1447 Training Loss: 1.550776481628418 Validation Loss: 1.207261323928833\n",
      "1448 Training Loss: 1.5520546436309814 Validation Loss: 1.2061028480529785\n",
      "1449 Training Loss: 1.5475268363952637 Validation Loss: 1.2050056457519531\n",
      "1450 Training Loss: 1.5488463640213013 Validation Loss: 1.2038577795028687\n",
      "1451 Training Loss: 1.549646019935608 Validation Loss: 1.2027119398117065\n",
      "1452 Training Loss: 1.5429496765136719 Validation Loss: 1.2016386985778809\n",
      "1453 Training Loss: 1.536527156829834 Validation Loss: 1.2005574703216553\n",
      "1454 Training Loss: 1.53513765335083 Validation Loss: 1.199339509010315\n",
      "1455 Training Loss: 1.5333622694015503 Validation Loss: 1.1980223655700684\n",
      "1456 Training Loss: 1.5291701555252075 Validation Loss: 1.1966590881347656\n",
      "1457 Training Loss: 1.5291950702667236 Validation Loss: 1.1953355073928833\n",
      "1458 Training Loss: 1.5233595371246338 Validation Loss: 1.1940553188323975\n",
      "1459 Training Loss: 1.5290193557739258 Validation Loss: 1.1926929950714111\n",
      "1460 Training Loss: 1.5284744501113892 Validation Loss: 1.1912401914596558\n",
      "1461 Training Loss: 1.51993727684021 Validation Loss: 1.1895856857299805\n",
      "1462 Training Loss: 1.5227326154708862 Validation Loss: 1.1879396438598633\n",
      "1463 Training Loss: 1.5238523483276367 Validation Loss: 1.186271071434021\n",
      "1464 Training Loss: 1.5131572484970093 Validation Loss: 1.1845817565917969\n",
      "1465 Training Loss: 1.508323311805725 Validation Loss: 1.1829748153686523\n",
      "1466 Training Loss: 1.5057300329208374 Validation Loss: 1.1815279722213745\n",
      "1467 Training Loss: 1.5091824531555176 Validation Loss: 1.1799366474151611\n",
      "1468 Training Loss: 1.5024441480636597 Validation Loss: 1.1782995462417603\n",
      "1469 Training Loss: 1.5001850128173828 Validation Loss: 1.1765912771224976\n",
      "1470 Training Loss: 1.5016957521438599 Validation Loss: 1.174896478652954\n",
      "1471 Training Loss: 1.4986114501953125 Validation Loss: 1.173211932182312\n",
      "1472 Training Loss: 1.491553783416748 Validation Loss: 1.1716039180755615\n",
      "1473 Training Loss: 1.4908215999603271 Validation Loss: 1.1700619459152222\n",
      "1474 Training Loss: 1.48989999294281 Validation Loss: 1.1686087846755981\n",
      "1475 Training Loss: 1.4955049753189087 Validation Loss: 1.167138934135437\n",
      "1476 Training Loss: 1.4792007207870483 Validation Loss: 1.1657723188400269\n",
      "1477 Training Loss: 1.4796828031539917 Validation Loss: 1.1646065711975098\n",
      "1478 Training Loss: 1.4777858257293701 Validation Loss: 1.1633949279785156\n",
      "1479 Training Loss: 1.4818633794784546 Validation Loss: 1.1621224880218506\n",
      "1480 Training Loss: 1.4712671041488647 Validation Loss: 1.160888671875\n",
      "1481 Training Loss: 1.4694525003433228 Validation Loss: 1.1597273349761963\n",
      "1482 Training Loss: 1.4666420221328735 Validation Loss: 1.158574104309082\n",
      "1483 Training Loss: 1.4665194749832153 Validation Loss: 1.157410740852356\n",
      "1484 Training Loss: 1.4718860387802124 Validation Loss: 1.1560648679733276\n",
      "1485 Training Loss: 1.4656404256820679 Validation Loss: 1.154616355895996\n",
      "1486 Training Loss: 1.4581239223480225 Validation Loss: 1.1532375812530518\n",
      "1487 Training Loss: 1.4559608697891235 Validation Loss: 1.1519144773483276\n",
      "1488 Training Loss: 1.4564626216888428 Validation Loss: 1.1503970623016357\n",
      "1489 Training Loss: 1.4555504322052002 Validation Loss: 1.1488021612167358\n",
      "1490 Training Loss: 1.4438836574554443 Validation Loss: 1.1472461223602295\n",
      "1491 Training Loss: 1.440967321395874 Validation Loss: 1.1458041667938232\n",
      "1492 Training Loss: 1.4506112337112427 Validation Loss: 1.144362449645996\n",
      "1493 Training Loss: 1.4407951831817627 Validation Loss: 1.1429293155670166\n",
      "1494 Training Loss: 1.439966082572937 Validation Loss: 1.1413450241088867\n",
      "1495 Training Loss: 1.4427043199539185 Validation Loss: 1.1397178173065186\n",
      "1496 Training Loss: 1.4369794130325317 Validation Loss: 1.1380245685577393\n",
      "1497 Training Loss: 1.4370933771133423 Validation Loss: 1.1361887454986572\n",
      "1498 Training Loss: 1.431863784790039 Validation Loss: 1.134307622909546\n",
      "1499 Training Loss: 1.417827844619751 Validation Loss: 1.1324965953826904\n",
      "1500 Training Loss: 1.4266780614852905 Validation Loss: 1.1306813955307007\n",
      "1501 Training Loss: 1.4224005937576294 Validation Loss: 1.1289968490600586\n",
      "1502 Training Loss: 1.4171292781829834 Validation Loss: 1.1273601055145264\n",
      "1503 Training Loss: 1.4260302782058716 Validation Loss: 1.125610589981079\n",
      "1504 Training Loss: 1.4174330234527588 Validation Loss: 1.1238797903060913\n",
      "1505 Training Loss: 1.4019925594329834 Validation Loss: 1.122281551361084\n",
      "1506 Training Loss: 1.40369713306427 Validation Loss: 1.1208240985870361\n",
      "1507 Training Loss: 1.410072922706604 Validation Loss: 1.1193052530288696\n",
      "1508 Training Loss: 1.4000167846679688 Validation Loss: 1.1179603338241577\n",
      "1509 Training Loss: 1.403869867324829 Validation Loss: 1.1167142391204834\n",
      "1510 Training Loss: 1.3940412998199463 Validation Loss: 1.1154634952545166\n",
      "1511 Training Loss: 1.3942173719406128 Validation Loss: 1.1142536401748657\n",
      "1512 Training Loss: 1.389938473701477 Validation Loss: 1.1132378578186035\n",
      "1513 Training Loss: 1.3907318115234375 Validation Loss: 1.1121087074279785\n",
      "1514 Training Loss: 1.3912345170974731 Validation Loss: 1.1107443571090698\n",
      "1515 Training Loss: 1.3788938522338867 Validation Loss: 1.10930597782135\n",
      "1516 Training Loss: 1.3753364086151123 Validation Loss: 1.108020544052124\n",
      "1517 Training Loss: 1.381916880607605 Validation Loss: 1.1065577268600464\n",
      "1518 Training Loss: 1.376800775527954 Validation Loss: 1.1049926280975342\n",
      "1519 Training Loss: 1.373943567276001 Validation Loss: 1.1033389568328857\n",
      "1520 Training Loss: 1.3677459955215454 Validation Loss: 1.101872205734253\n",
      "1521 Training Loss: 1.363645076751709 Validation Loss: 1.1004258394241333\n",
      "1522 Training Loss: 1.3669766187667847 Validation Loss: 1.0989981889724731\n",
      "1523 Training Loss: 1.3591797351837158 Validation Loss: 1.09763503074646\n",
      "1524 Training Loss: 1.3604736328125 Validation Loss: 1.0962846279144287\n",
      "1525 Training Loss: 1.357286810874939 Validation Loss: 1.094973087310791\n",
      "1526 Training Loss: 1.3531005382537842 Validation Loss: 1.0934783220291138\n",
      "1527 Training Loss: 1.3605912923812866 Validation Loss: 1.0916799306869507\n",
      "1528 Training Loss: 1.3516921997070312 Validation Loss: 1.0899927616119385\n",
      "1529 Training Loss: 1.3564497232437134 Validation Loss: 1.088308572769165\n",
      "1530 Training Loss: 1.3327585458755493 Validation Loss: 1.0867935419082642\n",
      "1531 Training Loss: 1.3355870246887207 Validation Loss: 1.0854324102401733\n",
      "1532 Training Loss: 1.334597110748291 Validation Loss: 1.083990216255188\n",
      "1533 Training Loss: 1.3407045602798462 Validation Loss: 1.0824871063232422\n",
      "1534 Training Loss: 1.3382232189178467 Validation Loss: 1.0809406042099\n",
      "1535 Training Loss: 1.3283830881118774 Validation Loss: 1.0792973041534424\n",
      "1536 Training Loss: 1.327133059501648 Validation Loss: 1.0774799585342407\n",
      "1537 Training Loss: 1.3306186199188232 Validation Loss: 1.0754151344299316\n",
      "1538 Training Loss: 1.3223756551742554 Validation Loss: 1.073411226272583\n",
      "1539 Training Loss: 1.3224140405654907 Validation Loss: 1.0713938474655151\n",
      "1540 Training Loss: 1.3180676698684692 Validation Loss: 1.069401741027832\n",
      "1541 Training Loss: 1.3211092948913574 Validation Loss: 1.0672893524169922\n",
      "1542 Training Loss: 1.3049044609069824 Validation Loss: 1.0652024745941162\n",
      "1543 Training Loss: 1.3022699356079102 Validation Loss: 1.0632754564285278\n",
      "1544 Training Loss: 1.3078454732894897 Validation Loss: 1.0611521005630493\n",
      "1545 Training Loss: 1.2878745794296265 Validation Loss: 1.0594213008880615\n",
      "1546 Training Loss: 1.3067090511322021 Validation Loss: 1.0576388835906982\n",
      "1547 Training Loss: 1.2995976209640503 Validation Loss: 1.055903673171997\n",
      "1548 Training Loss: 1.287869930267334 Validation Loss: 1.05438232421875\n",
      "1549 Training Loss: 1.2840715646743774 Validation Loss: 1.0530158281326294\n",
      "1550 Training Loss: 1.2894279956817627 Validation Loss: 1.0515316724777222\n",
      "1551 Training Loss: 1.2893192768096924 Validation Loss: 1.0499993562698364\n",
      "1552 Training Loss: 1.2893805503845215 Validation Loss: 1.0486280918121338\n",
      "1553 Training Loss: 1.290274739265442 Validation Loss: 1.0472381114959717\n",
      "1554 Training Loss: 1.2840800285339355 Validation Loss: 1.0458835363388062\n",
      "1555 Training Loss: 1.2755959033966064 Validation Loss: 1.0445656776428223\n",
      "1556 Training Loss: 1.2649849653244019 Validation Loss: 1.0435397624969482\n",
      "1557 Training Loss: 1.2737079858779907 Validation Loss: 1.0422067642211914\n",
      "1558 Training Loss: 1.2834737300872803 Validation Loss: 1.040587067604065\n",
      "1559 Training Loss: 1.2903550863265991 Validation Loss: 1.038788080215454\n",
      "1560 Training Loss: 1.2664545774459839 Validation Loss: 1.0371721982955933\n",
      "1561 Training Loss: 1.254612922668457 Validation Loss: 1.0358911752700806\n",
      "1562 Training Loss: 1.2611432075500488 Validation Loss: 1.034759283065796\n",
      "1563 Training Loss: 1.2536932229995728 Validation Loss: 1.0337727069854736\n",
      "1564 Training Loss: 1.2441561222076416 Validation Loss: 1.0329399108886719\n",
      "1565 Training Loss: 1.2441306114196777 Validation Loss: 1.0320580005645752\n",
      "1566 Training Loss: 1.2485010623931885 Validation Loss: 1.0312615633010864\n",
      "1567 Training Loss: 1.2352474927902222 Validation Loss: 1.0304617881774902\n",
      "1568 Training Loss: 1.2351560592651367 Validation Loss: 1.0294601917266846\n",
      "1569 Training Loss: 1.2241337299346924 Validation Loss: 1.0287708044052124\n",
      "1570 Training Loss: 1.2450473308563232 Validation Loss: 1.0279346704483032\n",
      "1571 Training Loss: 1.2427443265914917 Validation Loss: 1.0269801616668701\n",
      "1572 Training Loss: 1.2356951236724854 Validation Loss: 1.025604248046875\n",
      "1573 Training Loss: 1.2205923795700073 Validation Loss: 1.024289846420288\n",
      "1574 Training Loss: 1.221678376197815 Validation Loss: 1.0229380130767822\n",
      "1575 Training Loss: 1.2315952777862549 Validation Loss: 1.0212914943695068\n",
      "1576 Training Loss: 1.2126414775848389 Validation Loss: 1.0195928812026978\n",
      "1577 Training Loss: 1.2259607315063477 Validation Loss: 1.0178906917572021\n",
      "1578 Training Loss: 1.2112370729446411 Validation Loss: 1.016127109527588\n",
      "1579 Training Loss: 1.203273892402649 Validation Loss: 1.0142555236816406\n",
      "1580 Training Loss: 1.2117962837219238 Validation Loss: 1.0122936964035034\n",
      "1581 Training Loss: 1.208925724029541 Validation Loss: 1.010326623916626\n",
      "1582 Training Loss: 1.211884617805481 Validation Loss: 1.008185625076294\n",
      "1583 Training Loss: 1.1853216886520386 Validation Loss: 1.0064657926559448\n",
      "1584 Training Loss: 1.1942092180252075 Validation Loss: 1.0048924684524536\n",
      "1585 Training Loss: 1.1857249736785889 Validation Loss: 1.0034527778625488\n",
      "1586 Training Loss: 1.1841297149658203 Validation Loss: 1.002233624458313\n",
      "1587 Training Loss: 1.1875249147415161 Validation Loss: 1.0010055303573608\n",
      "1588 Training Loss: 1.1821035146713257 Validation Loss: 1.0000255107879639\n",
      "1589 Training Loss: 1.189566731452942 Validation Loss: 0.9988059997558594\n",
      "1590 Training Loss: 1.1813708543777466 Validation Loss: 0.9975317716598511\n",
      "1591 Training Loss: 1.182466745376587 Validation Loss: 0.9959050416946411\n",
      "1592 Training Loss: 1.1699817180633545 Validation Loss: 0.9942126274108887\n",
      "1593 Training Loss: 1.174953579902649 Validation Loss: 0.9924622178077698\n",
      "1594 Training Loss: 1.175746202468872 Validation Loss: 0.9905673265457153\n",
      "1595 Training Loss: 1.1616723537445068 Validation Loss: 0.9888301491737366\n",
      "1596 Training Loss: 1.1657487154006958 Validation Loss: 0.9872262477874756\n",
      "1597 Training Loss: 1.1670852899551392 Validation Loss: 0.9851581454277039\n",
      "1598 Training Loss: 1.1484875679016113 Validation Loss: 0.983346700668335\n",
      "1599 Training Loss: 1.146746039390564 Validation Loss: 0.9819130897521973\n",
      "1600 Training Loss: 1.167116641998291 Validation Loss: 0.9802119731903076\n",
      "1601 Training Loss: 1.1496143341064453 Validation Loss: 0.9783729314804077\n",
      "1602 Training Loss: 1.1600885391235352 Validation Loss: 0.9762523174285889\n",
      "1603 Training Loss: 1.142107605934143 Validation Loss: 0.9744173288345337\n",
      "1604 Training Loss: 1.146508812904358 Validation Loss: 0.9726166129112244\n",
      "1605 Training Loss: 1.1455440521240234 Validation Loss: 0.9707498550415039\n",
      "1606 Training Loss: 1.1426706314086914 Validation Loss: 0.9690098762512207\n",
      "1607 Training Loss: 1.1298314332962036 Validation Loss: 0.9675782918930054\n",
      "1608 Training Loss: 1.1408624649047852 Validation Loss: 0.9663327932357788\n",
      "1609 Training Loss: 1.1243016719818115 Validation Loss: 0.9650333523750305\n",
      "1610 Training Loss: 1.1276272535324097 Validation Loss: 0.9637465476989746\n",
      "1611 Training Loss: 1.1251137256622314 Validation Loss: 0.962365984916687\n",
      "1612 Training Loss: 1.10618257522583 Validation Loss: 0.9612260460853577\n",
      "1613 Training Loss: 1.1206637620925903 Validation Loss: 0.9601415991783142\n",
      "1614 Training Loss: 1.1110761165618896 Validation Loss: 0.9594322443008423\n",
      "1615 Training Loss: 1.1108797788619995 Validation Loss: 0.9587782621383667\n",
      "1616 Training Loss: 1.1056510210037231 Validation Loss: 0.9580154418945312\n",
      "1617 Training Loss: 1.0982295274734497 Validation Loss: 0.9571241736412048\n",
      "1618 Training Loss: 1.1068036556243896 Validation Loss: 0.9562131762504578\n",
      "1619 Training Loss: 1.0890820026397705 Validation Loss: 0.9554551839828491\n",
      "1620 Training Loss: 1.0905282497406006 Validation Loss: 0.9547562599182129\n",
      "1621 Training Loss: 1.0896331071853638 Validation Loss: 0.9539218544960022\n",
      "1622 Training Loss: 1.1029800176620483 Validation Loss: 0.9528040885925293\n",
      "1623 Training Loss: 1.1169036626815796 Validation Loss: 0.9511718153953552\n",
      "1624 Training Loss: 1.0996793508529663 Validation Loss: 0.9492230415344238\n",
      "1625 Training Loss: 1.1003074645996094 Validation Loss: 0.9472106695175171\n",
      "1626 Training Loss: 1.0791690349578857 Validation Loss: 0.9452028870582581\n",
      "1627 Training Loss: 1.0673879384994507 Validation Loss: 0.9434047937393188\n",
      "1628 Training Loss: 1.0761384963989258 Validation Loss: 0.9419507384300232\n",
      "1629 Training Loss: 1.0735381841659546 Validation Loss: 0.9402909278869629\n",
      "1630 Training Loss: 1.0809279680252075 Validation Loss: 0.9384415149688721\n",
      "1631 Training Loss: 1.0643601417541504 Validation Loss: 0.93647301197052\n",
      "1632 Training Loss: 1.0598036050796509 Validation Loss: 0.9347344040870667\n",
      "1633 Training Loss: 1.0560979843139648 Validation Loss: 0.9335209727287292\n",
      "1634 Training Loss: 1.079052448272705 Validation Loss: 0.9318783283233643\n",
      "1635 Training Loss: 1.0437625646591187 Validation Loss: 0.9302780628204346\n",
      "1636 Training Loss: 1.0492008924484253 Validation Loss: 0.9287511706352234\n",
      "1637 Training Loss: 1.0548542737960815 Validation Loss: 0.9273326396942139\n",
      "1638 Training Loss: 1.0503085851669312 Validation Loss: 0.9257284998893738\n",
      "1639 Training Loss: 1.046520709991455 Validation Loss: 0.9245907664299011\n",
      "1640 Training Loss: 1.054430603981018 Validation Loss: 0.9233660101890564\n",
      "1641 Training Loss: 1.043485164642334 Validation Loss: 0.9221889972686768\n",
      "1642 Training Loss: 1.051274299621582 Validation Loss: 0.9207392334938049\n",
      "1643 Training Loss: 1.0464204549789429 Validation Loss: 0.91889488697052\n",
      "1644 Training Loss: 1.0283747911453247 Validation Loss: 0.9173418879508972\n",
      "1645 Training Loss: 1.0235626697540283 Validation Loss: 0.9162910580635071\n",
      "1646 Training Loss: 1.0201239585876465 Validation Loss: 0.9155632257461548\n",
      "1647 Training Loss: 1.0212516784667969 Validation Loss: 0.9150040149688721\n",
      "1648 Training Loss: 1.0410839319229126 Validation Loss: 0.91379314661026\n",
      "1649 Training Loss: 1.00694739818573 Validation Loss: 0.9132465124130249\n",
      "1650 Training Loss: 1.0403255224227905 Validation Loss: 0.9121086597442627\n",
      "1651 Training Loss: 1.0206924676895142 Validation Loss: 0.9106894135475159\n",
      "1652 Training Loss: 1.004939079284668 Validation Loss: 0.9096658229827881\n",
      "1653 Training Loss: 1.007948637008667 Validation Loss: 0.9088286757469177\n",
      "1654 Training Loss: 1.0083833932876587 Validation Loss: 0.9080730676651001\n",
      "1655 Training Loss: 1.0085394382476807 Validation Loss: 0.9071259498596191\n",
      "1656 Training Loss: 1.0008022785186768 Validation Loss: 0.9062288999557495\n",
      "1657 Training Loss: 1.0092668533325195 Validation Loss: 0.90471351146698\n",
      "1658 Training Loss: 1.0037145614624023 Validation Loss: 0.9025775194168091\n",
      "1659 Training Loss: 0.9989665150642395 Validation Loss: 0.8997857570648193\n",
      "1660 Training Loss: 0.97662752866745 Validation Loss: 0.8973386287689209\n",
      "1661 Training Loss: 0.9897239208221436 Validation Loss: 0.8950812816619873\n",
      "1662 Training Loss: 0.995213508605957 Validation Loss: 0.8928617238998413\n",
      "1663 Training Loss: 1.0068001747131348 Validation Loss: 0.8903182744979858\n",
      "1664 Training Loss: 0.9971912503242493 Validation Loss: 0.887785792350769\n",
      "1665 Training Loss: 0.9750267863273621 Validation Loss: 0.8852846622467041\n",
      "1666 Training Loss: 0.9697693586349487 Validation Loss: 0.8836127519607544\n",
      "1667 Training Loss: 1.000494360923767 Validation Loss: 0.8816261887550354\n",
      "1668 Training Loss: 0.9761013388633728 Validation Loss: 0.8801302909851074\n",
      "1669 Training Loss: 0.9829930663108826 Validation Loss: 0.8788019418716431\n",
      "1670 Training Loss: 0.9674959778785706 Validation Loss: 0.8776302337646484\n",
      "1671 Training Loss: 0.9783424139022827 Validation Loss: 0.8761434555053711\n",
      "1672 Training Loss: 0.9693835377693176 Validation Loss: 0.8745537996292114\n",
      "1673 Training Loss: 0.9637498259544373 Validation Loss: 0.8727482557296753\n",
      "1674 Training Loss: 0.964205265045166 Validation Loss: 0.8710744380950928\n",
      "1675 Training Loss: 0.979322075843811 Validation Loss: 0.8694451451301575\n",
      "1676 Training Loss: 0.9550092816352844 Validation Loss: 0.8676508665084839\n",
      "1677 Training Loss: 0.9700016975402832 Validation Loss: 0.8659958243370056\n",
      "1678 Training Loss: 0.9642239212989807 Validation Loss: 0.8643770217895508\n",
      "1679 Training Loss: 0.9572734832763672 Validation Loss: 0.8628352880477905\n",
      "1680 Training Loss: 0.9589782953262329 Validation Loss: 0.861292839050293\n",
      "1681 Training Loss: 0.9540064930915833 Validation Loss: 0.8600035905838013\n",
      "1682 Training Loss: 0.9378366470336914 Validation Loss: 0.8590269088745117\n",
      "1683 Training Loss: 0.9466498494148254 Validation Loss: 0.8584681749343872\n",
      "1684 Training Loss: 0.9429442882537842 Validation Loss: 0.8572950959205627\n",
      "1685 Training Loss: 0.9297893047332764 Validation Loss: 0.8564839363098145\n",
      "1686 Training Loss: 0.929669201374054 Validation Loss: 0.8556502461433411\n",
      "1687 Training Loss: 0.9488909840583801 Validation Loss: 0.8545706272125244\n",
      "1688 Training Loss: 0.9301264882087708 Validation Loss: 0.8532979488372803\n",
      "1689 Training Loss: 0.9081571698188782 Validation Loss: 0.8519558906555176\n",
      "1690 Training Loss: 0.9153866767883301 Validation Loss: 0.8507678508758545\n",
      "1691 Training Loss: 0.9093230962753296 Validation Loss: 0.8503697514533997\n",
      "1692 Training Loss: 0.9151701927185059 Validation Loss: 0.8499800562858582\n",
      "1693 Training Loss: 0.9159048199653625 Validation Loss: 0.8490282297134399\n",
      "1694 Training Loss: 0.9123013019561768 Validation Loss: 0.8480715751647949\n",
      "1695 Training Loss: 0.9103885889053345 Validation Loss: 0.8467904329299927\n",
      "1696 Training Loss: 0.9375027418136597 Validation Loss: 0.8453500270843506\n",
      "1697 Training Loss: 0.924983561038971 Validation Loss: 0.8438247442245483\n",
      "1698 Training Loss: 0.9306390285491943 Validation Loss: 0.8416824340820312\n",
      "1699 Training Loss: 0.8993707895278931 Validation Loss: 0.8397523760795593\n",
      "1700 Training Loss: 0.9144974946975708 Validation Loss: 0.8370358347892761\n",
      "1701 Training Loss: 0.913672924041748 Validation Loss: 0.8349086046218872\n",
      "1702 Training Loss: 0.8953721523284912 Validation Loss: 0.8330366015434265\n",
      "1703 Training Loss: 0.9196858406066895 Validation Loss: 0.8311814665794373\n",
      "1704 Training Loss: 0.8739925622940063 Validation Loss: 0.8299293518066406\n",
      "1705 Training Loss: 0.8924489617347717 Validation Loss: 0.8285034894943237\n",
      "1706 Training Loss: 0.8791796565055847 Validation Loss: 0.8277719020843506\n",
      "1707 Training Loss: 0.8811354041099548 Validation Loss: 0.8275779485702515\n",
      "1708 Training Loss: 0.9019379019737244 Validation Loss: 0.8275389671325684\n",
      "1709 Training Loss: 0.9033523797988892 Validation Loss: 0.8272662162780762\n",
      "1710 Training Loss: 0.8874502182006836 Validation Loss: 0.8261610269546509\n",
      "1711 Training Loss: 0.8735666275024414 Validation Loss: 0.8257342576980591\n",
      "1712 Training Loss: 0.8676092028617859 Validation Loss: 0.8245561718940735\n",
      "1713 Training Loss: 0.8655277490615845 Validation Loss: 0.8233607411384583\n",
      "1714 Training Loss: 0.8703058362007141 Validation Loss: 0.8221290111541748\n",
      "1715 Training Loss: 0.8865914344787598 Validation Loss: 0.8197407126426697\n",
      "1716 Training Loss: 0.8562973737716675 Validation Loss: 0.8176719546318054\n",
      "1717 Training Loss: 0.8247886300086975 Validation Loss: 0.8172723054885864\n",
      "1718 Training Loss: 0.8755862712860107 Validation Loss: 0.8170355558395386\n",
      "1719 Training Loss: 0.8553190231323242 Validation Loss: 0.8169243335723877\n",
      "1720 Training Loss: 0.8529286980628967 Validation Loss: 0.8165772557258606\n",
      "1721 Training Loss: 0.825108528137207 Validation Loss: 0.8168050050735474\n",
      "1722 Training Loss: 0.8305387496948242 Validation Loss: 0.817449688911438\n",
      "1723 Training Loss: 0.8138073682785034 Validation Loss: 0.8192448019981384\n",
      "1724 Training Loss: 0.8472636938095093 Validation Loss: 0.820425271987915\n",
      "1725 Training Loss: 0.8527778387069702 Validation Loss: 0.8207235336303711\n",
      "1726 Training Loss: 0.8391316533088684 Validation Loss: 0.8203938007354736\n",
      "1727 Training Loss: 0.8381032347679138 Validation Loss: 0.8196514844894409\n",
      "1728 Training Loss: 0.8418864011764526 Validation Loss: 0.8184395432472229\n",
      "1729 Training Loss: 0.8603190183639526 Validation Loss: 0.8158620595932007\n",
      "1730 Training Loss: 0.8322627544403076 Validation Loss: 0.8132193088531494\n",
      "1731 Training Loss: 0.8171761631965637 Validation Loss: 0.8105794191360474\n",
      "1732 Training Loss: 0.8739817142486572 Validation Loss: 0.8079041242599487\n",
      "1733 Training Loss: 0.8332375288009644 Validation Loss: 0.8052722215652466\n",
      "1734 Training Loss: 0.8202871680259705 Validation Loss: 0.8020570874214172\n",
      "1735 Training Loss: 0.8001356720924377 Validation Loss: 0.7991514801979065\n",
      "1736 Training Loss: 0.8280343413352966 Validation Loss: 0.7963330745697021\n",
      "1737 Training Loss: 0.8380561470985413 Validation Loss: 0.7925100922584534\n",
      "1738 Training Loss: 0.8019096851348877 Validation Loss: 0.7898201942443848\n",
      "1739 Training Loss: 0.8023272752761841 Validation Loss: 0.7874761819839478\n",
      "1740 Training Loss: 0.8355353474617004 Validation Loss: 0.7851155400276184\n",
      "1741 Training Loss: 0.827828586101532 Validation Loss: 0.7825237512588501\n",
      "1742 Training Loss: 0.816399872303009 Validation Loss: 0.779706597328186\n",
      "1743 Training Loss: 0.8104013204574585 Validation Loss: 0.7773029804229736\n",
      "1744 Training Loss: 0.8318887948989868 Validation Loss: 0.7751326560974121\n",
      "1745 Training Loss: 0.8116735219955444 Validation Loss: 0.7730368375778198\n",
      "1746 Training Loss: 0.838312566280365 Validation Loss: 0.7702639698982239\n",
      "1747 Training Loss: 0.7844821810722351 Validation Loss: 0.7689529061317444\n",
      "1748 Training Loss: 0.7710361480712891 Validation Loss: 0.7687116861343384\n",
      "1749 Training Loss: 0.7792484760284424 Validation Loss: 0.7692247629165649\n",
      "1750 Training Loss: 0.8041984438896179 Validation Loss: 0.7699631452560425\n",
      "1751 Training Loss: 0.8131146430969238 Validation Loss: 0.770383358001709\n",
      "1752 Training Loss: 0.791640043258667 Validation Loss: 0.7704992294311523\n",
      "1753 Training Loss: 0.793607771396637 Validation Loss: 0.7704493999481201\n",
      "1754 Training Loss: 0.7707461714744568 Validation Loss: 0.7712266445159912\n",
      "1755 Training Loss: 0.7783479690551758 Validation Loss: 0.771920382976532\n",
      "1756 Training Loss: 0.7842766046524048 Validation Loss: 0.772234320640564\n",
      "1757 Training Loss: 0.8125325441360474 Validation Loss: 0.7712008357048035\n",
      "1758 Training Loss: 0.8049042224884033 Validation Loss: 0.7692293524742126\n",
      "1759 Training Loss: 0.7745112180709839 Validation Loss: 0.7666285037994385\n",
      "1760 Training Loss: 0.7776243686676025 Validation Loss: 0.7639954090118408\n",
      "1761 Training Loss: 0.7601641416549683 Validation Loss: 0.7626100778579712\n",
      "1762 Training Loss: 0.7864561676979065 Validation Loss: 0.760249137878418\n",
      "1763 Training Loss: 0.7790253758430481 Validation Loss: 0.7569366097450256\n",
      "1764 Training Loss: 0.7939329743385315 Validation Loss: 0.7530574798583984\n",
      "1765 Training Loss: 0.7510152459144592 Validation Loss: 0.7499333620071411\n",
      "1766 Training Loss: 0.7477014064788818 Validation Loss: 0.747573733329773\n",
      "1767 Training Loss: 0.7583839893341064 Validation Loss: 0.7458429932594299\n",
      "1768 Training Loss: 0.7373217940330505 Validation Loss: 0.7447722554206848\n",
      "1769 Training Loss: 0.7838137745857239 Validation Loss: 0.7433139085769653\n",
      "1770 Training Loss: 0.7246351838111877 Validation Loss: 0.7434054613113403\n",
      "1771 Training Loss: 0.7895988821983337 Validation Loss: 0.7425984740257263\n",
      "1772 Training Loss: 0.7422831058502197 Validation Loss: 0.742150068283081\n",
      "1773 Training Loss: 0.7488352656364441 Validation Loss: 0.7420967221260071\n",
      "1774 Training Loss: 0.7411049604415894 Validation Loss: 0.7422116994857788\n",
      "1775 Training Loss: 0.7471890449523926 Validation Loss: 0.7421900629997253\n",
      "1776 Training Loss: 0.7244476079940796 Validation Loss: 0.7427062392234802\n",
      "1777 Training Loss: 0.7286622524261475 Validation Loss: 0.7432785034179688\n",
      "1778 Training Loss: 0.7299098372459412 Validation Loss: 0.7438329458236694\n",
      "1779 Training Loss: 0.7592997550964355 Validation Loss: 0.743160605430603\n",
      "1780 Training Loss: 0.7565049529075623 Validation Loss: 0.7415543794631958\n",
      "1781 Training Loss: 0.7421689033508301 Validation Loss: 0.7395763993263245\n",
      "1782 Training Loss: 0.7367382049560547 Validation Loss: 0.7375534772872925\n",
      "1783 Training Loss: 0.7168068885803223 Validation Loss: 0.7360256910324097\n",
      "1784 Training Loss: 0.7400885224342346 Validation Loss: 0.733635425567627\n",
      "1785 Training Loss: 0.7276418209075928 Validation Loss: 0.7320822477340698\n",
      "1786 Training Loss: 0.6963208317756653 Validation Loss: 0.7312790751457214\n",
      "1787 Training Loss: 0.7264246940612793 Validation Loss: 0.7299409508705139\n",
      "1788 Training Loss: 0.7332361340522766 Validation Loss: 0.7293169498443604\n",
      "1789 Training Loss: 0.7098860144615173 Validation Loss: 0.7285090088844299\n",
      "1790 Training Loss: 0.6947637796401978 Validation Loss: 0.7284384965896606\n",
      "1791 Training Loss: 0.726775586605072 Validation Loss: 0.7272543907165527\n",
      "1792 Training Loss: 0.7149887084960938 Validation Loss: 0.7264151573181152\n",
      "1793 Training Loss: 0.7206542491912842 Validation Loss: 0.7255345582962036\n",
      "1794 Training Loss: 0.7341923117637634 Validation Loss: 0.72297203540802\n",
      "1795 Training Loss: 0.7218663692474365 Validation Loss: 0.7201212048530579\n",
      "1796 Training Loss: 0.7095749974250793 Validation Loss: 0.7166185975074768\n",
      "1797 Training Loss: 0.7112134695053101 Validation Loss: 0.7127495408058167\n",
      "1798 Training Loss: 0.682223379611969 Validation Loss: 0.7101342678070068\n",
      "1799 Training Loss: 0.7442159652709961 Validation Loss: 0.7061640024185181\n",
      "1800 Training Loss: 0.6917043924331665 Validation Loss: 0.7034523487091064\n",
      "1801 Training Loss: 0.6805510520935059 Validation Loss: 0.7021958231925964\n",
      "1802 Training Loss: 0.7044108510017395 Validation Loss: 0.7010588645935059\n",
      "1803 Training Loss: 0.6889917850494385 Validation Loss: 0.700924813747406\n",
      "1804 Training Loss: 0.7115680575370789 Validation Loss: 0.700420618057251\n",
      "1805 Training Loss: 0.6976285576820374 Validation Loss: 0.6998685598373413\n",
      "1806 Training Loss: 0.6992728114128113 Validation Loss: 0.6989355087280273\n",
      "1807 Training Loss: 0.6756995320320129 Validation Loss: 0.6993738412857056\n",
      "1808 Training Loss: 0.6700137853622437 Validation Loss: 0.7009662985801697\n",
      "1809 Training Loss: 0.6899032592773438 Validation Loss: 0.7025429010391235\n",
      "1810 Training Loss: 0.6648626327514648 Validation Loss: 0.7043156623840332\n",
      "1811 Training Loss: 0.668402373790741 Validation Loss: 0.7067623734474182\n",
      "1812 Training Loss: 0.6931930780410767 Validation Loss: 0.7073626518249512\n",
      "1813 Training Loss: 0.6704443693161011 Validation Loss: 0.7076142430305481\n",
      "1814 Training Loss: 0.6590939164161682 Validation Loss: 0.7075735330581665\n",
      "1815 Training Loss: 0.6883639097213745 Validation Loss: 0.7069946527481079\n",
      "1816 Training Loss: 0.658473551273346 Validation Loss: 0.7063761949539185\n",
      "1817 Training Loss: 0.6655453443527222 Validation Loss: 0.7049749493598938\n",
      "1818 Training Loss: 0.6975871324539185 Validation Loss: 0.7020124197006226\n",
      "1819 Training Loss: 0.6529128551483154 Validation Loss: 0.6990776062011719\n",
      "1820 Training Loss: 0.6712527275085449 Validation Loss: 0.6953375339508057\n",
      "1821 Training Loss: 0.6838275194168091 Validation Loss: 0.691261887550354\n",
      "1822 Training Loss: 0.6957094669342041 Validation Loss: 0.6850488781929016\n",
      "1823 Training Loss: 0.6551982760429382 Validation Loss: 0.6796677112579346\n",
      "1824 Training Loss: 0.658293604850769 Validation Loss: 0.6746665239334106\n",
      "1825 Training Loss: 0.6711550354957581 Validation Loss: 0.6705450415611267\n",
      "1826 Training Loss: 0.640026330947876 Validation Loss: 0.6671038866043091\n",
      "1827 Training Loss: 0.6557205319404602 Validation Loss: 0.6648510694503784\n",
      "1828 Training Loss: 0.6397644281387329 Validation Loss: 0.6632057428359985\n",
      "1829 Training Loss: 0.6367447376251221 Validation Loss: 0.6628509759902954\n",
      "1830 Training Loss: 0.6589537858963013 Validation Loss: 0.6639366745948792\n",
      "1831 Training Loss: 0.61940598487854 Validation Loss: 0.6661429405212402\n",
      "1832 Training Loss: 0.6598692536354065 Validation Loss: 0.668061375617981\n",
      "1833 Training Loss: 0.6690281629562378 Validation Loss: 0.6698653697967529\n",
      "1834 Training Loss: 0.6379126310348511 Validation Loss: 0.6724520325660706\n",
      "1835 Training Loss: 0.6253617405891418 Validation Loss: 0.6748001575469971\n",
      "1836 Training Loss: 0.6162198781967163 Validation Loss: 0.6768114566802979\n",
      "1837 Training Loss: 0.6545065641403198 Validation Loss: 0.6770254373550415\n",
      "1838 Training Loss: 0.62950199842453 Validation Loss: 0.6772973537445068\n",
      "1839 Training Loss: 0.6627206206321716 Validation Loss: 0.6762846112251282\n",
      "1840 Training Loss: 0.5945857167243958 Validation Loss: 0.6761940717697144\n",
      "1841 Training Loss: 0.6211920976638794 Validation Loss: 0.6753814220428467\n",
      "1842 Training Loss: 0.6348605751991272 Validation Loss: 0.6733331680297852\n",
      "1843 Training Loss: 0.5912265181541443 Validation Loss: 0.6714476346969604\n",
      "1844 Training Loss: 0.6307873725891113 Validation Loss: 0.6684839129447937\n",
      "1845 Training Loss: 0.6075867414474487 Validation Loss: 0.6648688912391663\n",
      "1846 Training Loss: 0.6165133714675903 Validation Loss: 0.6613719463348389\n",
      "1847 Training Loss: 0.6449511051177979 Validation Loss: 0.6575124263763428\n",
      "1848 Training Loss: 0.6014986634254456 Validation Loss: 0.6546062231063843\n",
      "1849 Training Loss: 0.6365458369255066 Validation Loss: 0.6515179872512817\n",
      "1850 Training Loss: 0.5930259823799133 Validation Loss: 0.6499974131584167\n",
      "1851 Training Loss: 0.574124813079834 Validation Loss: 0.6494594216346741\n",
      "1852 Training Loss: 0.6062843799591064 Validation Loss: 0.6489640474319458\n",
      "1853 Training Loss: 0.5956071019172668 Validation Loss: 0.6487857103347778\n",
      "1854 Training Loss: 0.6102504730224609 Validation Loss: 0.6472711563110352\n",
      "1855 Training Loss: 0.6005077362060547 Validation Loss: 0.6466774940490723\n",
      "1856 Training Loss: 0.5801262259483337 Validation Loss: 0.647386908531189\n",
      "1857 Training Loss: 0.5849369764328003 Validation Loss: 0.6490538716316223\n",
      "1858 Training Loss: 0.5811764001846313 Validation Loss: 0.6512908935546875\n",
      "1859 Training Loss: 0.5801190137863159 Validation Loss: 0.6534761786460876\n",
      "1860 Training Loss: 0.6016241908073425 Validation Loss: 0.653853178024292\n",
      "1861 Training Loss: 0.6022024750709534 Validation Loss: 0.6543512344360352\n",
      "1862 Training Loss: 0.6186411380767822 Validation Loss: 0.6534183025360107\n",
      "1863 Training Loss: 0.5758687257766724 Validation Loss: 0.6529504060745239\n",
      "1864 Training Loss: 0.5719170570373535 Validation Loss: 0.6522164344787598\n",
      "1865 Training Loss: 0.5718111395835876 Validation Loss: 0.6521669030189514\n",
      "1866 Training Loss: 0.5840296745300293 Validation Loss: 0.6521177291870117\n",
      "1867 Training Loss: 0.5865582823753357 Validation Loss: 0.6509684324264526\n",
      "1868 Training Loss: 0.593193769454956 Validation Loss: 0.6483181715011597\n",
      "1869 Training Loss: 0.5870891213417053 Validation Loss: 0.6449804306030273\n",
      "1870 Training Loss: 0.5775631666183472 Validation Loss: 0.6412126421928406\n",
      "1871 Training Loss: 0.581501305103302 Validation Loss: 0.6385276317596436\n",
      "1872 Training Loss: 0.5739002823829651 Validation Loss: 0.6358859539031982\n",
      "1873 Training Loss: 0.5677244067192078 Validation Loss: 0.6326255202293396\n",
      "1874 Training Loss: 0.5700579285621643 Validation Loss: 0.6296080350875854\n",
      "1875 Training Loss: 0.5905232429504395 Validation Loss: 0.6265653371810913\n",
      "1876 Training Loss: 0.5805888772010803 Validation Loss: 0.6242682933807373\n",
      "1877 Training Loss: 0.5785512328147888 Validation Loss: 0.6215379238128662\n",
      "1878 Training Loss: 0.5492892861366272 Validation Loss: 0.6198539733886719\n",
      "1879 Training Loss: 0.5405393242835999 Validation Loss: 0.6191539764404297\n",
      "1880 Training Loss: 0.5650851726531982 Validation Loss: 0.6186480522155762\n",
      "1881 Training Loss: 0.5736383199691772 Validation Loss: 0.6187242269515991\n",
      "1882 Training Loss: 0.5648737549781799 Validation Loss: 0.6184383630752563\n",
      "1883 Training Loss: 0.576431155204773 Validation Loss: 0.6174376010894775\n",
      "1884 Training Loss: 0.5524791479110718 Validation Loss: 0.6168094873428345\n",
      "1885 Training Loss: 0.5649824738502502 Validation Loss: 0.6169630289077759\n",
      "1886 Training Loss: 0.5778708457946777 Validation Loss: 0.6161878108978271\n",
      "1887 Training Loss: 0.5712829232215881 Validation Loss: 0.6146251559257507\n",
      "1888 Training Loss: 0.5462661385536194 Validation Loss: 0.6134969592094421\n",
      "1889 Training Loss: 0.5304361581802368 Validation Loss: 0.6139089465141296\n",
      "1890 Training Loss: 0.5450807809829712 Validation Loss: 0.6141477823257446\n",
      "1891 Training Loss: 0.5702366828918457 Validation Loss: 0.6133104562759399\n",
      "1892 Training Loss: 0.5490235090255737 Validation Loss: 0.6123617887496948\n",
      "1893 Training Loss: 0.5429825782775879 Validation Loss: 0.6116429567337036\n",
      "1894 Training Loss: 0.5485685467720032 Validation Loss: 0.6097636222839355\n",
      "1895 Training Loss: 0.5711963772773743 Validation Loss: 0.6070510149002075\n",
      "1896 Training Loss: 0.5493144392967224 Validation Loss: 0.6053953766822815\n",
      "1897 Training Loss: 0.5442977547645569 Validation Loss: 0.604672908782959\n",
      "1898 Training Loss: 0.5497035980224609 Validation Loss: 0.6038808822631836\n",
      "1899 Training Loss: 0.5411442518234253 Validation Loss: 0.6031837463378906\n",
      "1900 Training Loss: 0.5135549306869507 Validation Loss: 0.6039317846298218\n",
      "1901 Training Loss: 0.5169192552566528 Validation Loss: 0.6048875451087952\n",
      "1902 Training Loss: 0.551321268081665 Validation Loss: 0.6047821640968323\n",
      "1903 Training Loss: 0.517080545425415 Validation Loss: 0.6055853366851807\n",
      "1904 Training Loss: 0.5418157577514648 Validation Loss: 0.6065741181373596\n",
      "1905 Training Loss: 0.5155600309371948 Validation Loss: 0.6077532768249512\n",
      "1906 Training Loss: 0.5467368364334106 Validation Loss: 0.6086527109146118\n",
      "1907 Training Loss: 0.5530152320861816 Validation Loss: 0.6083372235298157\n",
      "1908 Training Loss: 0.5139975547790527 Validation Loss: 0.6084299087524414\n",
      "1909 Training Loss: 0.500104546546936 Validation Loss: 0.607311487197876\n",
      "1910 Training Loss: 0.5128276348114014 Validation Loss: 0.6057136058807373\n",
      "1911 Training Loss: 0.5221782922744751 Validation Loss: 0.6020259857177734\n",
      "1912 Training Loss: 0.5116497874259949 Validation Loss: 0.5989025831222534\n",
      "1913 Training Loss: 0.5301669239997864 Validation Loss: 0.5948882102966309\n",
      "1914 Training Loss: 0.528403639793396 Validation Loss: 0.5901558995246887\n",
      "1915 Training Loss: 0.5142247080802917 Validation Loss: 0.5860762596130371\n",
      "1916 Training Loss: 0.5408213138580322 Validation Loss: 0.5813839435577393\n",
      "1917 Training Loss: 0.5111606121063232 Validation Loss: 0.5770838260650635\n",
      "1918 Training Loss: 0.48987776041030884 Validation Loss: 0.5751405954360962\n",
      "1919 Training Loss: 0.5145729780197144 Validation Loss: 0.5735265016555786\n",
      "1920 Training Loss: 0.5052669048309326 Validation Loss: 0.5729660987854004\n",
      "1921 Training Loss: 0.5326672792434692 Validation Loss: 0.5709555149078369\n",
      "1922 Training Loss: 0.5078690648078918 Validation Loss: 0.5695240497589111\n",
      "1923 Training Loss: 0.49258530139923096 Validation Loss: 0.5695874691009521\n",
      "1924 Training Loss: 0.4925381541252136 Validation Loss: 0.5704045295715332\n",
      "1925 Training Loss: 0.5099190473556519 Validation Loss: 0.5714609622955322\n",
      "1926 Training Loss: 0.5005855560302734 Validation Loss: 0.5733537673950195\n",
      "1927 Training Loss: 0.5352808237075806 Validation Loss: 0.5745303630828857\n",
      "1928 Training Loss: 0.5202056169509888 Validation Loss: 0.5747028589248657\n",
      "1929 Training Loss: 0.5267819762229919 Validation Loss: 0.5742493867874146\n",
      "1930 Training Loss: 0.5287885665893555 Validation Loss: 0.5719074010848999\n",
      "1931 Training Loss: 0.5195832848548889 Validation Loss: 0.5687949657440186\n",
      "1932 Training Loss: 0.489977091550827 Validation Loss: 0.5672281980514526\n",
      "1933 Training Loss: 0.4770488142967224 Validation Loss: 0.566614031791687\n",
      "1934 Training Loss: 0.5083665251731873 Validation Loss: 0.565517783164978\n",
      "1935 Training Loss: 0.49356579780578613 Validation Loss: 0.5649231672286987\n",
      "1936 Training Loss: 0.504417896270752 Validation Loss: 0.563141405582428\n",
      "1937 Training Loss: 0.4824158847332001 Validation Loss: 0.562008261680603\n",
      "1938 Training Loss: 0.5294366478919983 Validation Loss: 0.5588229894638062\n",
      "1939 Training Loss: 0.4832319915294647 Validation Loss: 0.5562145113945007\n",
      "1940 Training Loss: 0.514634370803833 Validation Loss: 0.5543532371520996\n",
      "1941 Training Loss: 0.48605015873908997 Validation Loss: 0.5524560213088989\n",
      "1942 Training Loss: 0.46697643399238586 Validation Loss: 0.5512393712997437\n",
      "1943 Training Loss: 0.4816170036792755 Validation Loss: 0.5509984493255615\n",
      "1944 Training Loss: 0.5000137090682983 Validation Loss: 0.5506151914596558\n",
      "1945 Training Loss: 0.4698263108730316 Validation Loss: 0.5503408908843994\n",
      "1946 Training Loss: 0.4463338553905487 Validation Loss: 0.5512197017669678\n",
      "1947 Training Loss: 0.4787699282169342 Validation Loss: 0.5523537397384644\n",
      "1948 Training Loss: 0.4587796628475189 Validation Loss: 0.5535730123519897\n",
      "1949 Training Loss: 0.45294463634490967 Validation Loss: 0.5553873777389526\n",
      "1950 Training Loss: 0.4678730368614197 Validation Loss: 0.5577434301376343\n",
      "1951 Training Loss: 0.49133777618408203 Validation Loss: 0.5596107244491577\n",
      "1952 Training Loss: 0.4428832530975342 Validation Loss: 0.5623511075973511\n",
      "1953 Training Loss: 0.4689556956291199 Validation Loss: 0.5635131001472473\n",
      "1954 Training Loss: 0.4890732169151306 Validation Loss: 0.5636650919914246\n",
      "1955 Training Loss: 0.5027763247489929 Validation Loss: 0.561805009841919\n",
      "1956 Training Loss: 0.4611392021179199 Validation Loss: 0.5590165853500366\n",
      "1957 Training Loss: 0.4733542501926422 Validation Loss: 0.5560277104377747\n",
      "1958 Training Loss: 0.4449179172515869 Validation Loss: 0.5536683797836304\n",
      "1959 Training Loss: 0.43232157826423645 Validation Loss: 0.5520654320716858\n",
      "1960 Training Loss: 0.4505208134651184 Validation Loss: 0.5515336394309998\n",
      "1961 Training Loss: 0.46944600343704224 Validation Loss: 0.5503923892974854\n",
      "1962 Training Loss: 0.4692766070365906 Validation Loss: 0.5473266839981079\n",
      "1963 Training Loss: 0.4568067491054535 Validation Loss: 0.5446580052375793\n",
      "1964 Training Loss: 0.4717315137386322 Validation Loss: 0.5405557751655579\n",
      "1965 Training Loss: 0.47161224484443665 Validation Loss: 0.5352144241333008\n",
      "1966 Training Loss: 0.45727288722991943 Validation Loss: 0.5308887958526611\n",
      "1967 Training Loss: 0.46151646971702576 Validation Loss: 0.5264172554016113\n",
      "1968 Training Loss: 0.4400901198387146 Validation Loss: 0.5232751965522766\n",
      "1969 Training Loss: 0.4559110701084137 Validation Loss: 0.5207711458206177\n",
      "1970 Training Loss: 0.4509940445423126 Validation Loss: 0.5200493335723877\n",
      "1971 Training Loss: 0.44239184260368347 Validation Loss: 0.5201376676559448\n",
      "1972 Training Loss: 0.46424126625061035 Validation Loss: 0.5203529596328735\n",
      "1973 Training Loss: 0.4643383026123047 Validation Loss: 0.5193277597427368\n",
      "1974 Training Loss: 0.4575776755809784 Validation Loss: 0.5186762809753418\n",
      "1975 Training Loss: 0.4644109904766083 Validation Loss: 0.5174374580383301\n",
      "1976 Training Loss: 0.42843320965766907 Validation Loss: 0.5176631212234497\n",
      "1977 Training Loss: 0.47520652413368225 Validation Loss: 0.5162138342857361\n",
      "1978 Training Loss: 0.4467998445034027 Validation Loss: 0.5154187679290771\n",
      "1979 Training Loss: 0.4468590021133423 Validation Loss: 0.51398766040802\n",
      "1980 Training Loss: 0.4330252707004547 Validation Loss: 0.5138155817985535\n",
      "1981 Training Loss: 0.4364367723464966 Validation Loss: 0.5137687921524048\n",
      "1982 Training Loss: 0.4630950093269348 Validation Loss: 0.5134142637252808\n",
      "1983 Training Loss: 0.4317983388900757 Validation Loss: 0.5136454105377197\n",
      "1984 Training Loss: 0.4095621705055237 Validation Loss: 0.5148216485977173\n",
      "1985 Training Loss: 0.45276781916618347 Validation Loss: 0.5157967805862427\n",
      "1986 Training Loss: 0.4411813020706177 Validation Loss: 0.5165293216705322\n",
      "1987 Training Loss: 0.4250306189060211 Validation Loss: 0.5183651447296143\n",
      "1988 Training Loss: 0.41338247060775757 Validation Loss: 0.5207195281982422\n",
      "1989 Training Loss: 0.46153736114501953 Validation Loss: 0.5215249061584473\n",
      "1990 Training Loss: 0.4082493484020233 Validation Loss: 0.5238735675811768\n",
      "1991 Training Loss: 0.45695844292640686 Validation Loss: 0.5247102975845337\n",
      "1992 Training Loss: 0.4644013047218323 Validation Loss: 0.5217312574386597\n",
      "1993 Training Loss: 0.4222452938556671 Validation Loss: 0.5180149674415588\n",
      "1994 Training Loss: 0.46116504073143005 Validation Loss: 0.5131217837333679\n",
      "1995 Training Loss: 0.4422164559364319 Validation Loss: 0.507339358329773\n",
      "1996 Training Loss: 0.41210347414016724 Validation Loss: 0.5024418234825134\n",
      "1997 Training Loss: 0.42496776580810547 Validation Loss: 0.4975034296512604\n",
      "1998 Training Loss: 0.4324304461479187 Validation Loss: 0.49309515953063965\n",
      "1999 Training Loss: 0.4509502947330475 Validation Loss: 0.48867228627204895\n",
      "2000 Training Loss: 0.42238932847976685 Validation Loss: 0.48560333251953125\n",
      "2001 Training Loss: 0.40718674659729004 Validation Loss: 0.48442161083221436\n",
      "2002 Training Loss: 0.42774975299835205 Validation Loss: 0.483833372592926\n",
      "2003 Training Loss: 0.41749444603919983 Validation Loss: 0.4843830466270447\n",
      "2004 Training Loss: 0.4156809449195862 Validation Loss: 0.4853200912475586\n",
      "2005 Training Loss: 0.4045867621898651 Validation Loss: 0.4872519373893738\n",
      "2006 Training Loss: 0.41678887605667114 Validation Loss: 0.48937422037124634\n",
      "2007 Training Loss: 0.39754244685173035 Validation Loss: 0.49209266901016235\n",
      "2008 Training Loss: 0.39043307304382324 Validation Loss: 0.49646487832069397\n",
      "2009 Training Loss: 0.43067964911460876 Validation Loss: 0.49905696511268616\n",
      "2010 Training Loss: 0.4327070415019989 Validation Loss: 0.5018846988677979\n",
      "2011 Training Loss: 0.38427454233169556 Validation Loss: 0.5054010152816772\n",
      "2012 Training Loss: 0.39792612195014954 Validation Loss: 0.5079485774040222\n",
      "2013 Training Loss: 0.4079785645008087 Validation Loss: 0.5085041522979736\n",
      "2014 Training Loss: 0.40637728571891785 Validation Loss: 0.5075222849845886\n",
      "2015 Training Loss: 0.41246992349624634 Validation Loss: 0.5045816898345947\n",
      "2016 Training Loss: 0.44622495770454407 Validation Loss: 0.49784597754478455\n",
      "2017 Training Loss: 0.40452903509140015 Validation Loss: 0.49192124605178833\n",
      "2018 Training Loss: 0.3862398862838745 Validation Loss: 0.48780086636543274\n",
      "2019 Training Loss: 0.4033433794975281 Validation Loss: 0.4831497073173523\n",
      "2020 Training Loss: 0.4097716212272644 Validation Loss: 0.47928130626678467\n",
      "2021 Training Loss: 0.3871062994003296 Validation Loss: 0.47620928287506104\n",
      "2022 Training Loss: 0.3860918879508972 Validation Loss: 0.47419312596321106\n",
      "2023 Training Loss: 0.3993677496910095 Validation Loss: 0.4714377820491791\n",
      "2024 Training Loss: 0.4025525450706482 Validation Loss: 0.46940112113952637\n",
      "2025 Training Loss: 0.4068545699119568 Validation Loss: 0.4674362540245056\n",
      "2026 Training Loss: 0.4163658022880554 Validation Loss: 0.4655380845069885\n",
      "2027 Training Loss: 0.38231849670410156 Validation Loss: 0.4647541046142578\n",
      "2028 Training Loss: 0.4217645525932312 Validation Loss: 0.46335849165916443\n",
      "2029 Training Loss: 0.4026535153388977 Validation Loss: 0.46276235580444336\n",
      "2030 Training Loss: 0.38797980546951294 Validation Loss: 0.46247953176498413\n",
      "2031 Training Loss: 0.40602758526802063 Validation Loss: 0.462441623210907\n",
      "2032 Training Loss: 0.38335731625556946 Validation Loss: 0.4635965824127197\n",
      "2033 Training Loss: 0.3730144500732422 Validation Loss: 0.4656466245651245\n",
      "2034 Training Loss: 0.4016686677932739 Validation Loss: 0.46739423274993896\n",
      "2035 Training Loss: 0.3707830011844635 Validation Loss: 0.4700525999069214\n",
      "2036 Training Loss: 0.42489463090896606 Validation Loss: 0.4705936312675476\n",
      "2037 Training Loss: 0.3658955693244934 Validation Loss: 0.47101739048957825\n",
      "2038 Training Loss: 0.3927356004714966 Validation Loss: 0.470464289188385\n",
      "2039 Training Loss: 0.41594934463500977 Validation Loss: 0.4682936668395996\n",
      "2040 Training Loss: 0.39807912707328796 Validation Loss: 0.46560049057006836\n",
      "2041 Training Loss: 0.3738919496536255 Validation Loss: 0.46342357993125916\n",
      "2042 Training Loss: 0.3988305926322937 Validation Loss: 0.46160903573036194\n",
      "2043 Training Loss: 0.3654487729072571 Validation Loss: 0.46061354875564575\n",
      "2044 Training Loss: 0.37027257680892944 Validation Loss: 0.4605647921562195\n",
      "2045 Training Loss: 0.3644077479839325 Validation Loss: 0.46128469705581665\n",
      "2046 Training Loss: 0.36846840381622314 Validation Loss: 0.46251222491264343\n",
      "2047 Training Loss: 0.37777501344680786 Validation Loss: 0.4633352756500244\n",
      "2048 Training Loss: 0.38562679290771484 Validation Loss: 0.46235528588294983\n",
      "2049 Training Loss: 0.36101531982421875 Validation Loss: 0.46165525913238525\n",
      "2050 Training Loss: 0.39703187346458435 Validation Loss: 0.46011388301849365\n",
      "2051 Training Loss: 0.3915846347808838 Validation Loss: 0.4567193388938904\n",
      "2052 Training Loss: 0.375295490026474 Validation Loss: 0.45304566621780396\n",
      "2053 Training Loss: 0.36108049750328064 Validation Loss: 0.4492802321910858\n",
      "2054 Training Loss: 0.3706222176551819 Validation Loss: 0.44539543986320496\n",
      "2055 Training Loss: 0.3623303771018982 Validation Loss: 0.44184309244155884\n",
      "2056 Training Loss: 0.37815791368484497 Validation Loss: 0.43869858980178833\n",
      "2057 Training Loss: 0.3595484495162964 Validation Loss: 0.4370908737182617\n",
      "2058 Training Loss: 0.3976008892059326 Validation Loss: 0.43552038073539734\n",
      "2059 Training Loss: 0.33594006299972534 Validation Loss: 0.4359617829322815\n",
      "2060 Training Loss: 0.3898251950740814 Validation Loss: 0.4347583055496216\n",
      "2061 Training Loss: 0.3615032136440277 Validation Loss: 0.4342755079269409\n",
      "2062 Training Loss: 0.3780105710029602 Validation Loss: 0.4343549907207489\n",
      "2063 Training Loss: 0.35414907336235046 Validation Loss: 0.4353393316268921\n",
      "2064 Training Loss: 0.3513364791870117 Validation Loss: 0.43718329071998596\n",
      "2065 Training Loss: 0.3641771972179413 Validation Loss: 0.439081609249115\n",
      "2066 Training Loss: 0.33153557777404785 Validation Loss: 0.4419149160385132\n",
      "2067 Training Loss: 0.34761831164360046 Validation Loss: 0.44567960500717163\n",
      "2068 Training Loss: 0.3622712790966034 Validation Loss: 0.448843777179718\n",
      "2069 Training Loss: 0.3280266225337982 Validation Loss: 0.452529639005661\n",
      "2070 Training Loss: 0.3783544600009918 Validation Loss: 0.4555499851703644\n",
      "2071 Training Loss: 0.40720802545547485 Validation Loss: 0.45492303371429443\n",
      "2072 Training Loss: 0.3650071918964386 Validation Loss: 0.4533050060272217\n",
      "2073 Training Loss: 0.36789530515670776 Validation Loss: 0.45008546113967896\n",
      "2074 Training Loss: 0.3972855806350708 Validation Loss: 0.4444793164730072\n",
      "2075 Training Loss: 0.3577342629432678 Validation Loss: 0.4395450949668884\n",
      "2076 Training Loss: 0.3449627757072449 Validation Loss: 0.43448489904403687\n",
      "2077 Training Loss: 0.3496914803981781 Validation Loss: 0.43042492866516113\n",
      "2078 Training Loss: 0.32673367857933044 Validation Loss: 0.4279583692550659\n",
      "2079 Training Loss: 0.35104086995124817 Validation Loss: 0.4269276261329651\n",
      "2080 Training Loss: 0.35502487421035767 Validation Loss: 0.4265943169593811\n",
      "2081 Training Loss: 0.3367023169994354 Validation Loss: 0.42675501108169556\n",
      "2082 Training Loss: 0.3520372807979584 Validation Loss: 0.4270969033241272\n",
      "2083 Training Loss: 0.3491630554199219 Validation Loss: 0.42632949352264404\n",
      "2084 Training Loss: 0.3322729766368866 Validation Loss: 0.4274669289588928\n",
      "2085 Training Loss: 0.3728053569793701 Validation Loss: 0.42746442556381226\n",
      "2086 Training Loss: 0.34560900926589966 Validation Loss: 0.42733848094940186\n",
      "2087 Training Loss: 0.339433491230011 Validation Loss: 0.42695754766464233\n",
      "2088 Training Loss: 0.320767343044281 Validation Loss: 0.4276498258113861\n",
      "2089 Training Loss: 0.31696656346321106 Validation Loss: 0.42993175983428955\n",
      "2090 Training Loss: 0.3326200544834137 Validation Loss: 0.4330381155014038\n",
      "2091 Training Loss: 0.3143526017665863 Validation Loss: 0.43668216466903687\n",
      "2092 Training Loss: 0.36211588978767395 Validation Loss: 0.43790334463119507\n",
      "2093 Training Loss: 0.3576093912124634 Validation Loss: 0.43689584732055664\n",
      "2094 Training Loss: 0.3383147120475769 Validation Loss: 0.4350348114967346\n",
      "2095 Training Loss: 0.3378356695175171 Validation Loss: 0.43309903144836426\n",
      "2096 Training Loss: 0.3386290371417999 Validation Loss: 0.4306448698043823\n",
      "2097 Training Loss: 0.335607647895813 Validation Loss: 0.4278446435928345\n",
      "2098 Training Loss: 0.349204957485199 Validation Loss: 0.42448049783706665\n",
      "2099 Training Loss: 0.33240342140197754 Validation Loss: 0.4201926290988922\n",
      "2100 Training Loss: 0.3351736068725586 Validation Loss: 0.4167090654373169\n",
      "2101 Training Loss: 0.31798356771469116 Validation Loss: 0.414906769990921\n",
      "2102 Training Loss: 0.32572367787361145 Validation Loss: 0.4137621819972992\n",
      "2103 Training Loss: 0.3349134922027588 Validation Loss: 0.4125702381134033\n",
      "2104 Training Loss: 0.3232688903808594 Validation Loss: 0.4120209217071533\n",
      "2105 Training Loss: 0.3264518976211548 Validation Loss: 0.41213536262512207\n",
      "2106 Training Loss: 0.3005148470401764 Validation Loss: 0.4137563705444336\n",
      "2107 Training Loss: 0.31383731961250305 Validation Loss: 0.41588515043258667\n",
      "2108 Training Loss: 0.32771193981170654 Validation Loss: 0.41684603691101074\n",
      "2109 Training Loss: 0.3479498028755188 Validation Loss: 0.4163798987865448\n",
      "2110 Training Loss: 0.33058276772499084 Validation Loss: 0.41593262553215027\n",
      "2111 Training Loss: 0.32109934091567993 Validation Loss: 0.41559576988220215\n",
      "2112 Training Loss: 0.3301326334476471 Validation Loss: 0.4145527780056\n",
      "2113 Training Loss: 0.3538285493850708 Validation Loss: 0.41204872727394104\n",
      "2114 Training Loss: 0.3441752791404724 Validation Loss: 0.4096912145614624\n",
      "2115 Training Loss: 0.32919156551361084 Validation Loss: 0.4074011445045471\n",
      "2116 Training Loss: 0.3041432201862335 Validation Loss: 0.40611714124679565\n",
      "2117 Training Loss: 0.3231673836708069 Validation Loss: 0.4045012891292572\n",
      "2118 Training Loss: 0.29785770177841187 Validation Loss: 0.4051061272621155\n",
      "2119 Training Loss: 0.30082038044929504 Validation Loss: 0.40664979815483093\n",
      "2120 Training Loss: 0.31829267740249634 Validation Loss: 0.4080304503440857\n",
      "2121 Training Loss: 0.33153295516967773 Validation Loss: 0.4074074625968933\n",
      "2122 Training Loss: 0.3154504895210266 Validation Loss: 0.40648674964904785\n",
      "2123 Training Loss: 0.2990332245826721 Validation Loss: 0.4063151180744171\n",
      "2124 Training Loss: 0.3153354525566101 Validation Loss: 0.4056922197341919\n",
      "2125 Training Loss: 0.3220440149307251 Validation Loss: 0.4045548439025879\n",
      "2126 Training Loss: 0.34278130531311035 Validation Loss: 0.40287691354751587\n",
      "2127 Training Loss: 0.3233538866043091 Validation Loss: 0.40077319741249084\n",
      "2128 Training Loss: 0.3145487904548645 Validation Loss: 0.3986385762691498\n",
      "2129 Training Loss: 0.32233136892318726 Validation Loss: 0.39670583605766296\n",
      "2130 Training Loss: 0.2979128360748291 Validation Loss: 0.3967472016811371\n",
      "2131 Training Loss: 0.3220274746417999 Validation Loss: 0.39606398344039917\n",
      "2132 Training Loss: 0.3049420416355133 Validation Loss: 0.39615148305892944\n",
      "2133 Training Loss: 0.3349785804748535 Validation Loss: 0.3947485685348511\n",
      "2134 Training Loss: 0.3299117088317871 Validation Loss: 0.3921554684638977\n",
      "2135 Training Loss: 0.3087189197540283 Validation Loss: 0.3895084857940674\n",
      "2136 Training Loss: 0.2866772413253784 Validation Loss: 0.38826707005500793\n",
      "2137 Training Loss: 0.2967268228530884 Validation Loss: 0.3890019655227661\n",
      "2138 Training Loss: 0.32335227727890015 Validation Loss: 0.38989847898483276\n",
      "2139 Training Loss: 0.3163195550441742 Validation Loss: 0.3904244303703308\n",
      "2140 Training Loss: 0.3219558000564575 Validation Loss: 0.3901990056037903\n",
      "2141 Training Loss: 0.29601404070854187 Validation Loss: 0.39006301760673523\n",
      "2142 Training Loss: 0.28631237149238586 Validation Loss: 0.3915403485298157\n",
      "2143 Training Loss: 0.2866998612880707 Validation Loss: 0.3929603695869446\n",
      "2144 Training Loss: 0.2859218418598175 Validation Loss: 0.3936381936073303\n",
      "2145 Training Loss: 0.2851889431476593 Validation Loss: 0.3950822353363037\n",
      "2146 Training Loss: 0.32945942878723145 Validation Loss: 0.3938688039779663\n",
      "2147 Training Loss: 0.31196558475494385 Validation Loss: 0.3915443420410156\n",
      "2148 Training Loss: 0.29210469126701355 Validation Loss: 0.3902323246002197\n",
      "2149 Training Loss: 0.3088691234588623 Validation Loss: 0.38832908868789673\n",
      "2150 Training Loss: 0.27804964780807495 Validation Loss: 0.3875575065612793\n",
      "2151 Training Loss: 0.3116576075553894 Validation Loss: 0.38578253984451294\n",
      "2152 Training Loss: 0.28980839252471924 Validation Loss: 0.38473230600357056\n",
      "2153 Training Loss: 0.2920246124267578 Validation Loss: 0.384092777967453\n",
      "2154 Training Loss: 0.2643285095691681 Validation Loss: 0.3844778537750244\n",
      "2155 Training Loss: 0.27885767817497253 Validation Loss: 0.38537102937698364\n",
      "2156 Training Loss: 0.30286648869514465 Validation Loss: 0.38473159074783325\n",
      "2157 Training Loss: 0.2785862982273102 Validation Loss: 0.3839375078678131\n",
      "2158 Training Loss: 0.2975960373878479 Validation Loss: 0.38262510299682617\n",
      "2159 Training Loss: 0.3461731970310211 Validation Loss: 0.37813800573349\n",
      "2160 Training Loss: 0.2815949320793152 Validation Loss: 0.37446659803390503\n",
      "2161 Training Loss: 0.2820988893508911 Validation Loss: 0.3718579411506653\n",
      "2162 Training Loss: 0.288589745759964 Validation Loss: 0.3701398968696594\n",
      "2163 Training Loss: 0.2730880379676819 Validation Loss: 0.3698246479034424\n",
      "2164 Training Loss: 0.2742033004760742 Validation Loss: 0.37087973952293396\n",
      "2165 Training Loss: 0.2854047417640686 Validation Loss: 0.37151527404785156\n",
      "2166 Training Loss: 0.28116315603256226 Validation Loss: 0.3733108937740326\n",
      "2167 Training Loss: 0.29618898034095764 Validation Loss: 0.3751128315925598\n",
      "2168 Training Loss: 0.2690984010696411 Validation Loss: 0.3779764175415039\n",
      "2169 Training Loss: 0.2791439890861511 Validation Loss: 0.38106662034988403\n",
      "2170 Training Loss: 0.27734220027923584 Validation Loss: 0.382845938205719\n",
      "2171 Training Loss: 0.30466368794441223 Validation Loss: 0.3836185336112976\n",
      "2172 Training Loss: 0.30713731050491333 Validation Loss: 0.3829917907714844\n",
      "2173 Training Loss: 0.2756493389606476 Validation Loss: 0.3826586604118347\n",
      "2174 Training Loss: 0.30649489164352417 Validation Loss: 0.3802548348903656\n",
      "2175 Training Loss: 0.31169581413269043 Validation Loss: 0.37562960386276245\n",
      "2176 Training Loss: 0.2798846960067749 Validation Loss: 0.37156641483306885\n",
      "2177 Training Loss: 0.2805258631706238 Validation Loss: 0.3682188093662262\n",
      "2178 Training Loss: 0.2815728187561035 Validation Loss: 0.3650602698326111\n",
      "2179 Training Loss: 0.25588464736938477 Validation Loss: 0.36368224024772644\n",
      "2180 Training Loss: 0.2862202525138855 Validation Loss: 0.3623467981815338\n",
      "2181 Training Loss: 0.2692127823829651 Validation Loss: 0.3613896369934082\n",
      "2182 Training Loss: 0.2814512252807617 Validation Loss: 0.36115479469299316\n",
      "2183 Training Loss: 0.2809264659881592 Validation Loss: 0.36073851585388184\n",
      "2184 Training Loss: 0.29683777689933777 Validation Loss: 0.3585853576660156\n",
      "2185 Training Loss: 0.2787688672542572 Validation Loss: 0.3562140464782715\n",
      "2186 Training Loss: 0.28924983739852905 Validation Loss: 0.35398876667022705\n",
      "2187 Training Loss: 0.2771342694759369 Validation Loss: 0.35245728492736816\n",
      "2188 Training Loss: 0.2572796046733856 Validation Loss: 0.35200613737106323\n",
      "2189 Training Loss: 0.259832501411438 Validation Loss: 0.352804958820343\n",
      "2190 Training Loss: 0.2845210134983063 Validation Loss: 0.3534806966781616\n",
      "2191 Training Loss: 0.28497007489204407 Validation Loss: 0.3542637228965759\n",
      "2192 Training Loss: 0.2776993215084076 Validation Loss: 0.35509246587753296\n",
      "2193 Training Loss: 0.31288942694664 Validation Loss: 0.35305121541023254\n",
      "2194 Training Loss: 0.27104389667510986 Validation Loss: 0.35143136978149414\n",
      "2195 Training Loss: 0.27885711193084717 Validation Loss: 0.34955137968063354\n",
      "2196 Training Loss: 0.24786704778671265 Validation Loss: 0.34943023324012756\n",
      "2197 Training Loss: 0.2715429961681366 Validation Loss: 0.34965795278549194\n",
      "2198 Training Loss: 0.27747440338134766 Validation Loss: 0.3501881957054138\n",
      "2199 Training Loss: 0.28675997257232666 Validation Loss: 0.34943127632141113\n",
      "2200 Training Loss: 0.2786403298377991 Validation Loss: 0.34808510541915894\n",
      "2201 Training Loss: 0.2507622539997101 Validation Loss: 0.34808623790740967\n",
      "2202 Training Loss: 0.2560013234615326 Validation Loss: 0.3488067388534546\n",
      "2203 Training Loss: 0.2555422782897949 Validation Loss: 0.3503255844116211\n",
      "2204 Training Loss: 0.27020150423049927 Validation Loss: 0.35179775953292847\n",
      "2205 Training Loss: 0.2671007215976715 Validation Loss: 0.35311615467071533\n",
      "2206 Training Loss: 0.27174311876296997 Validation Loss: 0.3538275957107544\n",
      "2207 Training Loss: 0.27795660495758057 Validation Loss: 0.35325485467910767\n",
      "2208 Training Loss: 0.25789523124694824 Validation Loss: 0.3534395694732666\n",
      "2209 Training Loss: 0.26699361205101013 Validation Loss: 0.3525769114494324\n",
      "2210 Training Loss: 0.2757023572921753 Validation Loss: 0.35154396295547485\n",
      "2211 Training Loss: 0.26736027002334595 Validation Loss: 0.3498513698577881\n",
      "2212 Training Loss: 0.25648564100265503 Validation Loss: 0.34896111488342285\n",
      "2213 Training Loss: 0.25127625465393066 Validation Loss: 0.3490822911262512\n",
      "2214 Training Loss: 0.28707361221313477 Validation Loss: 0.34761956334114075\n",
      "2215 Training Loss: 0.2657349407672882 Validation Loss: 0.3461593687534332\n",
      "2216 Training Loss: 0.25821787118911743 Validation Loss: 0.34440281987190247\n",
      "2217 Training Loss: 0.26315152645111084 Validation Loss: 0.3422026038169861\n",
      "2218 Training Loss: 0.24827083945274353 Validation Loss: 0.34044769406318665\n",
      "2219 Training Loss: 0.2545803189277649 Validation Loss: 0.3396099805831909\n",
      "2220 Training Loss: 0.24698498845100403 Validation Loss: 0.3391481041908264\n",
      "2221 Training Loss: 0.24592150747776031 Validation Loss: 0.33962327241897583\n",
      "2222 Training Loss: 0.2554432451725006 Validation Loss: 0.3408986032009125\n",
      "2223 Training Loss: 0.2668454051017761 Validation Loss: 0.34050795435905457\n",
      "2224 Training Loss: 0.2504987120628357 Validation Loss: 0.3401952385902405\n",
      "2225 Training Loss: 0.26856228709220886 Validation Loss: 0.3395429849624634\n",
      "2226 Training Loss: 0.2425990104675293 Validation Loss: 0.34037452936172485\n",
      "2227 Training Loss: 0.2585258185863495 Validation Loss: 0.34054431319236755\n",
      "2228 Training Loss: 0.25564464926719666 Validation Loss: 0.3401543200016022\n",
      "2229 Training Loss: 0.2564232349395752 Validation Loss: 0.3399812579154968\n",
      "2230 Training Loss: 0.23421287536621094 Validation Loss: 0.3404054641723633\n",
      "2231 Training Loss: 0.22869107127189636 Validation Loss: 0.3421775698661804\n",
      "2232 Training Loss: 0.27170330286026 Validation Loss: 0.34211891889572144\n",
      "2233 Training Loss: 0.26026830077171326 Validation Loss: 0.34107300639152527\n",
      "2234 Training Loss: 0.2141297459602356 Validation Loss: 0.3424574136734009\n",
      "2235 Training Loss: 0.30047470331192017 Validation Loss: 0.34129390120506287\n",
      "2236 Training Loss: 0.23590996861457825 Validation Loss: 0.34077271819114685\n",
      "2237 Training Loss: 0.24480608105659485 Validation Loss: 0.34013473987579346\n",
      "2238 Training Loss: 0.2300228476524353 Validation Loss: 0.34120097756385803\n",
      "2239 Training Loss: 0.271045982837677 Validation Loss: 0.3403993546962738\n",
      "2240 Training Loss: 0.2654760181903839 Validation Loss: 0.3387751281261444\n",
      "2241 Training Loss: 0.2391894906759262 Validation Loss: 0.33676695823669434\n",
      "2242 Training Loss: 0.2525145411491394 Validation Loss: 0.3336600661277771\n",
      "2243 Training Loss: 0.23243117332458496 Validation Loss: 0.33168578147888184\n",
      "2244 Training Loss: 0.26501399278640747 Validation Loss: 0.3290901482105255\n",
      "2245 Training Loss: 0.2423083633184433 Validation Loss: 0.3270859718322754\n",
      "2246 Training Loss: 0.25523412227630615 Validation Loss: 0.3240763545036316\n",
      "2247 Training Loss: 0.24291665852069855 Validation Loss: 0.3215234875679016\n",
      "2248 Training Loss: 0.2553083896636963 Validation Loss: 0.3194493055343628\n",
      "2249 Training Loss: 0.2330940067768097 Validation Loss: 0.3189684748649597\n",
      "2250 Training Loss: 0.243666872382164 Validation Loss: 0.31881654262542725\n",
      "2251 Training Loss: 0.24972859025001526 Validation Loss: 0.31970396637916565\n",
      "2252 Training Loss: 0.24173450469970703 Validation Loss: 0.32075777649879456\n",
      "2253 Training Loss: 0.26076316833496094 Validation Loss: 0.32142215967178345\n",
      "2254 Training Loss: 0.24776755273342133 Validation Loss: 0.32274186611175537\n",
      "2255 Training Loss: 0.26831090450286865 Validation Loss: 0.3218522369861603\n",
      "2256 Training Loss: 0.26770493388175964 Validation Loss: 0.31923723220825195\n",
      "2257 Training Loss: 0.2599894404411316 Validation Loss: 0.3168761432170868\n",
      "2258 Training Loss: 0.23526178300380707 Validation Loss: 0.31497693061828613\n",
      "2259 Training Loss: 0.24961790442466736 Validation Loss: 0.3132456839084625\n",
      "2260 Training Loss: 0.25326481461524963 Validation Loss: 0.31151968240737915\n",
      "2261 Training Loss: 0.232308030128479 Validation Loss: 0.3109089732170105\n",
      "2262 Training Loss: 0.2285972684621811 Validation Loss: 0.31147611141204834\n",
      "2263 Training Loss: 0.22745802998542786 Validation Loss: 0.31262773275375366\n",
      "2264 Training Loss: 0.23779767751693726 Validation Loss: 0.3138400912284851\n",
      "2265 Training Loss: 0.2509719133377075 Validation Loss: 0.3144381046295166\n",
      "2266 Training Loss: 0.2500699460506439 Validation Loss: 0.31408435106277466\n",
      "2267 Training Loss: 0.23426774144172668 Validation Loss: 0.3141673505306244\n",
      "2268 Training Loss: 0.23053434491157532 Validation Loss: 0.31524184346199036\n",
      "2269 Training Loss: 0.2223920226097107 Validation Loss: 0.3165286183357239\n",
      "2270 Training Loss: 0.21907636523246765 Validation Loss: 0.3184419572353363\n",
      "2271 Training Loss: 0.2433364987373352 Validation Loss: 0.3194412589073181\n",
      "2272 Training Loss: 0.22572968900203705 Validation Loss: 0.3205093741416931\n",
      "2273 Training Loss: 0.2049352377653122 Validation Loss: 0.32254505157470703\n",
      "2274 Training Loss: 0.21279744803905487 Validation Loss: 0.3254407048225403\n",
      "2275 Training Loss: 0.27369168400764465 Validation Loss: 0.32584860920906067\n",
      "2276 Training Loss: 0.22091156244277954 Validation Loss: 0.3258334696292877\n",
      "2277 Training Loss: 0.24150174856185913 Validation Loss: 0.3239404261112213\n",
      "2278 Training Loss: 0.228940948843956 Validation Loss: 0.32115882635116577\n",
      "2279 Training Loss: 0.2253570556640625 Validation Loss: 0.3184261918067932\n",
      "2280 Training Loss: 0.21310274302959442 Validation Loss: 0.31710565090179443\n",
      "2281 Training Loss: 0.21619567275047302 Validation Loss: 0.3161061108112335\n",
      "2282 Training Loss: 0.2335490584373474 Validation Loss: 0.3143676817417145\n",
      "2283 Training Loss: 0.22248615324497223 Validation Loss: 0.3129400610923767\n",
      "2284 Training Loss: 0.2522026598453522 Validation Loss: 0.3093256950378418\n",
      "2285 Training Loss: 0.22608911991119385 Validation Loss: 0.3056882619857788\n",
      "2286 Training Loss: 0.23456038534641266 Validation Loss: 0.30214810371398926\n",
      "2287 Training Loss: 0.2394755780696869 Validation Loss: 0.29910799860954285\n",
      "2288 Training Loss: 0.22680537402629852 Validation Loss: 0.2967362701892853\n",
      "2289 Training Loss: 0.21761786937713623 Validation Loss: 0.2957577109336853\n",
      "2290 Training Loss: 0.22544731199741364 Validation Loss: 0.2952311336994171\n",
      "2291 Training Loss: 0.22846592962741852 Validation Loss: 0.2949286103248596\n",
      "2292 Training Loss: 0.22008833289146423 Validation Loss: 0.29614967107772827\n",
      "2293 Training Loss: 0.235182523727417 Validation Loss: 0.29714155197143555\n",
      "2294 Training Loss: 0.24001336097717285 Validation Loss: 0.2983650267124176\n",
      "2295 Training Loss: 0.24755419790744781 Validation Loss: 0.2974017858505249\n",
      "2296 Training Loss: 0.20287546515464783 Validation Loss: 0.2976415753364563\n",
      "2297 Training Loss: 0.2116277664899826 Validation Loss: 0.29853588342666626\n",
      "2298 Training Loss: 0.21893417835235596 Validation Loss: 0.29994621872901917\n",
      "2299 Training Loss: 0.2084149271249771 Validation Loss: 0.30254945158958435\n",
      "2300 Training Loss: 0.22697365283966064 Validation Loss: 0.3048078119754791\n",
      "2301 Training Loss: 0.2207069844007492 Validation Loss: 0.30717429518699646\n",
      "2302 Training Loss: 0.23142361640930176 Validation Loss: 0.3078370988368988\n",
      "2303 Training Loss: 0.19925883412361145 Validation Loss: 0.30928468704223633\n",
      "2304 Training Loss: 0.19783930480480194 Validation Loss: 0.3117712736129761\n",
      "2305 Training Loss: 0.20365220308303833 Validation Loss: 0.3133518397808075\n",
      "2306 Training Loss: 0.2262638807296753 Validation Loss: 0.31349924206733704\n",
      "2307 Training Loss: 0.21422801911830902 Validation Loss: 0.31286942958831787\n",
      "2308 Training Loss: 0.2303144633769989 Validation Loss: 0.31017452478408813\n",
      "2309 Training Loss: 0.21497896313667297 Validation Loss: 0.30726051330566406\n",
      "2310 Training Loss: 0.21440674364566803 Validation Loss: 0.3029111921787262\n",
      "2311 Training Loss: 0.23169854283332825 Validation Loss: 0.298255980014801\n",
      "2312 Training Loss: 0.21934866905212402 Validation Loss: 0.2938918471336365\n",
      "2313 Training Loss: 0.24867211282253265 Validation Loss: 0.28911375999450684\n",
      "2314 Training Loss: 0.20974138379096985 Validation Loss: 0.2857428193092346\n",
      "2315 Training Loss: 0.20596253871917725 Validation Loss: 0.2841032147407532\n",
      "2316 Training Loss: 0.20274242758750916 Validation Loss: 0.28433454036712646\n",
      "2317 Training Loss: 0.22786876559257507 Validation Loss: 0.2841821312904358\n",
      "2318 Training Loss: 0.20431295037269592 Validation Loss: 0.28511863946914673\n",
      "2319 Training Loss: 0.21247929334640503 Validation Loss: 0.2859595715999603\n",
      "2320 Training Loss: 0.1981925070285797 Validation Loss: 0.28839296102523804\n",
      "2321 Training Loss: 0.22256247699260712 Validation Loss: 0.2903466522693634\n",
      "2322 Training Loss: 0.2134399116039276 Validation Loss: 0.29212185740470886\n",
      "2323 Training Loss: 0.19915473461151123 Validation Loss: 0.2940434217453003\n",
      "2324 Training Loss: 0.1996321827173233 Validation Loss: 0.29631397128105164\n",
      "2325 Training Loss: 0.21696096658706665 Validation Loss: 0.2975931763648987\n",
      "2326 Training Loss: 0.2106802761554718 Validation Loss: 0.2981165051460266\n",
      "2327 Training Loss: 0.2004113495349884 Validation Loss: 0.298200398683548\n",
      "2328 Training Loss: 0.2110307365655899 Validation Loss: 0.29836440086364746\n",
      "2329 Training Loss: 0.21189957857131958 Validation Loss: 0.29786184430122375\n",
      "2330 Training Loss: 0.19717933237552643 Validation Loss: 0.297441303730011\n",
      "2331 Training Loss: 0.20982199907302856 Validation Loss: 0.2960771322250366\n",
      "2332 Training Loss: 0.2209952175617218 Validation Loss: 0.2931036055088043\n",
      "2333 Training Loss: 0.1961665153503418 Validation Loss: 0.29016852378845215\n",
      "2334 Training Loss: 0.17909052968025208 Validation Loss: 0.28933894634246826\n",
      "2335 Training Loss: 0.20265012979507446 Validation Loss: 0.28810298442840576\n",
      "2336 Training Loss: 0.24397405982017517 Validation Loss: 0.28441882133483887\n",
      "2337 Training Loss: 0.20355015993118286 Validation Loss: 0.281036913394928\n",
      "2338 Training Loss: 0.21110886335372925 Validation Loss: 0.27780604362487793\n",
      "2339 Training Loss: 0.19375547766685486 Validation Loss: 0.2760549783706665\n",
      "2340 Training Loss: 0.22550082206726074 Validation Loss: 0.2738547623157501\n",
      "2341 Training Loss: 0.21262900531291962 Validation Loss: 0.2723437547683716\n",
      "2342 Training Loss: 0.20115119218826294 Validation Loss: 0.2717529237270355\n",
      "2343 Training Loss: 0.20856831967830658 Validation Loss: 0.2718336582183838\n",
      "2344 Training Loss: 0.1918349713087082 Validation Loss: 0.2729201316833496\n",
      "2345 Training Loss: 0.1924198865890503 Validation Loss: 0.2749849557876587\n",
      "2346 Training Loss: 0.19106042385101318 Validation Loss: 0.2775498032569885\n",
      "2347 Training Loss: 0.20058530569076538 Validation Loss: 0.2800288200378418\n",
      "2348 Training Loss: 0.21130767464637756 Validation Loss: 0.28187793493270874\n",
      "2349 Training Loss: 0.20662929117679596 Validation Loss: 0.28280115127563477\n",
      "2350 Training Loss: 0.19727739691734314 Validation Loss: 0.28348833322525024\n",
      "2351 Training Loss: 0.22106271982192993 Validation Loss: 0.28242892026901245\n",
      "2352 Training Loss: 0.20505744218826294 Validation Loss: 0.2812791168689728\n",
      "2353 Training Loss: 0.21486452221870422 Validation Loss: 0.27852779626846313\n",
      "2354 Training Loss: 0.21344679594039917 Validation Loss: 0.27549466490745544\n",
      "2355 Training Loss: 0.17933189868927002 Validation Loss: 0.2742890417575836\n",
      "2356 Training Loss: 0.20060402154922485 Validation Loss: 0.27344614267349243\n",
      "2357 Training Loss: 0.18606819212436676 Validation Loss: 0.2734389007091522\n",
      "2358 Training Loss: 0.18752871453762054 Validation Loss: 0.27439454197883606\n",
      "2359 Training Loss: 0.19570456445217133 Validation Loss: 0.275753915309906\n",
      "2360 Training Loss: 0.18332462012767792 Validation Loss: 0.27768081426620483\n",
      "2361 Training Loss: 0.18423166871070862 Validation Loss: 0.2808748185634613\n",
      "2362 Training Loss: 0.19305726885795593 Validation Loss: 0.2834508717060089\n",
      "2363 Training Loss: 0.1707022786140442 Validation Loss: 0.2871675193309784\n",
      "2364 Training Loss: 0.18620283901691437 Validation Loss: 0.2913835346698761\n",
      "2365 Training Loss: 0.17809215188026428 Validation Loss: 0.29573285579681396\n",
      "2366 Training Loss: 0.18974390625953674 Validation Loss: 0.2983890771865845\n",
      "2367 Training Loss: 0.2160516381263733 Validation Loss: 0.29572099447250366\n",
      "2368 Training Loss: 0.20287597179412842 Validation Loss: 0.29120364785194397\n",
      "2369 Training Loss: 0.18769341707229614 Validation Loss: 0.28613656759262085\n",
      "2370 Training Loss: 0.18781812489032745 Validation Loss: 0.2820318341255188\n",
      "2371 Training Loss: 0.19162851572036743 Validation Loss: 0.2788633108139038\n",
      "2372 Training Loss: 0.19986164569854736 Validation Loss: 0.2746613919734955\n",
      "2373 Training Loss: 0.1810424029827118 Validation Loss: 0.2716732621192932\n",
      "2374 Training Loss: 0.17743483185768127 Validation Loss: 0.26973554491996765\n",
      "2375 Training Loss: 0.1980326920747757 Validation Loss: 0.2684599757194519\n",
      "2376 Training Loss: 0.16501010954380035 Validation Loss: 0.2696131765842438\n",
      "2377 Training Loss: 0.1866462081670761 Validation Loss: 0.2710634171962738\n",
      "2378 Training Loss: 0.18129149079322815 Validation Loss: 0.2733100950717926\n",
      "2379 Training Loss: 0.20243462920188904 Validation Loss: 0.2751588225364685\n",
      "2380 Training Loss: 0.2034931629896164 Validation Loss: 0.27650612592697144\n",
      "2381 Training Loss: 0.19373942911624908 Validation Loss: 0.2763868570327759\n",
      "2382 Training Loss: 0.19114841520786285 Validation Loss: 0.27643755078315735\n",
      "2383 Training Loss: 0.19026923179626465 Validation Loss: 0.2765023112297058\n",
      "2384 Training Loss: 0.16703590750694275 Validation Loss: 0.27835774421691895\n",
      "2385 Training Loss: 0.16525599360466003 Validation Loss: 0.28031086921691895\n",
      "2386 Training Loss: 0.19282980263233185 Validation Loss: 0.2806829512119293\n",
      "2387 Training Loss: 0.19534263014793396 Validation Loss: 0.27959004044532776\n",
      "2388 Training Loss: 0.23755064606666565 Validation Loss: 0.2736964821815491\n",
      "2389 Training Loss: 0.171412855386734 Validation Loss: 0.2690742313861847\n",
      "2390 Training Loss: 0.1962234377861023 Validation Loss: 0.26447632908821106\n",
      "2391 Training Loss: 0.1697942614555359 Validation Loss: 0.26167988777160645\n",
      "2392 Training Loss: 0.183302104473114 Validation Loss: 0.25989478826522827\n",
      "2393 Training Loss: 0.18092121183872223 Validation Loss: 0.2588764727115631\n",
      "2394 Training Loss: 0.15902629494667053 Validation Loss: 0.2597123682498932\n",
      "2395 Training Loss: 0.18080207705497742 Validation Loss: 0.2609741985797882\n",
      "2396 Training Loss: 0.1693471223115921 Validation Loss: 0.2635755240917206\n",
      "2397 Training Loss: 0.1981070339679718 Validation Loss: 0.2647067904472351\n",
      "2398 Training Loss: 0.21210333704948425 Validation Loss: 0.26431167125701904\n",
      "2399 Training Loss: 0.1723172813653946 Validation Loss: 0.2642689645290375\n",
      "2400 Training Loss: 0.2056117057800293 Validation Loss: 0.2628627121448517\n",
      "2401 Training Loss: 0.19266313314437866 Validation Loss: 0.26142486929893494\n",
      "2402 Training Loss: 0.1936541050672531 Validation Loss: 0.25968465209007263\n",
      "2403 Training Loss: 0.17167361080646515 Validation Loss: 0.25844860076904297\n",
      "2404 Training Loss: 0.17557910084724426 Validation Loss: 0.25784292817115784\n",
      "2405 Training Loss: 0.18057258427143097 Validation Loss: 0.2576674818992615\n",
      "2406 Training Loss: 0.17635945975780487 Validation Loss: 0.2574211359024048\n",
      "2407 Training Loss: 0.16580235958099365 Validation Loss: 0.2580161988735199\n",
      "2408 Training Loss: 0.1666085571050644 Validation Loss: 0.2590632140636444\n",
      "2409 Training Loss: 0.1835734248161316 Validation Loss: 0.25952666997909546\n",
      "2410 Training Loss: 0.16077172756195068 Validation Loss: 0.26119232177734375\n",
      "2411 Training Loss: 0.1893470585346222 Validation Loss: 0.2608638405799866\n",
      "2412 Training Loss: 0.17167475819587708 Validation Loss: 0.2607678771018982\n",
      "2413 Training Loss: 0.16239027678966522 Validation Loss: 0.2607243061065674\n",
      "2414 Training Loss: 0.1688312590122223 Validation Loss: 0.26109766960144043\n",
      "2415 Training Loss: 0.17042841017246246 Validation Loss: 0.261460542678833\n",
      "2416 Training Loss: 0.1808883547782898 Validation Loss: 0.2615084946155548\n",
      "2417 Training Loss: 0.16888779401779175 Validation Loss: 0.26137158274650574\n",
      "2418 Training Loss: 0.17470157146453857 Validation Loss: 0.2608239948749542\n",
      "2419 Training Loss: 0.1667318046092987 Validation Loss: 0.2602582573890686\n",
      "2420 Training Loss: 0.17238721251487732 Validation Loss: 0.26008349657058716\n",
      "2421 Training Loss: 0.16039355099201202 Validation Loss: 0.2608020305633545\n",
      "2422 Training Loss: 0.17013177275657654 Validation Loss: 0.26113617420196533\n",
      "2423 Training Loss: 0.1611294150352478 Validation Loss: 0.26167693734169006\n",
      "2424 Training Loss: 0.14998899400234222 Validation Loss: 0.263508141040802\n",
      "2425 Training Loss: 0.18419048190116882 Validation Loss: 0.26430147886276245\n",
      "2426 Training Loss: 0.16749915480613708 Validation Loss: 0.2655524015426636\n",
      "2427 Training Loss: 0.15737730264663696 Validation Loss: 0.26712414622306824\n",
      "2428 Training Loss: 0.16942967474460602 Validation Loss: 0.26780444383621216\n",
      "2429 Training Loss: 0.17749011516571045 Validation Loss: 0.26719942688941956\n",
      "2430 Training Loss: 0.14938461780548096 Validation Loss: 0.26747485995292664\n",
      "2431 Training Loss: 0.16699521243572235 Validation Loss: 0.2671127915382385\n",
      "2432 Training Loss: 0.16043268144130707 Validation Loss: 0.26694077253341675\n",
      "2433 Training Loss: 0.1919841170310974 Validation Loss: 0.2648692727088928\n",
      "2434 Training Loss: 0.18040776252746582 Validation Loss: 0.26117604970932007\n",
      "2435 Training Loss: 0.1610116958618164 Validation Loss: 0.2585194408893585\n",
      "2436 Training Loss: 0.18190985918045044 Validation Loss: 0.25505387783050537\n",
      "2437 Training Loss: 0.15688274800777435 Validation Loss: 0.25257912278175354\n",
      "2438 Training Loss: 0.16300122439861298 Validation Loss: 0.25070980191230774\n",
      "2439 Training Loss: 0.17508363723754883 Validation Loss: 0.24917903542518616\n",
      "2440 Training Loss: 0.1582937091588974 Validation Loss: 0.24886588752269745\n",
      "2441 Training Loss: 0.1683959811925888 Validation Loss: 0.2490869164466858\n",
      "2442 Training Loss: 0.1734846979379654 Validation Loss: 0.24942263960838318\n",
      "2443 Training Loss: 0.1887493133544922 Validation Loss: 0.24776166677474976\n",
      "2444 Training Loss: 0.14914923906326294 Validation Loss: 0.24784991145133972\n",
      "2445 Training Loss: 0.1594628244638443 Validation Loss: 0.24870997667312622\n",
      "2446 Training Loss: 0.16709256172180176 Validation Loss: 0.24927149713039398\n",
      "2447 Training Loss: 0.17539529502391815 Validation Loss: 0.2499205768108368\n",
      "2448 Training Loss: 0.16546298563480377 Validation Loss: 0.2505093216896057\n",
      "2449 Training Loss: 0.18024837970733643 Validation Loss: 0.2493128478527069\n",
      "2450 Training Loss: 0.18779915571212769 Validation Loss: 0.2475433051586151\n",
      "2451 Training Loss: 0.16821947693824768 Validation Loss: 0.24595963954925537\n",
      "2452 Training Loss: 0.15894734859466553 Validation Loss: 0.2449413388967514\n",
      "2453 Training Loss: 0.1634194552898407 Validation Loss: 0.24441704154014587\n",
      "2454 Training Loss: 0.16205120086669922 Validation Loss: 0.2440812885761261\n",
      "2455 Training Loss: 0.15761615335941315 Validation Loss: 0.24463176727294922\n",
      "2456 Training Loss: 0.1565980315208435 Validation Loss: 0.245218425989151\n",
      "2457 Training Loss: 0.1420527547597885 Validation Loss: 0.24719300866127014\n",
      "2458 Training Loss: 0.16500751674175262 Validation Loss: 0.24808861315250397\n",
      "2459 Training Loss: 0.1799159049987793 Validation Loss: 0.2478720247745514\n",
      "2460 Training Loss: 0.16803047060966492 Validation Loss: 0.24683967232704163\n",
      "2461 Training Loss: 0.15192659199237823 Validation Loss: 0.2468188852071762\n",
      "2462 Training Loss: 0.14975786209106445 Validation Loss: 0.2470020055770874\n",
      "2463 Training Loss: 0.17059653997421265 Validation Loss: 0.24539822340011597\n",
      "2464 Training Loss: 0.15682144463062286 Validation Loss: 0.2434750497341156\n",
      "2465 Training Loss: 0.16282661259174347 Validation Loss: 0.2416277527809143\n",
      "2466 Training Loss: 0.15918460488319397 Validation Loss: 0.24060826003551483\n",
      "2467 Training Loss: 0.1660974621772766 Validation Loss: 0.2391863465309143\n",
      "2468 Training Loss: 0.16153177618980408 Validation Loss: 0.23836632072925568\n",
      "2469 Training Loss: 0.1402415931224823 Validation Loss: 0.23905637860298157\n",
      "2470 Training Loss: 0.18697774410247803 Validation Loss: 0.2373592108488083\n",
      "2471 Training Loss: 0.1600247025489807 Validation Loss: 0.23608501255512238\n",
      "2472 Training Loss: 0.14286716282367706 Validation Loss: 0.23661556839942932\n",
      "2473 Training Loss: 0.147553950548172 Validation Loss: 0.23806387186050415\n",
      "2474 Training Loss: 0.1760435849428177 Validation Loss: 0.2381327599287033\n",
      "2475 Training Loss: 0.16193880140781403 Validation Loss: 0.23790010809898376\n",
      "2476 Training Loss: 0.16161876916885376 Validation Loss: 0.23774689435958862\n",
      "2477 Training Loss: 0.1659025400876999 Validation Loss: 0.23780111968517303\n",
      "2478 Training Loss: 0.16783154010772705 Validation Loss: 0.2373535931110382\n",
      "2479 Training Loss: 0.14625000953674316 Validation Loss: 0.2374904304742813\n",
      "2480 Training Loss: 0.1425521820783615 Validation Loss: 0.23844072222709656\n",
      "2481 Training Loss: 0.1522979587316513 Validation Loss: 0.23933659493923187\n",
      "2482 Training Loss: 0.15251705050468445 Validation Loss: 0.24062898755073547\n",
      "2483 Training Loss: 0.12774574756622314 Validation Loss: 0.24401316046714783\n",
      "2484 Training Loss: 0.1650848537683487 Validation Loss: 0.24604058265686035\n",
      "2485 Training Loss: 0.14144012331962585 Validation Loss: 0.24767018854618073\n",
      "2486 Training Loss: 0.13705889880657196 Validation Loss: 0.2500664293766022\n",
      "2487 Training Loss: 0.14483702182769775 Validation Loss: 0.25162577629089355\n",
      "2488 Training Loss: 0.17474161088466644 Validation Loss: 0.25025448203086853\n",
      "2489 Training Loss: 0.15916527807712555 Validation Loss: 0.2481951117515564\n",
      "2490 Training Loss: 0.14009138941764832 Validation Loss: 0.24664489924907684\n",
      "2491 Training Loss: 0.1384163200855255 Validation Loss: 0.24603238701820374\n",
      "2492 Training Loss: 0.15625876188278198 Validation Loss: 0.24447017908096313\n",
      "2493 Training Loss: 0.15370246767997742 Validation Loss: 0.24232050776481628\n",
      "2494 Training Loss: 0.15676599740982056 Validation Loss: 0.2388002574443817\n",
      "2495 Training Loss: 0.15276193618774414 Validation Loss: 0.23499277234077454\n",
      "2496 Training Loss: 0.14656570553779602 Validation Loss: 0.23237183690071106\n",
      "2497 Training Loss: 0.16651776432991028 Validation Loss: 0.22942140698432922\n",
      "2498 Training Loss: 0.13736723363399506 Validation Loss: 0.22801806032657623\n",
      "2499 Training Loss: 0.16303053498268127 Validation Loss: 0.22664234042167664\n",
      "2500 Training Loss: 0.14202891290187836 Validation Loss: 0.2268933653831482\n",
      "2501 Training Loss: 0.14321142435073853 Validation Loss: 0.22796326875686646\n",
      "2502 Training Loss: 0.15361738204956055 Validation Loss: 0.2294912338256836\n",
      "2503 Training Loss: 0.14266251027584076 Validation Loss: 0.23194028437137604\n",
      "2504 Training Loss: 0.1371847689151764 Validation Loss: 0.23499077558517456\n",
      "2505 Training Loss: 0.15273898839950562 Validation Loss: 0.23711484670639038\n",
      "2506 Training Loss: 0.18383532762527466 Validation Loss: 0.23623326420783997\n",
      "2507 Training Loss: 0.1320982426404953 Validation Loss: 0.2361164093017578\n",
      "2508 Training Loss: 0.14508916437625885 Validation Loss: 0.23626819252967834\n",
      "2509 Training Loss: 0.12672044336795807 Validation Loss: 0.23740489780902863\n",
      "2510 Training Loss: 0.15591545403003693 Validation Loss: 0.23840926587581635\n",
      "2511 Training Loss: 0.14803028106689453 Validation Loss: 0.23888607323169708\n",
      "2512 Training Loss: 0.1870322972536087 Validation Loss: 0.23614877462387085\n",
      "2513 Training Loss: 0.15193623304367065 Validation Loss: 0.23278748989105225\n",
      "2514 Training Loss: 0.12717823684215546 Validation Loss: 0.2313198745250702\n",
      "2515 Training Loss: 0.15610572695732117 Validation Loss: 0.22994865477085114\n",
      "2516 Training Loss: 0.14583474397659302 Validation Loss: 0.22798539698123932\n",
      "2517 Training Loss: 0.15252315998077393 Validation Loss: 0.22659388184547424\n",
      "2518 Training Loss: 0.13132356107234955 Validation Loss: 0.22631341218948364\n",
      "2519 Training Loss: 0.14042405784130096 Validation Loss: 0.22710613906383514\n",
      "2520 Training Loss: 0.12591606378555298 Validation Loss: 0.22979086637496948\n",
      "2521 Training Loss: 0.13397613167762756 Validation Loss: 0.23296284675598145\n",
      "2522 Training Loss: 0.1388920098543167 Validation Loss: 0.23593486845493317\n",
      "2523 Training Loss: 0.15601500868797302 Validation Loss: 0.23774224519729614\n",
      "2524 Training Loss: 0.14603012800216675 Validation Loss: 0.23868420720100403\n",
      "2525 Training Loss: 0.1422705203294754 Validation Loss: 0.23862698674201965\n",
      "2526 Training Loss: 0.1482749730348587 Validation Loss: 0.2371828854084015\n",
      "2527 Training Loss: 0.14439858496189117 Validation Loss: 0.23459231853485107\n",
      "2528 Training Loss: 0.1258854866027832 Validation Loss: 0.23366111516952515\n",
      "2529 Training Loss: 0.16288597881793976 Validation Loss: 0.23081903159618378\n",
      "2530 Training Loss: 0.1417509764432907 Validation Loss: 0.22826749086380005\n",
      "2531 Training Loss: 0.13881631195545197 Validation Loss: 0.2258952558040619\n",
      "2532 Training Loss: 0.16157472133636475 Validation Loss: 0.22319912910461426\n",
      "2533 Training Loss: 0.1346103996038437 Validation Loss: 0.22144033014774323\n",
      "2534 Training Loss: 0.14140024781227112 Validation Loss: 0.2200596034526825\n",
      "2535 Training Loss: 0.1302182972431183 Validation Loss: 0.21966323256492615\n",
      "2536 Training Loss: 0.14968565106391907 Validation Loss: 0.21920627355575562\n",
      "2537 Training Loss: 0.1364203691482544 Validation Loss: 0.219454824924469\n",
      "2538 Training Loss: 0.12555378675460815 Validation Loss: 0.221270352602005\n",
      "2539 Training Loss: 0.12612202763557434 Validation Loss: 0.22414684295654297\n",
      "2540 Training Loss: 0.13210904598236084 Validation Loss: 0.2268725484609604\n",
      "2541 Training Loss: 0.1488305926322937 Validation Loss: 0.22852107882499695\n",
      "2542 Training Loss: 0.12962616980075836 Validation Loss: 0.23101425170898438\n",
      "2543 Training Loss: 0.16038891673088074 Validation Loss: 0.23094095289707184\n",
      "2544 Training Loss: 0.1497422307729721 Validation Loss: 0.22942182421684265\n",
      "2545 Training Loss: 0.14441558718681335 Validation Loss: 0.22766025364398956\n",
      "2546 Training Loss: 0.12613876163959503 Validation Loss: 0.22620953619480133\n",
      "2547 Training Loss: 0.16403041779994965 Validation Loss: 0.22249799966812134\n",
      "2548 Training Loss: 0.12184914946556091 Validation Loss: 0.2201123833656311\n",
      "2549 Training Loss: 0.13837730884552002 Validation Loss: 0.21831749379634857\n",
      "2550 Training Loss: 0.12961065769195557 Validation Loss: 0.21765580773353577\n",
      "2551 Training Loss: 0.16166265308856964 Validation Loss: 0.21538272500038147\n",
      "2552 Training Loss: 0.13134756684303284 Validation Loss: 0.21414172649383545\n",
      "2553 Training Loss: 0.14411979913711548 Validation Loss: 0.21321681141853333\n",
      "2554 Training Loss: 0.13793641328811646 Validation Loss: 0.21320471167564392\n",
      "2555 Training Loss: 0.14677290618419647 Validation Loss: 0.21350771188735962\n",
      "2556 Training Loss: 0.12433739006519318 Validation Loss: 0.21457038819789886\n",
      "2557 Training Loss: 0.14544402062892914 Validation Loss: 0.21443036198616028\n",
      "2558 Training Loss: 0.155916228890419 Validation Loss: 0.21299153566360474\n",
      "2559 Training Loss: 0.12400692701339722 Validation Loss: 0.21295656263828278\n",
      "2560 Training Loss: 0.13437402248382568 Validation Loss: 0.21255849301815033\n",
      "2561 Training Loss: 0.12280424684286118 Validation Loss: 0.2132752537727356\n",
      "2562 Training Loss: 0.1319483518600464 Validation Loss: 0.21455194056034088\n",
      "2563 Training Loss: 0.1445802003145218 Validation Loss: 0.21541939675807953\n",
      "2564 Training Loss: 0.1326233446598053 Validation Loss: 0.21600636839866638\n",
      "2565 Training Loss: 0.11968159675598145 Validation Loss: 0.21780435740947723\n",
      "2566 Training Loss: 0.11736549437046051 Validation Loss: 0.2204817831516266\n",
      "2567 Training Loss: 0.1396251916885376 Validation Loss: 0.2217913419008255\n",
      "2568 Training Loss: 0.14290767908096313 Validation Loss: 0.22187167406082153\n",
      "2569 Training Loss: 0.1465129405260086 Validation Loss: 0.22077207267284393\n",
      "2570 Training Loss: 0.1245146244764328 Validation Loss: 0.22010502219200134\n",
      "2571 Training Loss: 0.12576787173748016 Validation Loss: 0.2194037139415741\n",
      "2572 Training Loss: 0.1276085525751114 Validation Loss: 0.2189987450838089\n",
      "2573 Training Loss: 0.13259685039520264 Validation Loss: 0.2187376767396927\n",
      "2574 Training Loss: 0.12605488300323486 Validation Loss: 0.21874871850013733\n",
      "2575 Training Loss: 0.14012694358825684 Validation Loss: 0.21773366630077362\n",
      "2576 Training Loss: 0.11971922963857651 Validation Loss: 0.21800073981285095\n",
      "2577 Training Loss: 0.148549422621727 Validation Loss: 0.21702459454536438\n",
      "2578 Training Loss: 0.14410953223705292 Validation Loss: 0.21498258411884308\n",
      "2579 Training Loss: 0.12743403017520905 Validation Loss: 0.21309125423431396\n",
      "2580 Training Loss: 0.12616823613643646 Validation Loss: 0.21161681413650513\n",
      "2581 Training Loss: 0.10984236747026443 Validation Loss: 0.21182723343372345\n",
      "2582 Training Loss: 0.13182573020458221 Validation Loss: 0.21192657947540283\n",
      "2583 Training Loss: 0.12035125494003296 Validation Loss: 0.21261098980903625\n",
      "2584 Training Loss: 0.12643152475357056 Validation Loss: 0.21348096430301666\n",
      "2585 Training Loss: 0.1281431019306183 Validation Loss: 0.21435457468032837\n",
      "2586 Training Loss: 0.14436228573322296 Validation Loss: 0.21467778086662292\n",
      "2587 Training Loss: 0.11831562221050262 Validation Loss: 0.21546871960163116\n",
      "2588 Training Loss: 0.1268865168094635 Validation Loss: 0.21633213758468628\n",
      "2589 Training Loss: 0.14004865288734436 Validation Loss: 0.21721051633358002\n",
      "2590 Training Loss: 0.1482682079076767 Validation Loss: 0.21600914001464844\n",
      "2591 Training Loss: 0.12153995037078857 Validation Loss: 0.2147897332906723\n",
      "2592 Training Loss: 0.12712185084819794 Validation Loss: 0.2136397361755371\n",
      "2593 Training Loss: 0.1345537006855011 Validation Loss: 0.21192745864391327\n",
      "2594 Training Loss: 0.1303010880947113 Validation Loss: 0.21049833297729492\n",
      "2595 Training Loss: 0.1252470761537552 Validation Loss: 0.20920684933662415\n",
      "2596 Training Loss: 0.13519752025604248 Validation Loss: 0.20693182945251465\n",
      "2597 Training Loss: 0.13563194870948792 Validation Loss: 0.20479650795459747\n",
      "2598 Training Loss: 0.11921937763690948 Validation Loss: 0.20306679606437683\n",
      "2599 Training Loss: 0.1300218105316162 Validation Loss: 0.20140010118484497\n",
      "2600 Training Loss: 0.12273633480072021 Validation Loss: 0.20038101077079773\n",
      "2601 Training Loss: 0.11090867966413498 Validation Loss: 0.20104101300239563\n",
      "2602 Training Loss: 0.12102965265512466 Validation Loss: 0.20276877284049988\n",
      "2603 Training Loss: 0.11544778943061829 Validation Loss: 0.2054401934146881\n",
      "2604 Training Loss: 0.1351940631866455 Validation Loss: 0.20772603154182434\n",
      "2605 Training Loss: 0.11160887032747269 Validation Loss: 0.21072918176651\n",
      "2606 Training Loss: 0.11267751455307007 Validation Loss: 0.21440589427947998\n",
      "2607 Training Loss: 0.10961911082267761 Validation Loss: 0.2187534123659134\n",
      "2608 Training Loss: 0.12559106945991516 Validation Loss: 0.22219198942184448\n",
      "2609 Training Loss: 0.11959145218133926 Validation Loss: 0.22485849261283875\n",
      "2610 Training Loss: 0.1206178218126297 Validation Loss: 0.2265978455543518\n",
      "2611 Training Loss: 0.13163182139396667 Validation Loss: 0.22592777013778687\n",
      "2612 Training Loss: 0.150797501206398 Validation Loss: 0.221777081489563\n",
      "2613 Training Loss: 0.11048536002635956 Validation Loss: 0.21855595707893372\n",
      "2614 Training Loss: 0.12595166265964508 Validation Loss: 0.21462690830230713\n",
      "2615 Training Loss: 0.11181225627660751 Validation Loss: 0.2117205560207367\n",
      "2616 Training Loss: 0.11838805675506592 Validation Loss: 0.20922169089317322\n",
      "2617 Training Loss: 0.14421066641807556 Validation Loss: 0.20451705157756805\n",
      "2618 Training Loss: 0.12345628440380096 Validation Loss: 0.2008550465106964\n",
      "2619 Training Loss: 0.12149365246295929 Validation Loss: 0.19765998423099518\n",
      "2620 Training Loss: 0.12863042950630188 Validation Loss: 0.19539296627044678\n",
      "2621 Training Loss: 0.11288521438837051 Validation Loss: 0.19456860423088074\n",
      "2622 Training Loss: 0.12617871165275574 Validation Loss: 0.1939697265625\n",
      "2623 Training Loss: 0.1287049502134323 Validation Loss: 0.19361761212348938\n",
      "2624 Training Loss: 0.13605616986751556 Validation Loss: 0.19336998462677002\n",
      "2625 Training Loss: 0.1185692846775055 Validation Loss: 0.19404686987400055\n",
      "2626 Training Loss: 0.12274684011936188 Validation Loss: 0.19565926492214203\n",
      "2627 Training Loss: 0.11315685510635376 Validation Loss: 0.19833610951900482\n",
      "2628 Training Loss: 0.12378387153148651 Validation Loss: 0.20075201988220215\n",
      "2629 Training Loss: 0.11932410299777985 Validation Loss: 0.20321710407733917\n",
      "2630 Training Loss: 0.12188231945037842 Validation Loss: 0.20487269759178162\n",
      "2631 Training Loss: 0.11753906309604645 Validation Loss: 0.20658937096595764\n",
      "2632 Training Loss: 0.12238596379756927 Validation Loss: 0.20815050601959229\n",
      "2633 Training Loss: 0.11466243863105774 Validation Loss: 0.20907291769981384\n",
      "2634 Training Loss: 0.1303441971540451 Validation Loss: 0.20903854072093964\n",
      "2635 Training Loss: 0.12814639508724213 Validation Loss: 0.20710526406764984\n",
      "2636 Training Loss: 0.12012533098459244 Validation Loss: 0.2049408107995987\n",
      "2637 Training Loss: 0.1260518878698349 Validation Loss: 0.20269960165023804\n",
      "2638 Training Loss: 0.11357924342155457 Validation Loss: 0.20075294375419617\n",
      "2639 Training Loss: 0.10406052321195602 Validation Loss: 0.20043015480041504\n",
      "2640 Training Loss: 0.15105611085891724 Validation Loss: 0.19752711057662964\n",
      "2641 Training Loss: 0.12348480522632599 Validation Loss: 0.19457170367240906\n",
      "2642 Training Loss: 0.12605765461921692 Validation Loss: 0.1914905607700348\n",
      "2643 Training Loss: 0.12503494322299957 Validation Loss: 0.18866416811943054\n",
      "2644 Training Loss: 0.11136381328105927 Validation Loss: 0.18762944638729095\n",
      "2645 Training Loss: 0.10752059519290924 Validation Loss: 0.18800339102745056\n",
      "2646 Training Loss: 0.11111455410718918 Validation Loss: 0.18937397003173828\n",
      "2647 Training Loss: 0.11408887803554535 Validation Loss: 0.19136956334114075\n",
      "2648 Training Loss: 0.1095956414937973 Validation Loss: 0.19411955773830414\n",
      "2649 Training Loss: 0.13075466454029083 Validation Loss: 0.1962495893239975\n",
      "2650 Training Loss: 0.12081416696310043 Validation Loss: 0.19812798500061035\n",
      "2651 Training Loss: 0.11411698907613754 Validation Loss: 0.20003657042980194\n",
      "2652 Training Loss: 0.1239435002207756 Validation Loss: 0.20036828517913818\n",
      "2653 Training Loss: 0.11336609721183777 Validation Loss: 0.20025098323822021\n",
      "2654 Training Loss: 0.12760335206985474 Validation Loss: 0.19864925742149353\n",
      "2655 Training Loss: 0.11523176729679108 Validation Loss: 0.19664998352527618\n",
      "2656 Training Loss: 0.11573851108551025 Validation Loss: 0.1938265860080719\n",
      "2657 Training Loss: 0.11486338824033737 Validation Loss: 0.19155722856521606\n",
      "2658 Training Loss: 0.11804380267858505 Validation Loss: 0.19046753644943237\n",
      "2659 Training Loss: 0.11673440039157867 Validation Loss: 0.18978631496429443\n",
      "2660 Training Loss: 0.10915480554103851 Validation Loss: 0.1899944692850113\n",
      "2661 Training Loss: 0.10077424347400665 Validation Loss: 0.19155803322792053\n",
      "2662 Training Loss: 0.11958718299865723 Validation Loss: 0.1922089159488678\n",
      "2663 Training Loss: 0.10350857675075531 Validation Loss: 0.19324302673339844\n",
      "2664 Training Loss: 0.12474388629198074 Validation Loss: 0.1936919093132019\n",
      "2665 Training Loss: 0.1080799251794815 Validation Loss: 0.19347885251045227\n",
      "2666 Training Loss: 0.12022949755191803 Validation Loss: 0.19265028834342957\n",
      "2667 Training Loss: 0.1311679184436798 Validation Loss: 0.19114777445793152\n",
      "2668 Training Loss: 0.13528560101985931 Validation Loss: 0.18879322707653046\n",
      "2669 Training Loss: 0.12217753380537033 Validation Loss: 0.18652372062206268\n",
      "2670 Training Loss: 0.11602707207202911 Validation Loss: 0.18434283137321472\n",
      "2671 Training Loss: 0.12162569165229797 Validation Loss: 0.18165357410907745\n",
      "2672 Training Loss: 0.10677865892648697 Validation Loss: 0.18033260107040405\n",
      "2673 Training Loss: 0.11533786356449127 Validation Loss: 0.17978030443191528\n",
      "2674 Training Loss: 0.12242326140403748 Validation Loss: 0.1795186698436737\n",
      "2675 Training Loss: 0.1336955428123474 Validation Loss: 0.17861849069595337\n",
      "2676 Training Loss: 0.10719028860330582 Validation Loss: 0.17887814342975616\n",
      "2677 Training Loss: 0.10998967289924622 Validation Loss: 0.17874325811862946\n",
      "2678 Training Loss: 0.12135197222232819 Validation Loss: 0.17832839488983154\n",
      "2679 Training Loss: 0.10140316188335419 Validation Loss: 0.17967095971107483\n",
      "2680 Training Loss: 0.10708507150411606 Validation Loss: 0.18101057410240173\n",
      "2681 Training Loss: 0.11165477335453033 Validation Loss: 0.18307451903820038\n",
      "2682 Training Loss: 0.11988982558250427 Validation Loss: 0.18477128446102142\n",
      "2683 Training Loss: 0.10805109888315201 Validation Loss: 0.1872255802154541\n",
      "2684 Training Loss: 0.13388203084468842 Validation Loss: 0.18802452087402344\n",
      "2685 Training Loss: 0.10372292995452881 Validation Loss: 0.18915723264217377\n",
      "2686 Training Loss: 0.09545712172985077 Validation Loss: 0.19080331921577454\n",
      "2687 Training Loss: 0.10614173114299774 Validation Loss: 0.19224098324775696\n",
      "2688 Training Loss: 0.11021917313337326 Validation Loss: 0.19303452968597412\n",
      "2689 Training Loss: 0.1016940325498581 Validation Loss: 0.19434833526611328\n",
      "2690 Training Loss: 0.09824301302433014 Validation Loss: 0.19543446600437164\n",
      "2691 Training Loss: 0.1325543373823166 Validation Loss: 0.1933862715959549\n",
      "2692 Training Loss: 0.09660088270902634 Validation Loss: 0.1919017732143402\n",
      "2693 Training Loss: 0.107895627617836 Validation Loss: 0.18967479467391968\n",
      "2694 Training Loss: 0.095467709004879 Validation Loss: 0.18827325105667114\n",
      "2695 Training Loss: 0.1087128072977066 Validation Loss: 0.18674831092357635\n",
      "2696 Training Loss: 0.11872097849845886 Validation Loss: 0.1848372519016266\n",
      "2697 Training Loss: 0.11043144762516022 Validation Loss: 0.18295688927173615\n",
      "2698 Training Loss: 0.12634950876235962 Validation Loss: 0.17969809472560883\n",
      "2699 Training Loss: 0.12904825806617737 Validation Loss: 0.1755620241165161\n",
      "2700 Training Loss: 0.10248225927352905 Validation Loss: 0.17329086363315582\n",
      "2701 Training Loss: 0.12651072442531586 Validation Loss: 0.1704053282737732\n",
      "2702 Training Loss: 0.11233264207839966 Validation Loss: 0.16861389577388763\n",
      "2703 Training Loss: 0.10273731499910355 Validation Loss: 0.1677244007587433\n",
      "2704 Training Loss: 0.09801778197288513 Validation Loss: 0.1684393733739853\n",
      "2705 Training Loss: 0.11254352331161499 Validation Loss: 0.16932706534862518\n",
      "2706 Training Loss: 0.1027611717581749 Validation Loss: 0.1710985153913498\n",
      "2707 Training Loss: 0.11395908892154694 Validation Loss: 0.17290975153446198\n",
      "2708 Training Loss: 0.09308795630931854 Validation Loss: 0.17558951675891876\n",
      "2709 Training Loss: 0.12012405693531036 Validation Loss: 0.17744266986846924\n",
      "2710 Training Loss: 0.10466021299362183 Validation Loss: 0.17948386073112488\n",
      "2711 Training Loss: 0.10688011348247528 Validation Loss: 0.18152041733264923\n",
      "2712 Training Loss: 0.11626783758401871 Validation Loss: 0.18257156014442444\n",
      "2713 Training Loss: 0.10132637619972229 Validation Loss: 0.18348008394241333\n",
      "2714 Training Loss: 0.10043405741453171 Validation Loss: 0.18370595574378967\n",
      "2715 Training Loss: 0.10947705060243607 Validation Loss: 0.1828279048204422\n",
      "2716 Training Loss: 0.09711241722106934 Validation Loss: 0.18294478952884674\n",
      "2717 Training Loss: 0.0970616415143013 Validation Loss: 0.1827954202890396\n",
      "2718 Training Loss: 0.1113494336605072 Validation Loss: 0.1815720498561859\n",
      "2719 Training Loss: 0.10197371244430542 Validation Loss: 0.18014532327651978\n",
      "2720 Training Loss: 0.09363987296819687 Validation Loss: 0.17951703071594238\n",
      "2721 Training Loss: 0.10887609422206879 Validation Loss: 0.1787533015012741\n",
      "2722 Training Loss: 0.08747261762619019 Validation Loss: 0.17960888147354126\n",
      "2723 Training Loss: 0.10566497594118118 Validation Loss: 0.1799411177635193\n",
      "2724 Training Loss: 0.09907932579517365 Validation Loss: 0.18061181902885437\n",
      "2725 Training Loss: 0.0903964713215828 Validation Loss: 0.182107612490654\n",
      "2726 Training Loss: 0.11947748810052872 Validation Loss: 0.18167375028133392\n",
      "2727 Training Loss: 0.10064475983381271 Validation Loss: 0.18163980543613434\n",
      "2728 Training Loss: 0.08754079788923264 Validation Loss: 0.18248049914836884\n",
      "2729 Training Loss: 0.10148430615663528 Validation Loss: 0.18294766545295715\n",
      "2730 Training Loss: 0.11292192339897156 Validation Loss: 0.1827993094921112\n",
      "2731 Training Loss: 0.09515509754419327 Validation Loss: 0.18224871158599854\n",
      "2732 Training Loss: 0.09714530408382416 Validation Loss: 0.1822211742401123\n",
      "2733 Training Loss: 0.09825677424669266 Validation Loss: 0.18248960375785828\n",
      "2734 Training Loss: 0.10604166984558105 Validation Loss: 0.1826597899198532\n",
      "2735 Training Loss: 0.13723716139793396 Validation Loss: 0.1793552041053772\n",
      "2736 Training Loss: 0.10096535831689835 Validation Loss: 0.17563265562057495\n",
      "2737 Training Loss: 0.1071295514702797 Validation Loss: 0.17228877544403076\n",
      "2738 Training Loss: 0.10524088889360428 Validation Loss: 0.16948139667510986\n",
      "2739 Training Loss: 0.09902463853359222 Validation Loss: 0.16778060793876648\n",
      "2740 Training Loss: 0.11877895891666412 Validation Loss: 0.16564534604549408\n",
      "2741 Training Loss: 0.1189257800579071 Validation Loss: 0.16323353350162506\n",
      "2742 Training Loss: 0.09210381656885147 Validation Loss: 0.16231709718704224\n",
      "2743 Training Loss: 0.11425717920064926 Validation Loss: 0.16102665662765503\n",
      "2744 Training Loss: 0.10757045447826385 Validation Loss: 0.16000694036483765\n",
      "2745 Training Loss: 0.09346505254507065 Validation Loss: 0.16033798456192017\n",
      "2746 Training Loss: 0.10320987552404404 Validation Loss: 0.161391943693161\n",
      "2747 Training Loss: 0.10618318617343903 Validation Loss: 0.16225659847259521\n",
      "2748 Training Loss: 0.113288514316082 Validation Loss: 0.1627771407365799\n",
      "2749 Training Loss: 0.12555360794067383 Validation Loss: 0.16285374760627747\n",
      "2750 Training Loss: 0.09362740814685822 Validation Loss: 0.16350293159484863\n",
      "2751 Training Loss: 0.09414932131767273 Validation Loss: 0.16521531343460083\n",
      "2752 Training Loss: 0.10974419116973877 Validation Loss: 0.16679255664348602\n",
      "2753 Training Loss: 0.10763469338417053 Validation Loss: 0.1674683541059494\n",
      "2754 Training Loss: 0.11556902527809143 Validation Loss: 0.1673089563846588\n",
      "2755 Training Loss: 0.10091067105531693 Validation Loss: 0.16740405559539795\n",
      "2756 Training Loss: 0.12616819143295288 Validation Loss: 0.16615748405456543\n",
      "2757 Training Loss: 0.09656121581792831 Validation Loss: 0.16523391008377075\n",
      "2758 Training Loss: 0.11018781363964081 Validation Loss: 0.16325528919696808\n",
      "2759 Training Loss: 0.09215271472930908 Validation Loss: 0.16206669807434082\n",
      "2760 Training Loss: 0.11441244184970856 Validation Loss: 0.15977859497070312\n",
      "2761 Training Loss: 0.1006484106183052 Validation Loss: 0.1577393114566803\n",
      "2762 Training Loss: 0.09656597673892975 Validation Loss: 0.15640869736671448\n",
      "2763 Training Loss: 0.10177217423915863 Validation Loss: 0.15521369874477386\n",
      "2764 Training Loss: 0.10039687901735306 Validation Loss: 0.15432864427566528\n",
      "2765 Training Loss: 0.10763881355524063 Validation Loss: 0.15373295545578003\n",
      "2766 Training Loss: 0.09174845367670059 Validation Loss: 0.15443776547908783\n",
      "2767 Training Loss: 0.10583756864070892 Validation Loss: 0.15521018207073212\n",
      "2768 Training Loss: 0.09468677639961243 Validation Loss: 0.15674301981925964\n",
      "2769 Training Loss: 0.11359536647796631 Validation Loss: 0.15665623545646667\n",
      "2770 Training Loss: 0.10287012904882431 Validation Loss: 0.1564803123474121\n",
      "2771 Training Loss: 0.09031128138303757 Validation Loss: 0.15733006596565247\n",
      "2772 Training Loss: 0.08797641098499298 Validation Loss: 0.15897619724273682\n",
      "2773 Training Loss: 0.09514300525188446 Validation Loss: 0.16120973229408264\n",
      "2774 Training Loss: 0.09363044053316116 Validation Loss: 0.16355472803115845\n",
      "2775 Training Loss: 0.09267589449882507 Validation Loss: 0.16578373312950134\n",
      "2776 Training Loss: 0.11558395624160767 Validation Loss: 0.16570448875427246\n",
      "2777 Training Loss: 0.10468621551990509 Validation Loss: 0.16503407061100006\n",
      "2778 Training Loss: 0.10053510963916779 Validation Loss: 0.16378772258758545\n",
      "2779 Training Loss: 0.1104237511754036 Validation Loss: 0.1609627604484558\n",
      "2780 Training Loss: 0.089913010597229 Validation Loss: 0.15879200398921967\n",
      "2781 Training Loss: 0.09287840873003006 Validation Loss: 0.157327339053154\n",
      "2782 Training Loss: 0.0966680496931076 Validation Loss: 0.15580880641937256\n",
      "2783 Training Loss: 0.10442520678043365 Validation Loss: 0.1542942076921463\n",
      "2784 Training Loss: 0.09583798050880432 Validation Loss: 0.15317904949188232\n",
      "2785 Training Loss: 0.08749578148126602 Validation Loss: 0.15340730547904968\n",
      "2786 Training Loss: 0.09280523657798767 Validation Loss: 0.1544688642024994\n",
      "2787 Training Loss: 0.1100711077451706 Validation Loss: 0.15475016832351685\n",
      "2788 Training Loss: 0.10721072554588318 Validation Loss: 0.15401685237884521\n",
      "2789 Training Loss: 0.08946515619754791 Validation Loss: 0.15400125086307526\n",
      "2790 Training Loss: 0.10085736215114594 Validation Loss: 0.1535286158323288\n",
      "2791 Training Loss: 0.0867295041680336 Validation Loss: 0.15381987392902374\n",
      "2792 Training Loss: 0.09513171017169952 Validation Loss: 0.1534634828567505\n",
      "2793 Training Loss: 0.11107316613197327 Validation Loss: 0.1522388607263565\n",
      "2794 Training Loss: 0.1078079491853714 Validation Loss: 0.15074709057807922\n",
      "2795 Training Loss: 0.096147820353508 Validation Loss: 0.15050680935382843\n",
      "2796 Training Loss: 0.1022593230009079 Validation Loss: 0.15071308612823486\n",
      "2797 Training Loss: 0.11187535524368286 Validation Loss: 0.15035568177700043\n",
      "2798 Training Loss: 0.08278198540210724 Validation Loss: 0.15109294652938843\n",
      "2799 Training Loss: 0.10304909944534302 Validation Loss: 0.15108463168144226\n",
      "2800 Training Loss: 0.11577665060758591 Validation Loss: 0.15093331038951874\n",
      "2801 Training Loss: 0.08214680105447769 Validation Loss: 0.15181463956832886\n",
      "2802 Training Loss: 0.1015712320804596 Validation Loss: 0.1525806486606598\n",
      "2803 Training Loss: 0.08584485948085785 Validation Loss: 0.15423278510570526\n",
      "2804 Training Loss: 0.09033605456352234 Validation Loss: 0.15551826357841492\n",
      "2805 Training Loss: 0.0852268859744072 Validation Loss: 0.15710870921611786\n",
      "2806 Training Loss: 0.08408253639936447 Validation Loss: 0.1591215878725052\n",
      "2807 Training Loss: 0.08760514110326767 Validation Loss: 0.16145005822181702\n",
      "2808 Training Loss: 0.08362537622451782 Validation Loss: 0.16395843029022217\n",
      "2809 Training Loss: 0.09188558161258698 Validation Loss: 0.1652921736240387\n",
      "2810 Training Loss: 0.08643367141485214 Validation Loss: 0.1666172593832016\n",
      "2811 Training Loss: 0.099305659532547 Validation Loss: 0.16593311727046967\n",
      "2812 Training Loss: 0.09898515045642853 Validation Loss: 0.16436894237995148\n",
      "2813 Training Loss: 0.10118189454078674 Validation Loss: 0.16143594682216644\n",
      "2814 Training Loss: 0.0827794224023819 Validation Loss: 0.15923255681991577\n",
      "2815 Training Loss: 0.09454930573701859 Validation Loss: 0.15665844082832336\n",
      "2816 Training Loss: 0.0923948660492897 Validation Loss: 0.15436318516731262\n",
      "2817 Training Loss: 0.08041547238826752 Validation Loss: 0.15356063842773438\n",
      "2818 Training Loss: 0.08084877580404282 Validation Loss: 0.1533125638961792\n",
      "2819 Training Loss: 0.08080630749464035 Validation Loss: 0.15386657416820526\n",
      "2820 Training Loss: 0.09809494018554688 Validation Loss: 0.15365783870220184\n",
      "2821 Training Loss: 0.08209644258022308 Validation Loss: 0.15423351526260376\n",
      "2822 Training Loss: 0.09322667121887207 Validation Loss: 0.15501871705055237\n",
      "2823 Training Loss: 0.09237851202487946 Validation Loss: 0.1555408537387848\n",
      "2824 Training Loss: 0.08233850449323654 Validation Loss: 0.15593628585338593\n",
      "2825 Training Loss: 0.07753288745880127 Validation Loss: 0.15731686353683472\n",
      "2826 Training Loss: 0.09938770532608032 Validation Loss: 0.157780259847641\n",
      "2827 Training Loss: 0.086269810795784 Validation Loss: 0.15806885063648224\n",
      "2828 Training Loss: 0.09137207269668579 Validation Loss: 0.1584835648536682\n",
      "2829 Training Loss: 0.09395704418420792 Validation Loss: 0.15829604864120483\n",
      "2830 Training Loss: 0.11128634214401245 Validation Loss: 0.15639299154281616\n",
      "2831 Training Loss: 0.08390530943870544 Validation Loss: 0.15505178272724152\n",
      "2832 Training Loss: 0.08553501218557358 Validation Loss: 0.15406006574630737\n",
      "2833 Training Loss: 0.10488246381282806 Validation Loss: 0.15184305608272552\n",
      "2834 Training Loss: 0.08230338990688324 Validation Loss: 0.15001845359802246\n",
      "2835 Training Loss: 0.09677952527999878 Validation Loss: 0.1478772610425949\n",
      "2836 Training Loss: 0.09280107170343399 Validation Loss: 0.14589568972587585\n",
      "2837 Training Loss: 0.11002202332019806 Validation Loss: 0.14331716299057007\n",
      "2838 Training Loss: 0.09010770171880722 Validation Loss: 0.14133228361606598\n",
      "2839 Training Loss: 0.08026555925607681 Validation Loss: 0.14088399708271027\n",
      "2840 Training Loss: 0.08464842289686203 Validation Loss: 0.14113497734069824\n",
      "2841 Training Loss: 0.10153758525848389 Validation Loss: 0.1411174237728119\n",
      "2842 Training Loss: 0.08615931868553162 Validation Loss: 0.14209094643592834\n",
      "2843 Training Loss: 0.09727407991886139 Validation Loss: 0.14354315400123596\n",
      "2844 Training Loss: 0.08540431410074234 Validation Loss: 0.14536285400390625\n",
      "2845 Training Loss: 0.09991631656885147 Validation Loss: 0.14650146663188934\n",
      "2846 Training Loss: 0.10506054013967514 Validation Loss: 0.14614836871623993\n",
      "2847 Training Loss: 0.08996667712926865 Validation Loss: 0.14616215229034424\n",
      "2848 Training Loss: 0.08384283632040024 Validation Loss: 0.14678525924682617\n",
      "2849 Training Loss: 0.08730083703994751 Validation Loss: 0.14731626212596893\n",
      "2850 Training Loss: 0.1041281670331955 Validation Loss: 0.1465165764093399\n",
      "2851 Training Loss: 0.0948057472705841 Validation Loss: 0.14543119072914124\n",
      "2852 Training Loss: 0.1028735563158989 Validation Loss: 0.1435907483100891\n",
      "2853 Training Loss: 0.09344079345464706 Validation Loss: 0.14148566126823425\n",
      "2854 Training Loss: 0.0926910787820816 Validation Loss: 0.13916945457458496\n",
      "2855 Training Loss: 0.09430587291717529 Validation Loss: 0.13716760277748108\n",
      "2856 Training Loss: 0.09610075503587723 Validation Loss: 0.1351349651813507\n",
      "2857 Training Loss: 0.07818765193223953 Validation Loss: 0.1346167027950287\n",
      "2858 Training Loss: 0.10210878401994705 Validation Loss: 0.13380905985832214\n",
      "2859 Training Loss: 0.09145061671733856 Validation Loss: 0.1333748996257782\n",
      "2860 Training Loss: 0.09213997423648834 Validation Loss: 0.13346776366233826\n",
      "2861 Training Loss: 0.10440754145383835 Validation Loss: 0.1326817274093628\n",
      "2862 Training Loss: 0.09652477502822876 Validation Loss: 0.131790429353714\n",
      "2863 Training Loss: 0.07804546505212784 Validation Loss: 0.13206875324249268\n",
      "2864 Training Loss: 0.08192607015371323 Validation Loss: 0.13302278518676758\n",
      "2865 Training Loss: 0.09007295221090317 Validation Loss: 0.13450460135936737\n",
      "2866 Training Loss: 0.09292520582675934 Validation Loss: 0.13596300780773163\n",
      "2867 Training Loss: 0.09262578934431076 Validation Loss: 0.1376987099647522\n",
      "2868 Training Loss: 0.09484051167964935 Validation Loss: 0.13942211866378784\n",
      "2869 Training Loss: 0.08216046541929245 Validation Loss: 0.14119648933410645\n",
      "2870 Training Loss: 0.09771022945642471 Validation Loss: 0.14198188483715057\n",
      "2871 Training Loss: 0.07770590484142303 Validation Loss: 0.14329926669597626\n",
      "2872 Training Loss: 0.07047763466835022 Validation Loss: 0.14541684091091156\n",
      "2873 Training Loss: 0.09504979848861694 Validation Loss: 0.14590561389923096\n",
      "2874 Training Loss: 0.09492640942335129 Validation Loss: 0.14506985247135162\n",
      "2875 Training Loss: 0.08729098737239838 Validation Loss: 0.14301063120365143\n",
      "2876 Training Loss: 0.09592904895544052 Validation Loss: 0.14073063433170319\n",
      "2877 Training Loss: 0.09834669530391693 Validation Loss: 0.1375831514596939\n",
      "2878 Training Loss: 0.08024217188358307 Validation Loss: 0.13510476052761078\n",
      "2879 Training Loss: 0.08790543675422668 Validation Loss: 0.132819265127182\n",
      "2880 Training Loss: 0.08987148851156235 Validation Loss: 0.1311909705400467\n",
      "2881 Training Loss: 0.09808686375617981 Validation Loss: 0.1292147934436798\n",
      "2882 Training Loss: 0.07749757170677185 Validation Loss: 0.12839460372924805\n",
      "2883 Training Loss: 0.07730775326490402 Validation Loss: 0.12854593992233276\n",
      "2884 Training Loss: 0.10110500454902649 Validation Loss: 0.12837892770767212\n",
      "2885 Training Loss: 0.08435697853565216 Validation Loss: 0.1287618726491928\n",
      "2886 Training Loss: 0.09431919455528259 Validation Loss: 0.12896570563316345\n",
      "2887 Training Loss: 0.09136739373207092 Validation Loss: 0.12913724780082703\n",
      "2888 Training Loss: 0.08435608446598053 Validation Loss: 0.12986376881599426\n",
      "2889 Training Loss: 0.09607015550136566 Validation Loss: 0.13057748973369598\n",
      "2890 Training Loss: 0.09687918424606323 Validation Loss: 0.130803644657135\n",
      "2891 Training Loss: 0.08169861882925034 Validation Loss: 0.13176798820495605\n",
      "2892 Training Loss: 0.09154736250638962 Validation Loss: 0.1320413053035736\n",
      "2893 Training Loss: 0.09770910441875458 Validation Loss: 0.13197898864746094\n",
      "2894 Training Loss: 0.0770697072148323 Validation Loss: 0.13240128755569458\n",
      "2895 Training Loss: 0.08454681932926178 Validation Loss: 0.133012056350708\n",
      "2896 Training Loss: 0.08744964748620987 Validation Loss: 0.13324348628520966\n",
      "2897 Training Loss: 0.07916557788848877 Validation Loss: 0.13351576030254364\n",
      "2898 Training Loss: 0.09002548456192017 Validation Loss: 0.13324898481369019\n",
      "2899 Training Loss: 0.07586926221847534 Validation Loss: 0.13361160457134247\n",
      "2900 Training Loss: 0.07321591675281525 Validation Loss: 0.1343955248594284\n",
      "2901 Training Loss: 0.06974872946739197 Validation Loss: 0.13624070584774017\n",
      "2902 Training Loss: 0.09086183458566666 Validation Loss: 0.13728144764900208\n",
      "2903 Training Loss: 0.09267078340053558 Validation Loss: 0.1372532695531845\n",
      "2904 Training Loss: 0.07579642534255981 Validation Loss: 0.13756193220615387\n",
      "2905 Training Loss: 0.08544325083494186 Validation Loss: 0.13721098005771637\n",
      "2906 Training Loss: 0.08458054810762405 Validation Loss: 0.13590121269226074\n",
      "2907 Training Loss: 0.08416444063186646 Validation Loss: 0.13447169959545135\n",
      "2908 Training Loss: 0.0773208886384964 Validation Loss: 0.13359007239341736\n",
      "2909 Training Loss: 0.09002220630645752 Validation Loss: 0.13184292614459991\n",
      "2910 Training Loss: 0.07346309721469879 Validation Loss: 0.13091734051704407\n",
      "2911 Training Loss: 0.08479387313127518 Validation Loss: 0.1298082023859024\n",
      "2912 Training Loss: 0.08721699565649033 Validation Loss: 0.12854336202144623\n",
      "2913 Training Loss: 0.07025028765201569 Validation Loss: 0.12856388092041016\n",
      "2914 Training Loss: 0.0792454183101654 Validation Loss: 0.12900367379188538\n",
      "2915 Training Loss: 0.08684255182743073 Validation Loss: 0.1291990876197815\n",
      "2916 Training Loss: 0.09701436758041382 Validation Loss: 0.12834563851356506\n",
      "2917 Training Loss: 0.07989777624607086 Validation Loss: 0.12786242365837097\n",
      "2918 Training Loss: 0.06659801304340363 Validation Loss: 0.12864336371421814\n",
      "2919 Training Loss: 0.08743836730718613 Validation Loss: 0.1294446885585785\n",
      "2920 Training Loss: 0.07770948857069016 Validation Loss: 0.13067907094955444\n",
      "2921 Training Loss: 0.06610293686389923 Validation Loss: 0.13304299116134644\n",
      "2922 Training Loss: 0.10249503701925278 Validation Loss: 0.13407166302204132\n",
      "2923 Training Loss: 0.07318320125341415 Validation Loss: 0.13555794954299927\n",
      "2924 Training Loss: 0.09336766600608826 Validation Loss: 0.13549797236919403\n",
      "2925 Training Loss: 0.06610903143882751 Validation Loss: 0.13601364195346832\n",
      "2926 Training Loss: 0.07153959572315216 Validation Loss: 0.1369781196117401\n",
      "2927 Training Loss: 0.07486003637313843 Validation Loss: 0.13794945180416107\n",
      "2928 Training Loss: 0.08081375807523727 Validation Loss: 0.13817420601844788\n",
      "2929 Training Loss: 0.07994551211595535 Validation Loss: 0.13797350227832794\n",
      "2930 Training Loss: 0.07243651151657104 Validation Loss: 0.13758929073810577\n",
      "2931 Training Loss: 0.07463084161281586 Validation Loss: 0.13759799301624298\n",
      "2932 Training Loss: 0.09845094382762909 Validation Loss: 0.13583049178123474\n",
      "2933 Training Loss: 0.09359830617904663 Validation Loss: 0.1328861266374588\n",
      "2934 Training Loss: 0.078866146504879 Validation Loss: 0.13022030889987946\n",
      "2935 Training Loss: 0.07560352981090546 Validation Loss: 0.1286306083202362\n",
      "2936 Training Loss: 0.09082947671413422 Validation Loss: 0.12654173374176025\n",
      "2937 Training Loss: 0.09589181840419769 Validation Loss: 0.12411540746688843\n",
      "2938 Training Loss: 0.07660584151744843 Validation Loss: 0.12237799912691116\n",
      "2939 Training Loss: 0.07197830826044083 Validation Loss: 0.12177213281393051\n",
      "2940 Training Loss: 0.0744788646697998 Validation Loss: 0.12220709025859833\n",
      "2941 Training Loss: 0.08281604945659637 Validation Loss: 0.12268777191638947\n",
      "2942 Training Loss: 0.08757664263248444 Validation Loss: 0.12358522415161133\n",
      "2943 Training Loss: 0.07819749414920807 Validation Loss: 0.12502126395702362\n",
      "2944 Training Loss: 0.08172223716974258 Validation Loss: 0.12664416432380676\n",
      "2945 Training Loss: 0.06523149460554123 Validation Loss: 0.12958915531635284\n",
      "2946 Training Loss: 0.09597621858119965 Validation Loss: 0.13045141100883484\n",
      "2947 Training Loss: 0.06819455325603485 Validation Loss: 0.13146942853927612\n",
      "2948 Training Loss: 0.08883053064346313 Validation Loss: 0.13139767944812775\n",
      "2949 Training Loss: 0.08394363522529602 Validation Loss: 0.13052916526794434\n",
      "2950 Training Loss: 0.0688164085149765 Validation Loss: 0.13019827008247375\n",
      "2951 Training Loss: 0.08665882050991058 Validation Loss: 0.1290644407272339\n",
      "2952 Training Loss: 0.07344266027212143 Validation Loss: 0.12787248194217682\n",
      "2953 Training Loss: 0.07686343044042587 Validation Loss: 0.12711210548877716\n",
      "2954 Training Loss: 0.06937766820192337 Validation Loss: 0.1272943615913391\n",
      "2955 Training Loss: 0.0846884548664093 Validation Loss: 0.12694671750068665\n",
      "2956 Training Loss: 0.07811915874481201 Validation Loss: 0.1267530769109726\n",
      "2957 Training Loss: 0.07184389233589172 Validation Loss: 0.12702813744544983\n",
      "2958 Training Loss: 0.09746159613132477 Validation Loss: 0.12627065181732178\n",
      "2959 Training Loss: 0.0751575380563736 Validation Loss: 0.1259385645389557\n",
      "2960 Training Loss: 0.08564130961894989 Validation Loss: 0.1256316602230072\n",
      "2961 Training Loss: 0.07658199965953827 Validation Loss: 0.1246616393327713\n",
      "2962 Training Loss: 0.06406263262033463 Validation Loss: 0.12470536679029465\n",
      "2963 Training Loss: 0.07907751947641373 Validation Loss: 0.12449205666780472\n",
      "2964 Training Loss: 0.07095173001289368 Validation Loss: 0.12463139742612839\n",
      "2965 Training Loss: 0.07270041108131409 Validation Loss: 0.12478135526180267\n",
      "2966 Training Loss: 0.08361989259719849 Validation Loss: 0.12399192154407501\n",
      "2967 Training Loss: 0.08394187688827515 Validation Loss: 0.12265415489673615\n",
      "2968 Training Loss: 0.0648694708943367 Validation Loss: 0.12256789207458496\n",
      "2969 Training Loss: 0.07433396577835083 Validation Loss: 0.12233440577983856\n",
      "2970 Training Loss: 0.0625094622373581 Validation Loss: 0.12333427369594574\n",
      "2971 Training Loss: 0.06764882057905197 Validation Loss: 0.12508447468280792\n",
      "2972 Training Loss: 0.06527832895517349 Validation Loss: 0.12751111388206482\n",
      "2973 Training Loss: 0.06542117148637772 Validation Loss: 0.13019098341464996\n",
      "2974 Training Loss: 0.08304748684167862 Validation Loss: 0.13184010982513428\n",
      "2975 Training Loss: 0.0738065242767334 Validation Loss: 0.13260480761528015\n",
      "2976 Training Loss: 0.07247282564640045 Validation Loss: 0.13292573392391205\n",
      "2977 Training Loss: 0.09107993543148041 Validation Loss: 0.13113828003406525\n",
      "2978 Training Loss: 0.0748022198677063 Validation Loss: 0.12917321920394897\n",
      "2979 Training Loss: 0.06927574425935745 Validation Loss: 0.12710973620414734\n",
      "2980 Training Loss: 0.08058210462331772 Validation Loss: 0.12487101554870605\n",
      "2981 Training Loss: 0.07293646782636642 Validation Loss: 0.12318376451730728\n",
      "2982 Training Loss: 0.07500659674406052 Validation Loss: 0.12184648215770721\n",
      "2983 Training Loss: 0.07059946656227112 Validation Loss: 0.12078065425157547\n",
      "2984 Training Loss: 0.07077569514513016 Validation Loss: 0.12015127390623093\n",
      "2985 Training Loss: 0.0687643364071846 Validation Loss: 0.12020187824964523\n",
      "2986 Training Loss: 0.07694773375988007 Validation Loss: 0.1205267384648323\n",
      "2987 Training Loss: 0.08581452816724777 Validation Loss: 0.1203298270702362\n",
      "2988 Training Loss: 0.06623855978250504 Validation Loss: 0.12097620964050293\n",
      "2989 Training Loss: 0.08113385736942291 Validation Loss: 0.12089502811431885\n",
      "2990 Training Loss: 0.10206204652786255 Validation Loss: 0.11946401000022888\n",
      "2991 Training Loss: 0.07532341033220291 Validation Loss: 0.11817699670791626\n",
      "2992 Training Loss: 0.06428975611925125 Validation Loss: 0.11832842975854874\n",
      "2993 Training Loss: 0.0791006088256836 Validation Loss: 0.11864875257015228\n",
      "2994 Training Loss: 0.07024312764406204 Validation Loss: 0.1191076785326004\n",
      "2995 Training Loss: 0.07397876679897308 Validation Loss: 0.11926373839378357\n",
      "2996 Training Loss: 0.07045277208089828 Validation Loss: 0.11957154422998428\n",
      "2997 Training Loss: 0.09387163817882538 Validation Loss: 0.11888966709375381\n",
      "2998 Training Loss: 0.07390673458576202 Validation Loss: 0.11850756406784058\n",
      "2999 Training Loss: 0.09343615919351578 Validation Loss: 0.11639779061079025\n",
      "3000 Training Loss: 0.07976630330085754 Validation Loss: 0.11459498107433319\n",
      "3001 Training Loss: 0.07598185539245605 Validation Loss: 0.11288172006607056\n",
      "3002 Training Loss: 0.06922371685504913 Validation Loss: 0.11183872818946838\n",
      "3003 Training Loss: 0.07439640164375305 Validation Loss: 0.11134817451238632\n",
      "3004 Training Loss: 0.0783931314945221 Validation Loss: 0.11076898127794266\n",
      "3005 Training Loss: 0.07676589488983154 Validation Loss: 0.11062472313642502\n",
      "3006 Training Loss: 0.08890694379806519 Validation Loss: 0.11037108302116394\n",
      "3007 Training Loss: 0.06191542372107506 Validation Loss: 0.1113220751285553\n",
      "3008 Training Loss: 0.06946831941604614 Validation Loss: 0.11259828507900238\n",
      "3009 Training Loss: 0.09141556918621063 Validation Loss: 0.11291708797216415\n",
      "3010 Training Loss: 0.06784161180257797 Validation Loss: 0.11351482570171356\n",
      "3011 Training Loss: 0.07036776840686798 Validation Loss: 0.11459311097860336\n",
      "3012 Training Loss: 0.06358153373003006 Validation Loss: 0.11606190353631973\n",
      "3013 Training Loss: 0.07313749939203262 Validation Loss: 0.11742081493139267\n",
      "3014 Training Loss: 0.07158486545085907 Validation Loss: 0.11881338059902191\n",
      "3015 Training Loss: 0.06347304582595825 Validation Loss: 0.12078841775655746\n",
      "3016 Training Loss: 0.08040755987167358 Validation Loss: 0.12121112644672394\n",
      "3017 Training Loss: 0.08129478991031647 Validation Loss: 0.12144532799720764\n",
      "3018 Training Loss: 0.07274714857339859 Validation Loss: 0.12125126272439957\n",
      "3019 Training Loss: 0.06959628313779831 Validation Loss: 0.12053684890270233\n",
      "3020 Training Loss: 0.07804971933364868 Validation Loss: 0.118986576795578\n",
      "3021 Training Loss: 0.059720054268836975 Validation Loss: 0.11824102699756622\n",
      "3022 Training Loss: 0.07246588170528412 Validation Loss: 0.116984061896801\n",
      "3023 Training Loss: 0.07169563323259354 Validation Loss: 0.11546014249324799\n",
      "3024 Training Loss: 0.0680910050868988 Validation Loss: 0.1144159734249115\n",
      "3025 Training Loss: 0.08273331820964813 Validation Loss: 0.11282537132501602\n",
      "3026 Training Loss: 0.07309415936470032 Validation Loss: 0.11208003014326096\n",
      "3027 Training Loss: 0.06772191822528839 Validation Loss: 0.11185409873723984\n",
      "3028 Training Loss: 0.06431331485509872 Validation Loss: 0.11262310296297073\n",
      "3029 Training Loss: 0.06597930192947388 Validation Loss: 0.11397238820791245\n",
      "3030 Training Loss: 0.07423195242881775 Validation Loss: 0.11526749283075333\n",
      "3031 Training Loss: 0.06460077315568924 Validation Loss: 0.1172417625784874\n",
      "3032 Training Loss: 0.07182052731513977 Validation Loss: 0.11847736686468124\n",
      "3033 Training Loss: 0.06781769543886185 Validation Loss: 0.1196499913930893\n",
      "3034 Training Loss: 0.07993081212043762 Validation Loss: 0.1202414408326149\n",
      "3035 Training Loss: 0.05883634090423584 Validation Loss: 0.12132061272859573\n",
      "3036 Training Loss: 0.0646715760231018 Validation Loss: 0.12219514697790146\n",
      "3037 Training Loss: 0.06841538101434708 Validation Loss: 0.12235493212938309\n",
      "3038 Training Loss: 0.07547754049301147 Validation Loss: 0.12141047418117523\n",
      "3039 Training Loss: 0.06772401183843613 Validation Loss: 0.1202607974410057\n",
      "3040 Training Loss: 0.06323365867137909 Validation Loss: 0.11942221969366074\n",
      "3041 Training Loss: 0.061584919691085815 Validation Loss: 0.11898953467607498\n",
      "3042 Training Loss: 0.07298431545495987 Validation Loss: 0.11765797436237335\n",
      "3043 Training Loss: 0.061193183064460754 Validation Loss: 0.1168522909283638\n",
      "3044 Training Loss: 0.06372619420289993 Validation Loss: 0.11671169847249985\n",
      "3045 Training Loss: 0.09814582020044327 Validation Loss: 0.11497863382101059\n",
      "3046 Training Loss: 0.0676741674542427 Validation Loss: 0.11343571543693542\n",
      "3047 Training Loss: 0.08372777700424194 Validation Loss: 0.11103665828704834\n",
      "3048 Training Loss: 0.06496339291334152 Validation Loss: 0.10936044156551361\n",
      "3049 Training Loss: 0.0634591206908226 Validation Loss: 0.1083516776561737\n",
      "3050 Training Loss: 0.07867971062660217 Validation Loss: 0.10703073441982269\n",
      "3051 Training Loss: 0.07272706180810928 Validation Loss: 0.1061481386423111\n",
      "3052 Training Loss: 0.0694524496793747 Validation Loss: 0.10567519068717957\n",
      "3053 Training Loss: 0.07093975692987442 Validation Loss: 0.1057177186012268\n",
      "3054 Training Loss: 0.07165732979774475 Validation Loss: 0.10616983473300934\n",
      "3055 Training Loss: 0.07512368261814117 Validation Loss: 0.10666191577911377\n",
      "3056 Training Loss: 0.06828536093235016 Validation Loss: 0.1078479140996933\n",
      "3057 Training Loss: 0.07246777415275574 Validation Loss: 0.10908789932727814\n",
      "3058 Training Loss: 0.06703484058380127 Validation Loss: 0.11085763573646545\n",
      "3059 Training Loss: 0.07017705589532852 Validation Loss: 0.11254027485847473\n",
      "3060 Training Loss: 0.07936786115169525 Validation Loss: 0.1129315048456192\n",
      "3061 Training Loss: 0.06340083479881287 Validation Loss: 0.11312899738550186\n",
      "3062 Training Loss: 0.0588228777050972 Validation Loss: 0.11355549097061157\n",
      "3063 Training Loss: 0.06485924124717712 Validation Loss: 0.11392341554164886\n",
      "3064 Training Loss: 0.06343057751655579 Validation Loss: 0.114049531519413\n",
      "3065 Training Loss: 0.06366777420043945 Validation Loss: 0.11412392556667328\n",
      "3066 Training Loss: 0.07471975684165955 Validation Loss: 0.11329331994056702\n",
      "3067 Training Loss: 0.06611549109220505 Validation Loss: 0.11265600472688675\n",
      "3068 Training Loss: 0.05946848541498184 Validation Loss: 0.11227253079414368\n",
      "3069 Training Loss: 0.06461718678474426 Validation Loss: 0.11192788183689117\n",
      "3070 Training Loss: 0.07673581689596176 Validation Loss: 0.1105346530675888\n",
      "3071 Training Loss: 0.0662461593747139 Validation Loss: 0.10942009091377258\n",
      "3072 Training Loss: 0.0797579288482666 Validation Loss: 0.10747753083705902\n",
      "3073 Training Loss: 0.07856254279613495 Validation Loss: 0.10579026490449905\n",
      "3074 Training Loss: 0.06125657632946968 Validation Loss: 0.1049567312002182\n",
      "3075 Training Loss: 0.07517509907484055 Validation Loss: 0.10383013635873795\n",
      "3076 Training Loss: 0.06143884360790253 Validation Loss: 0.10340455174446106\n",
      "3077 Training Loss: 0.06191824749112129 Validation Loss: 0.10361282527446747\n",
      "3078 Training Loss: 0.07686815410852432 Validation Loss: 0.10363660752773285\n",
      "3079 Training Loss: 0.09404142946004868 Validation Loss: 0.10242430865764618\n",
      "3080 Training Loss: 0.06896186619997025 Validation Loss: 0.1015719324350357\n",
      "3081 Training Loss: 0.06304992735385895 Validation Loss: 0.10104666650295258\n",
      "3082 Training Loss: 0.06741537153720856 Validation Loss: 0.10087769478559494\n",
      "3083 Training Loss: 0.06580635905265808 Validation Loss: 0.1009141057729721\n",
      "3084 Training Loss: 0.05956188961863518 Validation Loss: 0.10174909234046936\n",
      "3085 Training Loss: 0.07560694217681885 Validation Loss: 0.10278736054897308\n",
      "3086 Training Loss: 0.059736281633377075 Validation Loss: 0.10431326925754547\n",
      "3087 Training Loss: 0.06186182051897049 Validation Loss: 0.1060212254524231\n",
      "3088 Training Loss: 0.06279459595680237 Validation Loss: 0.10807210206985474\n",
      "3089 Training Loss: 0.060828641057014465 Validation Loss: 0.11024469137191772\n",
      "3090 Training Loss: 0.06000332906842232 Validation Loss: 0.11260733008384705\n",
      "3091 Training Loss: 0.08179214596748352 Validation Loss: 0.1135239452123642\n",
      "3092 Training Loss: 0.058774013072252274 Validation Loss: 0.11465015262365341\n",
      "3093 Training Loss: 0.07128292322158813 Validation Loss: 0.1142948716878891\n",
      "3094 Training Loss: 0.05792170390486717 Validation Loss: 0.11379051208496094\n",
      "3095 Training Loss: 0.08123951405286789 Validation Loss: 0.11171415448188782\n",
      "3096 Training Loss: 0.07810653001070023 Validation Loss: 0.10847160965204239\n",
      "3097 Training Loss: 0.058932721614837646 Validation Loss: 0.1061701700091362\n",
      "3098 Training Loss: 0.06728857010602951 Validation Loss: 0.10391789674758911\n",
      "3099 Training Loss: 0.0829920619726181 Validation Loss: 0.1012382060289383\n",
      "3100 Training Loss: 0.05596889555454254 Validation Loss: 0.09971094131469727\n",
      "3101 Training Loss: 0.06602201610803604 Validation Loss: 0.09864482283592224\n",
      "3102 Training Loss: 0.07340841740369797 Validation Loss: 0.09757432341575623\n",
      "3103 Training Loss: 0.0624394491314888 Validation Loss: 0.0971561074256897\n",
      "3104 Training Loss: 0.06321477144956589 Validation Loss: 0.09731719642877579\n",
      "3105 Training Loss: 0.06875617057085037 Validation Loss: 0.09787385910749435\n",
      "3106 Training Loss: 0.05727709084749222 Validation Loss: 0.09931105375289917\n",
      "3107 Training Loss: 0.05875816196203232 Validation Loss: 0.10111136734485626\n",
      "3108 Training Loss: 0.05498058721423149 Validation Loss: 0.10375675559043884\n",
      "3109 Training Loss: 0.06520719081163406 Validation Loss: 0.10627494752407074\n",
      "3110 Training Loss: 0.057064734399318695 Validation Loss: 0.10948602855205536\n",
      "3111 Training Loss: 0.07253971695899963 Validation Loss: 0.11147642880678177\n",
      "3112 Training Loss: 0.05575327202677727 Validation Loss: 0.11329050362110138\n",
      "3113 Training Loss: 0.0712704062461853 Validation Loss: 0.11420095711946487\n",
      "3114 Training Loss: 0.06709964573383331 Validation Loss: 0.11351330578327179\n",
      "3115 Training Loss: 0.06736689805984497 Validation Loss: 0.1121404767036438\n",
      "3116 Training Loss: 0.06967003643512726 Validation Loss: 0.11015943437814713\n",
      "3117 Training Loss: 0.06834858655929565 Validation Loss: 0.10785618424415588\n",
      "3118 Training Loss: 0.06391904503107071 Validation Loss: 0.10547000169754028\n",
      "3119 Training Loss: 0.07416552305221558 Validation Loss: 0.10245610773563385\n",
      "3120 Training Loss: 0.059582844376564026 Validation Loss: 0.10029690712690353\n",
      "3121 Training Loss: 0.0840323269367218 Validation Loss: 0.09777442365884781\n",
      "3122 Training Loss: 0.05839241296052933 Validation Loss: 0.09617725014686584\n",
      "3123 Training Loss: 0.062117066234350204 Validation Loss: 0.09524538367986679\n",
      "3124 Training Loss: 0.07413484156131744 Validation Loss: 0.09461060166358948\n",
      "3125 Training Loss: 0.05834953486919403 Validation Loss: 0.09468063712120056\n",
      "3126 Training Loss: 0.0650758296251297 Validation Loss: 0.09481228142976761\n",
      "3127 Training Loss: 0.08049513399600983 Validation Loss: 0.09451325237751007\n",
      "3128 Training Loss: 0.060525476932525635 Validation Loss: 0.09498689323663712\n",
      "3129 Training Loss: 0.06615060567855835 Validation Loss: 0.09571070969104767\n",
      "3130 Training Loss: 0.06591945886611938 Validation Loss: 0.09651360660791397\n",
      "3131 Training Loss: 0.07757031172513962 Validation Loss: 0.09678724408149719\n",
      "3132 Training Loss: 0.06205277517437935 Validation Loss: 0.0976872518658638\n",
      "3133 Training Loss: 0.06466858834028244 Validation Loss: 0.09888392686843872\n",
      "3134 Training Loss: 0.06069914251565933 Validation Loss: 0.10042747110128403\n",
      "3135 Training Loss: 0.08337850123643875 Validation Loss: 0.10064644366502762\n",
      "3136 Training Loss: 0.05547631159424782 Validation Loss: 0.10113083571195602\n",
      "3137 Training Loss: 0.07020945101976395 Validation Loss: 0.10096751898527145\n",
      "3138 Training Loss: 0.061362553387880325 Validation Loss: 0.10108941048383713\n",
      "3139 Training Loss: 0.06163855642080307 Validation Loss: 0.10124395042657852\n",
      "3140 Training Loss: 0.08254043757915497 Validation Loss: 0.10013547539710999\n",
      "3141 Training Loss: 0.0654207319021225 Validation Loss: 0.09899364411830902\n",
      "3142 Training Loss: 0.061635784804821014 Validation Loss: 0.0979127585887909\n",
      "3143 Training Loss: 0.06832492351531982 Validation Loss: 0.0966307520866394\n",
      "3144 Training Loss: 0.05539201945066452 Validation Loss: 0.09594939649105072\n",
      "3145 Training Loss: 0.0610167533159256 Validation Loss: 0.09560929238796234\n",
      "3146 Training Loss: 0.06257323920726776 Validation Loss: 0.0956263393163681\n",
      "3147 Training Loss: 0.06735149025917053 Validation Loss: 0.09565785527229309\n",
      "3148 Training Loss: 0.06233906373381615 Validation Loss: 0.09578157961368561\n",
      "3149 Training Loss: 0.06606058776378632 Validation Loss: 0.09604354202747345\n",
      "3150 Training Loss: 0.05773967131972313 Validation Loss: 0.09668917208909988\n",
      "3151 Training Loss: 0.056872159242630005 Validation Loss: 0.09777271747589111\n",
      "3152 Training Loss: 0.06755487620830536 Validation Loss: 0.0983203873038292\n",
      "3153 Training Loss: 0.05249731242656708 Validation Loss: 0.0996360182762146\n",
      "3154 Training Loss: 0.06744515895843506 Validation Loss: 0.0999828577041626\n",
      "3155 Training Loss: 0.06714631617069244 Validation Loss: 0.09996183216571808\n",
      "3156 Training Loss: 0.06391587853431702 Validation Loss: 0.09973756968975067\n",
      "3157 Training Loss: 0.06321586668491364 Validation Loss: 0.0990738645195961\n",
      "3158 Training Loss: 0.06557431817054749 Validation Loss: 0.09811738133430481\n",
      "3159 Training Loss: 0.06140647828578949 Validation Loss: 0.09721902012825012\n",
      "3160 Training Loss: 0.0735340565443039 Validation Loss: 0.09572672843933105\n",
      "3161 Training Loss: 0.052703022956848145 Validation Loss: 0.09511369466781616\n",
      "3162 Training Loss: 0.05560876801609993 Validation Loss: 0.09509016573429108\n",
      "3163 Training Loss: 0.055030498653650284 Validation Loss: 0.09582123905420303\n",
      "3164 Training Loss: 0.05331440642476082 Validation Loss: 0.09687848389148712\n",
      "3165 Training Loss: 0.0736003890633583 Validation Loss: 0.09699341654777527\n",
      "3166 Training Loss: 0.05583496019244194 Validation Loss: 0.0974138155579567\n",
      "3167 Training Loss: 0.053361572325229645 Validation Loss: 0.09802927076816559\n",
      "3168 Training Loss: 0.05378046631813049 Validation Loss: 0.09893189370632172\n",
      "3169 Training Loss: 0.05425889417529106 Validation Loss: 0.0998336672782898\n",
      "3170 Training Loss: 0.06838871538639069 Validation Loss: 0.09991253912448883\n",
      "3171 Training Loss: 0.06731706112623215 Validation Loss: 0.09929045289754868\n",
      "3172 Training Loss: 0.05066303536295891 Validation Loss: 0.09920115023851395\n",
      "3173 Training Loss: 0.059609074145555496 Validation Loss: 0.09863200783729553\n",
      "3174 Training Loss: 0.06146411597728729 Validation Loss: 0.09780863672494888\n",
      "3175 Training Loss: 0.05898143723607063 Validation Loss: 0.09720189869403839\n",
      "3176 Training Loss: 0.058943912386894226 Validation Loss: 0.09651700407266617\n",
      "3177 Training Loss: 0.05509583279490471 Validation Loss: 0.09609256684780121\n",
      "3178 Training Loss: 0.05343755707144737 Validation Loss: 0.09614626318216324\n",
      "3179 Training Loss: 0.07221713662147522 Validation Loss: 0.0954701155424118\n",
      "3180 Training Loss: 0.06591559946537018 Validation Loss: 0.09486802667379379\n",
      "3181 Training Loss: 0.059740565717220306 Validation Loss: 0.09423375874757767\n",
      "3182 Training Loss: 0.0565933957695961 Validation Loss: 0.0939464271068573\n",
      "3183 Training Loss: 0.05275358259677887 Validation Loss: 0.09431685507297516\n",
      "3184 Training Loss: 0.0544472262263298 Validation Loss: 0.09494182467460632\n",
      "3185 Training Loss: 0.0671808272600174 Validation Loss: 0.09496230632066727\n",
      "3186 Training Loss: 0.0680389553308487 Validation Loss: 0.09449252486228943\n",
      "3187 Training Loss: 0.0663810595870018 Validation Loss: 0.09364891052246094\n",
      "3188 Training Loss: 0.057515352964401245 Validation Loss: 0.09297157824039459\n",
      "3189 Training Loss: 0.061897650361061096 Validation Loss: 0.09243614226579666\n",
      "3190 Training Loss: 0.06381507217884064 Validation Loss: 0.0919661745429039\n",
      "3191 Training Loss: 0.05629190057516098 Validation Loss: 0.0917893797159195\n",
      "3192 Training Loss: 0.062014032155275345 Validation Loss: 0.0914507582783699\n",
      "3193 Training Loss: 0.050613775849342346 Validation Loss: 0.09173604100942612\n",
      "3194 Training Loss: 0.06494443118572235 Validation Loss: 0.09171336889266968\n",
      "3195 Training Loss: 0.058635905385017395 Validation Loss: 0.09184705466032028\n",
      "3196 Training Loss: 0.054721686989068985 Validation Loss: 0.09253768622875214\n",
      "3197 Training Loss: 0.06936438381671906 Validation Loss: 0.09283436089754105\n",
      "3198 Training Loss: 0.050672899931669235 Validation Loss: 0.09388723224401474\n",
      "3199 Training Loss: 0.05339817702770233 Validation Loss: 0.09513770043849945\n",
      "3200 Training Loss: 0.07055891305208206 Validation Loss: 0.09527190029621124\n",
      "3201 Training Loss: 0.055505700409412384 Validation Loss: 0.09562484920024872\n",
      "3202 Training Loss: 0.058254893869161606 Validation Loss: 0.09567049145698547\n",
      "3203 Training Loss: 0.07081949710845947 Validation Loss: 0.09477467089891434\n",
      "3204 Training Loss: 0.05308671295642853 Validation Loss: 0.09400489926338196\n",
      "3205 Training Loss: 0.07128491997718811 Validation Loss: 0.09240809082984924\n",
      "3206 Training Loss: 0.055462323129177094 Validation Loss: 0.09102886915206909\n",
      "3207 Training Loss: 0.05348090082406998 Validation Loss: 0.09005501866340637\n",
      "3208 Training Loss: 0.06144554167985916 Validation Loss: 0.08917393535375595\n",
      "3209 Training Loss: 0.052730266004800797 Validation Loss: 0.08884136378765106\n",
      "3210 Training Loss: 0.05588071793317795 Validation Loss: 0.08875502645969391\n",
      "3211 Training Loss: 0.06356018781661987 Validation Loss: 0.08847443759441376\n",
      "3212 Training Loss: 0.05057850852608681 Validation Loss: 0.08899132907390594\n",
      "3213 Training Loss: 0.05896289646625519 Validation Loss: 0.08964742720127106\n",
      "3214 Training Loss: 0.06225132942199707 Validation Loss: 0.09008143842220306\n",
      "3215 Training Loss: 0.048679716885089874 Validation Loss: 0.09124717116355896\n",
      "3216 Training Loss: 0.062330156564712524 Validation Loss: 0.09200024604797363\n",
      "3217 Training Loss: 0.06341192871332169 Validation Loss: 0.09248144924640656\n",
      "3218 Training Loss: 0.0525621697306633 Validation Loss: 0.09318608045578003\n",
      "3219 Training Loss: 0.074509397149086 Validation Loss: 0.09234050661325455\n",
      "3220 Training Loss: 0.05277906358242035 Validation Loss: 0.09223143011331558\n",
      "3221 Training Loss: 0.0630899965763092 Validation Loss: 0.09147653728723526\n",
      "3222 Training Loss: 0.056403785943984985 Validation Loss: 0.09078703075647354\n",
      "3223 Training Loss: 0.05452945828437805 Validation Loss: 0.0902353897690773\n",
      "3224 Training Loss: 0.06332924216985703 Validation Loss: 0.08906756341457367\n",
      "3225 Training Loss: 0.04757583886384964 Validation Loss: 0.08871907740831375\n",
      "3226 Training Loss: 0.05616092309355736 Validation Loss: 0.08867000043392181\n",
      "3227 Training Loss: 0.0533386692404747 Validation Loss: 0.08900513499975204\n",
      "3228 Training Loss: 0.06744788587093353 Validation Loss: 0.08865604549646378\n",
      "3229 Training Loss: 0.054180119186639786 Validation Loss: 0.0884552150964737\n",
      "3230 Training Loss: 0.05006665736436844 Validation Loss: 0.08891750872135162\n",
      "3231 Training Loss: 0.05819803103804588 Validation Loss: 0.08947399258613586\n",
      "3232 Training Loss: 0.05188627541065216 Validation Loss: 0.09015776216983795\n",
      "3233 Training Loss: 0.06081852689385414 Validation Loss: 0.09050863981246948\n",
      "3234 Training Loss: 0.06777092069387436 Validation Loss: 0.09008264541625977\n",
      "3235 Training Loss: 0.06192748248577118 Validation Loss: 0.08955022692680359\n",
      "3236 Training Loss: 0.057024456560611725 Validation Loss: 0.08916275203227997\n",
      "3237 Training Loss: 0.060197025537490845 Validation Loss: 0.08881824463605881\n",
      "3238 Training Loss: 0.06581860780715942 Validation Loss: 0.08801404386758804\n",
      "3239 Training Loss: 0.05097905546426773 Validation Loss: 0.08750247955322266\n",
      "3240 Training Loss: 0.04921039193868637 Validation Loss: 0.0875164270401001\n",
      "3241 Training Loss: 0.0756605938076973 Validation Loss: 0.08691386133432388\n",
      "3242 Training Loss: 0.06244377791881561 Validation Loss: 0.08616139739751816\n",
      "3243 Training Loss: 0.0554795116186142 Validation Loss: 0.08554437756538391\n",
      "3244 Training Loss: 0.04647687077522278 Validation Loss: 0.08571834862232208\n",
      "3245 Training Loss: 0.04676208272576332 Validation Loss: 0.08659542351961136\n",
      "3246 Training Loss: 0.05138388276100159 Validation Loss: 0.08760939538478851\n",
      "3247 Training Loss: 0.058371443301439285 Validation Loss: 0.08839713037014008\n",
      "3248 Training Loss: 0.05087726190686226 Validation Loss: 0.0892307311296463\n",
      "3249 Training Loss: 0.05582781881093979 Validation Loss: 0.08977146446704865\n",
      "3250 Training Loss: 0.052325986325740814 Validation Loss: 0.09033957868814468\n",
      "3251 Training Loss: 0.05320300906896591 Validation Loss: 0.090797059237957\n",
      "3252 Training Loss: 0.05578421801328659 Validation Loss: 0.09107249230146408\n",
      "3253 Training Loss: 0.052152328193187714 Validation Loss: 0.09125407785177231\n",
      "3254 Training Loss: 0.05067828670144081 Validation Loss: 0.09168673306703568\n",
      "3255 Training Loss: 0.050163693726062775 Validation Loss: 0.09181270748376846\n",
      "3256 Training Loss: 0.048036377876996994 Validation Loss: 0.09253060817718506\n",
      "3257 Training Loss: 0.06088366359472275 Validation Loss: 0.0926661342382431\n",
      "3258 Training Loss: 0.04875803738832474 Validation Loss: 0.09254373610019684\n",
      "3259 Training Loss: 0.048386864364147186 Validation Loss: 0.09238199144601822\n",
      "3260 Training Loss: 0.06519728899002075 Validation Loss: 0.09144368767738342\n",
      "3261 Training Loss: 0.05270620435476303 Validation Loss: 0.09022402763366699\n",
      "3262 Training Loss: 0.0459006130695343 Validation Loss: 0.08965993672609329\n",
      "3263 Training Loss: 0.04808197543025017 Validation Loss: 0.08940203487873077\n",
      "3264 Training Loss: 0.05201312154531479 Validation Loss: 0.08898505568504333\n",
      "3265 Training Loss: 0.04629664868116379 Validation Loss: 0.08944839239120483\n",
      "3266 Training Loss: 0.04601932317018509 Validation Loss: 0.09027952700853348\n",
      "3267 Training Loss: 0.05903366953134537 Validation Loss: 0.09059669822454453\n",
      "3268 Training Loss: 0.0479794405400753 Validation Loss: 0.09119436144828796\n",
      "3269 Training Loss: 0.06195412576198578 Validation Loss: 0.09079285711050034\n",
      "3270 Training Loss: 0.06576307862997055 Validation Loss: 0.0895516499876976\n",
      "3271 Training Loss: 0.051896948367357254 Validation Loss: 0.08845175802707672\n",
      "3272 Training Loss: 0.05222710594534874 Validation Loss: 0.08756047487258911\n",
      "3273 Training Loss: 0.05222772806882858 Validation Loss: 0.0867757722735405\n",
      "3274 Training Loss: 0.05491434037685394 Validation Loss: 0.08605218678712845\n",
      "3275 Training Loss: 0.04690583795309067 Validation Loss: 0.08598242700099945\n",
      "3276 Training Loss: 0.049683719873428345 Validation Loss: 0.08617040514945984\n",
      "3277 Training Loss: 0.06611675024032593 Validation Loss: 0.08560892194509506\n",
      "3278 Training Loss: 0.05239309370517731 Validation Loss: 0.0854371190071106\n",
      "3279 Training Loss: 0.05872994288802147 Validation Loss: 0.08503766357898712\n",
      "3280 Training Loss: 0.04931948706507683 Validation Loss: 0.08501552045345306\n",
      "3281 Training Loss: 0.05794493854045868 Validation Loss: 0.08533014357089996\n",
      "3282 Training Loss: 0.05324924737215042 Validation Loss: 0.0855519026517868\n",
      "3283 Training Loss: 0.0548146516084671 Validation Loss: 0.08574819564819336\n",
      "3284 Training Loss: 0.05482557415962219 Validation Loss: 0.08571808785200119\n",
      "3285 Training Loss: 0.053276289254426956 Validation Loss: 0.08568572998046875\n",
      "3286 Training Loss: 0.058938249945640564 Validation Loss: 0.08537422865629196\n",
      "3287 Training Loss: 0.061732131987810135 Validation Loss: 0.08460388332605362\n",
      "3288 Training Loss: 0.04549062252044678 Validation Loss: 0.08434091508388519\n",
      "3289 Training Loss: 0.054737597703933716 Validation Loss: 0.08417567610740662\n",
      "3290 Training Loss: 0.05017613619565964 Validation Loss: 0.08438176661729813\n",
      "3291 Training Loss: 0.05547313764691353 Validation Loss: 0.08412203192710876\n",
      "3292 Training Loss: 0.051655758172273636 Validation Loss: 0.08404868841171265\n",
      "3293 Training Loss: 0.04830794036388397 Validation Loss: 0.08416874706745148\n",
      "3294 Training Loss: 0.051022402942180634 Validation Loss: 0.08462713658809662\n",
      "3295 Training Loss: 0.053375255316495895 Validation Loss: 0.08530551195144653\n",
      "3296 Training Loss: 0.0442713126540184 Validation Loss: 0.08632959425449371\n",
      "3297 Training Loss: 0.057498179376125336 Validation Loss: 0.08707813918590546\n",
      "3298 Training Loss: 0.05325963348150253 Validation Loss: 0.08791881054639816\n",
      "3299 Training Loss: 0.04466620087623596 Validation Loss: 0.08903594315052032\n",
      "3300 Training Loss: 0.054151758551597595 Validation Loss: 0.08993489295244217\n",
      "3301 Training Loss: 0.05158048868179321 Validation Loss: 0.09078247100114822\n",
      "3302 Training Loss: 0.059108659625053406 Validation Loss: 0.09065613150596619\n",
      "3303 Training Loss: 0.06755909323692322 Validation Loss: 0.08920023590326309\n",
      "3304 Training Loss: 0.045524779707193375 Validation Loss: 0.0883542075753212\n",
      "3305 Training Loss: 0.044666141271591187 Validation Loss: 0.08770354837179184\n",
      "3306 Training Loss: 0.04469681158661842 Validation Loss: 0.08752281963825226\n",
      "3307 Training Loss: 0.0469236746430397 Validation Loss: 0.0874033197760582\n",
      "3308 Training Loss: 0.050469666719436646 Validation Loss: 0.08711196482181549\n",
      "3309 Training Loss: 0.051939256489276886 Validation Loss: 0.08674023300409317\n",
      "3310 Training Loss: 0.04947793483734131 Validation Loss: 0.0864618569612503\n",
      "3311 Training Loss: 0.05852727219462395 Validation Loss: 0.08569400757551193\n",
      "3312 Training Loss: 0.05566318333148956 Validation Loss: 0.08468540757894516\n",
      "3313 Training Loss: 0.06113387644290924 Validation Loss: 0.08337853848934174\n",
      "3314 Training Loss: 0.04634794220328331 Validation Loss: 0.08275960385799408\n",
      "3315 Training Loss: 0.05066519230604172 Validation Loss: 0.0823618546128273\n",
      "3316 Training Loss: 0.05834683030843735 Validation Loss: 0.08199534565210342\n",
      "3317 Training Loss: 0.05219453573226929 Validation Loss: 0.08211848139762878\n",
      "3318 Training Loss: 0.049095913767814636 Validation Loss: 0.08257754147052765\n",
      "3319 Training Loss: 0.04913588613271713 Validation Loss: 0.08308789879083633\n",
      "3320 Training Loss: 0.04470842331647873 Validation Loss: 0.08426842093467712\n",
      "3321 Training Loss: 0.05882187560200691 Validation Loss: 0.08494488894939423\n",
      "3322 Training Loss: 0.04720493033528328 Validation Loss: 0.08567093312740326\n",
      "3323 Training Loss: 0.046131957322359085 Validation Loss: 0.08625416457653046\n",
      "3324 Training Loss: 0.04555508866906166 Validation Loss: 0.0868338793516159\n",
      "3325 Training Loss: 0.054324790835380554 Validation Loss: 0.08694145083427429\n",
      "3326 Training Loss: 0.06475715339183807 Validation Loss: 0.0862116888165474\n",
      "3327 Training Loss: 0.046814486384391785 Validation Loss: 0.08568490296602249\n",
      "3328 Training Loss: 0.057784244418144226 Validation Loss: 0.08456091582775116\n",
      "3329 Training Loss: 0.0437762551009655 Validation Loss: 0.08422470092773438\n",
      "3330 Training Loss: 0.04986560344696045 Validation Loss: 0.08356864750385284\n",
      "3331 Training Loss: 0.05036346986889839 Validation Loss: 0.08295857161283493\n",
      "3332 Training Loss: 0.046702828258275986 Validation Loss: 0.08283713459968567\n",
      "3333 Training Loss: 0.0470004603266716 Validation Loss: 0.0826091468334198\n",
      "3334 Training Loss: 0.06560337543487549 Validation Loss: 0.08153518289327621\n",
      "3335 Training Loss: 0.043133486062288284 Validation Loss: 0.08124206215143204\n",
      "3336 Training Loss: 0.051320239901542664 Validation Loss: 0.08120454847812653\n",
      "3337 Training Loss: 0.04829609394073486 Validation Loss: 0.08131787925958633\n",
      "3338 Training Loss: 0.05549396574497223 Validation Loss: 0.08146335184574127\n",
      "3339 Training Loss: 0.06512275338172913 Validation Loss: 0.08060827851295471\n",
      "3340 Training Loss: 0.048455044627189636 Validation Loss: 0.0800519734621048\n",
      "3341 Training Loss: 0.05484282225370407 Validation Loss: 0.07885368913412094\n",
      "3342 Training Loss: 0.04589207470417023 Validation Loss: 0.07824119925498962\n",
      "3343 Training Loss: 0.0462946891784668 Validation Loss: 0.07798007875680923\n",
      "3344 Training Loss: 0.04846937954425812 Validation Loss: 0.0780092403292656\n",
      "3345 Training Loss: 0.05498198792338371 Validation Loss: 0.078439861536026\n",
      "3346 Training Loss: 0.045830801129341125 Validation Loss: 0.07916587591171265\n",
      "3347 Training Loss: 0.043766383081674576 Validation Loss: 0.08031418919563293\n",
      "3348 Training Loss: 0.05707739666104317 Validation Loss: 0.08070722222328186\n",
      "3349 Training Loss: 0.04316166043281555 Validation Loss: 0.08152548968791962\n",
      "3350 Training Loss: 0.045288655906915665 Validation Loss: 0.08239919692277908\n",
      "3351 Training Loss: 0.048106953501701355 Validation Loss: 0.08316585421562195\n",
      "3352 Training Loss: 0.04576097056269646 Validation Loss: 0.08405505120754242\n",
      "3353 Training Loss: 0.06178123503923416 Validation Loss: 0.08373836427927017\n",
      "3354 Training Loss: 0.04397866502404213 Validation Loss: 0.08344052731990814\n",
      "3355 Training Loss: 0.042642056941986084 Validation Loss: 0.08358613401651382\n",
      "3356 Training Loss: 0.047630149871110916 Validation Loss: 0.08349719643592834\n",
      "3357 Training Loss: 0.046857453882694244 Validation Loss: 0.08331939578056335\n",
      "3358 Training Loss: 0.046325720846652985 Validation Loss: 0.08283069729804993\n",
      "3359 Training Loss: 0.04422783851623535 Validation Loss: 0.08230181038379669\n",
      "3360 Training Loss: 0.05076951906085014 Validation Loss: 0.08132854849100113\n",
      "3361 Training Loss: 0.05320028215646744 Validation Loss: 0.08015473186969757\n",
      "3362 Training Loss: 0.053153831511735916 Validation Loss: 0.07858552783727646\n",
      "3363 Training Loss: 0.04636222496628761 Validation Loss: 0.07762600481510162\n",
      "3364 Training Loss: 0.051215760409832 Validation Loss: 0.07678622007369995\n",
      "3365 Training Loss: 0.05000896751880646 Validation Loss: 0.07622280716896057\n",
      "3366 Training Loss: 0.04511047899723053 Validation Loss: 0.07618416100740433\n",
      "3367 Training Loss: 0.046100568026304245 Validation Loss: 0.0766923576593399\n",
      "3368 Training Loss: 0.04357970878481865 Validation Loss: 0.07772330194711685\n",
      "3369 Training Loss: 0.05679117143154144 Validation Loss: 0.07846133410930634\n",
      "3370 Training Loss: 0.04567467048764229 Validation Loss: 0.0794963538646698\n",
      "3371 Training Loss: 0.04154378920793533 Validation Loss: 0.08120551705360413\n",
      "3372 Training Loss: 0.04241584241390228 Validation Loss: 0.08301417529582977\n",
      "3373 Training Loss: 0.05738700181245804 Validation Loss: 0.08388500660657883\n",
      "3374 Training Loss: 0.05284317582845688 Validation Loss: 0.08444562554359436\n",
      "3375 Training Loss: 0.05348953604698181 Validation Loss: 0.08449746668338776\n",
      "3376 Training Loss: 0.040470417588949203 Validation Loss: 0.08481947332620621\n",
      "3377 Training Loss: 0.04584227874875069 Validation Loss: 0.08468162268400192\n",
      "3378 Training Loss: 0.05676077678799629 Validation Loss: 0.08328381925821304\n",
      "3379 Training Loss: 0.05121973156929016 Validation Loss: 0.08159228414297104\n",
      "3380 Training Loss: 0.045499593019485474 Validation Loss: 0.08012262731790543\n",
      "3381 Training Loss: 0.0464789941906929 Validation Loss: 0.07899639755487442\n",
      "3382 Training Loss: 0.04761586710810661 Validation Loss: 0.07789982110261917\n",
      "3383 Training Loss: 0.06168335676193237 Validation Loss: 0.07623355835676193\n",
      "3384 Training Loss: 0.05713784694671631 Validation Loss: 0.07442648708820343\n",
      "3385 Training Loss: 0.047631245106458664 Validation Loss: 0.07328174263238907\n",
      "3386 Training Loss: 0.04269242659211159 Validation Loss: 0.0730099305510521\n",
      "3387 Training Loss: 0.041009336709976196 Validation Loss: 0.07364620268344879\n",
      "3388 Training Loss: 0.0424005463719368 Validation Loss: 0.07487313449382782\n",
      "3389 Training Loss: 0.04713498800992966 Validation Loss: 0.07618233561515808\n",
      "3390 Training Loss: 0.05480896681547165 Validation Loss: 0.07688610255718231\n",
      "3391 Training Loss: 0.046426426619291306 Validation Loss: 0.07736028730869293\n",
      "3392 Training Loss: 0.047565754503011703 Validation Loss: 0.07769925147294998\n",
      "3393 Training Loss: 0.06122961640357971 Validation Loss: 0.07734176516532898\n",
      "3394 Training Loss: 0.05563109368085861 Validation Loss: 0.0767916589975357\n",
      "3395 Training Loss: 0.06171505153179169 Validation Loss: 0.0754331424832344\n",
      "3396 Training Loss: 0.05061538517475128 Validation Loss: 0.07464136183261871\n",
      "3397 Training Loss: 0.06068006530404091 Validation Loss: 0.07347865402698517\n",
      "3398 Training Loss: 0.05101665481925011 Validation Loss: 0.07259584963321686\n",
      "3399 Training Loss: 0.04455915093421936 Validation Loss: 0.0721043199300766\n",
      "3400 Training Loss: 0.04401488974690437 Validation Loss: 0.07224802672863007\n",
      "3401 Training Loss: 0.052911389619112015 Validation Loss: 0.0725221186876297\n",
      "3402 Training Loss: 0.043255314230918884 Validation Loss: 0.07333638519048691\n",
      "3403 Training Loss: 0.053582996129989624 Validation Loss: 0.07421167194843292\n",
      "3404 Training Loss: 0.05980433523654938 Validation Loss: 0.07481110841035843\n",
      "3405 Training Loss: 0.04381958395242691 Validation Loss: 0.07589070498943329\n",
      "3406 Training Loss: 0.0505734384059906 Validation Loss: 0.07646217197179794\n",
      "3407 Training Loss: 0.051536135375499725 Validation Loss: 0.07682155072689056\n",
      "3408 Training Loss: 0.04158999025821686 Validation Loss: 0.07728780806064606\n",
      "3409 Training Loss: 0.046782486140728 Validation Loss: 0.07707952708005905\n",
      "3410 Training Loss: 0.050757721066474915 Validation Loss: 0.07608239352703094\n",
      "3411 Training Loss: 0.04694730043411255 Validation Loss: 0.07489749789237976\n",
      "3412 Training Loss: 0.043488338589668274 Validation Loss: 0.07388412207365036\n",
      "3413 Training Loss: 0.05064760893583298 Validation Loss: 0.07313521206378937\n",
      "3414 Training Loss: 0.043682269752025604 Validation Loss: 0.07252126187086105\n",
      "3415 Training Loss: 0.043821681290864944 Validation Loss: 0.07216286659240723\n",
      "3416 Training Loss: 0.04640825465321541 Validation Loss: 0.07217417657375336\n",
      "3417 Training Loss: 0.04738449305295944 Validation Loss: 0.07222680002450943\n",
      "3418 Training Loss: 0.043737541884183884 Validation Loss: 0.07238628715276718\n",
      "3419 Training Loss: 0.05051892250776291 Validation Loss: 0.07230072468519211\n",
      "3420 Training Loss: 0.04187177121639252 Validation Loss: 0.07272832840681076\n",
      "3421 Training Loss: 0.0453454926609993 Validation Loss: 0.07313771545886993\n",
      "3422 Training Loss: 0.039639588445425034 Validation Loss: 0.07409438490867615\n",
      "3423 Training Loss: 0.049579162150621414 Validation Loss: 0.07456846535205841\n",
      "3424 Training Loss: 0.03909362107515335 Validation Loss: 0.07544746994972229\n",
      "3425 Training Loss: 0.05028902739286423 Validation Loss: 0.07614122331142426\n",
      "3426 Training Loss: 0.038411274552345276 Validation Loss: 0.0771665871143341\n",
      "3427 Training Loss: 0.041937876492738724 Validation Loss: 0.07819512486457825\n",
      "3428 Training Loss: 0.043236762285232544 Validation Loss: 0.0792425125837326\n",
      "3429 Training Loss: 0.049297139048576355 Validation Loss: 0.07954816520214081\n",
      "3430 Training Loss: 0.057471197098493576 Validation Loss: 0.07849513739347458\n",
      "3431 Training Loss: 0.04977036267518997 Validation Loss: 0.07685708999633789\n",
      "3432 Training Loss: 0.05003691092133522 Validation Loss: 0.07471148669719696\n",
      "3433 Training Loss: 0.049219705164432526 Validation Loss: 0.07249234616756439\n",
      "3434 Training Loss: 0.05063904821872711 Validation Loss: 0.07057203352451324\n",
      "3435 Training Loss: 0.04356245696544647 Validation Loss: 0.06923914700746536\n",
      "3436 Training Loss: 0.0479314848780632 Validation Loss: 0.06834366917610168\n",
      "3437 Training Loss: 0.05544821918010712 Validation Loss: 0.06739714741706848\n",
      "3438 Training Loss: 0.056044235825538635 Validation Loss: 0.06627106666564941\n",
      "3439 Training Loss: 0.04844828322529793 Validation Loss: 0.06573500484228134\n",
      "3440 Training Loss: 0.049000561237335205 Validation Loss: 0.06544394791126251\n",
      "3441 Training Loss: 0.050907451659440994 Validation Loss: 0.06522108614444733\n",
      "3442 Training Loss: 0.04908357560634613 Validation Loss: 0.06533122062683105\n",
      "3443 Training Loss: 0.04074236750602722 Validation Loss: 0.06603517383337021\n",
      "3444 Training Loss: 0.04667069762945175 Validation Loss: 0.06706590950489044\n",
      "3445 Training Loss: 0.056955546140670776 Validation Loss: 0.06787366420030594\n",
      "3446 Training Loss: 0.04115775227546692 Validation Loss: 0.06936521828174591\n",
      "3447 Training Loss: 0.04449152201414108 Validation Loss: 0.07105223834514618\n",
      "3448 Training Loss: 0.0460289865732193 Validation Loss: 0.07225022464990616\n",
      "3449 Training Loss: 0.03842683881521225 Validation Loss: 0.07350680232048035\n",
      "3450 Training Loss: 0.047246843576431274 Validation Loss: 0.07440471649169922\n",
      "3451 Training Loss: 0.03878360614180565 Validation Loss: 0.07539698481559753\n",
      "3452 Training Loss: 0.04658723622560501 Validation Loss: 0.07550188153982162\n",
      "3453 Training Loss: 0.037613555788993835 Validation Loss: 0.07571263611316681\n",
      "3454 Training Loss: 0.048810847103595734 Validation Loss: 0.07494839280843735\n",
      "3455 Training Loss: 0.04824966564774513 Validation Loss: 0.07340479642152786\n",
      "3456 Training Loss: 0.054950643330812454 Validation Loss: 0.07155690342187881\n",
      "3457 Training Loss: 0.044638492166996 Validation Loss: 0.07020408660173416\n",
      "3458 Training Loss: 0.03966497629880905 Validation Loss: 0.06933369487524033\n",
      "3459 Training Loss: 0.05794856324791908 Validation Loss: 0.06829883903265\n",
      "3460 Training Loss: 0.04700722545385361 Validation Loss: 0.06735703349113464\n",
      "3461 Training Loss: 0.0535304918885231 Validation Loss: 0.06643300503492355\n",
      "3462 Training Loss: 0.04470103979110718 Validation Loss: 0.06585133075714111\n",
      "3463 Training Loss: 0.05351279303431511 Validation Loss: 0.06527445465326309\n",
      "3464 Training Loss: 0.044273748993873596 Validation Loss: 0.06510356813669205\n",
      "3465 Training Loss: 0.051091551780700684 Validation Loss: 0.0651368796825409\n",
      "3466 Training Loss: 0.0392204225063324 Validation Loss: 0.06599472463130951\n",
      "3467 Training Loss: 0.053492456674575806 Validation Loss: 0.06664808094501495\n",
      "3468 Training Loss: 0.05868986248970032 Validation Loss: 0.06654464453458786\n",
      "3469 Training Loss: 0.04372504726052284 Validation Loss: 0.06643691658973694\n",
      "3470 Training Loss: 0.041043173521757126 Validation Loss: 0.06653841584920883\n",
      "3471 Training Loss: 0.048320479691028595 Validation Loss: 0.06663179397583008\n",
      "3472 Training Loss: 0.05651983618736267 Validation Loss: 0.06622226536273956\n",
      "3473 Training Loss: 0.04386095330119133 Validation Loss: 0.06605495512485504\n",
      "3474 Training Loss: 0.04764390364289284 Validation Loss: 0.0658101886510849\n",
      "3475 Training Loss: 0.04159931093454361 Validation Loss: 0.06588618457317352\n",
      "3476 Training Loss: 0.04785323143005371 Validation Loss: 0.0658678188920021\n",
      "3477 Training Loss: 0.04171751067042351 Validation Loss: 0.0661776140332222\n",
      "3478 Training Loss: 0.04771006107330322 Validation Loss: 0.06631622463464737\n",
      "3479 Training Loss: 0.039866283535957336 Validation Loss: 0.06668215990066528\n",
      "3480 Training Loss: 0.0463719367980957 Validation Loss: 0.06686931848526001\n",
      "3481 Training Loss: 0.043474841862916946 Validation Loss: 0.06723573058843613\n",
      "3482 Training Loss: 0.04184313118457794 Validation Loss: 0.06759414821863174\n",
      "3483 Training Loss: 0.04159160330891609 Validation Loss: 0.06797921657562256\n",
      "3484 Training Loss: 0.045357346534729004 Validation Loss: 0.06836334615945816\n",
      "3485 Training Loss: 0.04245737940073013 Validation Loss: 0.06870047003030777\n",
      "3486 Training Loss: 0.043729618191719055 Validation Loss: 0.06881707906723022\n",
      "3487 Training Loss: 0.036716289818286896 Validation Loss: 0.06925759464502335\n",
      "3488 Training Loss: 0.04856094717979431 Validation Loss: 0.06932464987039566\n",
      "3489 Training Loss: 0.04618757218122482 Validation Loss: 0.06868772208690643\n",
      "3490 Training Loss: 0.046521153301000595 Validation Loss: 0.06769762933254242\n",
      "3491 Training Loss: 0.04328509420156479 Validation Loss: 0.06688418239355087\n",
      "3492 Training Loss: 0.04129612818360329 Validation Loss: 0.0666804164648056\n",
      "3493 Training Loss: 0.037590719759464264 Validation Loss: 0.06661596149206161\n",
      "3494 Training Loss: 0.04006600379943848 Validation Loss: 0.06659618020057678\n",
      "3495 Training Loss: 0.05570641905069351 Validation Loss: 0.06591254472732544\n",
      "3496 Training Loss: 0.04224400967359543 Validation Loss: 0.06553485989570618\n",
      "3497 Training Loss: 0.050873227417469025 Validation Loss: 0.06479975581169128\n",
      "3498 Training Loss: 0.05404752492904663 Validation Loss: 0.06381257623434067\n",
      "3499 Training Loss: 0.04350774362683296 Validation Loss: 0.06320598721504211\n",
      "3500 Training Loss: 0.04236506670713425 Validation Loss: 0.0630398690700531\n",
      "3501 Training Loss: 0.04096370190382004 Validation Loss: 0.06324674189090729\n",
      "3502 Training Loss: 0.03856411203742027 Validation Loss: 0.06379559636116028\n",
      "3503 Training Loss: 0.03794622793793678 Validation Loss: 0.0647621676325798\n",
      "3504 Training Loss: 0.046301402151584625 Validation Loss: 0.0655348151922226\n",
      "3505 Training Loss: 0.044454872608184814 Validation Loss: 0.0664353147149086\n",
      "3506 Training Loss: 0.034441493451595306 Validation Loss: 0.06791416555643082\n",
      "3507 Training Loss: 0.036931008100509644 Validation Loss: 0.06973597407341003\n",
      "3508 Training Loss: 0.036580123007297516 Validation Loss: 0.07199788093566895\n",
      "3509 Training Loss: 0.0519840344786644 Validation Loss: 0.07322657108306885\n",
      "3510 Training Loss: 0.05312182754278183 Validation Loss: 0.07335292547941208\n",
      "3511 Training Loss: 0.04869159311056137 Validation Loss: 0.07241997122764587\n",
      "3512 Training Loss: 0.036021940410137177 Validation Loss: 0.0717715173959732\n",
      "3513 Training Loss: 0.038045529276132584 Validation Loss: 0.07087591290473938\n",
      "3514 Training Loss: 0.0525798425078392 Validation Loss: 0.06896167993545532\n",
      "3515 Training Loss: 0.04784370958805084 Validation Loss: 0.06679123640060425\n",
      "3516 Training Loss: 0.04907703772187233 Validation Loss: 0.06443343311548233\n",
      "3517 Training Loss: 0.053400397300720215 Validation Loss: 0.06204997003078461\n",
      "3518 Training Loss: 0.04565233737230301 Validation Loss: 0.060355495661497116\n",
      "3519 Training Loss: 0.04121720418334007 Validation Loss: 0.05945758894085884\n",
      "3520 Training Loss: 0.039944447576999664 Validation Loss: 0.05927278846502304\n",
      "3521 Training Loss: 0.05202341824769974 Validation Loss: 0.05911390110850334\n",
      "3522 Training Loss: 0.04275304079055786 Validation Loss: 0.05939202755689621\n",
      "3523 Training Loss: 0.049662426114082336 Validation Loss: 0.05964866280555725\n",
      "3524 Training Loss: 0.048156335949897766 Validation Loss: 0.06006577983498573\n",
      "3525 Training Loss: 0.03752242773771286 Validation Loss: 0.06102073937654495\n",
      "3526 Training Loss: 0.041476789861917496 Validation Loss: 0.06228019669651985\n",
      "3527 Training Loss: 0.05338124558329582 Validation Loss: 0.06316286325454712\n",
      "3528 Training Loss: 0.038975898176431656 Validation Loss: 0.06430076062679291\n",
      "3529 Training Loss: 0.03461974859237671 Validation Loss: 0.065922811627388\n",
      "3530 Training Loss: 0.03872741013765335 Validation Loss: 0.06764689087867737\n",
      "3531 Training Loss: 0.036942336708307266 Validation Loss: 0.06970049440860748\n",
      "3532 Training Loss: 0.05568334460258484 Validation Loss: 0.07036809623241425\n",
      "3533 Training Loss: 0.044162601232528687 Validation Loss: 0.07007154077291489\n",
      "3534 Training Loss: 0.04883253946900368 Validation Loss: 0.06898953765630722\n",
      "3535 Training Loss: 0.04372192919254303 Validation Loss: 0.06735417991876602\n",
      "3536 Training Loss: 0.04063054174184799 Validation Loss: 0.06553768366575241\n",
      "3537 Training Loss: 0.035870905965566635 Validation Loss: 0.06434457004070282\n",
      "3538 Training Loss: 0.04208274558186531 Validation Loss: 0.0631176233291626\n",
      "3539 Training Loss: 0.03783063590526581 Validation Loss: 0.06204826012253761\n",
      "3540 Training Loss: 0.05577448755502701 Validation Loss: 0.06061915308237076\n",
      "3541 Training Loss: 0.03494029864668846 Validation Loss: 0.05983086675405502\n",
      "3542 Training Loss: 0.03588109090924263 Validation Loss: 0.059789739549160004\n",
      "3543 Training Loss: 0.03942877799272537 Validation Loss: 0.06020548939704895\n",
      "3544 Training Loss: 0.04232082515954971 Validation Loss: 0.06059568002820015\n",
      "3545 Training Loss: 0.05047635734081268 Validation Loss: 0.06075402349233627\n",
      "3546 Training Loss: 0.0441213995218277 Validation Loss: 0.06098237261176109\n",
      "3547 Training Loss: 0.048615895211696625 Validation Loss: 0.06094859540462494\n",
      "3548 Training Loss: 0.040794286876916885 Validation Loss: 0.06097082793712616\n",
      "3549 Training Loss: 0.03507634624838829 Validation Loss: 0.06145152449607849\n",
      "3550 Training Loss: 0.03962206467986107 Validation Loss: 0.06224143132567406\n",
      "3551 Training Loss: 0.04129963740706444 Validation Loss: 0.06324337422847748\n",
      "3552 Training Loss: 0.039638593792915344 Validation Loss: 0.06429480016231537\n",
      "3553 Training Loss: 0.039837323129177094 Validation Loss: 0.0652184784412384\n",
      "3554 Training Loss: 0.03779594600200653 Validation Loss: 0.06628133356571198\n",
      "3555 Training Loss: 0.03705471381545067 Validation Loss: 0.06746406853199005\n",
      "3556 Training Loss: 0.04315520077943802 Validation Loss: 0.06811346113681793\n",
      "3557 Training Loss: 0.049645476043224335 Validation Loss: 0.06770021468400955\n",
      "3558 Training Loss: 0.035793498158454895 Validation Loss: 0.06733434647321701\n",
      "3559 Training Loss: 0.04036310315132141 Validation Loss: 0.06646788120269775\n",
      "3560 Training Loss: 0.04811263084411621 Validation Loss: 0.06491479277610779\n",
      "3561 Training Loss: 0.05305451899766922 Validation Loss: 0.06252898275852203\n",
      "3562 Training Loss: 0.04107463359832764 Validation Loss: 0.06057493016123772\n",
      "3563 Training Loss: 0.047799885272979736 Validation Loss: 0.05881533771753311\n",
      "3564 Training Loss: 0.03730238974094391 Validation Loss: 0.057773515582084656\n",
      "3565 Training Loss: 0.037046972662210464 Validation Loss: 0.05734161660075188\n",
      "3566 Training Loss: 0.03960427641868591 Validation Loss: 0.057257816195487976\n",
      "3567 Training Loss: 0.04955379664897919 Validation Loss: 0.057268187403678894\n",
      "3568 Training Loss: 0.05446774885058403 Validation Loss: 0.057153381407260895\n",
      "3569 Training Loss: 0.04029097408056259 Validation Loss: 0.057401854544878006\n",
      "3570 Training Loss: 0.05974140763282776 Validation Loss: 0.05731019377708435\n",
      "3571 Training Loss: 0.05012137442827225 Validation Loss: 0.05708159878849983\n",
      "3572 Training Loss: 0.039222367107868195 Validation Loss: 0.05715789645910263\n",
      "3573 Training Loss: 0.03819795697927475 Validation Loss: 0.05759120360016823\n",
      "3574 Training Loss: 0.04065193980932236 Validation Loss: 0.058205731213092804\n",
      "3575 Training Loss: 0.05372020602226257 Validation Loss: 0.05867873504757881\n",
      "3576 Training Loss: 0.04334495961666107 Validation Loss: 0.0592077299952507\n",
      "3577 Training Loss: 0.040701109915971756 Validation Loss: 0.05990833044052124\n",
      "3578 Training Loss: 0.03623199090361595 Validation Loss: 0.06093979999423027\n",
      "3579 Training Loss: 0.039545416831970215 Validation Loss: 0.06192057579755783\n",
      "3580 Training Loss: 0.047283098101615906 Validation Loss: 0.06236406788229942\n",
      "3581 Training Loss: 0.037086233496665955 Validation Loss: 0.06256148219108582\n",
      "3582 Training Loss: 0.03847302868962288 Validation Loss: 0.062359776347875595\n",
      "3583 Training Loss: 0.035643525421619415 Validation Loss: 0.062187328934669495\n",
      "3584 Training Loss: 0.046712227165699005 Validation Loss: 0.0611630417406559\n",
      "3585 Training Loss: 0.03884956240653992 Validation Loss: 0.06026016175746918\n",
      "3586 Training Loss: 0.04529851675033569 Validation Loss: 0.05905793234705925\n",
      "3587 Training Loss: 0.03535868227481842 Validation Loss: 0.05839785188436508\n",
      "3588 Training Loss: 0.035867203027009964 Validation Loss: 0.05809583142399788\n",
      "3589 Training Loss: 0.03802965581417084 Validation Loss: 0.0579758957028389\n",
      "3590 Training Loss: 0.03577561303973198 Validation Loss: 0.05834134668111801\n",
      "3591 Training Loss: 0.03673215210437775 Validation Loss: 0.059105850756168365\n",
      "3592 Training Loss: 0.03821893408894539 Validation Loss: 0.059946976602077484\n",
      "3593 Training Loss: 0.037095773965120316 Validation Loss: 0.06092226505279541\n",
      "3594 Training Loss: 0.03935135155916214 Validation Loss: 0.06164249777793884\n",
      "3595 Training Loss: 0.03800809383392334 Validation Loss: 0.062179382890462875\n",
      "3596 Training Loss: 0.030893970280885696 Validation Loss: 0.06287585943937302\n",
      "3597 Training Loss: 0.04126755893230438 Validation Loss: 0.06340397894382477\n",
      "3598 Training Loss: 0.039889536798000336 Validation Loss: 0.063413105905056\n",
      "3599 Training Loss: 0.04685468226671219 Validation Loss: 0.06249703839421272\n",
      "3600 Training Loss: 0.039278268814086914 Validation Loss: 0.06154491752386093\n",
      "3601 Training Loss: 0.039586141705513 Validation Loss: 0.06060593202710152\n",
      "3602 Training Loss: 0.042642489075660706 Validation Loss: 0.05935398489236832\n",
      "3603 Training Loss: 0.040329307317733765 Validation Loss: 0.05826355516910553\n",
      "3604 Training Loss: 0.03803669661283493 Validation Loss: 0.05738901346921921\n",
      "3605 Training Loss: 0.0453711673617363 Validation Loss: 0.05672438442707062\n",
      "3606 Training Loss: 0.0488240122795105 Validation Loss: 0.05607893317937851\n",
      "3607 Training Loss: 0.037148620933294296 Validation Loss: 0.05575527623295784\n",
      "3608 Training Loss: 0.03563685342669487 Validation Loss: 0.056038402020931244\n",
      "3609 Training Loss: 0.03697345405817032 Validation Loss: 0.056854091584682465\n",
      "3610 Training Loss: 0.04319627955555916 Validation Loss: 0.05797047168016434\n",
      "3611 Training Loss: 0.03427789360284805 Validation Loss: 0.05965051054954529\n",
      "3612 Training Loss: 0.03489037603139877 Validation Loss: 0.06148318946361542\n",
      "3613 Training Loss: 0.04689463600516319 Validation Loss: 0.0625225156545639\n",
      "3614 Training Loss: 0.050612155348062515 Validation Loss: 0.06232547014951706\n",
      "3615 Training Loss: 0.03197134658694267 Validation Loss: 0.06241890415549278\n",
      "3616 Training Loss: 0.04852336272597313 Validation Loss: 0.06160392612218857\n",
      "3617 Training Loss: 0.031374115496873856 Validation Loss: 0.06127182021737099\n",
      "3618 Training Loss: 0.03687003254890442 Validation Loss: 0.06065475940704346\n",
      "3619 Training Loss: 0.04295319318771362 Validation Loss: 0.05957085266709328\n",
      "3620 Training Loss: 0.03887420892715454 Validation Loss: 0.058160774409770966\n",
      "3621 Training Loss: 0.03793814405798912 Validation Loss: 0.05702924355864525\n",
      "3622 Training Loss: 0.03927109017968178 Validation Loss: 0.05618701130151749\n",
      "3623 Training Loss: 0.03390827775001526 Validation Loss: 0.055947791785001755\n",
      "3624 Training Loss: 0.03525850176811218 Validation Loss: 0.05607109144330025\n",
      "3625 Training Loss: 0.03347624093294144 Validation Loss: 0.0565028190612793\n",
      "3626 Training Loss: 0.032674554735422134 Validation Loss: 0.05735396593809128\n",
      "3627 Training Loss: 0.04059108719229698 Validation Loss: 0.05812683328986168\n",
      "3628 Training Loss: 0.03188665211200714 Validation Loss: 0.059119705110788345\n",
      "3629 Training Loss: 0.04648914933204651 Validation Loss: 0.05941537767648697\n",
      "3630 Training Loss: 0.03373219072818756 Validation Loss: 0.05980074033141136\n",
      "3631 Training Loss: 0.03364554047584534 Validation Loss: 0.060299184173345566\n",
      "3632 Training Loss: 0.0327242873609066 Validation Loss: 0.06115401163697243\n",
      "3633 Training Loss: 0.04180409014225006 Validation Loss: 0.06159999966621399\n",
      "3634 Training Loss: 0.030970847234129906 Validation Loss: 0.062317922711372375\n",
      "3635 Training Loss: 0.04340076074004173 Validation Loss: 0.06247134879231453\n",
      "3636 Training Loss: 0.03478074073791504 Validation Loss: 0.06256823241710663\n",
      "3637 Training Loss: 0.04242350161075592 Validation Loss: 0.0620172880589962\n",
      "3638 Training Loss: 0.035876695066690445 Validation Loss: 0.06110038608312607\n",
      "3639 Training Loss: 0.038665805011987686 Validation Loss: 0.05973711982369423\n",
      "3640 Training Loss: 0.04204186052083969 Validation Loss: 0.058229126036167145\n",
      "3641 Training Loss: 0.035323578864336014 Validation Loss: 0.05735115706920624\n",
      "3642 Training Loss: 0.04825606197118759 Validation Loss: 0.05611579865217209\n",
      "3643 Training Loss: 0.03404635936021805 Validation Loss: 0.055547453463077545\n",
      "3644 Training Loss: 0.034120816737413406 Validation Loss: 0.05524740368127823\n",
      "3645 Training Loss: 0.03342577815055847 Validation Loss: 0.05535781756043434\n",
      "3646 Training Loss: 0.04134811460971832 Validation Loss: 0.05551702156662941\n",
      "3647 Training Loss: 0.05254455655813217 Validation Loss: 0.05498971417546272\n",
      "3648 Training Loss: 0.0468909814953804 Validation Loss: 0.05440422147512436\n",
      "3649 Training Loss: 0.03618262708187103 Validation Loss: 0.05424816161394119\n",
      "3650 Training Loss: 0.04969104379415512 Validation Loss: 0.05372932553291321\n",
      "3651 Training Loss: 0.045866046100854874 Validation Loss: 0.05332593992352486\n",
      "3652 Training Loss: 0.03741487115621567 Validation Loss: 0.05326280742883682\n",
      "3653 Training Loss: 0.04797018691897392 Validation Loss: 0.05305929109454155\n",
      "3654 Training Loss: 0.035260386765003204 Validation Loss: 0.053191009908914566\n",
      "3655 Training Loss: 0.032951850444078445 Validation Loss: 0.05388064682483673\n",
      "3656 Training Loss: 0.03830163925886154 Validation Loss: 0.05472875386476517\n",
      "3657 Training Loss: 0.037800904363393784 Validation Loss: 0.05589301511645317\n",
      "3658 Training Loss: 0.03587554022669792 Validation Loss: 0.057305797934532166\n",
      "3659 Training Loss: 0.03176384046673775 Validation Loss: 0.05899818614125252\n",
      "3660 Training Loss: 0.0353817455470562 Validation Loss: 0.0604228600859642\n",
      "3661 Training Loss: 0.03201691806316376 Validation Loss: 0.061630744487047195\n",
      "3662 Training Loss: 0.043154727667570114 Validation Loss: 0.06115656718611717\n",
      "3663 Training Loss: 0.04208045452833176 Validation Loss: 0.060159191489219666\n",
      "3664 Training Loss: 0.03909682482481003 Validation Loss: 0.05882839858531952\n",
      "3665 Training Loss: 0.03860215097665787 Validation Loss: 0.05749130994081497\n",
      "3666 Training Loss: 0.035096876323223114 Validation Loss: 0.05648823454976082\n",
      "3667 Training Loss: 0.03234954550862312 Validation Loss: 0.05579029768705368\n",
      "3668 Training Loss: 0.04134318232536316 Validation Loss: 0.055069051682949066\n",
      "3669 Training Loss: 0.035503968596458435 Validation Loss: 0.05449633300304413\n",
      "3670 Training Loss: 0.03493967652320862 Validation Loss: 0.05421237275004387\n",
      "3671 Training Loss: 0.04337645322084427 Validation Loss: 0.05352691560983658\n",
      "3672 Training Loss: 0.03169983625411987 Validation Loss: 0.05338122323155403\n",
      "3673 Training Loss: 0.042847346514463425 Validation Loss: 0.05332984775304794\n",
      "3674 Training Loss: 0.03556474298238754 Validation Loss: 0.05353612080216408\n",
      "3675 Training Loss: 0.03496602550148964 Validation Loss: 0.053786952048540115\n",
      "3676 Training Loss: 0.034085169434547424 Validation Loss: 0.054321762174367905\n",
      "3677 Training Loss: 0.04541155695915222 Validation Loss: 0.05428816005587578\n",
      "3678 Training Loss: 0.03479774668812752 Validation Loss: 0.05442223697900772\n",
      "3679 Training Loss: 0.0324481800198555 Validation Loss: 0.05510082095861435\n",
      "3680 Training Loss: 0.039113521575927734 Validation Loss: 0.05562412738800049\n",
      "3681 Training Loss: 0.03087865747511387 Validation Loss: 0.05618816614151001\n",
      "3682 Training Loss: 0.042818956077098846 Validation Loss: 0.05588280037045479\n",
      "3683 Training Loss: 0.03676686808466911 Validation Loss: 0.05556980520486832\n",
      "3684 Training Loss: 0.0355667918920517 Validation Loss: 0.055326882749795914\n",
      "3685 Training Loss: 0.03610235080122948 Validation Loss: 0.05495487153530121\n",
      "3686 Training Loss: 0.03847485035657883 Validation Loss: 0.05442330986261368\n",
      "3687 Training Loss: 0.03657291829586029 Validation Loss: 0.05414785072207451\n",
      "3688 Training Loss: 0.030560001730918884 Validation Loss: 0.054303720593452454\n",
      "3689 Training Loss: 0.03392293304204941 Validation Loss: 0.05473218113183975\n",
      "3690 Training Loss: 0.036064401268959045 Validation Loss: 0.05528414994478226\n",
      "3691 Training Loss: 0.04369372874498367 Validation Loss: 0.055425871163606644\n",
      "3692 Training Loss: 0.030347168445587158 Validation Loss: 0.05587885528802872\n",
      "3693 Training Loss: 0.04584697633981705 Validation Loss: 0.05536353588104248\n",
      "3694 Training Loss: 0.03037465550005436 Validation Loss: 0.05503106862306595\n",
      "3695 Training Loss: 0.03140765801072121 Validation Loss: 0.054927945137023926\n",
      "3696 Training Loss: 0.0344967320561409 Validation Loss: 0.05466141924262047\n",
      "3697 Training Loss: 0.038883842527866364 Validation Loss: 0.05425223708152771\n",
      "3698 Training Loss: 0.030230669304728508 Validation Loss: 0.05418512597680092\n",
      "3699 Training Loss: 0.03039625473320484 Validation Loss: 0.05457264930009842\n",
      "3700 Training Loss: 0.03245745599269867 Validation Loss: 0.05510378256440163\n",
      "3701 Training Loss: 0.03052196092903614 Validation Loss: 0.05591559782624245\n",
      "3702 Training Loss: 0.033573754131793976 Validation Loss: 0.056679997593164444\n",
      "3703 Training Loss: 0.0296037420630455 Validation Loss: 0.057788506150245667\n",
      "3704 Training Loss: 0.031451061367988586 Validation Loss: 0.05886457487940788\n",
      "3705 Training Loss: 0.03358080983161926 Validation Loss: 0.059410929679870605\n",
      "3706 Training Loss: 0.042093388736248016 Validation Loss: 0.05871991068124771\n",
      "3707 Training Loss: 0.040675971657037735 Validation Loss: 0.057343579828739166\n",
      "3708 Training Loss: 0.044035881757736206 Validation Loss: 0.055620525032281876\n",
      "3709 Training Loss: 0.03866831585764885 Validation Loss: 0.05403498560190201\n",
      "3710 Training Loss: 0.03791118413209915 Validation Loss: 0.05259647220373154\n",
      "3711 Training Loss: 0.030798975378274918 Validation Loss: 0.051858216524124146\n",
      "3712 Training Loss: 0.040473565459251404 Validation Loss: 0.051056187599897385\n",
      "3713 Training Loss: 0.03138039633631706 Validation Loss: 0.050777871161699295\n",
      "3714 Training Loss: 0.040760308504104614 Validation Loss: 0.05049249529838562\n",
      "3715 Training Loss: 0.03308946266770363 Validation Loss: 0.050543010234832764\n",
      "3716 Training Loss: 0.03143303096294403 Validation Loss: 0.0510297454893589\n",
      "3717 Training Loss: 0.02938653528690338 Validation Loss: 0.052026987075805664\n",
      "3718 Training Loss: 0.03159148246049881 Validation Loss: 0.05332488566637039\n",
      "3719 Training Loss: 0.036215513944625854 Validation Loss: 0.05454288423061371\n",
      "3720 Training Loss: 0.03450379520654678 Validation Loss: 0.05564795434474945\n",
      "3721 Training Loss: 0.03527773916721344 Validation Loss: 0.05635545402765274\n",
      "3722 Training Loss: 0.03649675473570824 Validation Loss: 0.05656387656927109\n",
      "3723 Training Loss: 0.03465244174003601 Validation Loss: 0.056425340473651886\n",
      "3724 Training Loss: 0.03184722363948822 Validation Loss: 0.05619130656123161\n",
      "3725 Training Loss: 0.03991758078336716 Validation Loss: 0.05513937026262283\n",
      "3726 Training Loss: 0.03469979390501976 Validation Loss: 0.05407585948705673\n",
      "3727 Training Loss: 0.0444173701107502 Validation Loss: 0.0526735857129097\n",
      "3728 Training Loss: 0.029291151091456413 Validation Loss: 0.05179930105805397\n",
      "3729 Training Loss: 0.033305633813142776 Validation Loss: 0.05128031224012375\n",
      "3730 Training Loss: 0.0411977618932724 Validation Loss: 0.050680194050073624\n",
      "3731 Training Loss: 0.033630937337875366 Validation Loss: 0.0503508523106575\n",
      "3732 Training Loss: 0.040823183953762054 Validation Loss: 0.050098467618227005\n",
      "3733 Training Loss: 0.03680046647787094 Validation Loss: 0.050019025802612305\n",
      "3734 Training Loss: 0.03778708726167679 Validation Loss: 0.049908947199583054\n",
      "3735 Training Loss: 0.035174883902072906 Validation Loss: 0.04992414638400078\n",
      "3736 Training Loss: 0.03538130223751068 Validation Loss: 0.04999249801039696\n",
      "3737 Training Loss: 0.030140701681375504 Validation Loss: 0.05044996738433838\n",
      "3738 Training Loss: 0.030809596180915833 Validation Loss: 0.0512474961578846\n",
      "3739 Training Loss: 0.03294510766863823 Validation Loss: 0.05221724137663841\n",
      "3740 Training Loss: 0.030173467472195625 Validation Loss: 0.05340011790394783\n",
      "3741 Training Loss: 0.03042960911989212 Validation Loss: 0.05472157895565033\n",
      "3742 Training Loss: 0.02964966371655464 Validation Loss: 0.05600893497467041\n",
      "3743 Training Loss: 0.05310804769396782 Validation Loss: 0.0555146187543869\n",
      "3744 Training Loss: 0.03163736313581467 Validation Loss: 0.05492603778839111\n",
      "3745 Training Loss: 0.0390051007270813 Validation Loss: 0.0537925586104393\n",
      "3746 Training Loss: 0.02860988676548004 Validation Loss: 0.05310763046145439\n",
      "3747 Training Loss: 0.040666911751031876 Validation Loss: 0.05218410864472389\n",
      "3748 Training Loss: 0.029670637100934982 Validation Loss: 0.051507484167814255\n",
      "3749 Training Loss: 0.03160274028778076 Validation Loss: 0.05118817463517189\n",
      "3750 Training Loss: 0.03145141899585724 Validation Loss: 0.05134512484073639\n",
      "3751 Training Loss: 0.03312259539961815 Validation Loss: 0.051460325717926025\n",
      "3752 Training Loss: 0.03708413988351822 Validation Loss: 0.05128061771392822\n",
      "3753 Training Loss: 0.032910920679569244 Validation Loss: 0.05128059163689613\n",
      "3754 Training Loss: 0.03547367453575134 Validation Loss: 0.05125964432954788\n",
      "3755 Training Loss: 0.03089328110218048 Validation Loss: 0.051491010934114456\n",
      "3756 Training Loss: 0.03448865935206413 Validation Loss: 0.05172085389494896\n",
      "3757 Training Loss: 0.03132421523332596 Validation Loss: 0.051926448941230774\n",
      "3758 Training Loss: 0.0283760167658329 Validation Loss: 0.052182555198669434\n",
      "3759 Training Loss: 0.039766065776348114 Validation Loss: 0.051813773810863495\n",
      "3760 Training Loss: 0.04245059937238693 Validation Loss: 0.050968870520591736\n",
      "3761 Training Loss: 0.034054409712553024 Validation Loss: 0.05032523348927498\n",
      "3762 Training Loss: 0.028247414156794548 Validation Loss: 0.050204046070575714\n",
      "3763 Training Loss: 0.04263060912489891 Validation Loss: 0.0497884675860405\n",
      "3764 Training Loss: 0.03423019126057625 Validation Loss: 0.0494302473962307\n",
      "3765 Training Loss: 0.0311939287930727 Validation Loss: 0.04952479898929596\n",
      "3766 Training Loss: 0.036538489162921906 Validation Loss: 0.049652326852083206\n",
      "3767 Training Loss: 0.037370506674051285 Validation Loss: 0.04976475611329079\n",
      "3768 Training Loss: 0.03618569299578667 Validation Loss: 0.04979349672794342\n",
      "3769 Training Loss: 0.04462966322898865 Validation Loss: 0.0492885448038578\n",
      "3770 Training Loss: 0.03767945617437363 Validation Loss: 0.04862620681524277\n",
      "3771 Training Loss: 0.03531999513506889 Validation Loss: 0.0479256771504879\n",
      "3772 Training Loss: 0.034407712519168854 Validation Loss: 0.04747113585472107\n",
      "3773 Training Loss: 0.028054116293787956 Validation Loss: 0.04749681428074837\n",
      "3774 Training Loss: 0.03065052255988121 Validation Loss: 0.04785018041729927\n",
      "3775 Training Loss: 0.035977430641651154 Validation Loss: 0.04823005944490433\n",
      "3776 Training Loss: 0.03843604028224945 Validation Loss: 0.04851775988936424\n",
      "3777 Training Loss: 0.0336894728243351 Validation Loss: 0.04884056746959686\n",
      "3778 Training Loss: 0.03824259340763092 Validation Loss: 0.04912729933857918\n",
      "3779 Training Loss: 0.04003385454416275 Validation Loss: 0.04941572993993759\n",
      "3780 Training Loss: 0.03702998906373978 Validation Loss: 0.04943951591849327\n",
      "3781 Training Loss: 0.03635958954691887 Validation Loss: 0.049417875707149506\n",
      "3782 Training Loss: 0.030922504141926765 Validation Loss: 0.04957839846611023\n",
      "3783 Training Loss: 0.04317203164100647 Validation Loss: 0.049430686980485916\n",
      "3784 Training Loss: 0.029256552457809448 Validation Loss: 0.04943321645259857\n",
      "3785 Training Loss: 0.030069638043642044 Validation Loss: 0.04946698620915413\n",
      "3786 Training Loss: 0.02825666032731533 Validation Loss: 0.04968928173184395\n",
      "3787 Training Loss: 0.03147996589541435 Validation Loss: 0.049720652401447296\n",
      "3788 Training Loss: 0.03458438068628311 Validation Loss: 0.04967138543725014\n",
      "3789 Training Loss: 0.0315999761223793 Validation Loss: 0.0495663657784462\n",
      "3790 Training Loss: 0.033805713057518005 Validation Loss: 0.049224816262722015\n",
      "3791 Training Loss: 0.027849499136209488 Validation Loss: 0.04913836717605591\n",
      "3792 Training Loss: 0.03307507559657097 Validation Loss: 0.049172546714544296\n",
      "3793 Training Loss: 0.03653450310230255 Validation Loss: 0.04875482618808746\n",
      "3794 Training Loss: 0.026980329304933548 Validation Loss: 0.04877619445323944\n",
      "3795 Training Loss: 0.03265378624200821 Validation Loss: 0.04862741753458977\n",
      "3796 Training Loss: 0.03911012411117554 Validation Loss: 0.048317402601242065\n",
      "3797 Training Loss: 0.032832998782396317 Validation Loss: 0.04813530296087265\n",
      "3798 Training Loss: 0.030107175931334496 Validation Loss: 0.04807634651660919\n",
      "3799 Training Loss: 0.03524934500455856 Validation Loss: 0.04793253540992737\n",
      "3800 Training Loss: 0.03009922429919243 Validation Loss: 0.04796263575553894\n",
      "3801 Training Loss: 0.04097175598144531 Validation Loss: 0.04768941551446915\n",
      "3802 Training Loss: 0.03385549411177635 Validation Loss: 0.04732548072934151\n",
      "3803 Training Loss: 0.02861304208636284 Validation Loss: 0.04722040146589279\n",
      "3804 Training Loss: 0.03662566840648651 Validation Loss: 0.04706910252571106\n",
      "3805 Training Loss: 0.030411284416913986 Validation Loss: 0.047145649790763855\n",
      "3806 Training Loss: 0.035109370946884155 Validation Loss: 0.047198452055454254\n",
      "3807 Training Loss: 0.0324288010597229 Validation Loss: 0.047386471182107925\n",
      "3808 Training Loss: 0.035131704062223434 Validation Loss: 0.04760460555553436\n",
      "3809 Training Loss: 0.03247518464922905 Validation Loss: 0.0477600172162056\n",
      "3810 Training Loss: 0.03890250623226166 Validation Loss: 0.04756024107336998\n",
      "3811 Training Loss: 0.03381333872675896 Validation Loss: 0.04705805703997612\n",
      "3812 Training Loss: 0.03493007272481918 Validation Loss: 0.04660797864198685\n",
      "3813 Training Loss: 0.03607442229986191 Validation Loss: 0.045939818024635315\n",
      "3814 Training Loss: 0.028164686635136604 Validation Loss: 0.04568804055452347\n",
      "3815 Training Loss: 0.027907999232411385 Validation Loss: 0.04588671028614044\n",
      "3816 Training Loss: 0.03236120939254761 Validation Loss: 0.04606376588344574\n",
      "3817 Training Loss: 0.027875367552042007 Validation Loss: 0.04665648192167282\n",
      "3818 Training Loss: 0.03171529993414879 Validation Loss: 0.047249577939510345\n",
      "3819 Training Loss: 0.02928430587053299 Validation Loss: 0.047902971506118774\n",
      "3820 Training Loss: 0.029041513800621033 Validation Loss: 0.04883250221610069\n",
      "3821 Training Loss: 0.03629941865801811 Validation Loss: 0.04914524406194687\n",
      "3822 Training Loss: 0.03045053780078888 Validation Loss: 0.04942959174513817\n",
      "3823 Training Loss: 0.028241731226444244 Validation Loss: 0.0496235191822052\n",
      "3824 Training Loss: 0.030993765220046043 Validation Loss: 0.04975169152021408\n",
      "3825 Training Loss: 0.028848061338067055 Validation Loss: 0.049755483865737915\n",
      "3826 Training Loss: 0.027399269863963127 Validation Loss: 0.04965793341398239\n",
      "3827 Training Loss: 0.034839533269405365 Validation Loss: 0.049005210399627686\n",
      "3828 Training Loss: 0.028716914355754852 Validation Loss: 0.04855683073401451\n",
      "3829 Training Loss: 0.026460975408554077 Validation Loss: 0.048251450061798096\n",
      "3830 Training Loss: 0.03045494109392166 Validation Loss: 0.047781702131032944\n",
      "3831 Training Loss: 0.030931439250707626 Validation Loss: 0.047441720962524414\n",
      "3832 Training Loss: 0.03552040457725525 Validation Loss: 0.046894896775484085\n",
      "3833 Training Loss: 0.028934191912412643 Validation Loss: 0.04650687053799629\n",
      "3834 Training Loss: 0.03240075334906578 Validation Loss: 0.046188466250896454\n",
      "3835 Training Loss: 0.03387665003538132 Validation Loss: 0.04591098427772522\n",
      "3836 Training Loss: 0.034012071788311005 Validation Loss: 0.045813512057065964\n",
      "3837 Training Loss: 0.02674519270658493 Validation Loss: 0.046043068170547485\n",
      "3838 Training Loss: 0.04375167191028595 Validation Loss: 0.04573493450880051\n",
      "3839 Training Loss: 0.04050751030445099 Validation Loss: 0.04530129209160805\n",
      "3840 Training Loss: 0.03283730521798134 Validation Loss: 0.04503510147333145\n",
      "3841 Training Loss: 0.02877262979745865 Validation Loss: 0.04498465731739998\n",
      "3842 Training Loss: 0.03503042459487915 Validation Loss: 0.044895660132169724\n",
      "3843 Training Loss: 0.032686058431863785 Validation Loss: 0.044934213161468506\n",
      "3844 Training Loss: 0.03693297877907753 Validation Loss: 0.04475555568933487\n",
      "3845 Training Loss: 0.0344473272562027 Validation Loss: 0.04468187317252159\n",
      "3846 Training Loss: 0.026374612003564835 Validation Loss: 0.04501798748970032\n",
      "3847 Training Loss: 0.027561932802200317 Validation Loss: 0.04566163569688797\n",
      "3848 Training Loss: 0.02892884612083435 Validation Loss: 0.046344876289367676\n",
      "3849 Training Loss: 0.044873014092445374 Validation Loss: 0.046232920140028\n",
      "3850 Training Loss: 0.03176366910338402 Validation Loss: 0.045928556472063065\n",
      "3851 Training Loss: 0.031083300709724426 Validation Loss: 0.04556336626410484\n",
      "3852 Training Loss: 0.029058581218123436 Validation Loss: 0.04542604088783264\n",
      "3853 Training Loss: 0.03569885715842247 Validation Loss: 0.04492412880063057\n",
      "3854 Training Loss: 0.028171636164188385 Validation Loss: 0.044703416526317596\n",
      "3855 Training Loss: 0.0317305289208889 Validation Loss: 0.044621746987104416\n",
      "3856 Training Loss: 0.027803346514701843 Validation Loss: 0.04480782523751259\n",
      "3857 Training Loss: 0.029724303632974625 Validation Loss: 0.045141179114580154\n",
      "3858 Training Loss: 0.032638441771268845 Validation Loss: 0.04530033469200134\n",
      "3859 Training Loss: 0.04204409569501877 Validation Loss: 0.04499174654483795\n",
      "3860 Training Loss: 0.02614225447177887 Validation Loss: 0.04489217698574066\n",
      "3861 Training Loss: 0.027744408696889877 Validation Loss: 0.044870588928461075\n",
      "3862 Training Loss: 0.028498634696006775 Validation Loss: 0.04500744491815567\n",
      "3863 Training Loss: 0.03514733910560608 Validation Loss: 0.04511256143450737\n",
      "3864 Training Loss: 0.034829992800951004 Validation Loss: 0.044817760586738586\n",
      "3865 Training Loss: 0.033116377890110016 Validation Loss: 0.04441803693771362\n",
      "3866 Training Loss: 0.03482458367943764 Validation Loss: 0.044041816145181656\n",
      "3867 Training Loss: 0.030629968270659447 Validation Loss: 0.04385581612586975\n",
      "3868 Training Loss: 0.03160960227251053 Validation Loss: 0.043848711997270584\n",
      "3869 Training Loss: 0.04662977159023285 Validation Loss: 0.04339621216058731\n",
      "3870 Training Loss: 0.027653703466057777 Validation Loss: 0.04336047172546387\n",
      "3871 Training Loss: 0.03501323610544205 Validation Loss: 0.04303477704524994\n",
      "3872 Training Loss: 0.032737188041210175 Validation Loss: 0.04276695102453232\n",
      "3873 Training Loss: 0.028427161276340485 Validation Loss: 0.04282929748296738\n",
      "3874 Training Loss: 0.03115835413336754 Validation Loss: 0.04293743893504143\n",
      "3875 Training Loss: 0.03702846169471741 Validation Loss: 0.042856041342020035\n",
      "3876 Training Loss: 0.03182095289230347 Validation Loss: 0.042955171316862106\n",
      "3877 Training Loss: 0.030716218054294586 Validation Loss: 0.04316814988851547\n",
      "3878 Training Loss: 0.03432697057723999 Validation Loss: 0.043406058102846146\n",
      "3879 Training Loss: 0.032336726784706116 Validation Loss: 0.043319668620824814\n",
      "3880 Training Loss: 0.027251917868852615 Validation Loss: 0.043412964791059494\n",
      "3881 Training Loss: 0.035301804542541504 Validation Loss: 0.043272390961647034\n",
      "3882 Training Loss: 0.028344716876745224 Validation Loss: 0.043371863663196564\n",
      "3883 Training Loss: 0.02914276532828808 Validation Loss: 0.04337890073657036\n",
      "3884 Training Loss: 0.03083219565451145 Validation Loss: 0.043395936489105225\n",
      "3885 Training Loss: 0.03554641082882881 Validation Loss: 0.04319857805967331\n",
      "3886 Training Loss: 0.0293072909116745 Validation Loss: 0.043061479926109314\n",
      "3887 Training Loss: 0.02720995992422104 Validation Loss: 0.04318416491150856\n",
      "3888 Training Loss: 0.02943608909845352 Validation Loss: 0.04336099699139595\n",
      "3889 Training Loss: 0.028453320264816284 Validation Loss: 0.043459147214889526\n",
      "3890 Training Loss: 0.028444742783904076 Validation Loss: 0.04349862411618233\n",
      "3891 Training Loss: 0.028203681111335754 Validation Loss: 0.04359300062060356\n",
      "3892 Training Loss: 0.04161006584763527 Validation Loss: 0.04311816394329071\n",
      "3893 Training Loss: 0.037350937724113464 Validation Loss: 0.04242042452096939\n",
      "3894 Training Loss: 0.02632109448313713 Validation Loss: 0.04205937311053276\n",
      "3895 Training Loss: 0.03521033748984337 Validation Loss: 0.04170933738350868\n",
      "3896 Training Loss: 0.027806438505649567 Validation Loss: 0.04160201549530029\n",
      "3897 Training Loss: 0.02878006361424923 Validation Loss: 0.04157744348049164\n",
      "3898 Training Loss: 0.03375733643770218 Validation Loss: 0.04149843007326126\n",
      "3899 Training Loss: 0.02613026648759842 Validation Loss: 0.04167986661195755\n",
      "3900 Training Loss: 0.03211557865142822 Validation Loss: 0.04186522960662842\n",
      "3901 Training Loss: 0.035640668123960495 Validation Loss: 0.04190624877810478\n",
      "3902 Training Loss: 0.02598915807902813 Validation Loss: 0.04234558343887329\n",
      "3903 Training Loss: 0.027082210406661034 Validation Loss: 0.042928297072649\n",
      "3904 Training Loss: 0.026837017387151718 Validation Loss: 0.04349353909492493\n",
      "3905 Training Loss: 0.029837792739272118 Validation Loss: 0.04405023157596588\n",
      "3906 Training Loss: 0.033252641558647156 Validation Loss: 0.04419342428445816\n",
      "3907 Training Loss: 0.030120447278022766 Validation Loss: 0.0441233366727829\n",
      "3908 Training Loss: 0.03788527473807335 Validation Loss: 0.0432610847055912\n",
      "3909 Training Loss: 0.03489220142364502 Validation Loss: 0.04231470823287964\n",
      "3910 Training Loss: 0.025274254381656647 Validation Loss: 0.041782427579164505\n",
      "3911 Training Loss: 0.04123086482286453 Validation Loss: 0.04098530858755112\n",
      "3912 Training Loss: 0.034800197929143906 Validation Loss: 0.04024721682071686\n",
      "3913 Training Loss: 0.025073600932955742 Validation Loss: 0.03998491168022156\n",
      "3914 Training Loss: 0.03303864598274231 Validation Loss: 0.03983017057180405\n",
      "3915 Training Loss: 0.0259880181401968 Validation Loss: 0.03995053842663765\n",
      "3916 Training Loss: 0.02959781512618065 Validation Loss: 0.040204182267189026\n",
      "3917 Training Loss: 0.03421466425061226 Validation Loss: 0.04037386551499367\n",
      "3918 Training Loss: 0.02465301752090454 Validation Loss: 0.04090739041566849\n",
      "3919 Training Loss: 0.027118628844618797 Validation Loss: 0.04155958071351051\n",
      "3920 Training Loss: 0.024021869525313377 Validation Loss: 0.04249069467186928\n",
      "3921 Training Loss: 0.0282900333404541 Validation Loss: 0.04334574565291405\n",
      "3922 Training Loss: 0.026844855397939682 Validation Loss: 0.044152405112981796\n",
      "3923 Training Loss: 0.02694004215300083 Validation Loss: 0.04486318305134773\n",
      "3924 Training Loss: 0.02707495726644993 Validation Loss: 0.04530242830514908\n",
      "3925 Training Loss: 0.028905129060149193 Validation Loss: 0.04545348882675171\n",
      "3926 Training Loss: 0.03497302532196045 Validation Loss: 0.045043230056762695\n",
      "3927 Training Loss: 0.02602461725473404 Validation Loss: 0.0447595939040184\n",
      "3928 Training Loss: 0.03405052796006203 Validation Loss: 0.04404248297214508\n",
      "3929 Training Loss: 0.024869244545698166 Validation Loss: 0.04352716729044914\n",
      "3930 Training Loss: 0.032377757132053375 Validation Loss: 0.042938411235809326\n",
      "3931 Training Loss: 0.030512575060129166 Validation Loss: 0.04215092211961746\n",
      "3932 Training Loss: 0.024282000958919525 Validation Loss: 0.04165137559175491\n",
      "3933 Training Loss: 0.029053568840026855 Validation Loss: 0.041094932705163956\n",
      "3934 Training Loss: 0.028335090726614 Validation Loss: 0.040622733533382416\n",
      "3935 Training Loss: 0.026932474225759506 Validation Loss: 0.040412791073322296\n",
      "3936 Training Loss: 0.02586807683110237 Validation Loss: 0.04038549214601517\n",
      "3937 Training Loss: 0.02723531797528267 Validation Loss: 0.04059622809290886\n",
      "3938 Training Loss: 0.03361964598298073 Validation Loss: 0.0406293049454689\n",
      "3939 Training Loss: 0.026513494551181793 Validation Loss: 0.040842071175575256\n",
      "3940 Training Loss: 0.040846943855285645 Validation Loss: 0.04052159562706947\n",
      "3941 Training Loss: 0.02464255690574646 Validation Loss: 0.04055488482117653\n",
      "3942 Training Loss: 0.030567876994609833 Validation Loss: 0.04067450389266014\n",
      "3943 Training Loss: 0.025750556960701942 Validation Loss: 0.040932461619377136\n",
      "3944 Training Loss: 0.031223570927977562 Validation Loss: 0.04113851860165596\n",
      "3945 Training Loss: 0.0298805870115757 Validation Loss: 0.04117206484079361\n",
      "3946 Training Loss: 0.025571640580892563 Validation Loss: 0.04141400754451752\n",
      "3947 Training Loss: 0.025446277111768723 Validation Loss: 0.04180294647812843\n",
      "3948 Training Loss: 0.023370251059532166 Validation Loss: 0.04239659756422043\n",
      "3949 Training Loss: 0.03298427164554596 Validation Loss: 0.04251717031002045\n",
      "3950 Training Loss: 0.03002341277897358 Validation Loss: 0.04224003478884697\n",
      "3951 Training Loss: 0.02617853507399559 Validation Loss: 0.04193657636642456\n",
      "3952 Training Loss: 0.030922183766961098 Validation Loss: 0.04169195145368576\n",
      "3953 Training Loss: 0.037207506597042084 Validation Loss: 0.04099688678979874\n",
      "3954 Training Loss: 0.025540541857481003 Validation Loss: 0.04046611860394478\n",
      "3955 Training Loss: 0.03192523866891861 Validation Loss: 0.03989686816930771\n",
      "3956 Training Loss: 0.030128169804811478 Validation Loss: 0.03942515701055527\n",
      "3957 Training Loss: 0.03664024919271469 Validation Loss: 0.038771260529756546\n",
      "3958 Training Loss: 0.027614440768957138 Validation Loss: 0.03837766870856285\n",
      "3959 Training Loss: 0.027514014393091202 Validation Loss: 0.03814797103404999\n",
      "3960 Training Loss: 0.023972591385245323 Validation Loss: 0.03825870528817177\n",
      "3961 Training Loss: 0.027659043669700623 Validation Loss: 0.038484640419483185\n",
      "3962 Training Loss: 0.028756912797689438 Validation Loss: 0.03881985321640968\n",
      "3963 Training Loss: 0.02794625237584114 Validation Loss: 0.03921201452612877\n",
      "3964 Training Loss: 0.026360923424363136 Validation Loss: 0.0397290401160717\n",
      "3965 Training Loss: 0.027870286256074905 Validation Loss: 0.040307123214006424\n",
      "3966 Training Loss: 0.03372470661997795 Validation Loss: 0.04046309366822243\n",
      "3967 Training Loss: 0.027379322797060013 Validation Loss: 0.04058172553777695\n",
      "3968 Training Loss: 0.02423795871436596 Validation Loss: 0.04087403416633606\n",
      "3969 Training Loss: 0.025547483935952187 Validation Loss: 0.040890008211135864\n",
      "3970 Training Loss: 0.02815990522503853 Validation Loss: 0.04082562029361725\n",
      "3971 Training Loss: 0.025990337133407593 Validation Loss: 0.040824759751558304\n",
      "3972 Training Loss: 0.02299388125538826 Validation Loss: 0.04097483307123184\n",
      "3973 Training Loss: 0.029282039031386375 Validation Loss: 0.04090021178126335\n",
      "3974 Training Loss: 0.03116396814584732 Validation Loss: 0.04077289253473282\n",
      "3975 Training Loss: 0.023585494607686996 Validation Loss: 0.040840864181518555\n",
      "3976 Training Loss: 0.03560071438550949 Validation Loss: 0.04046224057674408\n",
      "3977 Training Loss: 0.027397044003009796 Validation Loss: 0.04007820785045624\n",
      "3978 Training Loss: 0.03005429171025753 Validation Loss: 0.03960935026407242\n",
      "3979 Training Loss: 0.022879086434841156 Validation Loss: 0.03949447721242905\n",
      "3980 Training Loss: 0.028132226318120956 Validation Loss: 0.039375871419906616\n",
      "3981 Training Loss: 0.029812240973114967 Validation Loss: 0.039092130959033966\n",
      "3982 Training Loss: 0.03773045912384987 Validation Loss: 0.03859790414571762\n",
      "3983 Training Loss: 0.02486412599682808 Validation Loss: 0.038421303033828735\n",
      "3984 Training Loss: 0.035388581454753876 Validation Loss: 0.038068987429142\n",
      "3985 Training Loss: 0.026027865707874298 Validation Loss: 0.037940721958875656\n",
      "3986 Training Loss: 0.02643444389104843 Validation Loss: 0.03797030448913574\n",
      "3987 Training Loss: 0.03660718351602554 Validation Loss: 0.03779657557606697\n",
      "3988 Training Loss: 0.02747095376253128 Validation Loss: 0.037828899919986725\n",
      "3989 Training Loss: 0.024629075080156326 Validation Loss: 0.0380760058760643\n",
      "3990 Training Loss: 0.02415452152490616 Validation Loss: 0.038526952266693115\n",
      "3991 Training Loss: 0.03080056980252266 Validation Loss: 0.03874998167157173\n",
      "3992 Training Loss: 0.025572961196303368 Validation Loss: 0.03902318328619003\n",
      "3993 Training Loss: 0.033419471234083176 Validation Loss: 0.03899602219462395\n",
      "3994 Training Loss: 0.024970784783363342 Validation Loss: 0.03920035809278488\n",
      "3995 Training Loss: 0.022666124626994133 Validation Loss: 0.0396408885717392\n",
      "3996 Training Loss: 0.03089127317070961 Validation Loss: 0.039717063307762146\n",
      "3997 Training Loss: 0.030222725123167038 Validation Loss: 0.03938089311122894\n",
      "3998 Training Loss: 0.023813582956790924 Validation Loss: 0.039301708340644836\n",
      "3999 Training Loss: 0.024203181266784668 Validation Loss: 0.0393194705247879\n",
      "4000 Training Loss: 0.021490298211574554 Validation Loss: 0.03947308287024498\n",
      "4001 Training Loss: 0.027515437453985214 Validation Loss: 0.039486005902290344\n",
      "4002 Training Loss: 0.025541435927152634 Validation Loss: 0.039339691400527954\n",
      "4003 Training Loss: 0.022138562053442 Validation Loss: 0.03941910341382027\n",
      "4004 Training Loss: 0.031677260994911194 Validation Loss: 0.039275750517845154\n",
      "4005 Training Loss: 0.024026356637477875 Validation Loss: 0.039182133972644806\n",
      "4006 Training Loss: 0.025071922689676285 Validation Loss: 0.039151232689619064\n",
      "4007 Training Loss: 0.027305034920573235 Validation Loss: 0.039056964218616486\n",
      "4008 Training Loss: 0.02716057002544403 Validation Loss: 0.03886178880929947\n",
      "4009 Training Loss: 0.02532919868826866 Validation Loss: 0.03870471194386482\n",
      "4010 Training Loss: 0.033774301409721375 Validation Loss: 0.038234930485486984\n",
      "4011 Training Loss: 0.024086233228445053 Validation Loss: 0.03812994807958603\n",
      "4012 Training Loss: 0.022403975948691368 Validation Loss: 0.03818564862012863\n",
      "4013 Training Loss: 0.0242487583309412 Validation Loss: 0.03845837339758873\n",
      "4014 Training Loss: 0.023437391966581345 Validation Loss: 0.038784757256507874\n",
      "4015 Training Loss: 0.025425314903259277 Validation Loss: 0.03916317597031593\n",
      "4016 Training Loss: 0.024116115644574165 Validation Loss: 0.03951842337846756\n",
      "4017 Training Loss: 0.024787604808807373 Validation Loss: 0.039734892547130585\n",
      "4018 Training Loss: 0.028304610401391983 Validation Loss: 0.03971768915653229\n",
      "4019 Training Loss: 0.028517067432403564 Validation Loss: 0.03949445113539696\n",
      "4020 Training Loss: 0.03161045163869858 Validation Loss: 0.03877352178096771\n",
      "4021 Training Loss: 0.022185921669006348 Validation Loss: 0.038292016834020615\n",
      "4022 Training Loss: 0.027357738465070724 Validation Loss: 0.03785327076911926\n",
      "4023 Training Loss: 0.029802098870277405 Validation Loss: 0.03737843036651611\n",
      "4024 Training Loss: 0.024418799206614494 Validation Loss: 0.037125200033187866\n",
      "4025 Training Loss: 0.027412641793489456 Validation Loss: 0.037022240459918976\n",
      "4026 Training Loss: 0.03310421109199524 Validation Loss: 0.036851100623607635\n",
      "4027 Training Loss: 0.025983627885580063 Validation Loss: 0.03685595095157623\n",
      "4028 Training Loss: 0.0258060060441494 Validation Loss: 0.03692189231514931\n",
      "4029 Training Loss: 0.03696557134389877 Validation Loss: 0.0366593562066555\n",
      "4030 Training Loss: 0.036401573568582535 Validation Loss: 0.036223046481609344\n",
      "4031 Training Loss: 0.02346370555460453 Validation Loss: 0.03604589402675629\n",
      "4032 Training Loss: 0.02478814497590065 Validation Loss: 0.03610704839229584\n",
      "4033 Training Loss: 0.023613804951310158 Validation Loss: 0.036420807242393494\n",
      "4034 Training Loss: 0.026082854717969894 Validation Loss: 0.0368586927652359\n",
      "4035 Training Loss: 0.02135155349969864 Validation Loss: 0.0375337228178978\n",
      "4036 Training Loss: 0.023391177877783775 Validation Loss: 0.03842009976506233\n",
      "4037 Training Loss: 0.032735563814640045 Validation Loss: 0.0388135202229023\n",
      "4038 Training Loss: 0.024041183292865753 Validation Loss: 0.03918285667896271\n",
      "4039 Training Loss: 0.02356685884296894 Validation Loss: 0.03957057744264603\n",
      "4040 Training Loss: 0.022015614435076714 Validation Loss: 0.040036529302597046\n",
      "4041 Training Loss: 0.03200908005237579 Validation Loss: 0.039664532989263535\n",
      "4042 Training Loss: 0.034335002303123474 Validation Loss: 0.038643624633550644\n",
      "4043 Training Loss: 0.021759092807769775 Validation Loss: 0.03784603998064995\n",
      "4044 Training Loss: 0.025401897728443146 Validation Loss: 0.03719254583120346\n",
      "4045 Training Loss: 0.032361630350351334 Validation Loss: 0.03626891225576401\n",
      "4046 Training Loss: 0.023461315780878067 Validation Loss: 0.03578026592731476\n",
      "4047 Training Loss: 0.027072813361883163 Validation Loss: 0.0355050228536129\n",
      "4048 Training Loss: 0.023350726813077927 Validation Loss: 0.035491060465574265\n",
      "4049 Training Loss: 0.026090100407600403 Validation Loss: 0.035541802644729614\n",
      "4050 Training Loss: 0.024722274392843246 Validation Loss: 0.03575611487030983\n",
      "4051 Training Loss: 0.030264656990766525 Validation Loss: 0.03583860397338867\n",
      "4052 Training Loss: 0.025863368064165115 Validation Loss: 0.0359429270029068\n",
      "4053 Training Loss: 0.03288199380040169 Validation Loss: 0.03585965931415558\n",
      "4054 Training Loss: 0.03380362689495087 Validation Loss: 0.03555314987897873\n",
      "4055 Training Loss: 0.021985776722431183 Validation Loss: 0.03552401810884476\n",
      "4056 Training Loss: 0.033612728118896484 Validation Loss: 0.035308122634887695\n",
      "4057 Training Loss: 0.030259765684604645 Validation Loss: 0.035099539905786514\n",
      "4058 Training Loss: 0.03593491017818451 Validation Loss: 0.03472687304019928\n",
      "4059 Training Loss: 0.027062244713306427 Validation Loss: 0.03449350595474243\n",
      "4060 Training Loss: 0.028442971408367157 Validation Loss: 0.034324221312999725\n",
      "4061 Training Loss: 0.02559264935553074 Validation Loss: 0.03426647186279297\n",
      "4062 Training Loss: 0.030329756438732147 Validation Loss: 0.034227728843688965\n",
      "4063 Training Loss: 0.026064816862344742 Validation Loss: 0.034328434616327286\n",
      "4064 Training Loss: 0.029414350166916847 Validation Loss: 0.034424856305122375\n",
      "4065 Training Loss: 0.024852851405739784 Validation Loss: 0.034632373601198196\n",
      "4066 Training Loss: 0.023095017299056053 Validation Loss: 0.035005003213882446\n",
      "4067 Training Loss: 0.0243527851998806 Validation Loss: 0.03549112752079964\n",
      "4068 Training Loss: 0.02540171891450882 Validation Loss: 0.0359816737473011\n",
      "4069 Training Loss: 0.026554759591817856 Validation Loss: 0.036361679434776306\n",
      "4070 Training Loss: 0.022785838693380356 Validation Loss: 0.03677279129624367\n",
      "4071 Training Loss: 0.02414143830537796 Validation Loss: 0.03718176856637001\n",
      "4072 Training Loss: 0.023891907185316086 Validation Loss: 0.03753087669610977\n",
      "4073 Training Loss: 0.021474946290254593 Validation Loss: 0.03790359944105148\n",
      "4074 Training Loss: 0.030242696404457092 Validation Loss: 0.03782731294631958\n",
      "4075 Training Loss: 0.022785073146224022 Validation Loss: 0.03777086362242699\n",
      "4076 Training Loss: 0.029024232178926468 Validation Loss: 0.03728372976183891\n",
      "4077 Training Loss: 0.026908285915851593 Validation Loss: 0.03657851368188858\n",
      "4078 Training Loss: 0.022672321647405624 Validation Loss: 0.035776421427726746\n",
      "4079 Training Loss: 0.027178429067134857 Validation Loss: 0.034905821084976196\n",
      "4080 Training Loss: 0.023797564208507538 Validation Loss: 0.03415169566869736\n",
      "4081 Training Loss: 0.027475763112306595 Validation Loss: 0.03359798341989517\n",
      "4082 Training Loss: 0.023120637983083725 Validation Loss: 0.03332051634788513\n",
      "4083 Training Loss: 0.026702817529439926 Validation Loss: 0.03323221951723099\n",
      "4084 Training Loss: 0.026240278035402298 Validation Loss: 0.03325771540403366\n",
      "4085 Training Loss: 0.027877792716026306 Validation Loss: 0.033403657376766205\n",
      "4086 Training Loss: 0.02198813110589981 Validation Loss: 0.03387144207954407\n",
      "4087 Training Loss: 0.024637332186102867 Validation Loss: 0.03450095281004906\n",
      "4088 Training Loss: 0.02086292766034603 Validation Loss: 0.03530528396368027\n",
      "4089 Training Loss: 0.022121835500001907 Validation Loss: 0.03616119176149368\n",
      "4090 Training Loss: 0.03148648142814636 Validation Loss: 0.0365554615855217\n",
      "4091 Training Loss: 0.026504945009946823 Validation Loss: 0.03680965676903725\n",
      "4092 Training Loss: 0.028912227600812912 Validation Loss: 0.03686998412013054\n",
      "4093 Training Loss: 0.021624097600579262 Validation Loss: 0.03701140731573105\n",
      "4094 Training Loss: 0.02232753485441208 Validation Loss: 0.03691352903842926\n",
      "4095 Training Loss: 0.021850088611245155 Validation Loss: 0.03672051429748535\n",
      "4096 Training Loss: 0.02322230488061905 Validation Loss: 0.03633415326476097\n",
      "4097 Training Loss: 0.023238657042384148 Validation Loss: 0.035855021327733994\n",
      "4098 Training Loss: 0.021273884922266006 Validation Loss: 0.03552290052175522\n",
      "4099 Training Loss: 0.0226413793861866 Validation Loss: 0.03532157465815544\n",
      "4100 Training Loss: 0.026903340592980385 Validation Loss: 0.034988608211278915\n",
      "4101 Training Loss: 0.0208749920129776 Validation Loss: 0.03484777361154556\n",
      "4102 Training Loss: 0.02509651891887188 Validation Loss: 0.03473319113254547\n",
      "4103 Training Loss: 0.020340293645858765 Validation Loss: 0.03480157256126404\n",
      "4104 Training Loss: 0.02819960191845894 Validation Loss: 0.034690387547016144\n",
      "4105 Training Loss: 0.029258789494633675 Validation Loss: 0.0344330295920372\n",
      "4106 Training Loss: 0.025676149874925613 Validation Loss: 0.03418829292058945\n",
      "4107 Training Loss: 0.02507469244301319 Validation Loss: 0.03394085168838501\n",
      "4108 Training Loss: 0.022510811686515808 Validation Loss: 0.03386431559920311\n",
      "4109 Training Loss: 0.028682740405201912 Validation Loss: 0.03369444981217384\n",
      "4110 Training Loss: 0.02099945768713951 Validation Loss: 0.033777497708797455\n",
      "4111 Training Loss: 0.0332552045583725 Validation Loss: 0.03365425020456314\n",
      "4112 Training Loss: 0.02553730085492134 Validation Loss: 0.033500198274850845\n",
      "4113 Training Loss: 0.021058958023786545 Validation Loss: 0.03369669243693352\n",
      "4114 Training Loss: 0.02091478556394577 Validation Loss: 0.03417768329381943\n",
      "4115 Training Loss: 0.02821955643594265 Validation Loss: 0.03440641611814499\n",
      "4116 Training Loss: 0.025391358882188797 Validation Loss: 0.034417979419231415\n",
      "4117 Training Loss: 0.02057824842631817 Validation Loss: 0.03465041145682335\n",
      "4118 Training Loss: 0.031207140535116196 Validation Loss: 0.03438850864768028\n",
      "4119 Training Loss: 0.02257494442164898 Validation Loss: 0.03420848399400711\n",
      "4120 Training Loss: 0.023244502022862434 Validation Loss: 0.033995456993579865\n",
      "4121 Training Loss: 0.02610784024000168 Validation Loss: 0.033603161573410034\n",
      "4122 Training Loss: 0.023330047726631165 Validation Loss: 0.033349405974149704\n",
      "4123 Training Loss: 0.02300199307501316 Validation Loss: 0.03323601558804512\n",
      "4124 Training Loss: 0.019745497032999992 Validation Loss: 0.03337808698415756\n",
      "4125 Training Loss: 0.02784959226846695 Validation Loss: 0.033488888293504715\n",
      "4126 Training Loss: 0.02285180427134037 Validation Loss: 0.03362872824072838\n",
      "4127 Training Loss: 0.025033414363861084 Validation Loss: 0.03385915979743004\n",
      "4128 Training Loss: 0.02698035165667534 Validation Loss: 0.034103233367204666\n",
      "4129 Training Loss: 0.024512629956007004 Validation Loss: 0.034402187913656235\n",
      "4130 Training Loss: 0.02490725740790367 Validation Loss: 0.034559428691864014\n",
      "4131 Training Loss: 0.02333351969718933 Validation Loss: 0.03462185710668564\n",
      "4132 Training Loss: 0.02343721129000187 Validation Loss: 0.034620821475982666\n",
      "4133 Training Loss: 0.02504122257232666 Validation Loss: 0.034431662410497665\n",
      "4134 Training Loss: 0.02429666556417942 Validation Loss: 0.034200169146060944\n",
      "4135 Training Loss: 0.02108287438750267 Validation Loss: 0.03399933874607086\n",
      "4136 Training Loss: 0.019691482186317444 Validation Loss: 0.0339837372303009\n",
      "4137 Training Loss: 0.025691339746117592 Validation Loss: 0.03372759744524956\n",
      "4138 Training Loss: 0.021222293376922607 Validation Loss: 0.03360636904835701\n",
      "4139 Training Loss: 0.025775976479053497 Validation Loss: 0.03344213217496872\n",
      "4140 Training Loss: 0.027665378525853157 Validation Loss: 0.03301733732223511\n",
      "4141 Training Loss: 0.01908503659069538 Validation Loss: 0.03290753439068794\n",
      "4142 Training Loss: 0.021024225279688835 Validation Loss: 0.03299526870250702\n",
      "4143 Training Loss: 0.024144979193806648 Validation Loss: 0.03299713879823685\n",
      "4144 Training Loss: 0.03055952861905098 Validation Loss: 0.0328214205801487\n",
      "4145 Training Loss: 0.02296164445579052 Validation Loss: 0.032732680439949036\n",
      "4146 Training Loss: 0.02403866872191429 Validation Loss: 0.03268253058195114\n",
      "4147 Training Loss: 0.026631752029061317 Validation Loss: 0.03258216381072998\n",
      "4148 Training Loss: 0.024767208844423294 Validation Loss: 0.032501645386219025\n",
      "4149 Training Loss: 0.03885265067219734 Validation Loss: 0.032051585614681244\n",
      "4150 Training Loss: 0.024091174826025963 Validation Loss: 0.03177739679813385\n",
      "4151 Training Loss: 0.032391659915447235 Validation Loss: 0.03147754818201065\n",
      "4152 Training Loss: 0.0226467102766037 Validation Loss: 0.031339772045612335\n",
      "4153 Training Loss: 0.02355705201625824 Validation Loss: 0.03127627447247505\n",
      "4154 Training Loss: 0.0232615377753973 Validation Loss: 0.03130003437399864\n",
      "4155 Training Loss: 0.04256417602300644 Validation Loss: 0.031075255945324898\n",
      "4156 Training Loss: 0.027150887995958328 Validation Loss: 0.03081793338060379\n",
      "4157 Training Loss: 0.024542711675167084 Validation Loss: 0.030643241479992867\n",
      "4158 Training Loss: 0.02493293210864067 Validation Loss: 0.030647385865449905\n",
      "4159 Training Loss: 0.02062474563717842 Validation Loss: 0.03100774995982647\n",
      "4160 Training Loss: 0.024162843823432922 Validation Loss: 0.031485334038734436\n",
      "4161 Training Loss: 0.024051282554864883 Validation Loss: 0.03196786716580391\n",
      "4162 Training Loss: 0.02074870839715004 Validation Loss: 0.03253217414021492\n",
      "4163 Training Loss: 0.02388746663928032 Validation Loss: 0.03283305466175079\n",
      "4164 Training Loss: 0.021611977368593216 Validation Loss: 0.03296487033367157\n",
      "4165 Training Loss: 0.020435648038983345 Validation Loss: 0.03308454900979996\n",
      "4166 Training Loss: 0.021429868414998055 Validation Loss: 0.0331822894513607\n",
      "4167 Training Loss: 0.019778791815042496 Validation Loss: 0.0333382785320282\n",
      "4168 Training Loss: 0.025670118629932404 Validation Loss: 0.03324389457702637\n",
      "4169 Training Loss: 0.03727922961115837 Validation Loss: 0.032322585582733154\n",
      "4170 Training Loss: 0.02350355125963688 Validation Loss: 0.03157098963856697\n",
      "4171 Training Loss: 0.02488575130701065 Validation Loss: 0.031003067269921303\n",
      "4172 Training Loss: 0.031399138271808624 Validation Loss: 0.030500944703817368\n",
      "4173 Training Loss: 0.023669661954045296 Validation Loss: 0.03026392310857773\n",
      "4174 Training Loss: 0.02369348518550396 Validation Loss: 0.030194979161024094\n",
      "4175 Training Loss: 0.02511735074222088 Validation Loss: 0.030084319412708282\n",
      "4176 Training Loss: 0.02148982509970665 Validation Loss: 0.030111154541373253\n",
      "4177 Training Loss: 0.02471517026424408 Validation Loss: 0.03013557568192482\n",
      "4178 Training Loss: 0.02191263437271118 Validation Loss: 0.03035772405564785\n",
      "4179 Training Loss: 0.0185223538428545 Validation Loss: 0.030928250402212143\n",
      "4180 Training Loss: 0.021393898874521255 Validation Loss: 0.031619660556316376\n",
      "4181 Training Loss: 0.022440237924456596 Validation Loss: 0.03238999843597412\n",
      "4182 Training Loss: 0.02350909635424614 Validation Loss: 0.032973915338516235\n",
      "4183 Training Loss: 0.03307894617319107 Validation Loss: 0.03287280350923538\n",
      "4184 Training Loss: 0.02669946849346161 Validation Loss: 0.0324195995926857\n",
      "4185 Training Loss: 0.023636262863874435 Validation Loss: 0.03187353163957596\n",
      "4186 Training Loss: 0.022366346791386604 Validation Loss: 0.031400877982378006\n",
      "4187 Training Loss: 0.029206475242972374 Validation Loss: 0.03071223944425583\n",
      "4188 Training Loss: 0.02301597036421299 Validation Loss: 0.030163176357746124\n",
      "4189 Training Loss: 0.03030264750123024 Validation Loss: 0.029628094285726547\n",
      "4190 Training Loss: 0.02720016986131668 Validation Loss: 0.02924293279647827\n",
      "4191 Training Loss: 0.025492914021015167 Validation Loss: 0.028993654996156693\n",
      "4192 Training Loss: 0.022747136652469635 Validation Loss: 0.028846725821495056\n",
      "4193 Training Loss: 0.023487385362386703 Validation Loss: 0.02882818877696991\n",
      "4194 Training Loss: 0.03243032842874527 Validation Loss: 0.028799984604120255\n",
      "4195 Training Loss: 0.02377232536673546 Validation Loss: 0.028891758993268013\n",
      "4196 Training Loss: 0.02140144258737564 Validation Loss: 0.029089204967021942\n",
      "4197 Training Loss: 0.023179883137345314 Validation Loss: 0.02937791682779789\n",
      "4198 Training Loss: 0.023675918579101562 Validation Loss: 0.029771123081445694\n",
      "4199 Training Loss: 0.022245310246944427 Validation Loss: 0.03019021824002266\n",
      "4200 Training Loss: 0.022777162492275238 Validation Loss: 0.030590415000915527\n",
      "4201 Training Loss: 0.022289922460913658 Validation Loss: 0.03095882385969162\n",
      "4202 Training Loss: 0.022162316367030144 Validation Loss: 0.031282421201467514\n",
      "4203 Training Loss: 0.020322617143392563 Validation Loss: 0.03160271421074867\n",
      "4204 Training Loss: 0.02415960282087326 Validation Loss: 0.03170863538980484\n",
      "4205 Training Loss: 0.026661250740289688 Validation Loss: 0.03136554732918739\n",
      "4206 Training Loss: 0.020340807735919952 Validation Loss: 0.031066669151186943\n",
      "4207 Training Loss: 0.02139432542026043 Validation Loss: 0.03072460927069187\n",
      "4208 Training Loss: 0.020034458488225937 Validation Loss: 0.03048386424779892\n",
      "4209 Training Loss: 0.031927961856126785 Validation Loss: 0.02991560846567154\n",
      "4210 Training Loss: 0.021395079791545868 Validation Loss: 0.029500897973775864\n",
      "4211 Training Loss: 0.02127048186957836 Validation Loss: 0.02924378402531147\n",
      "4212 Training Loss: 0.020092010498046875 Validation Loss: 0.029108865186572075\n",
      "4213 Training Loss: 0.028741631656885147 Validation Loss: 0.02886900305747986\n",
      "4214 Training Loss: 0.02027352899312973 Validation Loss: 0.028784941881895065\n",
      "4215 Training Loss: 0.035539306700229645 Validation Loss: 0.028429294005036354\n",
      "4216 Training Loss: 0.021640289574861526 Validation Loss: 0.028270266950130463\n",
      "4217 Training Loss: 0.026323623955249786 Validation Loss: 0.028080511838197708\n",
      "4218 Training Loss: 0.02123558521270752 Validation Loss: 0.02802583947777748\n",
      "4219 Training Loss: 0.020264722406864166 Validation Loss: 0.02814767137169838\n",
      "4220 Training Loss: 0.02347133308649063 Validation Loss: 0.02841338701546192\n",
      "4221 Training Loss: 0.025253616273403168 Validation Loss: 0.02874242141842842\n",
      "4222 Training Loss: 0.023151760920882225 Validation Loss: 0.029074721038341522\n",
      "4223 Training Loss: 0.023274090141057968 Validation Loss: 0.0292684193700552\n",
      "4224 Training Loss: 0.031812649220228195 Validation Loss: 0.02906804531812668\n",
      "4225 Training Loss: 0.020756615325808525 Validation Loss: 0.029041219502687454\n",
      "4226 Training Loss: 0.023501461371779442 Validation Loss: 0.02900288626551628\n",
      "4227 Training Loss: 0.023170050233602524 Validation Loss: 0.02888573333621025\n",
      "4228 Training Loss: 0.020270876586437225 Validation Loss: 0.028874557465314865\n",
      "4229 Training Loss: 0.019018223509192467 Validation Loss: 0.028962569311261177\n",
      "4230 Training Loss: 0.026783980429172516 Validation Loss: 0.02884618192911148\n",
      "4231 Training Loss: 0.018041539937257767 Validation Loss: 0.028914134949445724\n",
      "4232 Training Loss: 0.02071169763803482 Validation Loss: 0.029030021280050278\n",
      "4233 Training Loss: 0.023996997624635696 Validation Loss: 0.0290434118360281\n",
      "4234 Training Loss: 0.0289686881005764 Validation Loss: 0.028815673664212227\n",
      "4235 Training Loss: 0.02332063391804695 Validation Loss: 0.028648000210523605\n",
      "4236 Training Loss: 0.02044750563800335 Validation Loss: 0.02857055515050888\n",
      "4237 Training Loss: 0.021122323349118233 Validation Loss: 0.02856147289276123\n",
      "4238 Training Loss: 0.02212308533489704 Validation Loss: 0.028622811660170555\n",
      "4239 Training Loss: 0.02926507592201233 Validation Loss: 0.02859039604663849\n",
      "4240 Training Loss: 0.022184863686561584 Validation Loss: 0.02855200693011284\n",
      "4241 Training Loss: 0.02483895793557167 Validation Loss: 0.02845502644777298\n",
      "4242 Training Loss: 0.02844838984310627 Validation Loss: 0.028172463178634644\n",
      "4243 Training Loss: 0.018752867355942726 Validation Loss: 0.02804598957300186\n",
      "4244 Training Loss: 0.019989052787423134 Validation Loss: 0.028020258992910385\n",
      "4245 Training Loss: 0.02140127867460251 Validation Loss: 0.02801625244319439\n",
      "4246 Training Loss: 0.018329761922359467 Validation Loss: 0.02818567119538784\n",
      "4247 Training Loss: 0.021999919787049294 Validation Loss: 0.028409311547875404\n",
      "4248 Training Loss: 0.02252202481031418 Validation Loss: 0.028516117483377457\n",
      "4249 Training Loss: 0.022144682705402374 Validation Loss: 0.028579218313097954\n",
      "4250 Training Loss: 0.0213337279856205 Validation Loss: 0.028706692159175873\n",
      "4251 Training Loss: 0.026812423020601273 Validation Loss: 0.02858961932361126\n",
      "4252 Training Loss: 0.020494764670729637 Validation Loss: 0.028387296944856644\n",
      "4253 Training Loss: 0.02150430716574192 Validation Loss: 0.028194837272167206\n",
      "4254 Training Loss: 0.025150272995233536 Validation Loss: 0.027893291786313057\n",
      "4255 Training Loss: 0.018754728138446808 Validation Loss: 0.02780190110206604\n",
      "4256 Training Loss: 0.019763601943850517 Validation Loss: 0.027853703126311302\n",
      "4257 Training Loss: 0.020838340744376183 Validation Loss: 0.027949126437306404\n",
      "4258 Training Loss: 0.02744187042117119 Validation Loss: 0.027920261025428772\n",
      "4259 Training Loss: 0.01746036298573017 Validation Loss: 0.028048263862729073\n",
      "4260 Training Loss: 0.024393387138843536 Validation Loss: 0.028079461306333542\n",
      "4261 Training Loss: 0.024567611515522003 Validation Loss: 0.028048895299434662\n",
      "4262 Training Loss: 0.02103792503476143 Validation Loss: 0.028024327009916306\n",
      "4263 Training Loss: 0.020576467737555504 Validation Loss: 0.02800440788269043\n",
      "4264 Training Loss: 0.020614374428987503 Validation Loss: 0.02804652974009514\n",
      "4265 Training Loss: 0.019339989870786667 Validation Loss: 0.02812880091369152\n",
      "4266 Training Loss: 0.020404836162924767 Validation Loss: 0.028244853019714355\n",
      "4267 Training Loss: 0.018579786643385887 Validation Loss: 0.02843840792775154\n",
      "4268 Training Loss: 0.0246049202978611 Validation Loss: 0.028434231877326965\n",
      "4269 Training Loss: 0.020224599167704582 Validation Loss: 0.028451327234506607\n",
      "4270 Training Loss: 0.031209399923682213 Validation Loss: 0.027994027361273766\n",
      "4271 Training Loss: 0.019417736679315567 Validation Loss: 0.027686867862939835\n",
      "4272 Training Loss: 0.02309352532029152 Validation Loss: 0.027415277436375618\n",
      "4273 Training Loss: 0.02690078318119049 Validation Loss: 0.027104126289486885\n",
      "4274 Training Loss: 0.02222989872097969 Validation Loss: 0.026934899389743805\n",
      "4275 Training Loss: 0.023376230150461197 Validation Loss: 0.026871655136346817\n",
      "4276 Training Loss: 0.03197186067700386 Validation Loss: 0.026874858886003494\n",
      "4277 Training Loss: 0.018222251906991005 Validation Loss: 0.027010291814804077\n",
      "4278 Training Loss: 0.026063986122608185 Validation Loss: 0.02715970389544964\n",
      "4279 Training Loss: 0.019594954326748848 Validation Loss: 0.027220143005251884\n",
      "4280 Training Loss: 0.021672353148460388 Validation Loss: 0.02712065540254116\n",
      "4281 Training Loss: 0.022955860942602158 Validation Loss: 0.027168890461325645\n",
      "4282 Training Loss: 0.01875859498977661 Validation Loss: 0.02746235951781273\n",
      "4283 Training Loss: 0.01915663667023182 Validation Loss: 0.02797934040427208\n",
      "4284 Training Loss: 0.017917174845933914 Validation Loss: 0.02869034744799137\n",
      "4285 Training Loss: 0.019887080416083336 Validation Loss: 0.029429925605654716\n",
      "4286 Training Loss: 0.02023754082620144 Validation Loss: 0.030085735023021698\n",
      "4287 Training Loss: 0.01727616786956787 Validation Loss: 0.030598077923059464\n",
      "4288 Training Loss: 0.022349238395690918 Validation Loss: 0.030685128644108772\n",
      "4289 Training Loss: 0.01868770271539688 Validation Loss: 0.030431851744651794\n",
      "4290 Training Loss: 0.02271629311144352 Validation Loss: 0.029639849439263344\n",
      "4291 Training Loss: 0.025710351765155792 Validation Loss: 0.028534281998872757\n",
      "4292 Training Loss: 0.029027577489614487 Validation Loss: 0.027350053191184998\n",
      "4293 Training Loss: 0.02721291035413742 Validation Loss: 0.02640843763947487\n",
      "4294 Training Loss: 0.02055511251091957 Validation Loss: 0.025865275412797928\n",
      "4295 Training Loss: 0.018297312781214714 Validation Loss: 0.02560994029045105\n",
      "4296 Training Loss: 0.02036627195775509 Validation Loss: 0.02552958019077778\n",
      "4297 Training Loss: 0.019827231764793396 Validation Loss: 0.025613825768232346\n",
      "4298 Training Loss: 0.022986581549048424 Validation Loss: 0.025799209251999855\n",
      "4299 Training Loss: 0.02519453875720501 Validation Loss: 0.025952722877264023\n",
      "4300 Training Loss: 0.022511105984449387 Validation Loss: 0.026136938482522964\n",
      "4301 Training Loss: 0.02500445395708084 Validation Loss: 0.026318993419408798\n",
      "4302 Training Loss: 0.017326397821307182 Validation Loss: 0.02664448879659176\n",
      "4303 Training Loss: 0.018051765859127045 Validation Loss: 0.02707420289516449\n",
      "4304 Training Loss: 0.019844084978103638 Validation Loss: 0.027644233778119087\n",
      "4305 Training Loss: 0.02164505049586296 Validation Loss: 0.028237974271178246\n",
      "4306 Training Loss: 0.020078616216778755 Validation Loss: 0.02875460311770439\n",
      "4307 Training Loss: 0.02472083270549774 Validation Loss: 0.028942061588168144\n",
      "4308 Training Loss: 0.016442980617284775 Validation Loss: 0.02897285297513008\n",
      "4309 Training Loss: 0.018340589478611946 Validation Loss: 0.02896762080490589\n",
      "4310 Training Loss: 0.019049083814024925 Validation Loss: 0.028817079961299896\n",
      "4311 Training Loss: 0.019388535991311073 Validation Loss: 0.028452396392822266\n",
      "4312 Training Loss: 0.02173529751598835 Validation Loss: 0.027881942689418793\n",
      "4313 Training Loss: 0.01671341247856617 Validation Loss: 0.027468321844935417\n",
      "4314 Training Loss: 0.022616581991314888 Validation Loss: 0.026914753019809723\n",
      "4315 Training Loss: 0.029644593596458435 Validation Loss: 0.026143118739128113\n",
      "4316 Training Loss: 0.02277085930109024 Validation Loss: 0.02547302469611168\n",
      "4317 Training Loss: 0.02048080414533615 Validation Loss: 0.025137128308415413\n",
      "4318 Training Loss: 0.025946829468011856 Validation Loss: 0.025008609518408775\n",
      "4319 Training Loss: 0.023961320519447327 Validation Loss: 0.02515590377151966\n",
      "4320 Training Loss: 0.0185007955878973 Validation Loss: 0.02542686089873314\n",
      "4321 Training Loss: 0.025934604927897453 Validation Loss: 0.025704657658934593\n",
      "4322 Training Loss: 0.02169562131166458 Validation Loss: 0.025893524289131165\n",
      "4323 Training Loss: 0.020683113485574722 Validation Loss: 0.026043256744742393\n",
      "4324 Training Loss: 0.018442858010530472 Validation Loss: 0.02617812156677246\n",
      "4325 Training Loss: 0.020092179998755455 Validation Loss: 0.026442160829901695\n",
      "4326 Training Loss: 0.022998366504907608 Validation Loss: 0.026811616495251656\n",
      "4327 Training Loss: 0.017938578501343727 Validation Loss: 0.02741512656211853\n",
      "4328 Training Loss: 0.019399218261241913 Validation Loss: 0.028054097667336464\n",
      "4329 Training Loss: 0.018570132553577423 Validation Loss: 0.02853887341916561\n",
      "4330 Training Loss: 0.017440641298890114 Validation Loss: 0.028810961171984673\n",
      "4331 Training Loss: 0.029999587684869766 Validation Loss: 0.02812994085252285\n",
      "4332 Training Loss: 0.023259762674570084 Validation Loss: 0.027250230312347412\n",
      "4333 Training Loss: 0.016880299896001816 Validation Loss: 0.02662660926580429\n",
      "4334 Training Loss: 0.02195349708199501 Validation Loss: 0.02611326240003109\n",
      "4335 Training Loss: 0.03890225663781166 Validation Loss: 0.02544526383280754\n",
      "4336 Training Loss: 0.02619423344731331 Validation Loss: 0.025003405287861824\n",
      "4337 Training Loss: 0.021865995600819588 Validation Loss: 0.024812936782836914\n",
      "4338 Training Loss: 0.019895382225513458 Validation Loss: 0.024724697694182396\n",
      "4339 Training Loss: 0.019668633118271828 Validation Loss: 0.024607833474874496\n",
      "4340 Training Loss: 0.019100815057754517 Validation Loss: 0.02453836053609848\n",
      "4341 Training Loss: 0.01932225190103054 Validation Loss: 0.024461720138788223\n",
      "4342 Training Loss: 0.019620008766651154 Validation Loss: 0.024579323828220367\n",
      "4343 Training Loss: 0.01889156550168991 Validation Loss: 0.025031544268131256\n",
      "4344 Training Loss: 0.02404942736029625 Validation Loss: 0.025598568841814995\n",
      "4345 Training Loss: 0.021057087928056717 Validation Loss: 0.026063954457640648\n",
      "4346 Training Loss: 0.021214019507169724 Validation Loss: 0.02636277861893177\n",
      "4347 Training Loss: 0.0262596495449543 Validation Loss: 0.0263464767485857\n",
      "4348 Training Loss: 0.020246729254722595 Validation Loss: 0.026265621185302734\n",
      "4349 Training Loss: 0.020679427310824394 Validation Loss: 0.026083489879965782\n",
      "4350 Training Loss: 0.01847435161471367 Validation Loss: 0.0259353369474411\n",
      "4351 Training Loss: 0.02155310846865177 Validation Loss: 0.025686481967568398\n",
      "4352 Training Loss: 0.01739264652132988 Validation Loss: 0.02552611008286476\n",
      "4353 Training Loss: 0.02242662012577057 Validation Loss: 0.025296898558735847\n",
      "4354 Training Loss: 0.02524789422750473 Validation Loss: 0.024949287995696068\n",
      "4355 Training Loss: 0.021607842296361923 Validation Loss: 0.024622872471809387\n",
      "4356 Training Loss: 0.017833778634667397 Validation Loss: 0.02441033162176609\n",
      "4357 Training Loss: 0.022895997390151024 Validation Loss: 0.02423829771578312\n",
      "4358 Training Loss: 0.01997947506606579 Validation Loss: 0.02416859194636345\n",
      "4359 Training Loss: 0.016841290518641472 Validation Loss: 0.024300798773765564\n",
      "4360 Training Loss: 0.0186702162027359 Validation Loss: 0.02451213076710701\n",
      "4361 Training Loss: 0.020378731191158295 Validation Loss: 0.024746788665652275\n",
      "4362 Training Loss: 0.018039491027593613 Validation Loss: 0.02501080557703972\n",
      "4363 Training Loss: 0.019340412691235542 Validation Loss: 0.02508707344532013\n",
      "4364 Training Loss: 0.016289932653307915 Validation Loss: 0.025282185524702072\n",
      "4365 Training Loss: 0.01602606289088726 Validation Loss: 0.025572216138243675\n",
      "4366 Training Loss: 0.021367818117141724 Validation Loss: 0.025564592331647873\n",
      "4367 Training Loss: 0.021393103525042534 Validation Loss: 0.025417806580662727\n",
      "4368 Training Loss: 0.016249412670731544 Validation Loss: 0.025413600727915764\n",
      "4369 Training Loss: 0.01675255596637726 Validation Loss: 0.025492973625659943\n",
      "4370 Training Loss: 0.016089919954538345 Validation Loss: 0.025598807260394096\n",
      "4371 Training Loss: 0.02102039009332657 Validation Loss: 0.025539323687553406\n",
      "4372 Training Loss: 0.020669611170887947 Validation Loss: 0.025431513786315918\n",
      "4373 Training Loss: 0.016368187963962555 Validation Loss: 0.025398869067430496\n",
      "4374 Training Loss: 0.02410222589969635 Validation Loss: 0.025127273052930832\n",
      "4375 Training Loss: 0.017771277576684952 Validation Loss: 0.024913467466831207\n",
      "4376 Training Loss: 0.02362222969532013 Validation Loss: 0.024614442139863968\n",
      "4377 Training Loss: 0.019580889493227005 Validation Loss: 0.02437683381140232\n",
      "4378 Training Loss: 0.016704803332686424 Validation Loss: 0.024291623383760452\n",
      "4379 Training Loss: 0.01726449280977249 Validation Loss: 0.024357018992304802\n",
      "4380 Training Loss: 0.02391105145215988 Validation Loss: 0.024292822927236557\n",
      "4381 Training Loss: 0.015913568437099457 Validation Loss: 0.02439420111477375\n",
      "4382 Training Loss: 0.02208414301276207 Validation Loss: 0.02445104904472828\n",
      "4383 Training Loss: 0.01744517683982849 Validation Loss: 0.02455182559788227\n",
      "4384 Training Loss: 0.016580915078520775 Validation Loss: 0.024695539847016335\n",
      "4385 Training Loss: 0.016840670257806778 Validation Loss: 0.0249171145260334\n",
      "4386 Training Loss: 0.020977988839149475 Validation Loss: 0.02498503029346466\n",
      "4387 Training Loss: 0.016550248488783836 Validation Loss: 0.025058019906282425\n",
      "4388 Training Loss: 0.02110169269144535 Validation Loss: 0.024907782673835754\n",
      "4389 Training Loss: 0.018263766542077065 Validation Loss: 0.02474793791770935\n",
      "4390 Training Loss: 0.01605215296149254 Validation Loss: 0.024725541472434998\n",
      "4391 Training Loss: 0.021999448537826538 Validation Loss: 0.024517472833395004\n",
      "4392 Training Loss: 0.018503937870264053 Validation Loss: 0.024390332400798798\n",
      "4393 Training Loss: 0.01677590422332287 Validation Loss: 0.024349678307771683\n",
      "4394 Training Loss: 0.0154630858451128 Validation Loss: 0.024453289806842804\n",
      "4395 Training Loss: 0.02536018192768097 Validation Loss: 0.02434181049466133\n",
      "4396 Training Loss: 0.016164405271410942 Validation Loss: 0.024335676804184914\n",
      "4397 Training Loss: 0.01769927330315113 Validation Loss: 0.024377573281526566\n",
      "4398 Training Loss: 0.019319966435432434 Validation Loss: 0.024357909336686134\n",
      "4399 Training Loss: 0.02798953652381897 Validation Loss: 0.024088077247142792\n",
      "4400 Training Loss: 0.021706346422433853 Validation Loss: 0.023836130276322365\n",
      "4401 Training Loss: 0.015700269490480423 Validation Loss: 0.023769376799464226\n",
      "4402 Training Loss: 0.02137121930718422 Validation Loss: 0.02374572679400444\n",
      "4403 Training Loss: 0.02153696119785309 Validation Loss: 0.023739643394947052\n",
      "4404 Training Loss: 0.016893431544303894 Validation Loss: 0.023755613714456558\n",
      "4405 Training Loss: 0.01634020358324051 Validation Loss: 0.02384667657315731\n",
      "4406 Training Loss: 0.019062809646129608 Validation Loss: 0.02397114410996437\n",
      "4407 Training Loss: 0.021909039467573166 Validation Loss: 0.02406509593129158\n",
      "4408 Training Loss: 0.022274520248174667 Validation Loss: 0.024110522121191025\n",
      "4409 Training Loss: 0.020399734377861023 Validation Loss: 0.024181460961699486\n",
      "4410 Training Loss: 0.016674796119332314 Validation Loss: 0.024303346872329712\n",
      "4411 Training Loss: 0.02642328292131424 Validation Loss: 0.024039089679718018\n",
      "4412 Training Loss: 0.015455772168934345 Validation Loss: 0.0238630510866642\n",
      "4413 Training Loss: 0.020308293402194977 Validation Loss: 0.023663116618990898\n",
      "4414 Training Loss: 0.016744030639529228 Validation Loss: 0.02356429398059845\n",
      "4415 Training Loss: 0.017094381153583527 Validation Loss: 0.023523107171058655\n",
      "4416 Training Loss: 0.021469028666615486 Validation Loss: 0.0234041977673769\n",
      "4417 Training Loss: 0.01814591884613037 Validation Loss: 0.023326445370912552\n",
      "4418 Training Loss: 0.020391400903463364 Validation Loss: 0.023186760023236275\n",
      "4419 Training Loss: 0.016965501010417938 Validation Loss: 0.023177463561296463\n",
      "4420 Training Loss: 0.01748439110815525 Validation Loss: 0.02323274314403534\n",
      "4421 Training Loss: 0.015292547643184662 Validation Loss: 0.02338888682425022\n",
      "4422 Training Loss: 0.020004713907837868 Validation Loss: 0.023509208112955093\n",
      "4423 Training Loss: 0.01737964153289795 Validation Loss: 0.023669734597206116\n",
      "4424 Training Loss: 0.01955851912498474 Validation Loss: 0.023821000009775162\n",
      "4425 Training Loss: 0.017670854926109314 Validation Loss: 0.023916523903608322\n",
      "4426 Training Loss: 0.022576097398996353 Validation Loss: 0.023757528513669968\n",
      "4427 Training Loss: 0.015902625396847725 Validation Loss: 0.0236650463193655\n",
      "4428 Training Loss: 0.020388655364513397 Validation Loss: 0.023370182141661644\n",
      "4429 Training Loss: 0.01716982200741768 Validation Loss: 0.023159701377153397\n",
      "4430 Training Loss: 0.016013875603675842 Validation Loss: 0.02304537035524845\n",
      "4431 Training Loss: 0.021433575078845024 Validation Loss: 0.02295103669166565\n",
      "4432 Training Loss: 0.015557876788079739 Validation Loss: 0.02300466224551201\n",
      "4433 Training Loss: 0.017124226316809654 Validation Loss: 0.023115241900086403\n",
      "4434 Training Loss: 0.01730586215853691 Validation Loss: 0.023284005001187325\n",
      "4435 Training Loss: 0.021023284643888474 Validation Loss: 0.023397138342261314\n",
      "4436 Training Loss: 0.01894625648856163 Validation Loss: 0.023466363549232483\n",
      "4437 Training Loss: 0.016327640041708946 Validation Loss: 0.023583391681313515\n",
      "4438 Training Loss: 0.02489265613257885 Validation Loss: 0.02354937605559826\n",
      "4439 Training Loss: 0.020339181646704674 Validation Loss: 0.023437967523932457\n",
      "4440 Training Loss: 0.018657516688108444 Validation Loss: 0.023323921486735344\n",
      "4441 Training Loss: 0.015302514657378197 Validation Loss: 0.023357022553682327\n",
      "4442 Training Loss: 0.017932984977960587 Validation Loss: 0.023377954959869385\n",
      "4443 Training Loss: 0.01845579780638218 Validation Loss: 0.023313205689191818\n",
      "4444 Training Loss: 0.02474638819694519 Validation Loss: 0.02292117290198803\n",
      "4445 Training Loss: 0.020923631265759468 Validation Loss: 0.022526318207383156\n",
      "4446 Training Loss: 0.017847545444965363 Validation Loss: 0.02222541533410549\n",
      "4447 Training Loss: 0.01879657432436943 Validation Loss: 0.02207261696457863\n",
      "4448 Training Loss: 0.016827678307890892 Validation Loss: 0.022060751914978027\n",
      "4449 Training Loss: 0.017776969820261 Validation Loss: 0.022090917453169823\n",
      "4450 Training Loss: 0.015783777460455894 Validation Loss: 0.022244436666369438\n",
      "4451 Training Loss: 0.023824768140912056 Validation Loss: 0.0223089586943388\n",
      "4452 Training Loss: 0.022080708295106888 Validation Loss: 0.022317254915833473\n",
      "4453 Training Loss: 0.020287180319428444 Validation Loss: 0.022358741611242294\n",
      "4454 Training Loss: 0.02250940352678299 Validation Loss: 0.022262590005993843\n",
      "4455 Training Loss: 0.016843238845467567 Validation Loss: 0.02223045565187931\n",
      "4456 Training Loss: 0.015233663842082024 Validation Loss: 0.02231074683368206\n",
      "4457 Training Loss: 0.016378702595829964 Validation Loss: 0.02243405394256115\n",
      "4458 Training Loss: 0.018165690824389458 Validation Loss: 0.022549927234649658\n",
      "4459 Training Loss: 0.01827593520283699 Validation Loss: 0.022607995197176933\n",
      "4460 Training Loss: 0.03109755739569664 Validation Loss: 0.022289779037237167\n",
      "4461 Training Loss: 0.026841137558221817 Validation Loss: 0.021900320425629616\n",
      "4462 Training Loss: 0.018265195190906525 Validation Loss: 0.021705089136958122\n",
      "4463 Training Loss: 0.02367587387561798 Validation Loss: 0.02165401726961136\n",
      "4464 Training Loss: 0.01877273991703987 Validation Loss: 0.021773280575871468\n",
      "4465 Training Loss: 0.01759796403348446 Validation Loss: 0.02183379977941513\n",
      "4466 Training Loss: 0.017617296427488327 Validation Loss: 0.021815160289406776\n",
      "4467 Training Loss: 0.017512472346425056 Validation Loss: 0.02176487259566784\n",
      "4468 Training Loss: 0.019617633894085884 Validation Loss: 0.021804960444569588\n",
      "4469 Training Loss: 0.01905781775712967 Validation Loss: 0.021928152069449425\n",
      "4470 Training Loss: 0.02040715515613556 Validation Loss: 0.02207622490823269\n",
      "4471 Training Loss: 0.017561348155140877 Validation Loss: 0.02225644141435623\n",
      "4472 Training Loss: 0.02116425335407257 Validation Loss: 0.022335603833198547\n",
      "4473 Training Loss: 0.015318121761083603 Validation Loss: 0.022457165643572807\n",
      "4474 Training Loss: 0.017495151609182358 Validation Loss: 0.022552916780114174\n",
      "4475 Training Loss: 0.019005682319402695 Validation Loss: 0.02253473736345768\n",
      "4476 Training Loss: 0.01831723004579544 Validation Loss: 0.022364038974046707\n",
      "4477 Training Loss: 0.016604335978627205 Validation Loss: 0.022184235975146294\n",
      "4478 Training Loss: 0.017563244327902794 Validation Loss: 0.021936466917395592\n",
      "4479 Training Loss: 0.023365452885627747 Validation Loss: 0.021570425480604172\n",
      "4480 Training Loss: 0.016648488119244576 Validation Loss: 0.021319208666682243\n",
      "4481 Training Loss: 0.015880785882472992 Validation Loss: 0.02118811383843422\n",
      "4482 Training Loss: 0.023193413391709328 Validation Loss: 0.021040331572294235\n",
      "4483 Training Loss: 0.017212999984622 Validation Loss: 0.020964059978723526\n",
      "4484 Training Loss: 0.015620524995028973 Validation Loss: 0.020972907543182373\n",
      "4485 Training Loss: 0.020012009888887405 Validation Loss: 0.020984021946787834\n",
      "4486 Training Loss: 0.016886988654732704 Validation Loss: 0.0210558008402586\n",
      "4487 Training Loss: 0.015930067747831345 Validation Loss: 0.021231580525636673\n",
      "4488 Training Loss: 0.015986673533916473 Validation Loss: 0.02149057760834694\n",
      "4489 Training Loss: 0.018026959151029587 Validation Loss: 0.021720845252275467\n",
      "4490 Training Loss: 0.015546467155218124 Validation Loss: 0.02198081836104393\n",
      "4491 Training Loss: 0.01823994889855385 Validation Loss: 0.022174350917339325\n",
      "4492 Training Loss: 0.016042090952396393 Validation Loss: 0.0223199762403965\n",
      "4493 Training Loss: 0.016315020620822906 Validation Loss: 0.022337626665830612\n",
      "4494 Training Loss: 0.017819853499531746 Validation Loss: 0.022199958562850952\n",
      "4495 Training Loss: 0.01484357938170433 Validation Loss: 0.022100277245044708\n",
      "4496 Training Loss: 0.01637214981019497 Validation Loss: 0.021963277831673622\n",
      "4497 Training Loss: 0.01553216204047203 Validation Loss: 0.021813295781612396\n",
      "4498 Training Loss: 0.014946367591619492 Validation Loss: 0.021731674671173096\n",
      "4499 Training Loss: 0.017728395760059357 Validation Loss: 0.02162628062069416\n",
      "4500 Training Loss: 0.015576479956507683 Validation Loss: 0.021580033004283905\n",
      "4501 Training Loss: 0.016303636133670807 Validation Loss: 0.02157948538661003\n",
      "4502 Training Loss: 0.01571374200284481 Validation Loss: 0.021627403795719147\n",
      "4503 Training Loss: 0.02357250079512596 Validation Loss: 0.021522214636206627\n",
      "4504 Training Loss: 0.018735026940703392 Validation Loss: 0.021386899054050446\n",
      "4505 Training Loss: 0.013714696280658245 Validation Loss: 0.021350450813770294\n",
      "4506 Training Loss: 0.014568150043487549 Validation Loss: 0.02139286696910858\n",
      "4507 Training Loss: 0.02410554513335228 Validation Loss: 0.021238839253783226\n",
      "4508 Training Loss: 0.020320981740951538 Validation Loss: 0.021044395864009857\n",
      "4509 Training Loss: 0.015794601291418076 Validation Loss: 0.0209515281021595\n",
      "4510 Training Loss: 0.0190056674182415 Validation Loss: 0.02086440846323967\n",
      "4511 Training Loss: 0.017336104065179825 Validation Loss: 0.020855113863945007\n",
      "4512 Training Loss: 0.01432100124657154 Validation Loss: 0.02095312625169754\n",
      "4513 Training Loss: 0.014245644211769104 Validation Loss: 0.021113399416208267\n",
      "4514 Training Loss: 0.016761258244514465 Validation Loss: 0.02124318853020668\n",
      "4515 Training Loss: 0.020048609003424644 Validation Loss: 0.02133794128894806\n",
      "4516 Training Loss: 0.013994485139846802 Validation Loss: 0.021540239453315735\n",
      "4517 Training Loss: 0.024688564240932465 Validation Loss: 0.02149995043873787\n",
      "4518 Training Loss: 0.021084479987621307 Validation Loss: 0.021387727931141853\n",
      "4519 Training Loss: 0.017953330650925636 Validation Loss: 0.02124728634953499\n",
      "4520 Training Loss: 0.014366395771503448 Validation Loss: 0.021178439259529114\n",
      "4521 Training Loss: 0.01794961839914322 Validation Loss: 0.021112289279699326\n",
      "4522 Training Loss: 0.015507618896663189 Validation Loss: 0.02108306810259819\n",
      "4523 Training Loss: 0.01664745807647705 Validation Loss: 0.02101856842637062\n",
      "4524 Training Loss: 0.017788898199796677 Validation Loss: 0.020921967923641205\n",
      "4525 Training Loss: 0.018493156880140305 Validation Loss: 0.02083023637533188\n",
      "4526 Training Loss: 0.017966408282518387 Validation Loss: 0.02073645405471325\n",
      "4527 Training Loss: 0.022373996675014496 Validation Loss: 0.020521318539977074\n",
      "4528 Training Loss: 0.01553087867796421 Validation Loss: 0.02037131041288376\n",
      "4529 Training Loss: 0.02127801440656185 Validation Loss: 0.02017490193247795\n",
      "4530 Training Loss: 0.02253834158182144 Validation Loss: 0.019991587847471237\n",
      "4531 Training Loss: 0.016796397045254707 Validation Loss: 0.019935492426156998\n",
      "4532 Training Loss: 0.0181407667696476 Validation Loss: 0.019932201132178307\n",
      "4533 Training Loss: 0.021167054772377014 Validation Loss: 0.020009635016322136\n",
      "4534 Training Loss: 0.015397373586893082 Validation Loss: 0.020115703344345093\n",
      "4535 Training Loss: 0.01622799225151539 Validation Loss: 0.020185943692922592\n",
      "4536 Training Loss: 0.0170779749751091 Validation Loss: 0.02025866135954857\n",
      "4537 Training Loss: 0.018057743087410927 Validation Loss: 0.020381201058626175\n",
      "4538 Training Loss: 0.015136264264583588 Validation Loss: 0.020557142794132233\n",
      "4539 Training Loss: 0.015255942940711975 Validation Loss: 0.02080739103257656\n",
      "4540 Training Loss: 0.017441529780626297 Validation Loss: 0.021046696230769157\n",
      "4541 Training Loss: 0.013772773556411266 Validation Loss: 0.021307818591594696\n",
      "4542 Training Loss: 0.014469004236161709 Validation Loss: 0.021524200215935707\n",
      "4543 Training Loss: 0.017281901091337204 Validation Loss: 0.021571939811110497\n",
      "4544 Training Loss: 0.013499006628990173 Validation Loss: 0.021596016362309456\n",
      "4545 Training Loss: 0.02179070934653282 Validation Loss: 0.021328791975975037\n",
      "4546 Training Loss: 0.013887518085539341 Validation Loss: 0.021105678752064705\n",
      "4547 Training Loss: 0.017605412751436234 Validation Loss: 0.020785417407751083\n",
      "4548 Training Loss: 0.016847869381308556 Validation Loss: 0.020467940717935562\n",
      "4549 Training Loss: 0.014089607633650303 Validation Loss: 0.020231669768691063\n",
      "4550 Training Loss: 0.018384374678134918 Validation Loss: 0.01998307555913925\n",
      "4551 Training Loss: 0.01955857127904892 Validation Loss: 0.01977209374308586\n",
      "4552 Training Loss: 0.01627206988632679 Validation Loss: 0.01964295655488968\n",
      "4553 Training Loss: 0.018950827419757843 Validation Loss: 0.019530657678842545\n",
      "4554 Training Loss: 0.019273800775408745 Validation Loss: 0.019415119662880898\n",
      "4555 Training Loss: 0.014994745142757893 Validation Loss: 0.019373418763279915\n",
      "4556 Training Loss: 0.01892160251736641 Validation Loss: 0.01937173679471016\n",
      "4557 Training Loss: 0.020650655031204224 Validation Loss: 0.019373998045921326\n",
      "4558 Training Loss: 0.019244879484176636 Validation Loss: 0.019397690892219543\n",
      "4559 Training Loss: 0.017701830714941025 Validation Loss: 0.019455524161458015\n",
      "4560 Training Loss: 0.017754966393113136 Validation Loss: 0.01950007677078247\n",
      "4561 Training Loss: 0.01618845947086811 Validation Loss: 0.01959574967622757\n",
      "4562 Training Loss: 0.016455359756946564 Validation Loss: 0.019731463864445686\n",
      "4563 Training Loss: 0.015393612906336784 Validation Loss: 0.019909154623746872\n",
      "4564 Training Loss: 0.017042269930243492 Validation Loss: 0.020079683512449265\n",
      "4565 Training Loss: 0.014779454097151756 Validation Loss: 0.020280474796891212\n",
      "4566 Training Loss: 0.014260467141866684 Validation Loss: 0.020497387275099754\n",
      "4567 Training Loss: 0.015281980857253075 Validation Loss: 0.020689696073532104\n",
      "4568 Training Loss: 0.018497468903660774 Validation Loss: 0.02075929380953312\n",
      "4569 Training Loss: 0.01737474650144577 Validation Loss: 0.020670419558882713\n",
      "4570 Training Loss: 0.018031684681773186 Validation Loss: 0.02047002501785755\n",
      "4571 Training Loss: 0.01948408968746662 Validation Loss: 0.02008204720914364\n",
      "4572 Training Loss: 0.01789787784218788 Validation Loss: 0.019612938165664673\n",
      "4573 Training Loss: 0.014126542955636978 Validation Loss: 0.019303321838378906\n",
      "4574 Training Loss: 0.021276813000440598 Validation Loss: 0.018935099244117737\n",
      "4575 Training Loss: 0.015224631875753403 Validation Loss: 0.01874074526131153\n",
      "4576 Training Loss: 0.015870897099375725 Validation Loss: 0.018638847395777702\n",
      "4577 Training Loss: 0.024705592542886734 Validation Loss: 0.01852882094681263\n",
      "4578 Training Loss: 0.015368933789432049 Validation Loss: 0.018543023616075516\n",
      "4579 Training Loss: 0.014752673916518688 Validation Loss: 0.018632328137755394\n",
      "4580 Training Loss: 0.01799086108803749 Validation Loss: 0.018723882734775543\n",
      "4581 Training Loss: 0.013955552130937576 Validation Loss: 0.018906600773334503\n",
      "4582 Training Loss: 0.01975381001830101 Validation Loss: 0.019080089405179024\n",
      "4583 Training Loss: 0.022782327607274055 Validation Loss: 0.01917041651904583\n",
      "4584 Training Loss: 0.014008657075464725 Validation Loss: 0.019310113042593002\n",
      "4585 Training Loss: 0.018718838691711426 Validation Loss: 0.01940312422811985\n",
      "4586 Training Loss: 0.022946953773498535 Validation Loss: 0.01938995160162449\n",
      "4587 Training Loss: 0.01421781163662672 Validation Loss: 0.01939382404088974\n",
      "4588 Training Loss: 0.013700957410037518 Validation Loss: 0.019422778859734535\n",
      "4589 Training Loss: 0.016636788845062256 Validation Loss: 0.01938638463616371\n",
      "4590 Training Loss: 0.017929505556821823 Validation Loss: 0.019323568791151047\n",
      "4591 Training Loss: 0.018374772742390633 Validation Loss: 0.019214553758502007\n",
      "4592 Training Loss: 0.014871079474687576 Validation Loss: 0.01912141963839531\n",
      "4593 Training Loss: 0.013948101550340652 Validation Loss: 0.01908019371330738\n",
      "4594 Training Loss: 0.01328125037252903 Validation Loss: 0.019108345732092857\n",
      "4595 Training Loss: 0.013916483148932457 Validation Loss: 0.019229654222726822\n",
      "4596 Training Loss: 0.014037450775504112 Validation Loss: 0.019456787034869194\n",
      "4597 Training Loss: 0.03171887621283531 Validation Loss: 0.01905175670981407\n",
      "4598 Training Loss: 0.016562387347221375 Validation Loss: 0.018704362213611603\n",
      "4599 Training Loss: 0.01561733614653349 Validation Loss: 0.01849801279604435\n",
      "4600 Training Loss: 0.015932565554976463 Validation Loss: 0.018386978656053543\n",
      "4601 Training Loss: 0.02067112922668457 Validation Loss: 0.01835465058684349\n",
      "4602 Training Loss: 0.0138966990634799 Validation Loss: 0.018393727019429207\n",
      "4603 Training Loss: 0.014133300632238388 Validation Loss: 0.018508248031139374\n",
      "4604 Training Loss: 0.01739223301410675 Validation Loss: 0.018561553210020065\n",
      "4605 Training Loss: 0.020453743636608124 Validation Loss: 0.018617305904626846\n",
      "4606 Training Loss: 0.016188550740480423 Validation Loss: 0.018686050549149513\n",
      "4607 Training Loss: 0.016670698300004005 Validation Loss: 0.01874597929418087\n",
      "4608 Training Loss: 0.01494855061173439 Validation Loss: 0.01879890263080597\n",
      "4609 Training Loss: 0.01803307607769966 Validation Loss: 0.01888507418334484\n",
      "4610 Training Loss: 0.017149535939097404 Validation Loss: 0.01892556995153427\n",
      "4611 Training Loss: 0.018780509009957314 Validation Loss: 0.018900249153375626\n",
      "4612 Training Loss: 0.01437118649482727 Validation Loss: 0.018908977508544922\n",
      "4613 Training Loss: 0.014206202700734138 Validation Loss: 0.018923012539744377\n",
      "4614 Training Loss: 0.018873244524002075 Validation Loss: 0.018871476873755455\n",
      "4615 Training Loss: 0.01816731132566929 Validation Loss: 0.018787087872624397\n",
      "4616 Training Loss: 0.01619289070367813 Validation Loss: 0.018718529492616653\n",
      "4617 Training Loss: 0.016573794186115265 Validation Loss: 0.018649980425834656\n",
      "4618 Training Loss: 0.015185657888650894 Validation Loss: 0.018513746559619904\n",
      "4619 Training Loss: 0.01459814514964819 Validation Loss: 0.018406448885798454\n",
      "4620 Training Loss: 0.012738469056785107 Validation Loss: 0.018381034955382347\n",
      "4621 Training Loss: 0.01632138155400753 Validation Loss: 0.018381882458925247\n",
      "4622 Training Loss: 0.0161233339458704 Validation Loss: 0.0183816347271204\n",
      "4623 Training Loss: 0.015135303139686584 Validation Loss: 0.018416456878185272\n",
      "4624 Training Loss: 0.0163276344537735 Validation Loss: 0.01843060553073883\n",
      "4625 Training Loss: 0.013903580605983734 Validation Loss: 0.018458468839526176\n",
      "4626 Training Loss: 0.017909538000822067 Validation Loss: 0.01836170256137848\n",
      "4627 Training Loss: 0.013145305216312408 Validation Loss: 0.018315082415938377\n",
      "4628 Training Loss: 0.01500897016376257 Validation Loss: 0.01825447753071785\n",
      "4629 Training Loss: 0.012973051518201828 Validation Loss: 0.018264014273881912\n",
      "4630 Training Loss: 0.020888378843665123 Validation Loss: 0.01816568523645401\n",
      "4631 Training Loss: 0.016099197790026665 Validation Loss: 0.01813739724457264\n",
      "4632 Training Loss: 0.013041555881500244 Validation Loss: 0.018262263387441635\n",
      "4633 Training Loss: 0.013444348238408566 Validation Loss: 0.018419459462165833\n",
      "4634 Training Loss: 0.01631745882332325 Validation Loss: 0.01853875070810318\n",
      "4635 Training Loss: 0.023501373827457428 Validation Loss: 0.018597181886434555\n",
      "4636 Training Loss: 0.014952437952160835 Validation Loss: 0.018607979640364647\n",
      "4637 Training Loss: 0.016547761857509613 Validation Loss: 0.018581239506602287\n",
      "4638 Training Loss: 0.014416501857340336 Validation Loss: 0.018569165840744972\n",
      "4639 Training Loss: 0.013581184670329094 Validation Loss: 0.0186073686927557\n",
      "4640 Training Loss: 0.015112603083252907 Validation Loss: 0.01868274249136448\n",
      "4641 Training Loss: 0.015932340174913406 Validation Loss: 0.018777336925268173\n",
      "4642 Training Loss: 0.013191379606723785 Validation Loss: 0.01888284832239151\n",
      "4643 Training Loss: 0.013409227132797241 Validation Loss: 0.01898493617773056\n",
      "4644 Training Loss: 0.016500534489750862 Validation Loss: 0.019011937081813812\n",
      "4645 Training Loss: 0.012811534106731415 Validation Loss: 0.019043345004320145\n",
      "4646 Training Loss: 0.012554844841361046 Validation Loss: 0.019040308892726898\n",
      "4647 Training Loss: 0.013928483240306377 Validation Loss: 0.018944241106510162\n",
      "4648 Training Loss: 0.015376782044768333 Validation Loss: 0.018733792006969452\n",
      "4649 Training Loss: 0.012703237123787403 Validation Loss: 0.018561452627182007\n",
      "4650 Training Loss: 0.0200228001922369 Validation Loss: 0.018271319568157196\n",
      "4651 Training Loss: 0.01383133139461279 Validation Loss: 0.01804940029978752\n",
      "4652 Training Loss: 0.013507014140486717 Validation Loss: 0.017900653183460236\n",
      "4653 Training Loss: 0.014375371858477592 Validation Loss: 0.01779523864388466\n",
      "4654 Training Loss: 0.01603825017809868 Validation Loss: 0.01769924908876419\n",
      "4655 Training Loss: 0.01364765502512455 Validation Loss: 0.01766008883714676\n",
      "4656 Training Loss: 0.012073822319507599 Validation Loss: 0.017718035727739334\n",
      "4657 Training Loss: 0.014315132051706314 Validation Loss: 0.017811503261327744\n",
      "4658 Training Loss: 0.019513724371790886 Validation Loss: 0.017824560403823853\n",
      "4659 Training Loss: 0.012432597577571869 Validation Loss: 0.01792045868933201\n",
      "4660 Training Loss: 0.021479103714227676 Validation Loss: 0.017853902652859688\n",
      "4661 Training Loss: 0.0157395638525486 Validation Loss: 0.01776043325662613\n",
      "4662 Training Loss: 0.016091715544462204 Validation Loss: 0.017689282074570656\n",
      "4663 Training Loss: 0.015751250088214874 Validation Loss: 0.017619265243411064\n",
      "4664 Training Loss: 0.014086388051509857 Validation Loss: 0.01759391278028488\n",
      "4665 Training Loss: 0.014677969738841057 Validation Loss: 0.01759185642004013\n",
      "4666 Training Loss: 0.013768270611763 Validation Loss: 0.017620008438825607\n",
      "4667 Training Loss: 0.022463681176304817 Validation Loss: 0.017496837303042412\n",
      "4668 Training Loss: 0.012576874345541 Validation Loss: 0.017444128170609474\n",
      "4669 Training Loss: 0.014309563674032688 Validation Loss: 0.017426561564207077\n",
      "4670 Training Loss: 0.013510270044207573 Validation Loss: 0.017446406185626984\n",
      "4671 Training Loss: 0.014285857789218426 Validation Loss: 0.017490606755018234\n",
      "4672 Training Loss: 0.013180961832404137 Validation Loss: 0.017589878290891647\n",
      "4673 Training Loss: 0.018056537955999374 Validation Loss: 0.017657741904258728\n",
      "4674 Training Loss: 0.012796388939023018 Validation Loss: 0.01780485361814499\n",
      "4675 Training Loss: 0.0136201661080122 Validation Loss: 0.017925893887877464\n",
      "4676 Training Loss: 0.01583564467728138 Validation Loss: 0.017938626930117607\n",
      "4677 Training Loss: 0.016899321228265762 Validation Loss: 0.01779744401574135\n",
      "4678 Training Loss: 0.013198825530707836 Validation Loss: 0.017678622156381607\n",
      "4679 Training Loss: 0.016958286985754967 Validation Loss: 0.017486419528722763\n",
      "4680 Training Loss: 0.014078914187848568 Validation Loss: 0.01735001429915428\n",
      "4681 Training Loss: 0.012466908432543278 Validation Loss: 0.017287377268075943\n",
      "4682 Training Loss: 0.014989910647273064 Validation Loss: 0.0172346793115139\n",
      "4683 Training Loss: 0.018192484974861145 Validation Loss: 0.017166201025247574\n",
      "4684 Training Loss: 0.01878112182021141 Validation Loss: 0.017073363065719604\n",
      "4685 Training Loss: 0.014395583420991898 Validation Loss: 0.017034342512488365\n",
      "4686 Training Loss: 0.02072944864630699 Validation Loss: 0.017040245234966278\n",
      "4687 Training Loss: 0.017432138323783875 Validation Loss: 0.017038846388459206\n",
      "4688 Training Loss: 0.016370907425880432 Validation Loss: 0.01701303943991661\n",
      "4689 Training Loss: 0.012498734518885612 Validation Loss: 0.016972947865724564\n",
      "4690 Training Loss: 0.017480921000242233 Validation Loss: 0.016999203711748123\n",
      "4691 Training Loss: 0.016928520053625107 Validation Loss: 0.016993839293718338\n",
      "4692 Training Loss: 0.013627912849187851 Validation Loss: 0.016993924975395203\n",
      "4693 Training Loss: 0.013931989669799805 Validation Loss: 0.017051301896572113\n",
      "4694 Training Loss: 0.016381841152906418 Validation Loss: 0.01711929962038994\n",
      "4695 Training Loss: 0.013432552106678486 Validation Loss: 0.0172516331076622\n",
      "4696 Training Loss: 0.01872653141617775 Validation Loss: 0.017238717526197433\n",
      "4697 Training Loss: 0.013201069086790085 Validation Loss: 0.0172543004155159\n",
      "4698 Training Loss: 0.011944355443120003 Validation Loss: 0.017269490286707878\n",
      "4699 Training Loss: 0.022361263632774353 Validation Loss: 0.016984328627586365\n",
      "4700 Training Loss: 0.014190662652254105 Validation Loss: 0.016758987680077553\n",
      "4701 Training Loss: 0.015376993454992771 Validation Loss: 0.016612499952316284\n",
      "4702 Training Loss: 0.014179188758134842 Validation Loss: 0.016600143164396286\n",
      "4703 Training Loss: 0.014078030362725258 Validation Loss: 0.01665818691253662\n",
      "4704 Training Loss: 0.014479277655482292 Validation Loss: 0.016790688037872314\n",
      "4705 Training Loss: 0.013771587051451206 Validation Loss: 0.016999904066324234\n",
      "4706 Training Loss: 0.014204030856490135 Validation Loss: 0.01716882362961769\n",
      "4707 Training Loss: 0.013059701770544052 Validation Loss: 0.01729678362607956\n",
      "4708 Training Loss: 0.013371031731367111 Validation Loss: 0.01730542629957199\n",
      "4709 Training Loss: 0.013528045266866684 Validation Loss: 0.017382927238941193\n",
      "4710 Training Loss: 0.012512246146798134 Validation Loss: 0.01757745072245598\n",
      "4711 Training Loss: 0.01892532780766487 Validation Loss: 0.01762322708964348\n",
      "4712 Training Loss: 0.01138751395046711 Validation Loss: 0.01769583486020565\n",
      "4713 Training Loss: 0.017298908904194832 Validation Loss: 0.01752719096839428\n",
      "4714 Training Loss: 0.013605887070298195 Validation Loss: 0.0173101257532835\n",
      "4715 Training Loss: 0.012838462367653847 Validation Loss: 0.017101695761084557\n",
      "4716 Training Loss: 0.013807668350636959 Validation Loss: 0.016924530267715454\n",
      "4717 Training Loss: 0.01334054209291935 Validation Loss: 0.01678200252354145\n",
      "4718 Training Loss: 0.01327469665557146 Validation Loss: 0.01669136807322502\n",
      "4719 Training Loss: 0.01372748427093029 Validation Loss: 0.016612615436315536\n",
      "4720 Training Loss: 0.013136719353497028 Validation Loss: 0.016560418531298637\n",
      "4721 Training Loss: 0.015565593726933002 Validation Loss: 0.016509415581822395\n",
      "4722 Training Loss: 0.014344273135066032 Validation Loss: 0.016495760530233383\n",
      "4723 Training Loss: 0.01834113523364067 Validation Loss: 0.016448650509119034\n",
      "4724 Training Loss: 0.012292325496673584 Validation Loss: 0.01649177446961403\n",
      "4725 Training Loss: 0.01366752665489912 Validation Loss: 0.016543598845601082\n",
      "4726 Training Loss: 0.01621059700846672 Validation Loss: 0.016628362238407135\n",
      "4727 Training Loss: 0.013951660133898258 Validation Loss: 0.016770144924521446\n",
      "4728 Training Loss: 0.018143296241760254 Validation Loss: 0.016914455220103264\n",
      "4729 Training Loss: 0.013052742928266525 Validation Loss: 0.017052872106432915\n",
      "4730 Training Loss: 0.012675239704549313 Validation Loss: 0.017119675874710083\n",
      "4731 Training Loss: 0.015069631859660149 Validation Loss: 0.017135465517640114\n",
      "4732 Training Loss: 0.015469305217266083 Validation Loss: 0.017106743529438972\n",
      "4733 Training Loss: 0.012133113108575344 Validation Loss: 0.017046790570020676\n",
      "4734 Training Loss: 0.017645426094532013 Validation Loss: 0.01690835691988468\n",
      "4735 Training Loss: 0.014856508001685143 Validation Loss: 0.01674431562423706\n",
      "4736 Training Loss: 0.013395101763308048 Validation Loss: 0.01664203405380249\n",
      "4737 Training Loss: 0.013614112511277199 Validation Loss: 0.01652923971414566\n",
      "4738 Training Loss: 0.01377858780324459 Validation Loss: 0.016391979530453682\n",
      "4739 Training Loss: 0.012428021058440208 Validation Loss: 0.016303561627864838\n",
      "4740 Training Loss: 0.013879543170332909 Validation Loss: 0.01620503142476082\n",
      "4741 Training Loss: 0.011999406851828098 Validation Loss: 0.016169490292668343\n",
      "4742 Training Loss: 0.01364822592586279 Validation Loss: 0.01614549569785595\n",
      "4743 Training Loss: 0.011908021755516529 Validation Loss: 0.016162388026714325\n",
      "4744 Training Loss: 0.01507592760026455 Validation Loss: 0.016150716692209244\n",
      "4745 Training Loss: 0.011500691063702106 Validation Loss: 0.01620175503194332\n",
      "4746 Training Loss: 0.011779583990573883 Validation Loss: 0.01628580316901207\n",
      "4747 Training Loss: 0.011879641562700272 Validation Loss: 0.01641278713941574\n",
      "4748 Training Loss: 0.011966770514845848 Validation Loss: 0.01655692607164383\n",
      "4749 Training Loss: 0.014128400012850761 Validation Loss: 0.01663540117442608\n",
      "4750 Training Loss: 0.012560936622321606 Validation Loss: 0.016735011711716652\n",
      "4751 Training Loss: 0.017502523958683014 Validation Loss: 0.016624851152300835\n",
      "4752 Training Loss: 0.012443574145436287 Validation Loss: 0.01653389446437359\n",
      "4753 Training Loss: 0.011691378429532051 Validation Loss: 0.01646338403224945\n",
      "4754 Training Loss: 0.021668529137969017 Validation Loss: 0.016242513433098793\n",
      "4755 Training Loss: 0.0118648000061512 Validation Loss: 0.016145018860697746\n",
      "4756 Training Loss: 0.01817021146416664 Validation Loss: 0.01607954129576683\n",
      "4757 Training Loss: 0.011505598202347755 Validation Loss: 0.016108036041259766\n",
      "4758 Training Loss: 0.012396497651934624 Validation Loss: 0.016156572848558426\n",
      "4759 Training Loss: 0.013191374950110912 Validation Loss: 0.016187598928809166\n",
      "4760 Training Loss: 0.01142759807407856 Validation Loss: 0.016238339245319366\n",
      "4761 Training Loss: 0.012769846245646477 Validation Loss: 0.01630789041519165\n",
      "4762 Training Loss: 0.012280775234103203 Validation Loss: 0.01645943894982338\n",
      "4763 Training Loss: 0.016295375302433968 Validation Loss: 0.016566075384616852\n",
      "4764 Training Loss: 0.013192782178521156 Validation Loss: 0.016646072268486023\n",
      "4765 Training Loss: 0.021398130804300308 Validation Loss: 0.016388464719057083\n",
      "4766 Training Loss: 0.01239065732806921 Validation Loss: 0.01614985428750515\n",
      "4767 Training Loss: 0.013798072002828121 Validation Loss: 0.015911847352981567\n",
      "4768 Training Loss: 0.0169003177434206 Validation Loss: 0.015651386231184006\n",
      "4769 Training Loss: 0.01457175426185131 Validation Loss: 0.015506206080317497\n",
      "4770 Training Loss: 0.015163896605372429 Validation Loss: 0.015496611595153809\n",
      "4771 Training Loss: 0.01189340092241764 Validation Loss: 0.015602905303239822\n",
      "4772 Training Loss: 0.016239935532212257 Validation Loss: 0.01569281332194805\n",
      "4773 Training Loss: 0.013283644802868366 Validation Loss: 0.015851883217692375\n",
      "4774 Training Loss: 0.017704859375953674 Validation Loss: 0.016101937741041183\n",
      "4775 Training Loss: 0.012640205211937428 Validation Loss: 0.01622232049703598\n",
      "4776 Training Loss: 0.015562967397272587 Validation Loss: 0.016208067536354065\n",
      "4777 Training Loss: 0.016353778541088104 Validation Loss: 0.016255907714366913\n",
      "4778 Training Loss: 0.011405556462705135 Validation Loss: 0.016318393871188164\n",
      "4779 Training Loss: 0.014235693961381912 Validation Loss: 0.016397709026932716\n",
      "4780 Training Loss: 0.012464639730751514 Validation Loss: 0.0164799764752388\n",
      "4781 Training Loss: 0.012562323361635208 Validation Loss: 0.016529962420463562\n",
      "4782 Training Loss: 0.013774553313851357 Validation Loss: 0.016559721902012825\n",
      "4783 Training Loss: 0.013655941933393478 Validation Loss: 0.016526183113455772\n",
      "4784 Training Loss: 0.017704609781503677 Validation Loss: 0.016324717551469803\n",
      "4785 Training Loss: 0.013182243332266808 Validation Loss: 0.01608862727880478\n",
      "4786 Training Loss: 0.011223988607525826 Validation Loss: 0.015883829444646835\n",
      "4787 Training Loss: 0.017231322824954987 Validation Loss: 0.015596836805343628\n",
      "4788 Training Loss: 0.014139149338006973 Validation Loss: 0.015378127805888653\n",
      "4789 Training Loss: 0.013472964987158775 Validation Loss: 0.015242751687765121\n",
      "4790 Training Loss: 0.016505707055330276 Validation Loss: 0.015112774446606636\n",
      "4791 Training Loss: 0.01176019012928009 Validation Loss: 0.015037817880511284\n",
      "4792 Training Loss: 0.012255897745490074 Validation Loss: 0.015042287297546864\n",
      "4793 Training Loss: 0.011420752853155136 Validation Loss: 0.015081632882356644\n",
      "4794 Training Loss: 0.014497799798846245 Validation Loss: 0.01514024380594492\n",
      "4795 Training Loss: 0.011863000690937042 Validation Loss: 0.015266124159097672\n",
      "4796 Training Loss: 0.013987580314278603 Validation Loss: 0.015372010879218578\n",
      "4797 Training Loss: 0.015882806852459908 Validation Loss: 0.015429982915520668\n",
      "4798 Training Loss: 0.01156202144920826 Validation Loss: 0.015533148311078548\n",
      "4799 Training Loss: 0.01782330498099327 Validation Loss: 0.015529465861618519\n",
      "4800 Training Loss: 0.014046335592865944 Validation Loss: 0.015492143109440804\n",
      "4801 Training Loss: 0.011905120685696602 Validation Loss: 0.015445247292518616\n",
      "4802 Training Loss: 0.012639595195651054 Validation Loss: 0.015385661274194717\n",
      "4803 Training Loss: 0.01754174754023552 Validation Loss: 0.015236488543450832\n",
      "4804 Training Loss: 0.012267937883734703 Validation Loss: 0.015131738036870956\n",
      "4805 Training Loss: 0.011734586209058762 Validation Loss: 0.015066536143422127\n",
      "4806 Training Loss: 0.011631447821855545 Validation Loss: 0.015041322447359562\n",
      "4807 Training Loss: 0.01213855016976595 Validation Loss: 0.015055270865559578\n",
      "4808 Training Loss: 0.011510511860251427 Validation Loss: 0.015106302686035633\n",
      "4809 Training Loss: 0.013642758131027222 Validation Loss: 0.015188800171017647\n",
      "4810 Training Loss: 0.01147634070366621 Validation Loss: 0.015276916325092316\n",
      "4811 Training Loss: 0.011472273617982864 Validation Loss: 0.01541273295879364\n",
      "4812 Training Loss: 0.011270131915807724 Validation Loss: 0.015526299364864826\n",
      "4813 Training Loss: 0.012093332596123219 Validation Loss: 0.015630988404154778\n",
      "4814 Training Loss: 0.01192292757332325 Validation Loss: 0.01568751409649849\n",
      "4815 Training Loss: 0.01693672314286232 Validation Loss: 0.015637466683983803\n",
      "4816 Training Loss: 0.010775279253721237 Validation Loss: 0.015611585229635239\n",
      "4817 Training Loss: 0.013244515284895897 Validation Loss: 0.015538139268755913\n",
      "4818 Training Loss: 0.01474209688603878 Validation Loss: 0.0153783755376935\n",
      "4819 Training Loss: 0.01156815979629755 Validation Loss: 0.015239632688462734\n",
      "4820 Training Loss: 0.015131931751966476 Validation Loss: 0.015005959197878838\n",
      "4821 Training Loss: 0.011629641987383366 Validation Loss: 0.014809196814894676\n",
      "4822 Training Loss: 0.011555580422282219 Validation Loss: 0.014665965922176838\n",
      "4823 Training Loss: 0.010753407143056393 Validation Loss: 0.014613962732255459\n",
      "4824 Training Loss: 0.016113365069031715 Validation Loss: 0.014546537771821022\n",
      "4825 Training Loss: 0.011192526668310165 Validation Loss: 0.014554956927895546\n",
      "4826 Training Loss: 0.011332114227116108 Validation Loss: 0.014620708301663399\n",
      "4827 Training Loss: 0.019181514158844948 Validation Loss: 0.014653520658612251\n",
      "4828 Training Loss: 0.01498754695057869 Validation Loss: 0.014720847830176353\n",
      "4829 Training Loss: 0.01647873967885971 Validation Loss: 0.014822352677583694\n",
      "4830 Training Loss: 0.011495938524603844 Validation Loss: 0.014944525435566902\n",
      "4831 Training Loss: 0.011606145650148392 Validation Loss: 0.015015269629657269\n",
      "4832 Training Loss: 0.014258099719882011 Validation Loss: 0.015103133395314217\n",
      "4833 Training Loss: 0.011730171740055084 Validation Loss: 0.015174301341176033\n",
      "4834 Training Loss: 0.014538819901645184 Validation Loss: 0.015168148092925549\n",
      "4835 Training Loss: 0.01356842927634716 Validation Loss: 0.015113277360796928\n",
      "4836 Training Loss: 0.01307026855647564 Validation Loss: 0.015095876529812813\n",
      "4837 Training Loss: 0.015202797949314117 Validation Loss: 0.015038683079183102\n",
      "4838 Training Loss: 0.014277681708335876 Validation Loss: 0.014984375797212124\n",
      "4839 Training Loss: 0.010449182242155075 Validation Loss: 0.014974556863307953\n",
      "4840 Training Loss: 0.013716327026486397 Validation Loss: 0.014962264336645603\n",
      "4841 Training Loss: 0.013365808874368668 Validation Loss: 0.01486784778535366\n",
      "4842 Training Loss: 0.011048892512917519 Validation Loss: 0.014786112122237682\n",
      "4843 Training Loss: 0.01331409253180027 Validation Loss: 0.01475350372493267\n",
      "4844 Training Loss: 0.012574467808008194 Validation Loss: 0.01473202183842659\n",
      "4845 Training Loss: 0.011142809875309467 Validation Loss: 0.014743918552994728\n",
      "4846 Training Loss: 0.011325044557452202 Validation Loss: 0.014740952290594578\n",
      "4847 Training Loss: 0.016102317720651627 Validation Loss: 0.014722649939358234\n",
      "4848 Training Loss: 0.010904677212238312 Validation Loss: 0.014698120765388012\n",
      "4849 Training Loss: 0.010341068729758263 Validation Loss: 0.014685665257275105\n",
      "4850 Training Loss: 0.0113389752805233 Validation Loss: 0.014692180790007114\n",
      "4851 Training Loss: 0.010430538095533848 Validation Loss: 0.014749237336218357\n",
      "4852 Training Loss: 0.010371267795562744 Validation Loss: 0.014856766909360886\n",
      "4853 Training Loss: 0.009879596531391144 Validation Loss: 0.014983009546995163\n",
      "4854 Training Loss: 0.012602726928889751 Validation Loss: 0.015032955445349216\n",
      "4855 Training Loss: 0.014660045504570007 Validation Loss: 0.014950226061046124\n",
      "4856 Training Loss: 0.011009159497916698 Validation Loss: 0.014881007373332977\n",
      "4857 Training Loss: 0.011994106695055962 Validation Loss: 0.014812976121902466\n",
      "4858 Training Loss: 0.011860670521855354 Validation Loss: 0.014750618487596512\n",
      "4859 Training Loss: 0.011548593640327454 Validation Loss: 0.014719696715474129\n",
      "4860 Training Loss: 0.016442563384771347 Validation Loss: 0.014719041995704174\n",
      "4861 Training Loss: 0.01511797122657299 Validation Loss: 0.014739414677023888\n",
      "4862 Training Loss: 0.014059620909392834 Validation Loss: 0.014788803644478321\n",
      "4863 Training Loss: 0.012274806387722492 Validation Loss: 0.014798450283706188\n",
      "4864 Training Loss: 0.013830003328621387 Validation Loss: 0.014719972386956215\n",
      "4865 Training Loss: 0.012158683501183987 Validation Loss: 0.01457437127828598\n",
      "4866 Training Loss: 0.01458795927464962 Validation Loss: 0.0144385090097785\n",
      "4867 Training Loss: 0.014158623293042183 Validation Loss: 0.014385441318154335\n",
      "4868 Training Loss: 0.012374987825751305 Validation Loss: 0.014334579929709435\n",
      "4869 Training Loss: 0.013216335326433182 Validation Loss: 0.014346614480018616\n",
      "4870 Training Loss: 0.010354982689023018 Validation Loss: 0.014424671418964863\n",
      "4871 Training Loss: 0.011141584254801273 Validation Loss: 0.01454838365316391\n",
      "4872 Training Loss: 0.015612849034368992 Validation Loss: 0.014571506530046463\n",
      "4873 Training Loss: 0.01277364045381546 Validation Loss: 0.01449274830520153\n",
      "4874 Training Loss: 0.01301681250333786 Validation Loss: 0.01435032207518816\n",
      "4875 Training Loss: 0.012204517610371113 Validation Loss: 0.014152411371469498\n",
      "4876 Training Loss: 0.011419248767197132 Validation Loss: 0.014004763215780258\n",
      "4877 Training Loss: 0.011065387167036533 Validation Loss: 0.013926919549703598\n",
      "4878 Training Loss: 0.015340849757194519 Validation Loss: 0.013880040496587753\n",
      "4879 Training Loss: 0.01294436864554882 Validation Loss: 0.01394850853830576\n",
      "4880 Training Loss: 0.010793331079185009 Validation Loss: 0.014112444594502449\n",
      "4881 Training Loss: 0.01233145035803318 Validation Loss: 0.014246215112507343\n",
      "4882 Training Loss: 0.012012967839837074 Validation Loss: 0.014338279142975807\n",
      "4883 Training Loss: 0.015525372698903084 Validation Loss: 0.014349229633808136\n",
      "4884 Training Loss: 0.010513516142964363 Validation Loss: 0.014365117996931076\n",
      "4885 Training Loss: 0.009819138795137405 Validation Loss: 0.014425138011574745\n",
      "4886 Training Loss: 0.010412901639938354 Validation Loss: 0.014521105214953423\n",
      "4887 Training Loss: 0.012046977877616882 Validation Loss: 0.014633361250162125\n",
      "4888 Training Loss: 0.012415839359164238 Validation Loss: 0.014710214920341969\n",
      "4889 Training Loss: 0.011525996960699558 Validation Loss: 0.014701073057949543\n",
      "4890 Training Loss: 0.011391067877411842 Validation Loss: 0.014636836014688015\n",
      "4891 Training Loss: 0.013596368953585625 Validation Loss: 0.014469042420387268\n",
      "4892 Training Loss: 0.014541352167725563 Validation Loss: 0.014248842373490334\n",
      "4893 Training Loss: 0.011237036436796188 Validation Loss: 0.014056854881346226\n",
      "4894 Training Loss: 0.011692657135426998 Validation Loss: 0.013880565762519836\n",
      "4895 Training Loss: 0.010420255362987518 Validation Loss: 0.013755896128714085\n",
      "4896 Training Loss: 0.011750486679375172 Validation Loss: 0.013678508810698986\n",
      "4897 Training Loss: 0.010647278279066086 Validation Loss: 0.013644643127918243\n",
      "4898 Training Loss: 0.011056721210479736 Validation Loss: 0.013657931238412857\n",
      "4899 Training Loss: 0.01067330501973629 Validation Loss: 0.01371665857732296\n",
      "4900 Training Loss: 0.013006123714148998 Validation Loss: 0.013771716505289078\n",
      "4901 Training Loss: 0.014899594709277153 Validation Loss: 0.013777939602732658\n",
      "4902 Training Loss: 0.014696336351335049 Validation Loss: 0.013765520416200161\n",
      "4903 Training Loss: 0.010445624589920044 Validation Loss: 0.013761967420578003\n",
      "4904 Training Loss: 0.010578403249382973 Validation Loss: 0.013794931583106518\n",
      "4905 Training Loss: 0.011694242246448994 Validation Loss: 0.013838754035532475\n",
      "4906 Training Loss: 0.01189497672021389 Validation Loss: 0.013861050829291344\n",
      "4907 Training Loss: 0.010363910347223282 Validation Loss: 0.013902582228183746\n",
      "4908 Training Loss: 0.010839976370334625 Validation Loss: 0.01396715547889471\n",
      "4909 Training Loss: 0.010265233926475048 Validation Loss: 0.014057407155632973\n",
      "4910 Training Loss: 0.009921987541019917 Validation Loss: 0.014159349724650383\n",
      "4911 Training Loss: 0.010247612372040749 Validation Loss: 0.014265341684222221\n",
      "4912 Training Loss: 0.011135519482195377 Validation Loss: 0.014290963299572468\n",
      "4913 Training Loss: 0.010402990505099297 Validation Loss: 0.014263458549976349\n",
      "4914 Training Loss: 0.010029695928096771 Validation Loss: 0.0142147121950984\n",
      "4915 Training Loss: 0.010653836652636528 Validation Loss: 0.014146349392831326\n",
      "4916 Training Loss: 0.017129821702837944 Validation Loss: 0.013925667852163315\n",
      "4917 Training Loss: 0.011421260423958302 Validation Loss: 0.013827839866280556\n",
      "4918 Training Loss: 0.012573951855301857 Validation Loss: 0.013823860324919224\n",
      "4919 Training Loss: 0.012838125228881836 Validation Loss: 0.013879471458494663\n",
      "4920 Training Loss: 0.011590349487960339 Validation Loss: 0.013818442821502686\n",
      "4921 Training Loss: 0.012916350737214088 Validation Loss: 0.01366611011326313\n",
      "4922 Training Loss: 0.011541853658854961 Validation Loss: 0.013499761931598186\n",
      "4923 Training Loss: 0.0139335161074996 Validation Loss: 0.013400614261627197\n",
      "4924 Training Loss: 0.009932950139045715 Validation Loss: 0.013438352383673191\n",
      "4925 Training Loss: 0.012831198051571846 Validation Loss: 0.013512006029486656\n",
      "4926 Training Loss: 0.010043976828455925 Validation Loss: 0.013639397919178009\n",
      "4927 Training Loss: 0.018240738660097122 Validation Loss: 0.013581642881035805\n",
      "4928 Training Loss: 0.0094602657482028 Validation Loss: 0.013562405481934547\n",
      "4929 Training Loss: 0.010020683519542217 Validation Loss: 0.013561507686972618\n",
      "4930 Training Loss: 0.01075318269431591 Validation Loss: 0.01357623003423214\n",
      "4931 Training Loss: 0.010699955746531487 Validation Loss: 0.013596195727586746\n",
      "4932 Training Loss: 0.015468507073819637 Validation Loss: 0.013554716482758522\n",
      "4933 Training Loss: 0.010790618136525154 Validation Loss: 0.01351911947131157\n",
      "4934 Training Loss: 0.009583866223692894 Validation Loss: 0.013510642573237419\n",
      "4935 Training Loss: 0.012091808021068573 Validation Loss: 0.013471711426973343\n",
      "4936 Training Loss: 0.01056691724807024 Validation Loss: 0.013461880385875702\n",
      "4937 Training Loss: 0.01682601496577263 Validation Loss: 0.013351483270525932\n",
      "4938 Training Loss: 0.010948479175567627 Validation Loss: 0.013271195814013481\n",
      "4939 Training Loss: 0.010616586543619633 Validation Loss: 0.013223106972873211\n",
      "4940 Training Loss: 0.010383497923612595 Validation Loss: 0.013203626498579979\n",
      "4941 Training Loss: 0.014897086657583714 Validation Loss: 0.013143139891326427\n",
      "4942 Training Loss: 0.009770753793418407 Validation Loss: 0.01313856616616249\n",
      "4943 Training Loss: 0.013006661087274551 Validation Loss: 0.013144152238965034\n",
      "4944 Training Loss: 0.010121320374310017 Validation Loss: 0.013189003802835941\n",
      "4945 Training Loss: 0.009682736359536648 Validation Loss: 0.013272743672132492\n",
      "4946 Training Loss: 0.01779901422560215 Validation Loss: 0.013261844404041767\n",
      "4947 Training Loss: 0.009648397564888 Validation Loss: 0.013291151262819767\n",
      "4948 Training Loss: 0.009840329177677631 Validation Loss: 0.013312515802681446\n",
      "4949 Training Loss: 0.011296208016574383 Validation Loss: 0.013319307006895542\n",
      "4950 Training Loss: 0.014814925380051136 Validation Loss: 0.01327936165034771\n",
      "4951 Training Loss: 0.010906508192420006 Validation Loss: 0.013242684304714203\n",
      "4952 Training Loss: 0.011442534625530243 Validation Loss: 0.013227544724941254\n",
      "4953 Training Loss: 0.014008346945047379 Validation Loss: 0.013185262680053711\n",
      "4954 Training Loss: 0.01087027695029974 Validation Loss: 0.013160992413759232\n",
      "4955 Training Loss: 0.009449523873627186 Validation Loss: 0.013170544989407063\n",
      "4956 Training Loss: 0.014539629220962524 Validation Loss: 0.013161159120500088\n",
      "4957 Training Loss: 0.010910389944911003 Validation Loss: 0.013126610778272152\n",
      "4958 Training Loss: 0.010992582887411118 Validation Loss: 0.013109292834997177\n",
      "4959 Training Loss: 0.010333986021578312 Validation Loss: 0.013123438693583012\n",
      "4960 Training Loss: 0.011217333376407623 Validation Loss: 0.013134857639670372\n",
      "4961 Training Loss: 0.010954719968140125 Validation Loss: 0.01313315611332655\n",
      "4962 Training Loss: 0.012078414671123028 Validation Loss: 0.013079886324703693\n",
      "4963 Training Loss: 0.01227166224271059 Validation Loss: 0.012999942526221275\n",
      "4964 Training Loss: 0.01040757354348898 Validation Loss: 0.012960290536284447\n",
      "4965 Training Loss: 0.011132162064313889 Validation Loss: 0.012957745231688023\n",
      "4966 Training Loss: 0.010492849163711071 Validation Loss: 0.012982863001525402\n",
      "4967 Training Loss: 0.00923041719943285 Validation Loss: 0.013062742538750172\n",
      "4968 Training Loss: 0.009559781290590763 Validation Loss: 0.01314790453761816\n",
      "4969 Training Loss: 0.009877600707113743 Validation Loss: 0.013239436782896519\n",
      "4970 Training Loss: 0.010264499112963676 Validation Loss: 0.013323002494871616\n",
      "4971 Training Loss: 0.010225268080830574 Validation Loss: 0.013425336219370365\n",
      "4972 Training Loss: 0.0114351911470294 Validation Loss: 0.013463146984577179\n",
      "4973 Training Loss: 0.010981984436511993 Validation Loss: 0.013425376266241074\n",
      "4974 Training Loss: 0.009546320885419846 Validation Loss: 0.01338451448827982\n",
      "4975 Training Loss: 0.011394643224775791 Validation Loss: 0.013292128220200539\n",
      "4976 Training Loss: 0.013168491423130035 Validation Loss: 0.013132035732269287\n",
      "4977 Training Loss: 0.01135720033198595 Validation Loss: 0.012973131611943245\n",
      "4978 Training Loss: 0.01182052493095398 Validation Loss: 0.012842035852372646\n",
      "4979 Training Loss: 0.012326350435614586 Validation Loss: 0.012723619118332863\n",
      "4980 Training Loss: 0.014186243526637554 Validation Loss: 0.012604087591171265\n",
      "4981 Training Loss: 0.009546265006065369 Validation Loss: 0.012546490877866745\n",
      "4982 Training Loss: 0.010378575883805752 Validation Loss: 0.012524183839559555\n",
      "4983 Training Loss: 0.010990278795361519 Validation Loss: 0.01254984550178051\n",
      "4984 Training Loss: 0.01081937924027443 Validation Loss: 0.012608436867594719\n",
      "4985 Training Loss: 0.010156456381082535 Validation Loss: 0.012677732855081558\n",
      "4986 Training Loss: 0.011041401885449886 Validation Loss: 0.012785043567419052\n",
      "4987 Training Loss: 0.01916007697582245 Validation Loss: 0.012782806530594826\n",
      "4988 Training Loss: 0.011734455823898315 Validation Loss: 0.012781034223735332\n",
      "4989 Training Loss: 0.011870363727211952 Validation Loss: 0.012755884788930416\n",
      "4990 Training Loss: 0.009648720733821392 Validation Loss: 0.012767819687724113\n",
      "4991 Training Loss: 0.01008701790124178 Validation Loss: 0.01276757474988699\n",
      "4992 Training Loss: 0.011659225448966026 Validation Loss: 0.012766923755407333\n",
      "4993 Training Loss: 0.011425098404288292 Validation Loss: 0.012767622247338295\n",
      "4994 Training Loss: 0.01228404138237238 Validation Loss: 0.01272623986005783\n",
      "4995 Training Loss: 0.010244930163025856 Validation Loss: 0.01267944648861885\n",
      "4996 Training Loss: 0.014227701351046562 Validation Loss: 0.012601448222994804\n",
      "4997 Training Loss: 0.012190134264528751 Validation Loss: 0.012515758164227009\n",
      "4998 Training Loss: 0.012529172003269196 Validation Loss: 0.012400160543620586\n",
      "4999 Training Loss: 0.009416349232196808 Validation Loss: 0.012336395680904388\n",
      "5000 Training Loss: 0.01151169091463089 Validation Loss: 0.012278812937438488\n",
      "5001 Training Loss: 0.009590883739292622 Validation Loss: 0.012262561358511448\n",
      "5002 Training Loss: 0.009232605807483196 Validation Loss: 0.012287614867091179\n",
      "5003 Training Loss: 0.015867605805397034 Validation Loss: 0.012233374640345573\n",
      "5004 Training Loss: 0.013412706553936005 Validation Loss: 0.012185067869722843\n",
      "5005 Training Loss: 0.010239144787192345 Validation Loss: 0.012186309322714806\n",
      "5006 Training Loss: 0.009937692433595657 Validation Loss: 0.012210401706397533\n",
      "5007 Training Loss: 0.0101110078394413 Validation Loss: 0.012258272618055344\n",
      "5008 Training Loss: 0.009291775524616241 Validation Loss: 0.012333218939602375\n",
      "5009 Training Loss: 0.009887549094855785 Validation Loss: 0.012449333444237709\n",
      "5010 Training Loss: 0.01092558167874813 Validation Loss: 0.012536577880382538\n",
      "5011 Training Loss: 0.011670378968119621 Validation Loss: 0.012587646022439003\n",
      "5012 Training Loss: 0.00864773616194725 Validation Loss: 0.012660354375839233\n",
      "5013 Training Loss: 0.009458609856665134 Validation Loss: 0.01273703295737505\n",
      "5014 Training Loss: 0.0099625363945961 Validation Loss: 0.012794997543096542\n",
      "5015 Training Loss: 0.010246653109788895 Validation Loss: 0.012810962274670601\n",
      "5016 Training Loss: 0.01330846268683672 Validation Loss: 0.012712137773633003\n",
      "5017 Training Loss: 0.014538781717419624 Validation Loss: 0.012539701536297798\n",
      "5018 Training Loss: 0.011793700978159904 Validation Loss: 0.012428004294633865\n",
      "5019 Training Loss: 0.01634194515645504 Validation Loss: 0.012388632632791996\n",
      "5020 Training Loss: 0.009338494390249252 Validation Loss: 0.01237945444881916\n",
      "5021 Training Loss: 0.009478981606662273 Validation Loss: 0.012364097870886326\n",
      "5022 Training Loss: 0.011771893128752708 Validation Loss: 0.012313893996179104\n",
      "5023 Training Loss: 0.009927041828632355 Validation Loss: 0.01223513763397932\n",
      "5024 Training Loss: 0.009545753709971905 Validation Loss: 0.0122030358761549\n",
      "5025 Training Loss: 0.00860724225640297 Validation Loss: 0.012271136045455933\n",
      "5026 Training Loss: 0.01635037548840046 Validation Loss: 0.012322768568992615\n",
      "5027 Training Loss: 0.010818038135766983 Validation Loss: 0.012393317185342312\n",
      "5028 Training Loss: 0.00936109758913517 Validation Loss: 0.012499218806624413\n",
      "5029 Training Loss: 0.010907070711255074 Validation Loss: 0.01257572416216135\n",
      "5030 Training Loss: 0.009205693379044533 Validation Loss: 0.012637379579246044\n",
      "5031 Training Loss: 0.010463234968483448 Validation Loss: 0.012609083205461502\n",
      "5032 Training Loss: 0.0111119095236063 Validation Loss: 0.012504490092396736\n",
      "5033 Training Loss: 0.010421786457300186 Validation Loss: 0.012369245290756226\n",
      "5034 Training Loss: 0.009642115794122219 Validation Loss: 0.012251610867679119\n",
      "5035 Training Loss: 0.008845173753798008 Validation Loss: 0.01218408439308405\n",
      "5036 Training Loss: 0.01017263624817133 Validation Loss: 0.01213907916098833\n",
      "5037 Training Loss: 0.013309020549058914 Validation Loss: 0.012086890637874603\n",
      "5038 Training Loss: 0.011631797067821026 Validation Loss: 0.012097425758838654\n",
      "5039 Training Loss: 0.011675470508635044 Validation Loss: 0.012147381901741028\n",
      "5040 Training Loss: 0.013265982270240784 Validation Loss: 0.012207277119159698\n",
      "5041 Training Loss: 0.01068928837776184 Validation Loss: 0.01214788667857647\n",
      "5042 Training Loss: 0.011680045165121555 Validation Loss: 0.012093224562704563\n",
      "5043 Training Loss: 0.011216609738767147 Validation Loss: 0.012002823874354362\n",
      "5044 Training Loss: 0.010646695271134377 Validation Loss: 0.011952601373195648\n",
      "5045 Training Loss: 0.01162597443908453 Validation Loss: 0.011967121623456478\n",
      "5046 Training Loss: 0.009844970889389515 Validation Loss: 0.01200045458972454\n",
      "5047 Training Loss: 0.011392410844564438 Validation Loss: 0.01203908771276474\n",
      "5048 Training Loss: 0.01057284977287054 Validation Loss: 0.012056468054652214\n",
      "5049 Training Loss: 0.010358947329223156 Validation Loss: 0.012056191451847553\n",
      "5050 Training Loss: 0.009300198405981064 Validation Loss: 0.012066330760717392\n",
      "5051 Training Loss: 0.009081186726689339 Validation Loss: 0.012089185416698456\n",
      "5052 Training Loss: 0.010664494708180428 Validation Loss: 0.012074155732989311\n",
      "5053 Training Loss: 0.009400919079780579 Validation Loss: 0.012055853381752968\n",
      "5054 Training Loss: 0.008776242844760418 Validation Loss: 0.012043911963701248\n",
      "5055 Training Loss: 0.011473971419036388 Validation Loss: 0.012009801343083382\n",
      "5056 Training Loss: 0.010242961347103119 Validation Loss: 0.012003450654447079\n",
      "5057 Training Loss: 0.01288145873695612 Validation Loss: 0.01201605424284935\n",
      "5058 Training Loss: 0.009266185574233532 Validation Loss: 0.012059376575052738\n",
      "5059 Training Loss: 0.012398078106343746 Validation Loss: 0.012111123651266098\n",
      "5060 Training Loss: 0.012541993521153927 Validation Loss: 0.01212669350206852\n",
      "5061 Training Loss: 0.01077724527567625 Validation Loss: 0.012182824313640594\n",
      "5062 Training Loss: 0.010191024281084538 Validation Loss: 0.012257464230060577\n",
      "5063 Training Loss: 0.012006079778075218 Validation Loss: 0.012227341532707214\n",
      "5064 Training Loss: 0.009506353177130222 Validation Loss: 0.012214655056595802\n",
      "5065 Training Loss: 0.010533755645155907 Validation Loss: 0.01212201826274395\n",
      "5066 Training Loss: 0.010971631854772568 Validation Loss: 0.012081540189683437\n",
      "5067 Training Loss: 0.008785906247794628 Validation Loss: 0.012057173997163773\n",
      "5068 Training Loss: 0.01184086687862873 Validation Loss: 0.012034261599183083\n",
      "5069 Training Loss: 0.012078344821929932 Validation Loss: 0.012013360857963562\n",
      "5070 Training Loss: 0.011614704504609108 Validation Loss: 0.011948719620704651\n",
      "5071 Training Loss: 0.012771885842084885 Validation Loss: 0.011829294264316559\n",
      "5072 Training Loss: 0.009896987117826939 Validation Loss: 0.01170852780342102\n",
      "5073 Training Loss: 0.011729934252798557 Validation Loss: 0.011579475365579128\n",
      "5074 Training Loss: 0.009679813869297504 Validation Loss: 0.011483896523714066\n",
      "5075 Training Loss: 0.009053046815097332 Validation Loss: 0.011434566229581833\n",
      "5076 Training Loss: 0.008826681412756443 Validation Loss: 0.011427321471273899\n",
      "5077 Training Loss: 0.011176373809576035 Validation Loss: 0.011423710733652115\n",
      "5078 Training Loss: 0.010937626473605633 Validation Loss: 0.01141799334436655\n",
      "5079 Training Loss: 0.012369813397526741 Validation Loss: 0.011415820568799973\n",
      "5080 Training Loss: 0.011036131531000137 Validation Loss: 0.011451615951955318\n",
      "5081 Training Loss: 0.008858207613229752 Validation Loss: 0.011515354737639427\n",
      "5082 Training Loss: 0.009154165163636208 Validation Loss: 0.01156702358275652\n",
      "5083 Training Loss: 0.01028404850512743 Validation Loss: 0.011588730849325657\n",
      "5084 Training Loss: 0.011855237185955048 Validation Loss: 0.011550608091056347\n",
      "5085 Training Loss: 0.008876124396920204 Validation Loss: 0.011560475453734398\n",
      "5086 Training Loss: 0.010889753699302673 Validation Loss: 0.01155884563922882\n",
      "5087 Training Loss: 0.010065609589219093 Validation Loss: 0.011574682779610157\n",
      "5088 Training Loss: 0.012486029416322708 Validation Loss: 0.011528488248586655\n",
      "5089 Training Loss: 0.011054232716560364 Validation Loss: 0.011433382518589497\n",
      "5090 Training Loss: 0.013193486258387566 Validation Loss: 0.011320319026708603\n",
      "5091 Training Loss: 0.008849961683154106 Validation Loss: 0.01127416267991066\n",
      "5092 Training Loss: 0.009236852638423443 Validation Loss: 0.011261770501732826\n",
      "5093 Training Loss: 0.010336240753531456 Validation Loss: 0.011210642755031586\n",
      "5094 Training Loss: 0.009187638759613037 Validation Loss: 0.0111907459795475\n",
      "5095 Training Loss: 0.013921988196671009 Validation Loss: 0.011168358847498894\n",
      "5096 Training Loss: 0.008734548464417458 Validation Loss: 0.011189338751137257\n",
      "5097 Training Loss: 0.009862448088824749 Validation Loss: 0.011237937957048416\n",
      "5098 Training Loss: 0.010535438545048237 Validation Loss: 0.011272869072854519\n",
      "5099 Training Loss: 0.016189677640795708 Validation Loss: 0.011265900917351246\n",
      "5100 Training Loss: 0.009548969566822052 Validation Loss: 0.011270016431808472\n",
      "5101 Training Loss: 0.014025027863681316 Validation Loss: 0.011340104043483734\n",
      "5102 Training Loss: 0.015850171446800232 Validation Loss: 0.01147940382361412\n",
      "5103 Training Loss: 0.010676163248717785 Validation Loss: 0.011589836329221725\n",
      "5104 Training Loss: 0.009911330416798592 Validation Loss: 0.011552244424819946\n",
      "5105 Training Loss: 0.012173088267445564 Validation Loss: 0.011376632377505302\n",
      "5106 Training Loss: 0.009581489488482475 Validation Loss: 0.01122310757637024\n",
      "5107 Training Loss: 0.010364801622927189 Validation Loss: 0.011138028465211391\n",
      "5108 Training Loss: 0.008492108434438705 Validation Loss: 0.011146551929414272\n",
      "5109 Training Loss: 0.010344426147639751 Validation Loss: 0.011194463819265366\n",
      "5110 Training Loss: 0.011135676875710487 Validation Loss: 0.011225285939872265\n",
      "5111 Training Loss: 0.010402566753327847 Validation Loss: 0.011218921281397343\n",
      "5112 Training Loss: 0.01018957607448101 Validation Loss: 0.011175157502293587\n",
      "5113 Training Loss: 0.008840985596179962 Validation Loss: 0.011140312999486923\n",
      "5114 Training Loss: 0.013209940865635872 Validation Loss: 0.01107387337833643\n",
      "5115 Training Loss: 0.013086717575788498 Validation Loss: 0.011043353006243706\n",
      "5116 Training Loss: 0.008273891173303127 Validation Loss: 0.011121049523353577\n",
      "5117 Training Loss: 0.014199363999068737 Validation Loss: 0.011287275701761246\n",
      "5118 Training Loss: 0.00906355120241642 Validation Loss: 0.011436325497925282\n",
      "5119 Training Loss: 0.011553289368748665 Validation Loss: 0.011536004953086376\n",
      "5120 Training Loss: 0.009218559600412846 Validation Loss: 0.011542199179530144\n",
      "5121 Training Loss: 0.009074784815311432 Validation Loss: 0.01141980942338705\n",
      "5122 Training Loss: 0.012140885926783085 Validation Loss: 0.011376980692148209\n",
      "5123 Training Loss: 0.011194907128810883 Validation Loss: 0.011276942677795887\n",
      "5124 Training Loss: 0.014670083299279213 Validation Loss: 0.011180775240063667\n",
      "5125 Training Loss: 0.010006112977862358 Validation Loss: 0.011129241436719894\n",
      "5126 Training Loss: 0.01043571438640356 Validation Loss: 0.011094151996076107\n",
      "5127 Training Loss: 0.010472952388226986 Validation Loss: 0.011056391522288322\n",
      "5128 Training Loss: 0.009940529242157936 Validation Loss: 0.011045475490391254\n",
      "5129 Training Loss: 0.011365769430994987 Validation Loss: 0.011036684736609459\n",
      "5130 Training Loss: 0.008759453892707825 Validation Loss: 0.01107085682451725\n",
      "5131 Training Loss: 0.0094016557559371 Validation Loss: 0.011101920157670975\n",
      "5132 Training Loss: 0.010800890624523163 Validation Loss: 0.011151738464832306\n",
      "5133 Training Loss: 0.009536154568195343 Validation Loss: 0.011201435700058937\n",
      "5134 Training Loss: 0.010386110283434391 Validation Loss: 0.011272004805505276\n",
      "5135 Training Loss: 0.008914229460060596 Validation Loss: 0.01133313775062561\n",
      "5136 Training Loss: 0.008794411085546017 Validation Loss: 0.011390965431928635\n",
      "5137 Training Loss: 0.008107015863060951 Validation Loss: 0.011447615921497345\n",
      "5138 Training Loss: 0.010180378332734108 Validation Loss: 0.011431221850216389\n",
      "5139 Training Loss: 0.014835571870207787 Validation Loss: 0.011385014280676842\n",
      "5140 Training Loss: 0.0093144616112113 Validation Loss: 0.01128544844686985\n",
      "5141 Training Loss: 0.011662203818559647 Validation Loss: 0.011161619797348976\n",
      "5142 Training Loss: 0.008241133764386177 Validation Loss: 0.011061558499932289\n",
      "5143 Training Loss: 0.011746510863304138 Validation Loss: 0.010930197313427925\n",
      "5144 Training Loss: 0.008547620847821236 Validation Loss: 0.010844022035598755\n",
      "5145 Training Loss: 0.00885176844894886 Validation Loss: 0.010783014819025993\n",
      "5146 Training Loss: 0.013548295013606548 Validation Loss: 0.010717468336224556\n",
      "5147 Training Loss: 0.009717700071632862 Validation Loss: 0.010654408484697342\n",
      "5148 Training Loss: 0.010003667324781418 Validation Loss: 0.01062875334173441\n",
      "5149 Training Loss: 0.00964753981679678 Validation Loss: 0.010609561577439308\n",
      "5150 Training Loss: 0.010438930243253708 Validation Loss: 0.010584788396954536\n",
      "5151 Training Loss: 0.010053890757262707 Validation Loss: 0.010613523423671722\n",
      "5152 Training Loss: 0.011471308767795563 Validation Loss: 0.010650036856532097\n",
      "5153 Training Loss: 0.00878865085542202 Validation Loss: 0.010697592049837112\n",
      "5154 Training Loss: 0.008310898207128048 Validation Loss: 0.010773696005344391\n",
      "5155 Training Loss: 0.01002880185842514 Validation Loss: 0.010863821022212505\n",
      "5156 Training Loss: 0.00953982025384903 Validation Loss: 0.010894473642110825\n",
      "5157 Training Loss: 0.012461664155125618 Validation Loss: 0.010898604989051819\n",
      "5158 Training Loss: 0.009204029105603695 Validation Loss: 0.010954238474369049\n",
      "5159 Training Loss: 0.009844433516263962 Validation Loss: 0.011020135134458542\n",
      "5160 Training Loss: 0.012064531445503235 Validation Loss: 0.011123064905405045\n",
      "5161 Training Loss: 0.00924290157854557 Validation Loss: 0.011233762837946415\n",
      "5162 Training Loss: 0.010690564289689064 Validation Loss: 0.011312194168567657\n",
      "5163 Training Loss: 0.009853781200945377 Validation Loss: 0.011288516223430634\n",
      "5164 Training Loss: 0.009928625077009201 Validation Loss: 0.01108541525900364\n",
      "5165 Training Loss: 0.008667739108204842 Validation Loss: 0.0109185092151165\n",
      "5166 Training Loss: 0.012150566093623638 Validation Loss: 0.010829188860952854\n",
      "5167 Training Loss: 0.009274391457438469 Validation Loss: 0.010771289467811584\n",
      "5168 Training Loss: 0.010189445689320564 Validation Loss: 0.010639687068760395\n",
      "5169 Training Loss: 0.011351622641086578 Validation Loss: 0.010547922924160957\n",
      "5170 Training Loss: 0.010305125266313553 Validation Loss: 0.010468997061252594\n",
      "5171 Training Loss: 0.010036561638116837 Validation Loss: 0.010427089408040047\n",
      "5172 Training Loss: 0.01064934954047203 Validation Loss: 0.010396834462881088\n",
      "5173 Training Loss: 0.008679196238517761 Validation Loss: 0.010428755544126034\n",
      "5174 Training Loss: 0.010334816761314869 Validation Loss: 0.010555955581367016\n",
      "5175 Training Loss: 0.01049354299902916 Validation Loss: 0.010662414133548737\n",
      "5176 Training Loss: 0.008523358032107353 Validation Loss: 0.010746261104941368\n",
      "5177 Training Loss: 0.010743306949734688 Validation Loss: 0.010882366448640823\n",
      "5178 Training Loss: 0.008738094009459019 Validation Loss: 0.011034611612558365\n",
      "5179 Training Loss: 0.010259549133479595 Validation Loss: 0.01102727185934782\n",
      "5180 Training Loss: 0.011790238320827484 Validation Loss: 0.011048146523535252\n",
      "5181 Training Loss: 0.010669098235666752 Validation Loss: 0.011045455932617188\n",
      "5182 Training Loss: 0.010618424043059349 Validation Loss: 0.010986905544996262\n",
      "5183 Training Loss: 0.008168434724211693 Validation Loss: 0.010904386639595032\n",
      "5184 Training Loss: 0.00865904800593853 Validation Loss: 0.010883564129471779\n",
      "5185 Training Loss: 0.008811622858047485 Validation Loss: 0.010849622078239918\n",
      "5186 Training Loss: 0.01244942657649517 Validation Loss: 0.01074284128844738\n",
      "5187 Training Loss: 0.009929806925356388 Validation Loss: 0.010596833191812038\n",
      "5188 Training Loss: 0.010190654546022415 Validation Loss: 0.010428769513964653\n",
      "5189 Training Loss: 0.009293614886701107 Validation Loss: 0.010297750122845173\n",
      "5190 Training Loss: 0.008210347034037113 Validation Loss: 0.010216417722404003\n",
      "5191 Training Loss: 0.008436862379312515 Validation Loss: 0.010181363672018051\n",
      "5192 Training Loss: 0.008642101660370827 Validation Loss: 0.010168327949941158\n",
      "5193 Training Loss: 0.010855613276362419 Validation Loss: 0.010139084421098232\n",
      "5194 Training Loss: 0.011691588908433914 Validation Loss: 0.010101882740855217\n",
      "5195 Training Loss: 0.008296245709061623 Validation Loss: 0.0101143354550004\n",
      "5196 Training Loss: 0.010032976046204567 Validation Loss: 0.010141371749341488\n",
      "5197 Training Loss: 0.008951378986239433 Validation Loss: 0.010146182030439377\n",
      "5198 Training Loss: 0.008550208993256092 Validation Loss: 0.010169652290642262\n",
      "5199 Training Loss: 0.008932691067457199 Validation Loss: 0.01021498255431652\n",
      "5200 Training Loss: 0.00854874774813652 Validation Loss: 0.010260423645377159\n",
      "5201 Training Loss: 0.008401983417570591 Validation Loss: 0.01033057738095522\n",
      "5202 Training Loss: 0.009151497855782509 Validation Loss: 0.010369924828410149\n",
      "5203 Training Loss: 0.010897643864154816 Validation Loss: 0.01041533425450325\n",
      "5204 Training Loss: 0.00826283823698759 Validation Loss: 0.010445406660437584\n",
      "5205 Training Loss: 0.010528050363063812 Validation Loss: 0.010421690531075\n",
      "5206 Training Loss: 0.008346222341060638 Validation Loss: 0.010383011773228645\n",
      "5207 Training Loss: 0.009676232933998108 Validation Loss: 0.010309889912605286\n",
      "5208 Training Loss: 0.009366319514811039 Validation Loss: 0.010223455727100372\n",
      "5209 Training Loss: 0.00814039446413517 Validation Loss: 0.010167608968913555\n",
      "5210 Training Loss: 0.010188475251197815 Validation Loss: 0.010108745656907558\n",
      "5211 Training Loss: 0.00952458567917347 Validation Loss: 0.01008327305316925\n",
      "5212 Training Loss: 0.007989853620529175 Validation Loss: 0.010116169229149818\n",
      "5213 Training Loss: 0.00834596622735262 Validation Loss: 0.010215130634605885\n",
      "5214 Training Loss: 0.009636761620640755 Validation Loss: 0.010338053107261658\n",
      "5215 Training Loss: 0.008217920549213886 Validation Loss: 0.01051514595746994\n",
      "5216 Training Loss: 0.008136081509292126 Validation Loss: 0.010672102682292461\n",
      "5217 Training Loss: 0.010369625873863697 Validation Loss: 0.010807476937770844\n",
      "5218 Training Loss: 0.008534446358680725 Validation Loss: 0.010884459130465984\n",
      "5219 Training Loss: 0.00862181931734085 Validation Loss: 0.01086556538939476\n",
      "5220 Training Loss: 0.015345576219260693 Validation Loss: 0.010925371199846268\n",
      "5221 Training Loss: 0.009064934216439724 Validation Loss: 0.010826274752616882\n",
      "5222 Training Loss: 0.009306635707616806 Validation Loss: 0.010757985524833202\n",
      "5223 Training Loss: 0.009882399812340736 Validation Loss: 0.010583738796412945\n",
      "5224 Training Loss: 0.0074817766435444355 Validation Loss: 0.010471946559846401\n",
      "5225 Training Loss: 0.00854426808655262 Validation Loss: 0.010346736758947372\n",
      "5226 Training Loss: 0.008663726970553398 Validation Loss: 0.010191820561885834\n",
      "5227 Training Loss: 0.00879969447851181 Validation Loss: 0.010099632665514946\n",
      "5228 Training Loss: 0.007940673269331455 Validation Loss: 0.010070925578474998\n",
      "5229 Training Loss: 0.01115136593580246 Validation Loss: 0.010019351728260517\n",
      "5230 Training Loss: 0.008610468357801437 Validation Loss: 0.009951421990990639\n",
      "5231 Training Loss: 0.016716690734028816 Validation Loss: 0.009763172827661037\n",
      "5232 Training Loss: 0.008812262676656246 Validation Loss: 0.009745292365550995\n",
      "5233 Training Loss: 0.008608020842075348 Validation Loss: 0.009891614317893982\n",
      "5234 Training Loss: 0.008507460355758667 Validation Loss: 0.01015400793403387\n",
      "5235 Training Loss: 0.009222769178450108 Validation Loss: 0.010425370186567307\n",
      "5236 Training Loss: 0.01468638889491558 Validation Loss: 0.010657900013029575\n",
      "5237 Training Loss: 0.00851175282150507 Validation Loss: 0.01071676891297102\n",
      "5238 Training Loss: 0.01029404066503048 Validation Loss: 0.010679541155695915\n",
      "5239 Training Loss: 0.008598566986620426 Validation Loss: 0.01057465746998787\n",
      "5240 Training Loss: 0.010413557291030884 Validation Loss: 0.010478776879608631\n",
      "5241 Training Loss: 0.01235506497323513 Validation Loss: 0.010416303761303425\n",
      "5242 Training Loss: 0.008177084848284721 Validation Loss: 0.01033102534711361\n",
      "5243 Training Loss: 0.008936852216720581 Validation Loss: 0.010234144516289234\n",
      "5244 Training Loss: 0.007860440760850906 Validation Loss: 0.010161809623241425\n",
      "5245 Training Loss: 0.008822111412882805 Validation Loss: 0.010106497444212437\n",
      "5246 Training Loss: 0.008709926158189774 Validation Loss: 0.010044076479971409\n",
      "5247 Training Loss: 0.011279577389359474 Validation Loss: 0.009880244731903076\n",
      "5248 Training Loss: 0.009496040642261505 Validation Loss: 0.009714653715491295\n",
      "5249 Training Loss: 0.007972480729222298 Validation Loss: 0.00958290696144104\n",
      "5250 Training Loss: 0.007923982106149197 Validation Loss: 0.009493567980825901\n",
      "5251 Training Loss: 0.008591971360147 Validation Loss: 0.009426241740584373\n",
      "5252 Training Loss: 0.007701958529651165 Validation Loss: 0.009405525401234627\n",
      "5253 Training Loss: 0.011778079904615879 Validation Loss: 0.009367961436510086\n",
      "5254 Training Loss: 0.009619606658816338 Validation Loss: 0.0093755554407835\n",
      "5255 Training Loss: 0.011669671162962914 Validation Loss: 0.009441917762160301\n",
      "5256 Training Loss: 0.010256022214889526 Validation Loss: 0.00961090624332428\n",
      "5257 Training Loss: 0.008411189541220665 Validation Loss: 0.009722010232508183\n",
      "5258 Training Loss: 0.009861025027930737 Validation Loss: 0.009761844761669636\n",
      "5259 Training Loss: 0.007924194447696209 Validation Loss: 0.009771425276994705\n",
      "5260 Training Loss: 0.008077878504991531 Validation Loss: 0.009775285609066486\n",
      "5261 Training Loss: 0.011074546724557877 Validation Loss: 0.009783487766981125\n",
      "5262 Training Loss: 0.014105426147580147 Validation Loss: 0.009730063378810883\n",
      "5263 Training Loss: 0.00802505761384964 Validation Loss: 0.009692620486021042\n",
      "5264 Training Loss: 0.00975218415260315 Validation Loss: 0.00964477751404047\n",
      "5265 Training Loss: 0.007908927276730537 Validation Loss: 0.009603656828403473\n",
      "5266 Training Loss: 0.007848761975765228 Validation Loss: 0.009576620534062386\n",
      "5267 Training Loss: 0.008859101682901382 Validation Loss: 0.00952671654522419\n",
      "5268 Training Loss: 0.012258819304406643 Validation Loss: 0.009431692771613598\n",
      "5269 Training Loss: 0.010949727147817612 Validation Loss: 0.009367149323225021\n",
      "5270 Training Loss: 0.008415737189352512 Validation Loss: 0.009356148540973663\n",
      "5271 Training Loss: 0.010374050587415695 Validation Loss: 0.00943051278591156\n",
      "5272 Training Loss: 0.007902308367192745 Validation Loss: 0.009528473019599915\n",
      "5273 Training Loss: 0.008328134194016457 Validation Loss: 0.009600416757166386\n",
      "5274 Training Loss: 0.00975651852786541 Validation Loss: 0.009642436169087887\n",
      "5275 Training Loss: 0.00932227075099945 Validation Loss: 0.009651510044932365\n",
      "5276 Training Loss: 0.0076513998210430145 Validation Loss: 0.009676650166511536\n",
      "5277 Training Loss: 0.011687682010233402 Validation Loss: 0.009763725101947784\n",
      "5278 Training Loss: 0.009256498888134956 Validation Loss: 0.009843269363045692\n",
      "5279 Training Loss: 0.010708596557378769 Validation Loss: 0.009840630926191807\n",
      "5280 Training Loss: 0.007139652967453003 Validation Loss: 0.009828728623688221\n",
      "5281 Training Loss: 0.009071916341781616 Validation Loss: 0.00978904590010643\n",
      "5282 Training Loss: 0.007395906839519739 Validation Loss: 0.009776752442121506\n",
      "5283 Training Loss: 0.007886738516390324 Validation Loss: 0.00977994967252016\n",
      "5284 Training Loss: 0.007537270430475473 Validation Loss: 0.009794048964977264\n",
      "5285 Training Loss: 0.0073810298927128315 Validation Loss: 0.009816929697990417\n",
      "5286 Training Loss: 0.009413378313183784 Validation Loss: 0.009766560047864914\n",
      "5287 Training Loss: 0.008046939969062805 Validation Loss: 0.009680457413196564\n",
      "5288 Training Loss: 0.0071250395849347115 Validation Loss: 0.009614883922040462\n",
      "5289 Training Loss: 0.011445151641964912 Validation Loss: 0.009575199335813522\n",
      "5290 Training Loss: 0.00811104103922844 Validation Loss: 0.009545162320137024\n",
      "5291 Training Loss: 0.01137414388358593 Validation Loss: 0.009494009427726269\n",
      "5292 Training Loss: 0.011851005256175995 Validation Loss: 0.0094671081751585\n",
      "5293 Training Loss: 0.012736164033412933 Validation Loss: 0.009539652615785599\n",
      "5294 Training Loss: 0.009337527677416801 Validation Loss: 0.009605979546904564\n",
      "5295 Training Loss: 0.008366801775991917 Validation Loss: 0.009592907503247261\n",
      "5296 Training Loss: 0.008093212731182575 Validation Loss: 0.00954680610448122\n",
      "5297 Training Loss: 0.008620798587799072 Validation Loss: 0.009424274787306786\n",
      "5298 Training Loss: 0.009033125825226307 Validation Loss: 0.009329423308372498\n",
      "5299 Training Loss: 0.007423929870128632 Validation Loss: 0.009357569739222527\n",
      "5300 Training Loss: 0.008249321021139622 Validation Loss: 0.009440615773200989\n",
      "5301 Training Loss: 0.008866976015269756 Validation Loss: 0.009526044130325317\n",
      "5302 Training Loss: 0.011020941659808159 Validation Loss: 0.009546373970806599\n",
      "5303 Training Loss: 0.007690075319260359 Validation Loss: 0.009543927386403084\n",
      "5304 Training Loss: 0.007324438542127609 Validation Loss: 0.009526634588837624\n",
      "5305 Training Loss: 0.01724107936024666 Validation Loss: 0.009490502998232841\n",
      "5306 Training Loss: 0.010295597836375237 Validation Loss: 0.009576331824064255\n",
      "5307 Training Loss: 0.007777740713208914 Validation Loss: 0.009733566083014011\n",
      "5308 Training Loss: 0.007948355749249458 Validation Loss: 0.009870174340903759\n",
      "5309 Training Loss: 0.008405856788158417 Validation Loss: 0.009980019181966782\n",
      "5310 Training Loss: 0.007991614751517773 Validation Loss: 0.010100255720317364\n",
      "5311 Training Loss: 0.008366284891963005 Validation Loss: 0.01014338992536068\n",
      "5312 Training Loss: 0.007711957208812237 Validation Loss: 0.010191562585532665\n",
      "5313 Training Loss: 0.007321109063923359 Validation Loss: 0.010219842195510864\n",
      "5314 Training Loss: 0.008320429362356663 Validation Loss: 0.010206768289208412\n",
      "5315 Training Loss: 0.006792924366891384 Validation Loss: 0.010234873741865158\n",
      "5316 Training Loss: 0.011138183996081352 Validation Loss: 0.010258648544549942\n",
      "5317 Training Loss: 0.009866749867796898 Validation Loss: 0.01021348312497139\n",
      "5318 Training Loss: 0.010270597413182259 Validation Loss: 0.010084890760481358\n",
      "5319 Training Loss: 0.007765987887978554 Validation Loss: 0.009920625016093254\n",
      "5320 Training Loss: 0.008927038870751858 Validation Loss: 0.009726428426802158\n",
      "5321 Training Loss: 0.011530553922057152 Validation Loss: 0.009473810903728008\n",
      "5322 Training Loss: 0.008922098204493523 Validation Loss: 0.009236153215169907\n",
      "5323 Training Loss: 0.008821917697787285 Validation Loss: 0.009048192761838436\n",
      "5324 Training Loss: 0.008224789053201675 Validation Loss: 0.008953003212809563\n",
      "5325 Training Loss: 0.007361371070146561 Validation Loss: 0.008888166397809982\n",
      "5326 Training Loss: 0.009809920564293861 Validation Loss: 0.008844932541251183\n",
      "5327 Training Loss: 0.008901924826204777 Validation Loss: 0.008834527805447578\n",
      "5328 Training Loss: 0.00735348928719759 Validation Loss: 0.008843050338327885\n",
      "5329 Training Loss: 0.007769085466861725 Validation Loss: 0.008869023062288761\n",
      "5330 Training Loss: 0.007367935497313738 Validation Loss: 0.008935685269534588\n",
      "5331 Training Loss: 0.007834728807210922 Validation Loss: 0.009011082351207733\n",
      "5332 Training Loss: 0.007820751518011093 Validation Loss: 0.009091932326555252\n",
      "5333 Training Loss: 0.008294455707073212 Validation Loss: 0.00919070653617382\n",
      "5334 Training Loss: 0.007817219011485577 Validation Loss: 0.009301949292421341\n",
      "5335 Training Loss: 0.008343243971467018 Validation Loss: 0.009390758350491524\n",
      "5336 Training Loss: 0.008034799247980118 Validation Loss: 0.009475832805037498\n",
      "5337 Training Loss: 0.00820133276283741 Validation Loss: 0.009557966142892838\n",
      "5338 Training Loss: 0.008890691213309765 Validation Loss: 0.009602578356862068\n",
      "5339 Training Loss: 0.007527767214924097 Validation Loss: 0.009568961337208748\n",
      "5340 Training Loss: 0.008964261040091515 Validation Loss: 0.009547161869704723\n",
      "5341 Training Loss: 0.00885014794766903 Validation Loss: 0.009498562663793564\n",
      "5342 Training Loss: 0.00789860263466835 Validation Loss: 0.00941369030624628\n",
      "5343 Training Loss: 0.01145627535879612 Validation Loss: 0.009359369054436684\n",
      "5344 Training Loss: 0.008946823887526989 Validation Loss: 0.009195540100336075\n",
      "5345 Training Loss: 0.007872060872614384 Validation Loss: 0.009067240171134472\n",
      "5346 Training Loss: 0.008027064613997936 Validation Loss: 0.00896760169416666\n",
      "5347 Training Loss: 0.007725870236754417 Validation Loss: 0.008902088738977909\n",
      "5348 Training Loss: 0.01029692031443119 Validation Loss: 0.008877929300069809\n",
      "5349 Training Loss: 0.00870505254715681 Validation Loss: 0.00886822771281004\n",
      "5350 Training Loss: 0.007056696340441704 Validation Loss: 0.008886931464076042\n",
      "5351 Training Loss: 0.007989424280822277 Validation Loss: 0.008917597122490406\n",
      "5352 Training Loss: 0.014148667454719543 Validation Loss: 0.008954550139605999\n",
      "5353 Training Loss: 0.008327065035700798 Validation Loss: 0.009043834172189236\n",
      "5354 Training Loss: 0.0071265194565057755 Validation Loss: 0.009202507324516773\n",
      "5355 Training Loss: 0.00831885077059269 Validation Loss: 0.009261850267648697\n",
      "5356 Training Loss: 0.011356113478541374 Validation Loss: 0.009358035400509834\n",
      "5357 Training Loss: 0.008998356759548187 Validation Loss: 0.009531340561807156\n",
      "5358 Training Loss: 0.007439783774316311 Validation Loss: 0.009642031975090504\n",
      "5359 Training Loss: 0.010711325332522392 Validation Loss: 0.009763287380337715\n",
      "5360 Training Loss: 0.009326117113232613 Validation Loss: 0.00993116945028305\n",
      "5361 Training Loss: 0.007090126164257526 Validation Loss: 0.009987344034016132\n",
      "5362 Training Loss: 0.008384402841329575 Validation Loss: 0.009954066015779972\n",
      "5363 Training Loss: 0.00759917963296175 Validation Loss: 0.009810646995902061\n",
      "5364 Training Loss: 0.007597357500344515 Validation Loss: 0.009661278687417507\n",
      "5365 Training Loss: 0.008523368276655674 Validation Loss: 0.009520470164716244\n",
      "5366 Training Loss: 0.008184531703591347 Validation Loss: 0.009370969608426094\n",
      "5367 Training Loss: 0.007272122427821159 Validation Loss: 0.009245118126273155\n",
      "5368 Training Loss: 0.007134292274713516 Validation Loss: 0.009165734983980656\n",
      "5369 Training Loss: 0.007781596854329109 Validation Loss: 0.009053134359419346\n",
      "5370 Training Loss: 0.009339289739727974 Validation Loss: 0.008914913982152939\n",
      "5371 Training Loss: 0.01039532944560051 Validation Loss: 0.00877153966575861\n",
      "5372 Training Loss: 0.008515633642673492 Validation Loss: 0.00868790689855814\n",
      "5373 Training Loss: 0.00864761509001255 Validation Loss: 0.008699607104063034\n",
      "5374 Training Loss: 0.008128290995955467 Validation Loss: 0.008838305249810219\n",
      "5375 Training Loss: 0.008368875831365585 Validation Loss: 0.009059302508831024\n",
      "5376 Training Loss: 0.007525875233113766 Validation Loss: 0.009249178692698479\n",
      "5377 Training Loss: 0.009964056313037872 Validation Loss: 0.009470966644585133\n",
      "5378 Training Loss: 0.008416449651122093 Validation Loss: 0.009526845067739487\n",
      "5379 Training Loss: 0.009212075732648373 Validation Loss: 0.009491418488323689\n",
      "5380 Training Loss: 0.007297660689800978 Validation Loss: 0.009393822401762009\n",
      "5381 Training Loss: 0.009702622890472412 Validation Loss: 0.009298274293541908\n",
      "5382 Training Loss: 0.007301586680114269 Validation Loss: 0.00920043233782053\n",
      "5383 Training Loss: 0.009346198290586472 Validation Loss: 0.009089123457670212\n",
      "5384 Training Loss: 0.006597619503736496 Validation Loss: 0.009051812812685966\n",
      "5385 Training Loss: 0.007266022730618715 Validation Loss: 0.00902925617992878\n",
      "5386 Training Loss: 0.007110550068318844 Validation Loss: 0.00897703692317009\n",
      "5387 Training Loss: 0.007519016973674297 Validation Loss: 0.0088924840092659\n",
      "5388 Training Loss: 0.011213364079594612 Validation Loss: 0.00877903401851654\n",
      "5389 Training Loss: 0.006924441084265709 Validation Loss: 0.008707292377948761\n",
      "5390 Training Loss: 0.009240702725946903 Validation Loss: 0.008755729533731937\n",
      "5391 Training Loss: 0.00748484767973423 Validation Loss: 0.008893746882677078\n",
      "5392 Training Loss: 0.006883196998387575 Validation Loss: 0.009035689756274223\n",
      "5393 Training Loss: 0.011932543478906155 Validation Loss: 0.00938236154615879\n",
      "5394 Training Loss: 0.009045104496181011 Validation Loss: 0.009758491069078445\n",
      "5395 Training Loss: 0.008940431289374828 Validation Loss: 0.010104628279805183\n",
      "5396 Training Loss: 0.008344877511262894 Validation Loss: 0.010173635557293892\n",
      "5397 Training Loss: 0.008817226625978947 Validation Loss: 0.010138506069779396\n",
      "5398 Training Loss: 0.008386597968637943 Validation Loss: 0.009955612011253834\n",
      "5399 Training Loss: 0.013568323105573654 Validation Loss: 0.009951740503311157\n",
      "5400 Training Loss: 0.0119142085313797 Validation Loss: 0.010008429177105427\n",
      "5401 Training Loss: 0.008519720286130905 Validation Loss: 0.010039061307907104\n",
      "5402 Training Loss: 0.007265806198120117 Validation Loss: 0.009886511601507664\n",
      "5403 Training Loss: 0.007852905429899693 Validation Loss: 0.009581618010997772\n",
      "5404 Training Loss: 0.008799348026514053 Validation Loss: 0.009341550059616566\n",
      "5405 Training Loss: 0.008130766451358795 Validation Loss: 0.009084304794669151\n",
      "5406 Training Loss: 0.010688912123441696 Validation Loss: 0.008905336260795593\n",
      "5407 Training Loss: 0.007594702765345573 Validation Loss: 0.008755871094763279\n",
      "5408 Training Loss: 0.010378679260611534 Validation Loss: 0.008653277531266212\n",
      "5409 Training Loss: 0.007915403693914413 Validation Loss: 0.008556913584470749\n",
      "5410 Training Loss: 0.007554471492767334 Validation Loss: 0.008513642475008965\n",
      "5411 Training Loss: 0.007817106321454048 Validation Loss: 0.008476497605443\n",
      "5412 Training Loss: 0.00905309896916151 Validation Loss: 0.00848323293030262\n",
      "5413 Training Loss: 0.008864698931574821 Validation Loss: 0.008589253760874271\n",
      "5414 Training Loss: 0.007590393535792828 Validation Loss: 0.008708560839295387\n",
      "5415 Training Loss: 0.007632180582731962 Validation Loss: 0.0088828569278121\n",
      "5416 Training Loss: 0.009619491174817085 Validation Loss: 0.0090589988976717\n",
      "5417 Training Loss: 0.006890433840453625 Validation Loss: 0.009167303331196308\n",
      "5418 Training Loss: 0.007028928492218256 Validation Loss: 0.009251818060874939\n",
      "5419 Training Loss: 0.007183073088526726 Validation Loss: 0.009334906004369259\n",
      "5420 Training Loss: 0.009004427120089531 Validation Loss: 0.009477896615862846\n",
      "5421 Training Loss: 0.00694219209253788 Validation Loss: 0.009562956169247627\n",
      "5422 Training Loss: 0.00971839390695095 Validation Loss: 0.00964281801134348\n",
      "5423 Training Loss: 0.007934052497148514 Validation Loss: 0.009591689333319664\n",
      "5424 Training Loss: 0.008446731604635715 Validation Loss: 0.009340444579720497\n",
      "5425 Training Loss: 0.007886197417974472 Validation Loss: 0.009123370982706547\n",
      "5426 Training Loss: 0.007039121352136135 Validation Loss: 0.009032112546265125\n",
      "5427 Training Loss: 0.008366044610738754 Validation Loss: 0.00881148874759674\n",
      "5428 Training Loss: 0.009728390723466873 Validation Loss: 0.008567854762077332\n",
      "5429 Training Loss: 0.00842705275863409 Validation Loss: 0.008372132666409016\n",
      "5430 Training Loss: 0.008563507348299026 Validation Loss: 0.008246109820902348\n",
      "5431 Training Loss: 0.007885655388236046 Validation Loss: 0.008149495348334312\n",
      "5432 Training Loss: 0.007604924496263266 Validation Loss: 0.008085404522716999\n",
      "5433 Training Loss: 0.009883537888526917 Validation Loss: 0.008043047972023487\n",
      "5434 Training Loss: 0.006769958417862654 Validation Loss: 0.008034476079046726\n",
      "5435 Training Loss: 0.006801599636673927 Validation Loss: 0.008042898029088974\n",
      "5436 Training Loss: 0.0090334452688694 Validation Loss: 0.008069314062595367\n",
      "5437 Training Loss: 0.008499884977936745 Validation Loss: 0.008112008683383465\n",
      "5438 Training Loss: 0.007211554795503616 Validation Loss: 0.008165793493390083\n",
      "5439 Training Loss: 0.007414793595671654 Validation Loss: 0.008219676092267036\n",
      "5440 Training Loss: 0.007020812481641769 Validation Loss: 0.00826689787209034\n",
      "5441 Training Loss: 0.00796483177691698 Validation Loss: 0.008335454389452934\n",
      "5442 Training Loss: 0.008093450218439102 Validation Loss: 0.00841573253273964\n",
      "5443 Training Loss: 0.006922096945345402 Validation Loss: 0.008527255617082119\n",
      "5444 Training Loss: 0.009278254583477974 Validation Loss: 0.008675258606672287\n",
      "5445 Training Loss: 0.008803321979939938 Validation Loss: 0.008735444396734238\n",
      "5446 Training Loss: 0.007042477838695049 Validation Loss: 0.008694503456354141\n",
      "5447 Training Loss: 0.008391153067350388 Validation Loss: 0.008635777980089188\n",
      "5448 Training Loss: 0.010893571190536022 Validation Loss: 0.008528301492333412\n",
      "5449 Training Loss: 0.0095644760876894 Validation Loss: 0.008398828096687794\n",
      "5450 Training Loss: 0.007243064697831869 Validation Loss: 0.008259076625108719\n",
      "5451 Training Loss: 0.010327988304197788 Validation Loss: 0.008140167221426964\n",
      "5452 Training Loss: 0.00922517478466034 Validation Loss: 0.00807851180434227\n",
      "5453 Training Loss: 0.0067473892122507095 Validation Loss: 0.008036590181291103\n",
      "5454 Training Loss: 0.01021372340619564 Validation Loss: 0.008051293902099133\n",
      "5455 Training Loss: 0.00761103630065918 Validation Loss: 0.008094541728496552\n",
      "5456 Training Loss: 0.007393253035843372 Validation Loss: 0.008073719218373299\n",
      "5457 Training Loss: 0.007740541361272335 Validation Loss: 0.008039559237658978\n",
      "5458 Training Loss: 0.007225001696497202 Validation Loss: 0.008066627196967602\n",
      "5459 Training Loss: 0.007668417878448963 Validation Loss: 0.008132298476994038\n",
      "5460 Training Loss: 0.0067754327319562435 Validation Loss: 0.008172067813575268\n",
      "5461 Training Loss: 0.006909338757395744 Validation Loss: 0.008229224942624569\n",
      "5462 Training Loss: 0.006825816351920366 Validation Loss: 0.00826139748096466\n",
      "5463 Training Loss: 0.0077789220958948135 Validation Loss: 0.00827950518578291\n",
      "5464 Training Loss: 0.006561025511473417 Validation Loss: 0.008295286446809769\n",
      "5465 Training Loss: 0.007340414449572563 Validation Loss: 0.008312280289828777\n",
      "5466 Training Loss: 0.007799183018505573 Validation Loss: 0.008363519795238972\n",
      "5467 Training Loss: 0.007812377065420151 Validation Loss: 0.008356442674994469\n",
      "5468 Training Loss: 0.007745752576738596 Validation Loss: 0.008300291374325752\n",
      "5469 Training Loss: 0.010976441204547882 Validation Loss: 0.008120890706777573\n",
      "5470 Training Loss: 0.007253616116940975 Validation Loss: 0.007990154437720776\n",
      "5471 Training Loss: 0.006914219819009304 Validation Loss: 0.007908583618700504\n",
      "5472 Training Loss: 0.008497944101691246 Validation Loss: 0.00784511398524046\n",
      "5473 Training Loss: 0.007040803320705891 Validation Loss: 0.007802037056535482\n",
      "5474 Training Loss: 0.006899796426296234 Validation Loss: 0.007795132230967283\n",
      "5475 Training Loss: 0.00629799347370863 Validation Loss: 0.007815901190042496\n",
      "5476 Training Loss: 0.007071048021316528 Validation Loss: 0.007865240797400475\n",
      "5477 Training Loss: 0.00862274132668972 Validation Loss: 0.007913803681731224\n",
      "5478 Training Loss: 0.008084582164883614 Validation Loss: 0.007987897843122482\n",
      "5479 Training Loss: 0.00629163533449173 Validation Loss: 0.008104189299046993\n",
      "5480 Training Loss: 0.008165738545358181 Validation Loss: 0.008236776106059551\n",
      "5481 Training Loss: 0.007024673745036125 Validation Loss: 0.008410084061324596\n",
      "5482 Training Loss: 0.006718127056956291 Validation Loss: 0.008592374622821808\n",
      "5483 Training Loss: 0.012186458334326744 Validation Loss: 0.008857190608978271\n",
      "5484 Training Loss: 0.007133133709430695 Validation Loss: 0.009029284119606018\n",
      "5485 Training Loss: 0.006555418483912945 Validation Loss: 0.009128103964030743\n",
      "5486 Training Loss: 0.006223035976290703 Validation Loss: 0.009156123735010624\n",
      "5487 Training Loss: 0.007494987919926643 Validation Loss: 0.00900889839977026\n",
      "5488 Training Loss: 0.006226039491593838 Validation Loss: 0.00883442535996437\n",
      "5489 Training Loss: 0.007631637156009674 Validation Loss: 0.008648443967103958\n",
      "5490 Training Loss: 0.00744885578751564 Validation Loss: 0.008504273369908333\n",
      "5491 Training Loss: 0.0071731992065906525 Validation Loss: 0.008360027335584164\n",
      "5492 Training Loss: 0.007009112276136875 Validation Loss: 0.008235817775130272\n",
      "5493 Training Loss: 0.006963420193642378 Validation Loss: 0.008140197955071926\n",
      "5494 Training Loss: 0.0072553264908492565 Validation Loss: 0.008036740124225616\n",
      "5495 Training Loss: 0.00718120951205492 Validation Loss: 0.007939244620501995\n",
      "5496 Training Loss: 0.008615653961896896 Validation Loss: 0.007878844626247883\n",
      "5497 Training Loss: 0.006192372180521488 Validation Loss: 0.007854847237467766\n",
      "5498 Training Loss: 0.006997847929596901 Validation Loss: 0.007871996611356735\n",
      "5499 Training Loss: 0.008664345368742943 Validation Loss: 0.007956372573971748\n",
      "5500 Training Loss: 0.009335124865174294 Validation Loss: 0.008100711740553379\n",
      "5501 Training Loss: 0.007970569655299187 Validation Loss: 0.008303544484078884\n",
      "5502 Training Loss: 0.012288693338632584 Validation Loss: 0.008510264568030834\n",
      "5503 Training Loss: 0.006629848852753639 Validation Loss: 0.00861155055463314\n",
      "5504 Training Loss: 0.007057251408696175 Validation Loss: 0.008675074204802513\n",
      "5505 Training Loss: 0.006380189210176468 Validation Loss: 0.008632856421172619\n",
      "5506 Training Loss: 0.006677013821899891 Validation Loss: 0.008520505391061306\n",
      "5507 Training Loss: 0.006805595010519028 Validation Loss: 0.008412807248532772\n",
      "5508 Training Loss: 0.006945997942239046 Validation Loss: 0.008360465988516808\n",
      "5509 Training Loss: 0.008543294854462147 Validation Loss: 0.008322552777826786\n",
      "5510 Training Loss: 0.00740725127980113 Validation Loss: 0.008285148069262505\n",
      "5511 Training Loss: 0.006961321458220482 Validation Loss: 0.008188172243535519\n",
      "5512 Training Loss: 0.006135678384453058 Validation Loss: 0.008104104548692703\n",
      "5513 Training Loss: 0.006821952760219574 Validation Loss: 0.008008196018636227\n",
      "5514 Training Loss: 0.01056298054754734 Validation Loss: 0.007927087135612965\n",
      "5515 Training Loss: 0.007743118330836296 Validation Loss: 0.007864842191338539\n",
      "5516 Training Loss: 0.007351640146225691 Validation Loss: 0.007827669382095337\n",
      "5517 Training Loss: 0.006651687901467085 Validation Loss: 0.0077841090969741344\n",
      "5518 Training Loss: 0.00882149487733841 Validation Loss: 0.00778652960434556\n",
      "5519 Training Loss: 0.007502837106585503 Validation Loss: 0.00777613976970315\n",
      "5520 Training Loss: 0.006526246666908264 Validation Loss: 0.00773986941203475\n",
      "5521 Training Loss: 0.010481547564268112 Validation Loss: 0.007726710755378008\n",
      "5522 Training Loss: 0.007022365927696228 Validation Loss: 0.007722957991063595\n",
      "5523 Training Loss: 0.008747203275561333 Validation Loss: 0.007739913649857044\n",
      "5524 Training Loss: 0.005993138067424297 Validation Loss: 0.007754407357424498\n",
      "5525 Training Loss: 0.006334677804261446 Validation Loss: 0.007757163140922785\n",
      "5526 Training Loss: 0.006578434258699417 Validation Loss: 0.007780453655868769\n",
      "5527 Training Loss: 0.006438072305172682 Validation Loss: 0.007838846184313297\n",
      "5528 Training Loss: 0.006273725535720587 Validation Loss: 0.007911942899227142\n",
      "5529 Training Loss: 0.006509666331112385 Validation Loss: 0.007967472076416016\n",
      "5530 Training Loss: 0.005959076341241598 Validation Loss: 0.008009254932403564\n",
      "5531 Training Loss: 0.008195321075618267 Validation Loss: 0.008060837164521217\n",
      "5532 Training Loss: 0.006645815446972847 Validation Loss: 0.008140667341649532\n",
      "5533 Training Loss: 0.006678755395114422 Validation Loss: 0.008250836282968521\n",
      "5534 Training Loss: 0.007735349237918854 Validation Loss: 0.008299088105559349\n",
      "5535 Training Loss: 0.008472904562950134 Validation Loss: 0.008379844948649406\n",
      "5536 Training Loss: 0.008280685171484947 Validation Loss: 0.008430154994130135\n",
      "5537 Training Loss: 0.012252557091414928 Validation Loss: 0.008482612669467926\n",
      "5538 Training Loss: 0.005922991782426834 Validation Loss: 0.008448522537946701\n",
      "5539 Training Loss: 0.010705439373850822 Validation Loss: 0.008509608916938305\n",
      "5540 Training Loss: 0.006958875805139542 Validation Loss: 0.008408162742853165\n",
      "5541 Training Loss: 0.006691628135740757 Validation Loss: 0.008244738914072514\n",
      "5542 Training Loss: 0.007059115916490555 Validation Loss: 0.008055582642555237\n",
      "5543 Training Loss: 0.006362213287502527 Validation Loss: 0.007885938510298729\n",
      "5544 Training Loss: 0.006134573370218277 Validation Loss: 0.007817705161869526\n",
      "5545 Training Loss: 0.011331380344927311 Validation Loss: 0.00779546145349741\n",
      "5546 Training Loss: 0.006581807974725962 Validation Loss: 0.007768360897898674\n",
      "5547 Training Loss: 0.006227961275726557 Validation Loss: 0.007723866030573845\n",
      "5548 Training Loss: 0.006884653586894274 Validation Loss: 0.007701171562075615\n",
      "5549 Training Loss: 0.006835684180259705 Validation Loss: 0.007678444031625986\n",
      "5550 Training Loss: 0.006344878114759922 Validation Loss: 0.007660404779016972\n",
      "5551 Training Loss: 0.00994940660893917 Validation Loss: 0.007692060433328152\n",
      "5552 Training Loss: 0.007586141116917133 Validation Loss: 0.007826462388038635\n",
      "5553 Training Loss: 0.006417818367481232 Validation Loss: 0.00797338504344225\n",
      "5554 Training Loss: 0.0065304930321872234 Validation Loss: 0.00808166153728962\n",
      "5555 Training Loss: 0.0063092634081840515 Validation Loss: 0.008129585534334183\n",
      "5556 Training Loss: 0.006963219493627548 Validation Loss: 0.008206918835639954\n",
      "5557 Training Loss: 0.00644784327596426 Validation Loss: 0.008245847187936306\n",
      "5558 Training Loss: 0.00823136791586876 Validation Loss: 0.008168711327016354\n",
      "5559 Training Loss: 0.00720240268856287 Validation Loss: 0.008090970106422901\n",
      "5560 Training Loss: 0.006773720495402813 Validation Loss: 0.007962802425026894\n",
      "5561 Training Loss: 0.00773977767676115 Validation Loss: 0.007874085567891598\n",
      "5562 Training Loss: 0.006966866552829742 Validation Loss: 0.007835227064788342\n",
      "5563 Training Loss: 0.010663365945219994 Validation Loss: 0.007807821035385132\n",
      "5564 Training Loss: 0.006973782554268837 Validation Loss: 0.007714196108281612\n",
      "5565 Training Loss: 0.009062893688678741 Validation Loss: 0.007701839320361614\n",
      "5566 Training Loss: 0.009360264986753464 Validation Loss: 0.007850367575883865\n",
      "5567 Training Loss: 0.0065658800303936005 Validation Loss: 0.007925670593976974\n",
      "5568 Training Loss: 0.006857752799987793 Validation Loss: 0.007971162907779217\n",
      "5569 Training Loss: 0.007597236894071102 Validation Loss: 0.008001869544386864\n",
      "5570 Training Loss: 0.006354018114507198 Validation Loss: 0.007948435842990875\n",
      "5571 Training Loss: 0.006841740570962429 Validation Loss: 0.00778760714456439\n",
      "5572 Training Loss: 0.007335331290960312 Validation Loss: 0.007707044016569853\n",
      "5573 Training Loss: 0.009775349870324135 Validation Loss: 0.007706282194703817\n",
      "5574 Training Loss: 0.007641048636287451 Validation Loss: 0.007698197849094868\n",
      "5575 Training Loss: 0.010966288857161999 Validation Loss: 0.007705495227128267\n",
      "5576 Training Loss: 0.00629159901291132 Validation Loss: 0.0077133094891905785\n",
      "5577 Training Loss: 0.007315657567232847 Validation Loss: 0.007842576131224632\n",
      "5578 Training Loss: 0.005917272064834833 Validation Loss: 0.007998054847121239\n",
      "5579 Training Loss: 0.006118432618677616 Validation Loss: 0.008172737434506416\n",
      "5580 Training Loss: 0.005764778703451157 Validation Loss: 0.00831794273108244\n",
      "5581 Training Loss: 0.00590538838878274 Validation Loss: 0.008379547856748104\n",
      "5582 Training Loss: 0.006846887990832329 Validation Loss: 0.0084640271961689\n",
      "5583 Training Loss: 0.00800194963812828 Validation Loss: 0.008516126312315464\n",
      "5584 Training Loss: 0.006868170574307442 Validation Loss: 0.008429063484072685\n",
      "5585 Training Loss: 0.0068438006564974785 Validation Loss: 0.008346804417669773\n",
      "5586 Training Loss: 0.006592837627977133 Validation Loss: 0.008192963898181915\n",
      "5587 Training Loss: 0.005926048383116722 Validation Loss: 0.00805155374109745\n",
      "5588 Training Loss: 0.008374028839170933 Validation Loss: 0.007957406342029572\n",
      "5589 Training Loss: 0.006482063326984644 Validation Loss: 0.007890783250331879\n",
      "5590 Training Loss: 0.00821780040860176 Validation Loss: 0.007850296795368195\n",
      "5591 Training Loss: 0.00692782225087285 Validation Loss: 0.007741264533251524\n",
      "5592 Training Loss: 0.0062542082741856575 Validation Loss: 0.007615070324391127\n",
      "5593 Training Loss: 0.006533493287861347 Validation Loss: 0.007478063460439444\n",
      "5594 Training Loss: 0.005762375891208649 Validation Loss: 0.007383724208921194\n",
      "5595 Training Loss: 0.0071816882118582726 Validation Loss: 0.007305526174604893\n",
      "5596 Training Loss: 0.007685462944209576 Validation Loss: 0.007266208063811064\n",
      "5597 Training Loss: 0.006690299604088068 Validation Loss: 0.007237739395350218\n",
      "5598 Training Loss: 0.006746417842805386 Validation Loss: 0.007229558192193508\n",
      "5599 Training Loss: 0.006918987724930048 Validation Loss: 0.00721325445920229\n",
      "5600 Training Loss: 0.006791176740080118 Validation Loss: 0.007199683226644993\n",
      "5601 Training Loss: 0.00873420387506485 Validation Loss: 0.007182802073657513\n",
      "5602 Training Loss: 0.006365196779370308 Validation Loss: 0.0071828244253993034\n",
      "5603 Training Loss: 0.008591766469180584 Validation Loss: 0.0072210440412163734\n",
      "5604 Training Loss: 0.00968704093247652 Validation Loss: 0.007316807750612497\n",
      "5605 Training Loss: 0.0073143113404512405 Validation Loss: 0.0074388412758708\n",
      "5606 Training Loss: 0.005921541713178158 Validation Loss: 0.007541396655142307\n",
      "5607 Training Loss: 0.006599347107112408 Validation Loss: 0.0075673386454582214\n",
      "5608 Training Loss: 0.005943286698311567 Validation Loss: 0.007579045370221138\n",
      "5609 Training Loss: 0.006060265004634857 Validation Loss: 0.0076307994313538074\n",
      "5610 Training Loss: 0.0061348797753453255 Validation Loss: 0.007659445516765118\n",
      "5611 Training Loss: 0.007093271240592003 Validation Loss: 0.007611090317368507\n",
      "5612 Training Loss: 0.006774093024432659 Validation Loss: 0.007545772939920425\n",
      "5613 Training Loss: 0.006663499865680933 Validation Loss: 0.00751071609556675\n",
      "5614 Training Loss: 0.006919032894074917 Validation Loss: 0.0074770026840269566\n",
      "5615 Training Loss: 0.006264802999794483 Validation Loss: 0.007410186808556318\n",
      "5616 Training Loss: 0.006978197488933802 Validation Loss: 0.007364761549979448\n",
      "5617 Training Loss: 0.008187329396605492 Validation Loss: 0.00739699974656105\n",
      "5618 Training Loss: 0.010257579386234283 Validation Loss: 0.007469114847481251\n",
      "5619 Training Loss: 0.006943475920706987 Validation Loss: 0.0074980962090194225\n",
      "5620 Training Loss: 0.006433720700442791 Validation Loss: 0.0075036389753222466\n",
      "5621 Training Loss: 0.008727168664336205 Validation Loss: 0.007560051046311855\n",
      "5622 Training Loss: 0.006493215914815664 Validation Loss: 0.007483447901904583\n",
      "5623 Training Loss: 0.007282036356627941 Validation Loss: 0.00739334337413311\n",
      "5624 Training Loss: 0.007354896515607834 Validation Loss: 0.007208640221506357\n",
      "5625 Training Loss: 0.005951129365712404 Validation Loss: 0.007111174054443836\n",
      "5626 Training Loss: 0.00831533782184124 Validation Loss: 0.007100112736225128\n",
      "5627 Training Loss: 0.008720709010958672 Validation Loss: 0.007157603744417429\n",
      "5628 Training Loss: 0.006334511563181877 Validation Loss: 0.007176259998232126\n",
      "5629 Training Loss: 0.006283466704189777 Validation Loss: 0.00721460347995162\n",
      "5630 Training Loss: 0.007462340407073498 Validation Loss: 0.007248843088746071\n",
      "5631 Training Loss: 0.006164867430925369 Validation Loss: 0.007251432165503502\n",
      "5632 Training Loss: 0.006658315658569336 Validation Loss: 0.00728300865739584\n",
      "5633 Training Loss: 0.007424307521432638 Validation Loss: 0.007324849721044302\n",
      "5634 Training Loss: 0.01012011244893074 Validation Loss: 0.007397453300654888\n",
      "5635 Training Loss: 0.005955778528004885 Validation Loss: 0.007412646431475878\n",
      "5636 Training Loss: 0.007709287106990814 Validation Loss: 0.007386878132820129\n",
      "5637 Training Loss: 0.011988149024546146 Validation Loss: 0.007432786747813225\n",
      "5638 Training Loss: 0.006052848417311907 Validation Loss: 0.007529512047767639\n",
      "5639 Training Loss: 0.008517218753695488 Validation Loss: 0.007629925850778818\n",
      "5640 Training Loss: 0.005927500315010548 Validation Loss: 0.007627412676811218\n",
      "5641 Training Loss: 0.006042844150215387 Validation Loss: 0.007555922027677298\n",
      "5642 Training Loss: 0.005655845161527395 Validation Loss: 0.0074905697256326675\n",
      "5643 Training Loss: 0.00762045057490468 Validation Loss: 0.0073758442886173725\n",
      "5644 Training Loss: 0.005982701200991869 Validation Loss: 0.007312112022191286\n",
      "5645 Training Loss: 0.006787904538214207 Validation Loss: 0.007273032795637846\n",
      "5646 Training Loss: 0.010077069513499737 Validation Loss: 0.007187316659837961\n",
      "5647 Training Loss: 0.00767222186550498 Validation Loss: 0.007115907967090607\n",
      "5648 Training Loss: 0.006058800034224987 Validation Loss: 0.007079508621245623\n",
      "5649 Training Loss: 0.007570328190922737 Validation Loss: 0.00710250623524189\n",
      "5650 Training Loss: 0.0056008948013186455 Validation Loss: 0.007233104668557644\n",
      "5651 Training Loss: 0.005880495999008417 Validation Loss: 0.007379772141575813\n",
      "5652 Training Loss: 0.0074936142191290855 Validation Loss: 0.0073908064514398575\n",
      "5653 Training Loss: 0.008528100326657295 Validation Loss: 0.007434394210577011\n",
      "5654 Training Loss: 0.006541830487549305 Validation Loss: 0.007358262315392494\n",
      "5655 Training Loss: 0.006934803444892168 Validation Loss: 0.007282410282641649\n",
      "5656 Training Loss: 0.006303934380412102 Validation Loss: 0.007231429219245911\n",
      "5657 Training Loss: 0.005514639429748058 Validation Loss: 0.007189962547272444\n",
      "5658 Training Loss: 0.008039696142077446 Validation Loss: 0.007163113448768854\n",
      "5659 Training Loss: 0.005774445831775665 Validation Loss: 0.007122845388948917\n",
      "5660 Training Loss: 0.006114860065281391 Validation Loss: 0.007127911783754826\n",
      "5661 Training Loss: 0.005974792409688234 Validation Loss: 0.007135644555091858\n",
      "5662 Training Loss: 0.006240868009626865 Validation Loss: 0.007155046332627535\n",
      "5663 Training Loss: 0.005933624692261219 Validation Loss: 0.007199594751000404\n",
      "5664 Training Loss: 0.007886575534939766 Validation Loss: 0.0073259081691503525\n",
      "5665 Training Loss: 0.005804100073873997 Validation Loss: 0.007487902883440256\n",
      "5666 Training Loss: 0.005605021491646767 Validation Loss: 0.007600285578519106\n",
      "5667 Training Loss: 0.006659724283963442 Validation Loss: 0.0076858666725456715\n",
      "5668 Training Loss: 0.006986977066844702 Validation Loss: 0.007559122517704964\n",
      "5669 Training Loss: 0.007325706537812948 Validation Loss: 0.007448870688676834\n",
      "5670 Training Loss: 0.0073342276737093925 Validation Loss: 0.007323689758777618\n",
      "5671 Training Loss: 0.005692060571163893 Validation Loss: 0.00718625308945775\n",
      "5672 Training Loss: 0.006147933658212423 Validation Loss: 0.00704346364364028\n",
      "5673 Training Loss: 0.006633874028921127 Validation Loss: 0.0069768307730555534\n",
      "5674 Training Loss: 0.005669744219630957 Validation Loss: 0.006963744759559631\n",
      "5675 Training Loss: 0.0060974652878940105 Validation Loss: 0.006985386833548546\n",
      "5676 Training Loss: 0.007221125066280365 Validation Loss: 0.007011185400187969\n",
      "5677 Training Loss: 0.005379793234169483 Validation Loss: 0.007056967820972204\n",
      "5678 Training Loss: 0.005735957529395819 Validation Loss: 0.007097952999174595\n",
      "5679 Training Loss: 0.005471878685057163 Validation Loss: 0.007134268991649151\n",
      "5680 Training Loss: 0.0060175443068146706 Validation Loss: 0.007185278460383415\n",
      "5681 Training Loss: 0.005404755473136902 Validation Loss: 0.007241265848278999\n",
      "5682 Training Loss: 0.007741370238363743 Validation Loss: 0.007320086006075144\n",
      "5683 Training Loss: 0.00655533280223608 Validation Loss: 0.007336031179875135\n",
      "5684 Training Loss: 0.006074783392250538 Validation Loss: 0.007364115212112665\n",
      "5685 Training Loss: 0.005366443656384945 Validation Loss: 0.007392925675958395\n",
      "5686 Training Loss: 0.006429411470890045 Validation Loss: 0.007424079813063145\n",
      "5687 Training Loss: 0.005724793765693903 Validation Loss: 0.007484090514481068\n",
      "5688 Training Loss: 0.0060029411688447 Validation Loss: 0.007449440658092499\n",
      "5689 Training Loss: 0.007835151627659798 Validation Loss: 0.007424956187605858\n",
      "5690 Training Loss: 0.008046723902225494 Validation Loss: 0.007473962381482124\n",
      "5691 Training Loss: 0.007661047857254744 Validation Loss: 0.007528735790401697\n",
      "5692 Training Loss: 0.006733157206326723 Validation Loss: 0.007582047022879124\n",
      "5693 Training Loss: 0.007370807230472565 Validation Loss: 0.007541693281382322\n",
      "5694 Training Loss: 0.008214795961976051 Validation Loss: 0.00755197461694479\n",
      "5695 Training Loss: 0.005897460505366325 Validation Loss: 0.0074098436161875725\n",
      "5696 Training Loss: 0.007153708953410387 Validation Loss: 0.007288863882422447\n",
      "5697 Training Loss: 0.006537868175655603 Validation Loss: 0.007187598384916782\n",
      "5698 Training Loss: 0.0058832354843616486 Validation Loss: 0.007101390976458788\n",
      "5699 Training Loss: 0.00646567065268755 Validation Loss: 0.007047426886856556\n",
      "5700 Training Loss: 0.006850455887615681 Validation Loss: 0.007011289708316326\n",
      "5701 Training Loss: 0.005894051399081945 Validation Loss: 0.007021584082394838\n",
      "5702 Training Loss: 0.006165525875985622 Validation Loss: 0.007018668577075005\n",
      "5703 Training Loss: 0.005485511850565672 Validation Loss: 0.007031502667814493\n",
      "5704 Training Loss: 0.005823950748890638 Validation Loss: 0.007097982801496983\n",
      "5705 Training Loss: 0.006913777440786362 Validation Loss: 0.007119814399629831\n",
      "5706 Training Loss: 0.006687534973025322 Validation Loss: 0.00712300930172205\n",
      "5707 Training Loss: 0.007649547420442104 Validation Loss: 0.0071650305762887\n",
      "5708 Training Loss: 0.005174399819225073 Validation Loss: 0.007217006292194128\n",
      "5709 Training Loss: 0.006423391867429018 Validation Loss: 0.0072981612756848335\n",
      "5710 Training Loss: 0.006339335814118385 Validation Loss: 0.007262914441525936\n",
      "5711 Training Loss: 0.007082736119627953 Validation Loss: 0.007250963244587183\n",
      "5712 Training Loss: 0.0056206160224974155 Validation Loss: 0.007217190228402615\n",
      "5713 Training Loss: 0.0066973548382520676 Validation Loss: 0.007168762851506472\n",
      "5714 Training Loss: 0.007160066626966 Validation Loss: 0.007141141686588526\n",
      "5715 Training Loss: 0.006677265278995037 Validation Loss: 0.00704177375882864\n",
      "5716 Training Loss: 0.007044352125376463 Validation Loss: 0.007025600410997868\n",
      "5717 Training Loss: 0.006285307928919792 Validation Loss: 0.0069465311244130135\n",
      "5718 Training Loss: 0.005179752595722675 Validation Loss: 0.006876199971884489\n",
      "5719 Training Loss: 0.006060594227164984 Validation Loss: 0.006775189191102982\n",
      "5720 Training Loss: 0.006964331492781639 Validation Loss: 0.00675175292417407\n",
      "5721 Training Loss: 0.009481893852353096 Validation Loss: 0.006792634725570679\n",
      "5722 Training Loss: 0.0058836848475039005 Validation Loss: 0.0068223015405237675\n",
      "5723 Training Loss: 0.0062279608100652695 Validation Loss: 0.006868161726742983\n",
      "5724 Training Loss: 0.007529708556830883 Validation Loss: 0.006824780721217394\n",
      "5725 Training Loss: 0.007947884500026703 Validation Loss: 0.006830745376646519\n",
      "5726 Training Loss: 0.005167711991816759 Validation Loss: 0.006841821596026421\n",
      "5727 Training Loss: 0.005972994491457939 Validation Loss: 0.006829064339399338\n",
      "5728 Training Loss: 0.0068123009987175465 Validation Loss: 0.00684954272583127\n",
      "5729 Training Loss: 0.007865913212299347 Validation Loss: 0.006846406497061253\n",
      "5730 Training Loss: 0.005876929499208927 Validation Loss: 0.0068689798936247826\n",
      "5731 Training Loss: 0.006551004946231842 Validation Loss: 0.006872054189443588\n",
      "5732 Training Loss: 0.006619937252253294 Validation Loss: 0.006891935132443905\n",
      "5733 Training Loss: 0.007664881180971861 Validation Loss: 0.006996306125074625\n",
      "5734 Training Loss: 0.005608433857560158 Validation Loss: 0.007051550783216953\n",
      "5735 Training Loss: 0.006106543354690075 Validation Loss: 0.0071339993737638\n",
      "5736 Training Loss: 0.00532898772507906 Validation Loss: 0.007164723239839077\n",
      "5737 Training Loss: 0.006965771317481995 Validation Loss: 0.0071466234512627125\n",
      "5738 Training Loss: 0.007799145765602589 Validation Loss: 0.007116210646927357\n",
      "5739 Training Loss: 0.006450112909078598 Validation Loss: 0.007089415565133095\n",
      "5740 Training Loss: 0.005918511189520359 Validation Loss: 0.006993606686592102\n",
      "5741 Training Loss: 0.005957977846264839 Validation Loss: 0.006838215049356222\n",
      "5742 Training Loss: 0.006462971679866314 Validation Loss: 0.0067368969321250916\n",
      "5743 Training Loss: 0.009287070482969284 Validation Loss: 0.006770408246666193\n",
      "5744 Training Loss: 0.005178784020245075 Validation Loss: 0.006862546317279339\n",
      "5745 Training Loss: 0.007984546944499016 Validation Loss: 0.0070150988176465034\n",
      "5746 Training Loss: 0.005382233764976263 Validation Loss: 0.007195750251412392\n",
      "5747 Training Loss: 0.005820335820317268 Validation Loss: 0.007369338534772396\n",
      "5748 Training Loss: 0.005937986541539431 Validation Loss: 0.007392870262265205\n",
      "5749 Training Loss: 0.0059449197724461555 Validation Loss: 0.00727462861686945\n",
      "5750 Training Loss: 0.005811433307826519 Validation Loss: 0.0071298363618552685\n",
      "5751 Training Loss: 0.00590179767459631 Validation Loss: 0.006951561663299799\n",
      "5752 Training Loss: 0.007447605021297932 Validation Loss: 0.006892098113894463\n",
      "5753 Training Loss: 0.007849049754440784 Validation Loss: 0.00687283743172884\n",
      "5754 Training Loss: 0.008710691705346107 Validation Loss: 0.006870603188872337\n",
      "5755 Training Loss: 0.005103487987071276 Validation Loss: 0.006873229052871466\n",
      "5756 Training Loss: 0.008048614487051964 Validation Loss: 0.006910053081810474\n",
      "5757 Training Loss: 0.005314970854669809 Validation Loss: 0.006945611909031868\n",
      "5758 Training Loss: 0.006196834146976471 Validation Loss: 0.006942383944988251\n",
      "5759 Training Loss: 0.005805061198771 Validation Loss: 0.00690086092799902\n",
      "5760 Training Loss: 0.005720933899283409 Validation Loss: 0.0067981849424541\n",
      "5761 Training Loss: 0.005116632208228111 Validation Loss: 0.006709895562380552\n",
      "5762 Training Loss: 0.006738756783306599 Validation Loss: 0.006658150814473629\n",
      "5763 Training Loss: 0.005781885236501694 Validation Loss: 0.006663454696536064\n",
      "5764 Training Loss: 0.007354318629950285 Validation Loss: 0.006688851863145828\n",
      "5765 Training Loss: 0.005707225762307644 Validation Loss: 0.00670227687805891\n",
      "5766 Training Loss: 0.008834874257445335 Validation Loss: 0.006741712335497141\n",
      "5767 Training Loss: 0.007405031472444534 Validation Loss: 0.006873634178191423\n",
      "5768 Training Loss: 0.006037035491317511 Validation Loss: 0.007036488503217697\n",
      "5769 Training Loss: 0.005609679501503706 Validation Loss: 0.007112112827599049\n",
      "5770 Training Loss: 0.006574983708560467 Validation Loss: 0.007064898498356342\n",
      "5771 Training Loss: 0.005395060870796442 Validation Loss: 0.0069467914290726185\n",
      "5772 Training Loss: 0.0053813825361430645 Validation Loss: 0.006793122738599777\n",
      "5773 Training Loss: 0.006524205207824707 Validation Loss: 0.006618797779083252\n",
      "5774 Training Loss: 0.005347575061023235 Validation Loss: 0.00654916325584054\n",
      "5775 Training Loss: 0.004918559454381466 Validation Loss: 0.006530507002025843\n",
      "5776 Training Loss: 0.00555447768419981 Validation Loss: 0.006530489772558212\n",
      "5777 Training Loss: 0.006052989512681961 Validation Loss: 0.006511804647743702\n",
      "5778 Training Loss: 0.005861975718289614 Validation Loss: 0.00648323493078351\n",
      "5779 Training Loss: 0.005718410946428776 Validation Loss: 0.006448064465075731\n",
      "5780 Training Loss: 0.005068966653198004 Validation Loss: 0.0064416006207466125\n",
      "5781 Training Loss: 0.005668210797011852 Validation Loss: 0.006478761322796345\n",
      "5782 Training Loss: 0.005423759110271931 Validation Loss: 0.006528565194457769\n",
      "5783 Training Loss: 0.005970820784568787 Validation Loss: 0.006669308058917522\n",
      "5784 Training Loss: 0.006419269368052483 Validation Loss: 0.006815698929131031\n",
      "5785 Training Loss: 0.007815327495336533 Validation Loss: 0.007057137321680784\n",
      "5786 Training Loss: 0.005791772156953812 Validation Loss: 0.00712469732388854\n",
      "5787 Training Loss: 0.005477370694279671 Validation Loss: 0.0071264393627643585\n",
      "5788 Training Loss: 0.005737127736210823 Validation Loss: 0.00701718358322978\n",
      "5789 Training Loss: 0.005253861658275127 Validation Loss: 0.006889859214425087\n",
      "5790 Training Loss: 0.005156231112778187 Validation Loss: 0.006782177370041609\n",
      "5791 Training Loss: 0.008399194106459618 Validation Loss: 0.006707779131829739\n",
      "5792 Training Loss: 0.005535779520869255 Validation Loss: 0.006635146215558052\n",
      "5793 Training Loss: 0.0062280576676130295 Validation Loss: 0.006578404456377029\n",
      "5794 Training Loss: 0.004956218414008617 Validation Loss: 0.006542261689901352\n",
      "5795 Training Loss: 0.006777747068554163 Validation Loss: 0.006498047150671482\n",
      "5796 Training Loss: 0.005095404572784901 Validation Loss: 0.006505051162093878\n",
      "5797 Training Loss: 0.008884669281542301 Validation Loss: 0.006576592568308115\n",
      "5798 Training Loss: 0.005267459899187088 Validation Loss: 0.006669824942946434\n",
      "5799 Training Loss: 0.005523525644093752 Validation Loss: 0.006682662293314934\n",
      "5800 Training Loss: 0.004941413179039955 Validation Loss: 0.006671201903373003\n",
      "5801 Training Loss: 0.005599655210971832 Validation Loss: 0.00661504315212369\n",
      "5802 Training Loss: 0.006470375694334507 Validation Loss: 0.006438565906137228\n",
      "5803 Training Loss: 0.007949097082018852 Validation Loss: 0.0063584186136722565\n",
      "5804 Training Loss: 0.009649114683270454 Validation Loss: 0.006306190975010395\n",
      "5805 Training Loss: 0.0050596147775650024 Validation Loss: 0.006282070651650429\n",
      "5806 Training Loss: 0.005496361758559942 Validation Loss: 0.006312324665486813\n",
      "5807 Training Loss: 0.0055064857006073 Validation Loss: 0.00635176245123148\n",
      "5808 Training Loss: 0.0060410466976463795 Validation Loss: 0.006428321823477745\n",
      "5809 Training Loss: 0.005740860942751169 Validation Loss: 0.0065151844173669815\n",
      "5810 Training Loss: 0.0048761749640107155 Validation Loss: 0.006601544097065926\n",
      "5811 Training Loss: 0.005305184982717037 Validation Loss: 0.006613035220652819\n",
      "5812 Training Loss: 0.005644120275974274 Validation Loss: 0.006561650894582272\n",
      "5813 Training Loss: 0.006844998337328434 Validation Loss: 0.00655495747923851\n",
      "5814 Training Loss: 0.004917901009321213 Validation Loss: 0.006564131937921047\n",
      "5815 Training Loss: 0.004893446806818247 Validation Loss: 0.006593007594347\n",
      "5816 Training Loss: 0.007112199906259775 Validation Loss: 0.006670396775007248\n",
      "5817 Training Loss: 0.0066438219510018826 Validation Loss: 0.006772842723876238\n",
      "5818 Training Loss: 0.006814410910010338 Validation Loss: 0.006878569722175598\n",
      "5819 Training Loss: 0.005481125321239233 Validation Loss: 0.0069066849537193775\n",
      "5820 Training Loss: 0.005918602459132671 Validation Loss: 0.006907932925969362\n",
      "5821 Training Loss: 0.005626850761473179 Validation Loss: 0.006841521710157394\n",
      "5822 Training Loss: 0.0052710301242768764 Validation Loss: 0.0067491959780454636\n",
      "5823 Training Loss: 0.007514037191867828 Validation Loss: 0.006553895305842161\n",
      "5824 Training Loss: 0.005422624759376049 Validation Loss: 0.006420114077627659\n",
      "5825 Training Loss: 0.0071844132617115974 Validation Loss: 0.006321724504232407\n",
      "5826 Training Loss: 0.005786221474409103 Validation Loss: 0.006238107569515705\n",
      "5827 Training Loss: 0.005146907642483711 Validation Loss: 0.00619154330343008\n",
      "5828 Training Loss: 0.0051149483770132065 Validation Loss: 0.006165520753711462\n",
      "5829 Training Loss: 0.0063891722820699215 Validation Loss: 0.006131377536803484\n",
      "5830 Training Loss: 0.0053933169692754745 Validation Loss: 0.006120150908827782\n",
      "5831 Training Loss: 0.005322032608091831 Validation Loss: 0.006114623509347439\n",
      "5832 Training Loss: 0.005727527663111687 Validation Loss: 0.006107556167989969\n",
      "5833 Training Loss: 0.005566223990172148 Validation Loss: 0.006111430935561657\n",
      "5834 Training Loss: 0.005117377731949091 Validation Loss: 0.006158626172691584\n",
      "5835 Training Loss: 0.005492545198649168 Validation Loss: 0.006264546886086464\n",
      "5836 Training Loss: 0.005242787301540375 Validation Loss: 0.006416613701730967\n",
      "5837 Training Loss: 0.004740423522889614 Validation Loss: 0.006587567739188671\n",
      "5838 Training Loss: 0.0065012406557798386 Validation Loss: 0.006788057740777731\n",
      "5839 Training Loss: 0.006233329884707928 Validation Loss: 0.006931730080395937\n",
      "5840 Training Loss: 0.004951535724103451 Validation Loss: 0.007057121489197016\n",
      "5841 Training Loss: 0.005852747708559036 Validation Loss: 0.006977852899581194\n",
      "5842 Training Loss: 0.005522644612938166 Validation Loss: 0.006800352595746517\n",
      "5843 Training Loss: 0.0058331359177827835 Validation Loss: 0.006611884571611881\n",
      "5844 Training Loss: 0.00980413518846035 Validation Loss: 0.006557472515851259\n",
      "5845 Training Loss: 0.004980083554983139 Validation Loss: 0.006465401034802198\n",
      "5846 Training Loss: 0.005601549055427313 Validation Loss: 0.006444137543439865\n",
      "5847 Training Loss: 0.004699046723544598 Validation Loss: 0.006403859704732895\n",
      "5848 Training Loss: 0.005233013071119785 Validation Loss: 0.00637940363958478\n",
      "5849 Training Loss: 0.0052337851375341415 Validation Loss: 0.006354983896017075\n",
      "5850 Training Loss: 0.008416208438575268 Validation Loss: 0.006395024247467518\n",
      "5851 Training Loss: 0.0046979691833257675 Validation Loss: 0.006442762911319733\n",
      "5852 Training Loss: 0.005875342525541782 Validation Loss: 0.006501383613795042\n",
      "5853 Training Loss: 0.010849389247596264 Validation Loss: 0.006637652404606342\n",
      "5854 Training Loss: 0.006347802933305502 Validation Loss: 0.006749744527041912\n",
      "5855 Training Loss: 0.005278699565678835 Validation Loss: 0.006765023805201054\n",
      "5856 Training Loss: 0.005643554497510195 Validation Loss: 0.006745351944118738\n",
      "5857 Training Loss: 0.007528243586421013 Validation Loss: 0.006667020730674267\n",
      "5858 Training Loss: 0.0050630634650588036 Validation Loss: 0.006555745843797922\n",
      "5859 Training Loss: 0.006012191064655781 Validation Loss: 0.0063435910269618034\n",
      "5860 Training Loss: 0.0050018178299069405 Validation Loss: 0.006253088358789682\n",
      "5861 Training Loss: 0.006200064904987812 Validation Loss: 0.006182433106005192\n",
      "5862 Training Loss: 0.005422255955636501 Validation Loss: 0.006142391357570887\n",
      "5863 Training Loss: 0.006668579764664173 Validation Loss: 0.0061179036274552345\n",
      "5864 Training Loss: 0.006070369388908148 Validation Loss: 0.006125161424279213\n",
      "5865 Training Loss: 0.005970820784568787 Validation Loss: 0.006140165030956268\n",
      "5866 Training Loss: 0.0055620102211833 Validation Loss: 0.006229241378605366\n",
      "5867 Training Loss: 0.008155157789587975 Validation Loss: 0.006389576476067305\n",
      "5868 Training Loss: 0.005378216039389372 Validation Loss: 0.006542735733091831\n",
      "5869 Training Loss: 0.004893031436949968 Validation Loss: 0.006626012735068798\n",
      "5870 Training Loss: 0.006004838272929192 Validation Loss: 0.0067186905071139336\n",
      "5871 Training Loss: 0.005711556412279606 Validation Loss: 0.006619335152208805\n",
      "5872 Training Loss: 0.006696850061416626 Validation Loss: 0.006518583744764328\n",
      "5873 Training Loss: 0.00502382405102253 Validation Loss: 0.00638236990198493\n",
      "5874 Training Loss: 0.005803448148071766 Validation Loss: 0.006323500536382198\n",
      "5875 Training Loss: 0.004997026175260544 Validation Loss: 0.006278836168348789\n",
      "5876 Training Loss: 0.005090814083814621 Validation Loss: 0.006232321262359619\n",
      "5877 Training Loss: 0.005796437151730061 Validation Loss: 0.006193062756210566\n",
      "5878 Training Loss: 0.0051249125972390175 Validation Loss: 0.006131254136562347\n",
      "5879 Training Loss: 0.004760497249662876 Validation Loss: 0.00609609205275774\n",
      "5880 Training Loss: 0.006544984877109528 Validation Loss: 0.006094923708587885\n",
      "5881 Training Loss: 0.0052668009884655476 Validation Loss: 0.006140376906841993\n",
      "5882 Training Loss: 0.0048486171290278435 Validation Loss: 0.006169760599732399\n",
      "5883 Training Loss: 0.005044959951192141 Validation Loss: 0.006155623588711023\n",
      "5884 Training Loss: 0.005484496243298054 Validation Loss: 0.006148295942693949\n",
      "5885 Training Loss: 0.005446538329124451 Validation Loss: 0.0061471411027014256\n",
      "5886 Training Loss: 0.007838444784283638 Validation Loss: 0.0062387133948504925\n",
      "5887 Training Loss: 0.00536381546407938 Validation Loss: 0.006250439211726189\n",
      "5888 Training Loss: 0.004868329968303442 Validation Loss: 0.00624598516151309\n",
      "5889 Training Loss: 0.005107136908918619 Validation Loss: 0.006280010566115379\n",
      "5890 Training Loss: 0.008671491406857967 Validation Loss: 0.0063363658264279366\n",
      "5891 Training Loss: 0.004708890803158283 Validation Loss: 0.006411375943571329\n",
      "5892 Training Loss: 0.005896472837775946 Validation Loss: 0.006505133118480444\n",
      "5893 Training Loss: 0.005495699122548103 Validation Loss: 0.006648263428360224\n",
      "5894 Training Loss: 0.00694009754806757 Validation Loss: 0.006757395341992378\n",
      "5895 Training Loss: 0.0055390093475580215 Validation Loss: 0.006745895370841026\n",
      "5896 Training Loss: 0.005291291978210211 Validation Loss: 0.006669376045465469\n",
      "5897 Training Loss: 0.005076987203210592 Validation Loss: 0.006611406337469816\n",
      "5898 Training Loss: 0.004950330592691898 Validation Loss: 0.006568636745214462\n",
      "5899 Training Loss: 0.004672441631555557 Validation Loss: 0.0064866188913583755\n",
      "5900 Training Loss: 0.006331063341349363 Validation Loss: 0.006408339831978083\n",
      "5901 Training Loss: 0.007250948343425989 Validation Loss: 0.006335632409900427\n",
      "5902 Training Loss: 0.005185725167393684 Validation Loss: 0.006235713604837656\n",
      "5903 Training Loss: 0.004835241474211216 Validation Loss: 0.006179364398121834\n",
      "5904 Training Loss: 0.006534290499985218 Validation Loss: 0.00611830223351717\n",
      "5905 Training Loss: 0.005172152072191238 Validation Loss: 0.006110198795795441\n",
      "5906 Training Loss: 0.0052306149154901505 Validation Loss: 0.006093058735132217\n",
      "5907 Training Loss: 0.00638747401535511 Validation Loss: 0.006145494990050793\n",
      "5908 Training Loss: 0.00481332978233695 Validation Loss: 0.006228909362107515\n",
      "5909 Training Loss: 0.006056386046111584 Validation Loss: 0.006334373261779547\n",
      "5910 Training Loss: 0.007042837329208851 Validation Loss: 0.006447607185691595\n",
      "5911 Training Loss: 0.006272957660257816 Validation Loss: 0.006713387556374073\n",
      "5912 Training Loss: 0.005366779863834381 Validation Loss: 0.006965901702642441\n",
      "5913 Training Loss: 0.006663382984697819 Validation Loss: 0.007088314276188612\n",
      "5914 Training Loss: 0.005323758348822594 Validation Loss: 0.00704028969630599\n",
      "5915 Training Loss: 0.0045993998646736145 Validation Loss: 0.006948498077690601\n",
      "5916 Training Loss: 0.0054285889491438866 Validation Loss: 0.006891279481351376\n",
      "5917 Training Loss: 0.005458680912852287 Validation Loss: 0.006892685778439045\n",
      "5918 Training Loss: 0.005073766224086285 Validation Loss: 0.006886839866638184\n",
      "5919 Training Loss: 0.004766275640577078 Validation Loss: 0.006872915662825108\n",
      "5920 Training Loss: 0.00552404997870326 Validation Loss: 0.006841260939836502\n",
      "5921 Training Loss: 0.005311695393174887 Validation Loss: 0.006782060023397207\n",
      "5922 Training Loss: 0.0054305968806147575 Validation Loss: 0.006615880411118269\n",
      "5923 Training Loss: 0.0049895914271473885 Validation Loss: 0.006503121927380562\n",
      "5924 Training Loss: 0.0050579397939145565 Validation Loss: 0.0063669574446976185\n",
      "5925 Training Loss: 0.0056475684978067875 Validation Loss: 0.006235198583453894\n",
      "5926 Training Loss: 0.005024431273341179 Validation Loss: 0.006102017592638731\n",
      "5927 Training Loss: 0.006898320280015469 Validation Loss: 0.006004243157804012\n",
      "5928 Training Loss: 0.004838329274207354 Validation Loss: 0.005950291641056538\n",
      "5929 Training Loss: 0.005532201379537582 Validation Loss: 0.005868109874427319\n",
      "5930 Training Loss: 0.006149020977318287 Validation Loss: 0.005822003819048405\n",
      "5931 Training Loss: 0.006294271443039179 Validation Loss: 0.00581892766058445\n",
      "5932 Training Loss: 0.005953799467533827 Validation Loss: 0.00584482541307807\n",
      "5933 Training Loss: 0.004971142392605543 Validation Loss: 0.005886576138436794\n",
      "5934 Training Loss: 0.004827339202165604 Validation Loss: 0.0059337317943573\n",
      "5935 Training Loss: 0.005961528979241848 Validation Loss: 0.005999531131237745\n",
      "5936 Training Loss: 0.00474102608859539 Validation Loss: 0.0060953921638429165\n",
      "5937 Training Loss: 0.004679638892412186 Validation Loss: 0.006196834146976471\n",
      "5938 Training Loss: 0.005675991997122765 Validation Loss: 0.006273153703659773\n",
      "5939 Training Loss: 0.0051524583250284195 Validation Loss: 0.006305476650595665\n",
      "5940 Training Loss: 0.007063613273203373 Validation Loss: 0.00639653205871582\n",
      "5941 Training Loss: 0.004852107260376215 Validation Loss: 0.006369478534907103\n",
      "5942 Training Loss: 0.004644500091671944 Validation Loss: 0.0062935082241892815\n",
      "5943 Training Loss: 0.005303518380969763 Validation Loss: 0.006245155818760395\n",
      "5944 Training Loss: 0.005765862762928009 Validation Loss: 0.006223132833838463\n",
      "5945 Training Loss: 0.004975055810064077 Validation Loss: 0.006124059669673443\n",
      "5946 Training Loss: 0.004967484623193741 Validation Loss: 0.005961802322417498\n",
      "5947 Training Loss: 0.004982761573046446 Validation Loss: 0.005835540127009153\n",
      "5948 Training Loss: 0.005176668055355549 Validation Loss: 0.005735771730542183\n",
      "5949 Training Loss: 0.005384485702961683 Validation Loss: 0.00569152319803834\n",
      "5950 Training Loss: 0.005435706581920385 Validation Loss: 0.005681548733264208\n",
      "5951 Training Loss: 0.005639619659632444 Validation Loss: 0.005698477849364281\n",
      "5952 Training Loss: 0.006539176218211651 Validation Loss: 0.005743075627833605\n",
      "5953 Training Loss: 0.005662457551807165 Validation Loss: 0.005872322246432304\n",
      "5954 Training Loss: 0.004840415436774492 Validation Loss: 0.0059774997644126415\n",
      "5955 Training Loss: 0.005177936516702175 Validation Loss: 0.006055484060198069\n",
      "5956 Training Loss: 0.005704495124518871 Validation Loss: 0.006083695683628321\n",
      "5957 Training Loss: 0.004923343658447266 Validation Loss: 0.006091485731303692\n",
      "5958 Training Loss: 0.0047160424292087555 Validation Loss: 0.0061212885193526745\n",
      "5959 Training Loss: 0.0058039347641170025 Validation Loss: 0.006184530444443226\n",
      "5960 Training Loss: 0.005091817118227482 Validation Loss: 0.006191329564899206\n",
      "5961 Training Loss: 0.007596057839691639 Validation Loss: 0.006297748535871506\n",
      "5962 Training Loss: 0.007523539941757917 Validation Loss: 0.006407842040061951\n",
      "5963 Training Loss: 0.004863380454480648 Validation Loss: 0.006440230645239353\n",
      "5964 Training Loss: 0.004909779876470566 Validation Loss: 0.006527275778353214\n",
      "5965 Training Loss: 0.006126224063336849 Validation Loss: 0.006686765234917402\n",
      "5966 Training Loss: 0.0052483477629721165 Validation Loss: 0.006711981724947691\n",
      "5967 Training Loss: 0.0065416814759373665 Validation Loss: 0.006778036244213581\n",
      "5968 Training Loss: 0.004506064113229513 Validation Loss: 0.00674024922773242\n",
      "5969 Training Loss: 0.006943054497241974 Validation Loss: 0.006710359826683998\n",
      "5970 Training Loss: 0.0046584573574364185 Validation Loss: 0.006575068458914757\n",
      "5971 Training Loss: 0.004752063658088446 Validation Loss: 0.006407283246517181\n",
      "5972 Training Loss: 0.005825224332511425 Validation Loss: 0.006302926689386368\n",
      "5973 Training Loss: 0.007154689636081457 Validation Loss: 0.006235436536371708\n",
      "5974 Training Loss: 0.004465816542506218 Validation Loss: 0.006200809497386217\n",
      "5975 Training Loss: 0.005567543674260378 Validation Loss: 0.006154918111860752\n",
      "5976 Training Loss: 0.004626383539289236 Validation Loss: 0.006148581393063068\n",
      "5977 Training Loss: 0.004387788940221071 Validation Loss: 0.006132184527814388\n",
      "5978 Training Loss: 0.004800178110599518 Validation Loss: 0.006144639104604721\n",
      "5979 Training Loss: 0.0048338682390749454 Validation Loss: 0.006195105612277985\n",
      "5980 Training Loss: 0.005552500020712614 Validation Loss: 0.006209246814250946\n",
      "5981 Training Loss: 0.00438651954755187 Validation Loss: 0.006203006953001022\n",
      "5982 Training Loss: 0.007151715457439423 Validation Loss: 0.006211881525814533\n",
      "5983 Training Loss: 0.005063926335424185 Validation Loss: 0.006137609947472811\n",
      "5984 Training Loss: 0.005526348017156124 Validation Loss: 0.006125130690634251\n",
      "5985 Training Loss: 0.005741342902183533 Validation Loss: 0.006222102791070938\n",
      "5986 Training Loss: 0.006835849955677986 Validation Loss: 0.0063641490414738655\n",
      "5987 Training Loss: 0.005418516229838133 Validation Loss: 0.006451070308685303\n",
      "5988 Training Loss: 0.004561054520308971 Validation Loss: 0.0064275553449988365\n",
      "5989 Training Loss: 0.004366757348179817 Validation Loss: 0.0063549065962433815\n",
      "5990 Training Loss: 0.00607307069003582 Validation Loss: 0.006261416245251894\n",
      "5991 Training Loss: 0.005312290973961353 Validation Loss: 0.006097865290939808\n",
      "5992 Training Loss: 0.008633873425424099 Validation Loss: 0.006109250243753195\n",
      "5993 Training Loss: 0.0047696297988295555 Validation Loss: 0.006067162379622459\n",
      "5994 Training Loss: 0.006552407518029213 Validation Loss: 0.006057091988623142\n",
      "5995 Training Loss: 0.006363501772284508 Validation Loss: 0.006114608608186245\n",
      "5996 Training Loss: 0.004866320174187422 Validation Loss: 0.0060933432541787624\n",
      "5997 Training Loss: 0.005353091284632683 Validation Loss: 0.006055503152310848\n",
      "5998 Training Loss: 0.004533866886049509 Validation Loss: 0.005996416788548231\n",
      "5999 Training Loss: 0.005364881828427315 Validation Loss: 0.005892609246075153\n",
      "6000 Training Loss: 0.005451597273349762 Validation Loss: 0.00574150774627924\n",
      "6001 Training Loss: 0.004391220863908529 Validation Loss: 0.005670570768415928\n",
      "6002 Training Loss: 0.0051934318616986275 Validation Loss: 0.00561862625181675\n",
      "6003 Training Loss: 0.0047010453417897224 Validation Loss: 0.005612594075500965\n",
      "6004 Training Loss: 0.00499341357499361 Validation Loss: 0.00565838348120451\n",
      "6005 Training Loss: 0.005063430406153202 Validation Loss: 0.005762218497693539\n",
      "6006 Training Loss: 0.004377632401883602 Validation Loss: 0.005918815732002258\n",
      "6007 Training Loss: 0.006098615005612373 Validation Loss: 0.006147933192551136\n",
      "6008 Training Loss: 0.0048577506095170975 Validation Loss: 0.006485943216830492\n",
      "6009 Training Loss: 0.0045778099447488785 Validation Loss: 0.0067870705388486385\n",
      "6010 Training Loss: 0.0052457330748438835 Validation Loss: 0.007033277302980423\n",
      "6011 Training Loss: 0.006424020975828171 Validation Loss: 0.006991459522396326\n",
      "6012 Training Loss: 0.00628820713609457 Validation Loss: 0.006804824806749821\n",
      "6013 Training Loss: 0.004991332069039345 Validation Loss: 0.006478884257376194\n",
      "6014 Training Loss: 0.005023816600441933 Validation Loss: 0.006091022398322821\n",
      "6015 Training Loss: 0.005813858471810818 Validation Loss: 0.005809263791888952\n",
      "6016 Training Loss: 0.004817396402359009 Validation Loss: 0.005625660996884108\n",
      "6017 Training Loss: 0.004891699645668268 Validation Loss: 0.005540149286389351\n",
      "6018 Training Loss: 0.004158974625170231 Validation Loss: 0.00549278361722827\n",
      "6019 Training Loss: 0.004636099096387625 Validation Loss: 0.00545745063573122\n",
      "6020 Training Loss: 0.004522685427218676 Validation Loss: 0.005438646301627159\n",
      "6021 Training Loss: 0.007535042241215706 Validation Loss: 0.00547668244689703\n",
      "6022 Training Loss: 0.004618238657712936 Validation Loss: 0.005569402128458023\n",
      "6023 Training Loss: 0.004784395918250084 Validation Loss: 0.00575175229460001\n",
      "6024 Training Loss: 0.005697878077626228 Validation Loss: 0.006028524599969387\n",
      "6025 Training Loss: 0.00557752326130867 Validation Loss: 0.006325924769043922\n",
      "6026 Training Loss: 0.004320616368204355 Validation Loss: 0.006505646742880344\n",
      "6027 Training Loss: 0.005447612144052982 Validation Loss: 0.006624555680900812\n",
      "6028 Training Loss: 0.005208916962146759 Validation Loss: 0.006546573713421822\n",
      "6029 Training Loss: 0.004851474426686764 Validation Loss: 0.0063873701728880405\n",
      "6030 Training Loss: 0.00415204931050539 Validation Loss: 0.006284141913056374\n",
      "6031 Training Loss: 0.0060278307646512985 Validation Loss: 0.006246090400964022\n",
      "6032 Training Loss: 0.006632519420236349 Validation Loss: 0.0062942830845713615\n",
      "6033 Training Loss: 0.004932505078613758 Validation Loss: 0.006382929161190987\n",
      "6034 Training Loss: 0.00485973572358489 Validation Loss: 0.006361379753798246\n",
      "6035 Training Loss: 0.007394037209451199 Validation Loss: 0.006346279289573431\n",
      "6036 Training Loss: 0.0072752973064780235 Validation Loss: 0.00637830700725317\n",
      "6037 Training Loss: 0.0052039059810340405 Validation Loss: 0.006211191415786743\n",
      "6038 Training Loss: 0.005652767606079578 Validation Loss: 0.006004730239510536\n",
      "6039 Training Loss: 0.0047308215871453285 Validation Loss: 0.005798881873488426\n",
      "6040 Training Loss: 0.00506241712719202 Validation Loss: 0.005697496235370636\n",
      "6041 Training Loss: 0.004572110250592232 Validation Loss: 0.005642717704176903\n",
      "6042 Training Loss: 0.0059291343204677105 Validation Loss: 0.005673328414559364\n",
      "6043 Training Loss: 0.0047040656208992004 Validation Loss: 0.005706137977540493\n",
      "6044 Training Loss: 0.006163544021546841 Validation Loss: 0.005801979452371597\n",
      "6045 Training Loss: 0.004525419790297747 Validation Loss: 0.005902763456106186\n",
      "6046 Training Loss: 0.004191019106656313 Validation Loss: 0.006022314075380564\n",
      "6047 Training Loss: 0.004994184244424105 Validation Loss: 0.006120952777564526\n",
      "6048 Training Loss: 0.004984978586435318 Validation Loss: 0.006092259660363197\n",
      "6049 Training Loss: 0.004387762397527695 Validation Loss: 0.006033723708242178\n",
      "6050 Training Loss: 0.005647309124469757 Validation Loss: 0.005855271592736244\n",
      "6051 Training Loss: 0.004804468713700771 Validation Loss: 0.005703212693333626\n",
      "6052 Training Loss: 0.004434027709066868 Validation Loss: 0.005585446022450924\n",
      "6053 Training Loss: 0.004393458366394043 Validation Loss: 0.005498066078871489\n",
      "6054 Training Loss: 0.00477635907009244 Validation Loss: 0.005428489297628403\n",
      "6055 Training Loss: 0.004225291311740875 Validation Loss: 0.005388767458498478\n",
      "6056 Training Loss: 0.004237684886902571 Validation Loss: 0.00536547414958477\n",
      "6057 Training Loss: 0.004202009178698063 Validation Loss: 0.005353198386728764\n",
      "6058 Training Loss: 0.004966228734701872 Validation Loss: 0.0053486451506614685\n",
      "6059 Training Loss: 0.006505485624074936 Validation Loss: 0.005406899377703667\n",
      "6060 Training Loss: 0.005699802190065384 Validation Loss: 0.005564026068896055\n",
      "6061 Training Loss: 0.00416172482073307 Validation Loss: 0.005751082208007574\n",
      "6062 Training Loss: 0.006046058610081673 Validation Loss: 0.0059710536152124405\n",
      "6063 Training Loss: 0.005261329002678394 Validation Loss: 0.006088924594223499\n",
      "6064 Training Loss: 0.004856727086007595 Validation Loss: 0.006091082468628883\n",
      "6065 Training Loss: 0.005404102616012096 Validation Loss: 0.00600324897095561\n",
      "6066 Training Loss: 0.0048554521054029465 Validation Loss: 0.00583491800352931\n",
      "6067 Training Loss: 0.004957512021064758 Validation Loss: 0.005717447493225336\n",
      "6068 Training Loss: 0.004347155336290598 Validation Loss: 0.005629862658679485\n",
      "6069 Training Loss: 0.0051097809337079525 Validation Loss: 0.005567657761275768\n",
      "6070 Training Loss: 0.0048142485320568085 Validation Loss: 0.005496485158801079\n",
      "6071 Training Loss: 0.0045435247011482716 Validation Loss: 0.005425219424068928\n",
      "6072 Training Loss: 0.006912757642567158 Validation Loss: 0.00539324851706624\n",
      "6073 Training Loss: 0.004163184203207493 Validation Loss: 0.005417156498879194\n",
      "6074 Training Loss: 0.0045532165095210075 Validation Loss: 0.005507958121597767\n",
      "6075 Training Loss: 0.004975009709596634 Validation Loss: 0.005540135316550732\n",
      "6076 Training Loss: 0.004631103482097387 Validation Loss: 0.005509829148650169\n",
      "6077 Training Loss: 0.005557107273489237 Validation Loss: 0.005519465543329716\n",
      "6078 Training Loss: 0.004465771373361349 Validation Loss: 0.005453888792544603\n",
      "6079 Training Loss: 0.004681069403886795 Validation Loss: 0.005463093519210815\n",
      "6080 Training Loss: 0.004289873410016298 Validation Loss: 0.00548990024253726\n",
      "6081 Training Loss: 0.00412994809448719 Validation Loss: 0.0055413618683815\n",
      "6082 Training Loss: 0.0041513098403811455 Validation Loss: 0.005618215538561344\n",
      "6083 Training Loss: 0.005646332632750273 Validation Loss: 0.0057632350362837315\n",
      "6084 Training Loss: 0.0053983936086297035 Validation Loss: 0.0058339438401162624\n",
      "6085 Training Loss: 0.005185293965041637 Validation Loss: 0.005911094602197409\n",
      "6086 Training Loss: 0.004376146476715803 Validation Loss: 0.005923270247876644\n",
      "6087 Training Loss: 0.004014169331640005 Validation Loss: 0.005900051444768906\n",
      "6088 Training Loss: 0.004424854181706905 Validation Loss: 0.005829900968819857\n",
      "6089 Training Loss: 0.004943836480379105 Validation Loss: 0.00568263977766037\n",
      "6090 Training Loss: 0.0051089562475681305 Validation Loss: 0.005600525066256523\n",
      "6091 Training Loss: 0.004358204081654549 Validation Loss: 0.005533299408853054\n",
      "6092 Training Loss: 0.00498490734025836 Validation Loss: 0.005409613251686096\n",
      "6093 Training Loss: 0.004434735514223576 Validation Loss: 0.005339247174561024\n",
      "6094 Training Loss: 0.004181856755167246 Validation Loss: 0.005306258797645569\n",
      "6095 Training Loss: 0.004022648558020592 Validation Loss: 0.0053169745951890945\n",
      "6096 Training Loss: 0.004229889716953039 Validation Loss: 0.005347567610442638\n",
      "6097 Training Loss: 0.004590794909745455 Validation Loss: 0.005408922675997019\n",
      "6098 Training Loss: 0.007440944667905569 Validation Loss: 0.0054834685288369656\n",
      "6099 Training Loss: 0.003994569648057222 Validation Loss: 0.0055746641010046005\n",
      "6100 Training Loss: 0.004242182243615389 Validation Loss: 0.0056795175187289715\n",
      "6101 Training Loss: 0.00442609004676342 Validation Loss: 0.005715933162719011\n",
      "6102 Training Loss: 0.006502937991172075 Validation Loss: 0.00576129462569952\n",
      "6103 Training Loss: 0.0040321312844753265 Validation Loss: 0.005771116353571415\n",
      "6104 Training Loss: 0.004826641175895929 Validation Loss: 0.0056915609166026115\n",
      "6105 Training Loss: 0.004395069554448128 Validation Loss: 0.005583474412560463\n",
      "6106 Training Loss: 0.007050660904496908 Validation Loss: 0.005649831611663103\n",
      "6107 Training Loss: 0.00424418319016695 Validation Loss: 0.005725100636482239\n",
      "6108 Training Loss: 0.00576163362711668 Validation Loss: 0.005810907576233149\n",
      "6109 Training Loss: 0.004587414674460888 Validation Loss: 0.005822524894028902\n",
      "6110 Training Loss: 0.004210728220641613 Validation Loss: 0.005745189264416695\n",
      "6111 Training Loss: 0.006384480744600296 Validation Loss: 0.005691719241440296\n",
      "6112 Training Loss: 0.004191509447991848 Validation Loss: 0.005599068943411112\n",
      "6113 Training Loss: 0.004127605818212032 Validation Loss: 0.00550408661365509\n",
      "6114 Training Loss: 0.004756864160299301 Validation Loss: 0.005403525196015835\n",
      "6115 Training Loss: 0.004226352088153362 Validation Loss: 0.005339699797332287\n",
      "6116 Training Loss: 0.005376145709306002 Validation Loss: 0.005338857416063547\n",
      "6117 Training Loss: 0.004185511264950037 Validation Loss: 0.005358743481338024\n",
      "6118 Training Loss: 0.004446200095117092 Validation Loss: 0.005340719595551491\n",
      "6119 Training Loss: 0.00439494801685214 Validation Loss: 0.005297979339957237\n",
      "6120 Training Loss: 0.004455510061234236 Validation Loss: 0.005220670253038406\n",
      "6121 Training Loss: 0.004421154037117958 Validation Loss: 0.005173172801733017\n",
      "6122 Training Loss: 0.005556031130254269 Validation Loss: 0.005167950410395861\n",
      "6123 Training Loss: 0.004086492117494345 Validation Loss: 0.005171090364456177\n",
      "6124 Training Loss: 0.004027900286018848 Validation Loss: 0.005178725812584162\n",
      "6125 Training Loss: 0.008531833067536354 Validation Loss: 0.005263525526970625\n",
      "6126 Training Loss: 0.0068161217495799065 Validation Loss: 0.005396253429353237\n",
      "6127 Training Loss: 0.004564377944916487 Validation Loss: 0.005481352098286152\n",
      "6128 Training Loss: 0.004453270696103573 Validation Loss: 0.005466360133141279\n",
      "6129 Training Loss: 0.005206427536904812 Validation Loss: 0.005481357220560312\n",
      "6130 Training Loss: 0.0044605787843465805 Validation Loss: 0.005408153869211674\n",
      "6131 Training Loss: 0.005242394283413887 Validation Loss: 0.005326207727193832\n",
      "6132 Training Loss: 0.006630283780395985 Validation Loss: 0.005313072353601456\n",
      "6133 Training Loss: 0.004271392710506916 Validation Loss: 0.005283040925860405\n",
      "6134 Training Loss: 0.004271536599844694 Validation Loss: 0.005283544771373272\n",
      "6135 Training Loss: 0.006480605807155371 Validation Loss: 0.005304872058331966\n",
      "6136 Training Loss: 0.006696798838675022 Validation Loss: 0.005348555743694305\n",
      "6137 Training Loss: 0.004200243856757879 Validation Loss: 0.005395573563873768\n",
      "6138 Training Loss: 0.0045989579521119595 Validation Loss: 0.005460334941744804\n",
      "6139 Training Loss: 0.005026802886277437 Validation Loss: 0.005481812637299299\n",
      "6140 Training Loss: 0.004829448647797108 Validation Loss: 0.0054375240579247475\n",
      "6141 Training Loss: 0.005466182716190815 Validation Loss: 0.005339118652045727\n",
      "6142 Training Loss: 0.003936286084353924 Validation Loss: 0.005250105634331703\n",
      "6143 Training Loss: 0.00468812370672822 Validation Loss: 0.005224148742854595\n",
      "6144 Training Loss: 0.0047627161256968975 Validation Loss: 0.0052395714446902275\n",
      "6145 Training Loss: 0.0055657364428043365 Validation Loss: 0.005317251197993755\n",
      "6146 Training Loss: 0.004041049629449844 Validation Loss: 0.005380889400839806\n",
      "6147 Training Loss: 0.005550037138164043 Validation Loss: 0.005478091537952423\n",
      "6148 Training Loss: 0.006550902500748634 Validation Loss: 0.005571933928877115\n",
      "6149 Training Loss: 0.006246296688914299 Validation Loss: 0.005717686843127012\n",
      "6150 Training Loss: 0.004468240309506655 Validation Loss: 0.0057050324976444244\n",
      "6151 Training Loss: 0.004518474452197552 Validation Loss: 0.0056760977022349834\n",
      "6152 Training Loss: 0.005527399480342865 Validation Loss: 0.005607245955616236\n",
      "6153 Training Loss: 0.004424892365932465 Validation Loss: 0.005590138025581837\n",
      "6154 Training Loss: 0.006176663562655449 Validation Loss: 0.005621321499347687\n",
      "6155 Training Loss: 0.004735549911856651 Validation Loss: 0.005715234205126762\n",
      "6156 Training Loss: 0.00470370939001441 Validation Loss: 0.005809710826724768\n",
      "6157 Training Loss: 0.004747655708342791 Validation Loss: 0.005706235766410828\n",
      "6158 Training Loss: 0.004115913063287735 Validation Loss: 0.005626216065138578\n",
      "6159 Training Loss: 0.004409899935126305 Validation Loss: 0.005579814314842224\n",
      "6160 Training Loss: 0.004240829031914473 Validation Loss: 0.005559190176427364\n",
      "6161 Training Loss: 0.003986092284321785 Validation Loss: 0.0055197314359247684\n",
      "6162 Training Loss: 0.004757792688906193 Validation Loss: 0.005418947897851467\n",
      "6163 Training Loss: 0.004243132192641497 Validation Loss: 0.005366378463804722\n",
      "6164 Training Loss: 0.004788027610629797 Validation Loss: 0.005303103942424059\n",
      "6165 Training Loss: 0.004565724171698093 Validation Loss: 0.0052528404630720615\n",
      "6166 Training Loss: 0.004448718391358852 Validation Loss: 0.005283636040985584\n",
      "6167 Training Loss: 0.0040560453198850155 Validation Loss: 0.005363409407436848\n",
      "6168 Training Loss: 0.006689851172268391 Validation Loss: 0.005521097220480442\n",
      "6169 Training Loss: 0.006326809525489807 Validation Loss: 0.005760404746979475\n",
      "6170 Training Loss: 0.003931689076125622 Validation Loss: 0.005916479974985123\n",
      "6171 Training Loss: 0.006325152702629566 Validation Loss: 0.006049243733286858\n",
      "6172 Training Loss: 0.004348022397607565 Validation Loss: 0.005992447026073933\n",
      "6173 Training Loss: 0.005922575946897268 Validation Loss: 0.00597732700407505\n",
      "6174 Training Loss: 0.005755847319960594 Validation Loss: 0.0059413299895823\n",
      "6175 Training Loss: 0.00459621986374259 Validation Loss: 0.0058199744671583176\n",
      "6176 Training Loss: 0.004473061766475439 Validation Loss: 0.005636177025735378\n",
      "6177 Training Loss: 0.004220588132739067 Validation Loss: 0.005475553683936596\n",
      "6178 Training Loss: 0.005654593929648399 Validation Loss: 0.005387656856328249\n",
      "6179 Training Loss: 0.004133731126785278 Validation Loss: 0.005303793121129274\n",
      "6180 Training Loss: 0.004112930502742529 Validation Loss: 0.00524412514641881\n",
      "6181 Training Loss: 0.003929593600332737 Validation Loss: 0.0052061062306165695\n",
      "6182 Training Loss: 0.003998655825853348 Validation Loss: 0.005206608213484287\n",
      "6183 Training Loss: 0.004197744652628899 Validation Loss: 0.0052629634737968445\n",
      "6184 Training Loss: 0.004148955922573805 Validation Loss: 0.005341052543371916\n",
      "6185 Training Loss: 0.0045916237868368626 Validation Loss: 0.005400947295129299\n",
      "6186 Training Loss: 0.004017355851829052 Validation Loss: 0.005418025888502598\n",
      "6187 Training Loss: 0.004005844239145517 Validation Loss: 0.0053899846971035\n",
      "6188 Training Loss: 0.004745436832308769 Validation Loss: 0.005384841468185186\n",
      "6189 Training Loss: 0.005267512984573841 Validation Loss: 0.005367799196392298\n",
      "6190 Training Loss: 0.006056454498320818 Validation Loss: 0.005357886198908091\n",
      "6191 Training Loss: 0.005375106818974018 Validation Loss: 0.005410905461758375\n",
      "6192 Training Loss: 0.005009138025343418 Validation Loss: 0.00540974410250783\n",
      "6193 Training Loss: 0.004370748996734619 Validation Loss: 0.005339388735592365\n",
      "6194 Training Loss: 0.006093339994549751 Validation Loss: 0.005305613856762648\n",
      "6195 Training Loss: 0.00520333694294095 Validation Loss: 0.005348048638552427\n",
      "6196 Training Loss: 0.004518526140600443 Validation Loss: 0.005441445857286453\n",
      "6197 Training Loss: 0.00463952636346221 Validation Loss: 0.005436582490801811\n",
      "6198 Training Loss: 0.004400534089654684 Validation Loss: 0.005394450388848782\n",
      "6199 Training Loss: 0.004524293355643749 Validation Loss: 0.005378894042223692\n",
      "6200 Training Loss: 0.004406210035085678 Validation Loss: 0.005323158111423254\n",
      "6201 Training Loss: 0.0041359285824000835 Validation Loss: 0.005282032303512096\n",
      "6202 Training Loss: 0.004196658730506897 Validation Loss: 0.005247702822089195\n",
      "6203 Training Loss: 0.003863580757752061 Validation Loss: 0.005246574990451336\n",
      "6204 Training Loss: 0.0037071749102324247 Validation Loss: 0.005300913937389851\n",
      "6205 Training Loss: 0.00616398174315691 Validation Loss: 0.005426147021353245\n",
      "6206 Training Loss: 0.00450805202126503 Validation Loss: 0.005546916741877794\n",
      "6207 Training Loss: 0.004251300357282162 Validation Loss: 0.005618447437882423\n",
      "6208 Training Loss: 0.003743247129023075 Validation Loss: 0.0056868358515203\n",
      "6209 Training Loss: 0.004658707417547703 Validation Loss: 0.005672996398061514\n",
      "6210 Training Loss: 0.004767247475683689 Validation Loss: 0.0054709878750145435\n",
      "6211 Training Loss: 0.0038251946680247784 Validation Loss: 0.005283658392727375\n",
      "6212 Training Loss: 0.0038112476468086243 Validation Loss: 0.005178382620215416\n",
      "6213 Training Loss: 0.006035435013473034 Validation Loss: 0.005116020329296589\n",
      "6214 Training Loss: 0.00471966527402401 Validation Loss: 0.0050347549840807915\n",
      "6215 Training Loss: 0.004038630053400993 Validation Loss: 0.004999254364520311\n",
      "6216 Training Loss: 0.00421694852411747 Validation Loss: 0.0049997796304523945\n",
      "6217 Training Loss: 0.006196328904479742 Validation Loss: 0.005104407202452421\n",
      "6218 Training Loss: 0.004002206493169069 Validation Loss: 0.005228735506534576\n",
      "6219 Training Loss: 0.006438537500798702 Validation Loss: 0.00543099083006382\n",
      "6220 Training Loss: 0.004286061506718397 Validation Loss: 0.005473990924656391\n",
      "6221 Training Loss: 0.004094406962394714 Validation Loss: 0.00547332176938653\n",
      "6222 Training Loss: 0.004413255490362644 Validation Loss: 0.005449951160699129\n",
      "6223 Training Loss: 0.003941555507481098 Validation Loss: 0.005383337382227182\n",
      "6224 Training Loss: 0.004092903807759285 Validation Loss: 0.005273859482258558\n",
      "6225 Training Loss: 0.0036046113818883896 Validation Loss: 0.005225508473813534\n",
      "6226 Training Loss: 0.006067852023988962 Validation Loss: 0.0051850914023816586\n",
      "6227 Training Loss: 0.003897333052009344 Validation Loss: 0.005150866694748402\n",
      "6228 Training Loss: 0.003992351237684488 Validation Loss: 0.005118697416037321\n",
      "6229 Training Loss: 0.006123394705355167 Validation Loss: 0.005148874595761299\n",
      "6230 Training Loss: 0.004019701853394508 Validation Loss: 0.005264469888061285\n",
      "6231 Training Loss: 0.003902930300682783 Validation Loss: 0.005408917553722858\n",
      "6232 Training Loss: 0.00496619613841176 Validation Loss: 0.005653474014252424\n",
      "6233 Training Loss: 0.004356723744422197 Validation Loss: 0.0059016053564846516\n",
      "6234 Training Loss: 0.005171933677047491 Validation Loss: 0.006125261075794697\n",
      "6235 Training Loss: 0.004072153940796852 Validation Loss: 0.0061461832374334335\n",
      "6236 Training Loss: 0.004112273920327425 Validation Loss: 0.005978564266115427\n",
      "6237 Training Loss: 0.005931771360337734 Validation Loss: 0.005784973036497831\n",
      "6238 Training Loss: 0.004388520028442144 Validation Loss: 0.0055142114870250225\n",
      "6239 Training Loss: 0.003669094294309616 Validation Loss: 0.005341739393770695\n",
      "6240 Training Loss: 0.003922109492123127 Validation Loss: 0.005274484399706125\n",
      "6241 Training Loss: 0.005417509004473686 Validation Loss: 0.0052481116726994514\n",
      "6242 Training Loss: 0.003957815933972597 Validation Loss: 0.005265351850539446\n",
      "6243 Training Loss: 0.004013428930193186 Validation Loss: 0.005273854825645685\n",
      "6244 Training Loss: 0.004149004817008972 Validation Loss: 0.005278789903968573\n",
      "6245 Training Loss: 0.0038598799146711826 Validation Loss: 0.005287317559123039\n",
      "6246 Training Loss: 0.004610060714185238 Validation Loss: 0.005278910510241985\n",
      "6247 Training Loss: 0.005659592337906361 Validation Loss: 0.005219829268753529\n",
      "6248 Training Loss: 0.004412704613059759 Validation Loss: 0.005096216686069965\n",
      "6249 Training Loss: 0.0037332517094910145 Validation Loss: 0.004993618931621313\n",
      "6250 Training Loss: 0.0043699853122234344 Validation Loss: 0.00488548306748271\n",
      "6251 Training Loss: 0.00453364010900259 Validation Loss: 0.004854339174926281\n",
      "6252 Training Loss: 0.003724221372976899 Validation Loss: 0.00484813516959548\n",
      "6253 Training Loss: 0.0055972859263420105 Validation Loss: 0.004851657897233963\n",
      "6254 Training Loss: 0.004426758270710707 Validation Loss: 0.004889267962425947\n",
      "6255 Training Loss: 0.004416174255311489 Validation Loss: 0.004970661364495754\n",
      "6256 Training Loss: 0.006050347350537777 Validation Loss: 0.005058052949607372\n",
      "6257 Training Loss: 0.006079001352190971 Validation Loss: 0.005161861889064312\n",
      "6258 Training Loss: 0.0038436069153249264 Validation Loss: 0.005191454663872719\n",
      "6259 Training Loss: 0.005355976056307554 Validation Loss: 0.005232907831668854\n",
      "6260 Training Loss: 0.004583991132676601 Validation Loss: 0.005187570583075285\n",
      "6261 Training Loss: 0.004564901813864708 Validation Loss: 0.005103498697280884\n",
      "6262 Training Loss: 0.005425991490483284 Validation Loss: 0.005045068915933371\n",
      "6263 Training Loss: 0.00366043858230114 Validation Loss: 0.004984500352293253\n",
      "6264 Training Loss: 0.0038221057038754225 Validation Loss: 0.004931877367198467\n",
      "6265 Training Loss: 0.004734928719699383 Validation Loss: 0.004920979030430317\n",
      "6266 Training Loss: 0.005847093649208546 Validation Loss: 0.004953542724251747\n",
      "6267 Training Loss: 0.0042893486097455025 Validation Loss: 0.005068975035101175\n",
      "6268 Training Loss: 0.0039098868146538734 Validation Loss: 0.005219276063144207\n",
      "6269 Training Loss: 0.003937934525310993 Validation Loss: 0.005289613269269466\n",
      "6270 Training Loss: 0.004615293350070715 Validation Loss: 0.005351324565708637\n",
      "6271 Training Loss: 0.004450742620974779 Validation Loss: 0.005290927831083536\n",
      "6272 Training Loss: 0.005225266329944134 Validation Loss: 0.005315306130796671\n",
      "6273 Training Loss: 0.006099268794059753 Validation Loss: 0.00531747518107295\n",
      "6274 Training Loss: 0.004701557569205761 Validation Loss: 0.005248468369245529\n",
      "6275 Training Loss: 0.004026930313557386 Validation Loss: 0.00510026328265667\n",
      "6276 Training Loss: 0.0048181465826928616 Validation Loss: 0.0050343237817287445\n",
      "6277 Training Loss: 0.003738755127415061 Validation Loss: 0.00497315963730216\n",
      "6278 Training Loss: 0.004544488154351711 Validation Loss: 0.004952873103320599\n",
      "6279 Training Loss: 0.0038283877074718475 Validation Loss: 0.0049538807943463326\n",
      "6280 Training Loss: 0.003767513670027256 Validation Loss: 0.004977361764758825\n",
      "6281 Training Loss: 0.004036040976643562 Validation Loss: 0.0049786814488470554\n",
      "6282 Training Loss: 0.003957245498895645 Validation Loss: 0.004958911798894405\n",
      "6283 Training Loss: 0.003470471827313304 Validation Loss: 0.004967277869582176\n",
      "6284 Training Loss: 0.005901627242565155 Validation Loss: 0.005004149861633778\n",
      "6285 Training Loss: 0.004155086353421211 Validation Loss: 0.005020352080464363\n",
      "6286 Training Loss: 0.006662988103926182 Validation Loss: 0.00510461675003171\n",
      "6287 Training Loss: 0.004270266741514206 Validation Loss: 0.005166034679859877\n",
      "6288 Training Loss: 0.0037527885288000107 Validation Loss: 0.005159702617675066\n",
      "6289 Training Loss: 0.004563578404486179 Validation Loss: 0.005061508622020483\n",
      "6290 Training Loss: 0.003831020789220929 Validation Loss: 0.004971013404428959\n",
      "6291 Training Loss: 0.0037822206504642963 Validation Loss: 0.004894423298537731\n",
      "6292 Training Loss: 0.003798362333327532 Validation Loss: 0.0048548374325037\n",
      "6293 Training Loss: 0.00389578053727746 Validation Loss: 0.0048536257818341255\n",
      "6294 Training Loss: 0.004302101209759712 Validation Loss: 0.004884567577391863\n",
      "6295 Training Loss: 0.0043844361789524555 Validation Loss: 0.0049090008251369\n",
      "6296 Training Loss: 0.0036237752065062523 Validation Loss: 0.004985028877854347\n",
      "6297 Training Loss: 0.0036890790797770023 Validation Loss: 0.005079810973256826\n",
      "6298 Training Loss: 0.003689095377922058 Validation Loss: 0.005158904939889908\n",
      "6299 Training Loss: 0.003919682465493679 Validation Loss: 0.005242227576673031\n",
      "6300 Training Loss: 0.004014124162495136 Validation Loss: 0.005250310059636831\n",
      "6301 Training Loss: 0.004085947759449482 Validation Loss: 0.005247022490948439\n",
      "6302 Training Loss: 0.003606111276894808 Validation Loss: 0.005248534958809614\n",
      "6303 Training Loss: 0.003711730008944869 Validation Loss: 0.00521541852504015\n",
      "6304 Training Loss: 0.004838453605771065 Validation Loss: 0.00516246072947979\n",
      "6305 Training Loss: 0.005726302042603493 Validation Loss: 0.005179883446544409\n",
      "6306 Training Loss: 0.003940723370760679 Validation Loss: 0.005179218016564846\n",
      "6307 Training Loss: 0.005130612291395664 Validation Loss: 0.0051341429352760315\n",
      "6308 Training Loss: 0.00496870931237936 Validation Loss: 0.005052416585385799\n",
      "6309 Training Loss: 0.004050583578646183 Validation Loss: 0.004985729232430458\n",
      "6310 Training Loss: 0.0040188077837228775 Validation Loss: 0.0049769142642617226\n",
      "6311 Training Loss: 0.0038893718738108873 Validation Loss: 0.004975582472980022\n",
      "6312 Training Loss: 0.005392922088503838 Validation Loss: 0.0049425396136939526\n",
      "6313 Training Loss: 0.004464656580239534 Validation Loss: 0.004849222023040056\n",
      "6314 Training Loss: 0.006864175666123629 Validation Loss: 0.004846401046961546\n",
      "6315 Training Loss: 0.00510262418538332 Validation Loss: 0.00484209880232811\n",
      "6316 Training Loss: 0.0041243950836360455 Validation Loss: 0.004785061813890934\n",
      "6317 Training Loss: 0.003936524037271738 Validation Loss: 0.004719754680991173\n",
      "6318 Training Loss: 0.0035585276782512665 Validation Loss: 0.00468617957085371\n",
      "6319 Training Loss: 0.006826487835496664 Validation Loss: 0.004733233246952295\n",
      "6320 Training Loss: 0.0034885983914136887 Validation Loss: 0.0048023550771176815\n",
      "6321 Training Loss: 0.004954379051923752 Validation Loss: 0.004958885721862316\n",
      "6322 Training Loss: 0.00408910121768713 Validation Loss: 0.00510774552822113\n",
      "6323 Training Loss: 0.004520665854215622 Validation Loss: 0.005228584166616201\n",
      "6324 Training Loss: 0.004734531976282597 Validation Loss: 0.005185524467378855\n",
      "6325 Training Loss: 0.003790374379605055 Validation Loss: 0.005084778182208538\n",
      "6326 Training Loss: 0.003573773894459009 Validation Loss: 0.0049868179485201836\n",
      "6327 Training Loss: 0.003338312264531851 Validation Loss: 0.0049160318449139595\n",
      "6328 Training Loss: 0.003523746272549033 Validation Loss: 0.004861385095864534\n",
      "6329 Training Loss: 0.004723460413515568 Validation Loss: 0.004822262562811375\n",
      "6330 Training Loss: 0.003411946352571249 Validation Loss: 0.004806072451174259\n",
      "6331 Training Loss: 0.004831891506910324 Validation Loss: 0.0048374575562775135\n",
      "6332 Training Loss: 0.005003608763217926 Validation Loss: 0.0049612680450081825\n",
      "6333 Training Loss: 0.0039025582373142242 Validation Loss: 0.005059199873358011\n",
      "6334 Training Loss: 0.004013405181467533 Validation Loss: 0.005078901536762714\n",
      "6335 Training Loss: 0.0035941586829721928 Validation Loss: 0.005029468331485987\n",
      "6336 Training Loss: 0.0038916687481105328 Validation Loss: 0.004915271885693073\n",
      "6337 Training Loss: 0.00444032670930028 Validation Loss: 0.0048091174103319645\n",
      "6338 Training Loss: 0.0044134194031357765 Validation Loss: 0.004765188321471214\n",
      "6339 Training Loss: 0.004759505391120911 Validation Loss: 0.004776265472173691\n",
      "6340 Training Loss: 0.005454717203974724 Validation Loss: 0.004789117723703384\n",
      "6341 Training Loss: 0.005898754112422466 Validation Loss: 0.004891663324087858\n",
      "6342 Training Loss: 0.003690759651362896 Validation Loss: 0.004972176160663366\n",
      "6343 Training Loss: 0.004988785367459059 Validation Loss: 0.0050240326672792435\n",
      "6344 Training Loss: 0.003739424981176853 Validation Loss: 0.004996305797249079\n",
      "6345 Training Loss: 0.005140691064298153 Validation Loss: 0.004973997361958027\n",
      "6346 Training Loss: 0.0046919966116547585 Validation Loss: 0.004969669505953789\n",
      "6347 Training Loss: 0.003637993009760976 Validation Loss: 0.0049896324053406715\n",
      "6348 Training Loss: 0.0037829880602657795 Validation Loss: 0.0049591949209570885\n",
      "6349 Training Loss: 0.0034670017194002867 Validation Loss: 0.004957086872309446\n",
      "6350 Training Loss: 0.0033441707491874695 Validation Loss: 0.0049707647413015366\n",
      "6351 Training Loss: 0.00413675419986248 Validation Loss: 0.004990556742995977\n",
      "6352 Training Loss: 0.004298006184399128 Validation Loss: 0.004978474695235491\n",
      "6353 Training Loss: 0.0034355672542005777 Validation Loss: 0.004962955601513386\n",
      "6354 Training Loss: 0.004506210796535015 Validation Loss: 0.004916952457278967\n",
      "6355 Training Loss: 0.004243273288011551 Validation Loss: 0.004858901724219322\n",
      "6356 Training Loss: 0.004002689383924007 Validation Loss: 0.004832586273550987\n",
      "6357 Training Loss: 0.003672122023999691 Validation Loss: 0.004793100990355015\n",
      "6358 Training Loss: 0.004255517385900021 Validation Loss: 0.0047791823744773865\n",
      "6359 Training Loss: 0.0034450578968971968 Validation Loss: 0.004772513173520565\n",
      "6360 Training Loss: 0.0034440145827829838 Validation Loss: 0.004756488837301731\n",
      "6361 Training Loss: 0.003722486551851034 Validation Loss: 0.004770074505358934\n",
      "6362 Training Loss: 0.0036162282340228558 Validation Loss: 0.004786553792655468\n",
      "6363 Training Loss: 0.00346330925822258 Validation Loss: 0.004807241261005402\n",
      "6364 Training Loss: 0.0036402156110852957 Validation Loss: 0.004842136055231094\n",
      "6365 Training Loss: 0.0043839444406330585 Validation Loss: 0.0048962244763970375\n",
      "6366 Training Loss: 0.0035715128760784864 Validation Loss: 0.004951163195073605\n",
      "6367 Training Loss: 0.0041356878355145454 Validation Loss: 0.004994799382984638\n",
      "6368 Training Loss: 0.004880816210061312 Validation Loss: 0.005059496965259314\n",
      "6369 Training Loss: 0.003384245093911886 Validation Loss: 0.005113687366247177\n",
      "6370 Training Loss: 0.0035154540091753006 Validation Loss: 0.005107711534947157\n",
      "6371 Training Loss: 0.006246225908398628 Validation Loss: 0.005168284755200148\n",
      "6372 Training Loss: 0.00608487892895937 Validation Loss: 0.00527387298643589\n",
      "6373 Training Loss: 0.004067852161824703 Validation Loss: 0.005350193008780479\n",
      "6374 Training Loss: 0.004452194552868605 Validation Loss: 0.005330846179276705\n",
      "6375 Training Loss: 0.003971931524574757 Validation Loss: 0.005155608523637056\n",
      "6376 Training Loss: 0.004219084046781063 Validation Loss: 0.004868213087320328\n",
      "6377 Training Loss: 0.004255227744579315 Validation Loss: 0.004705879371613264\n",
      "6378 Training Loss: 0.0033630849793553352 Validation Loss: 0.004643986467272043\n",
      "6379 Training Loss: 0.0042597707360982895 Validation Loss: 0.004631881136447191\n",
      "6380 Training Loss: 0.0038014384917914867 Validation Loss: 0.004620983265340328\n",
      "6381 Training Loss: 0.004405836574733257 Validation Loss: 0.00461544468998909\n",
      "6382 Training Loss: 0.003995854407548904 Validation Loss: 0.0046291109174489975\n",
      "6383 Training Loss: 0.004396623931825161 Validation Loss: 0.004679952748119831\n",
      "6384 Training Loss: 0.004133534152060747 Validation Loss: 0.004730880726128817\n",
      "6385 Training Loss: 0.0036932947114109993 Validation Loss: 0.00476966705173254\n",
      "6386 Training Loss: 0.003669461701065302 Validation Loss: 0.0048170932568609715\n",
      "6387 Training Loss: 0.0037262828554958105 Validation Loss: 0.004857371561229229\n",
      "6388 Training Loss: 0.0034375577233731747 Validation Loss: 0.004874047357589006\n",
      "6389 Training Loss: 0.003731226082891226 Validation Loss: 0.004905018489807844\n",
      "6390 Training Loss: 0.003962813876569271 Validation Loss: 0.0049025509506464005\n",
      "6391 Training Loss: 0.0038308249786496162 Validation Loss: 0.004846013151109219\n",
      "6392 Training Loss: 0.004030551295727491 Validation Loss: 0.004723620135337114\n",
      "6393 Training Loss: 0.0033163740299642086 Validation Loss: 0.004661695100367069\n",
      "6394 Training Loss: 0.003930290229618549 Validation Loss: 0.00461744936183095\n",
      "6395 Training Loss: 0.004276819061487913 Validation Loss: 0.004608331248164177\n",
      "6396 Training Loss: 0.0033547324128448963 Validation Loss: 0.004657989367842674\n",
      "6397 Training Loss: 0.005036951974034309 Validation Loss: 0.00481326412409544\n",
      "6398 Training Loss: 0.003368510864675045 Validation Loss: 0.004986428655683994\n",
      "6399 Training Loss: 0.004230287857353687 Validation Loss: 0.005130978766828775\n",
      "6400 Training Loss: 0.0049613481387495995 Validation Loss: 0.005202000495046377\n",
      "6401 Training Loss: 0.00404792046174407 Validation Loss: 0.005189090967178345\n",
      "6402 Training Loss: 0.004082247614860535 Validation Loss: 0.005173970479518175\n",
      "6403 Training Loss: 0.0038314650300890207 Validation Loss: 0.004982268437743187\n",
      "6404 Training Loss: 0.0048875086940824986 Validation Loss: 0.0049192290753126144\n",
      "6405 Training Loss: 0.0040211607702076435 Validation Loss: 0.0048728515394032\n",
      "6406 Training Loss: 0.0036070283968001604 Validation Loss: 0.004808477126061916\n",
      "6407 Training Loss: 0.006765156984329224 Validation Loss: 0.004858989734202623\n",
      "6408 Training Loss: 0.0051648737862706184 Validation Loss: 0.005035041831433773\n",
      "6409 Training Loss: 0.00368512119166553 Validation Loss: 0.005217481404542923\n",
      "6410 Training Loss: 0.0035750637762248516 Validation Loss: 0.0052835773676633835\n",
      "6411 Training Loss: 0.0036764389369636774 Validation Loss: 0.005188127979636192\n",
      "6412 Training Loss: 0.003874092362821102 Validation Loss: 0.005056456197053194\n",
      "6413 Training Loss: 0.004093179479241371 Validation Loss: 0.0048873284831643105\n",
      "6414 Training Loss: 0.0074961381033062935 Validation Loss: 0.004923191387206316\n",
      "6415 Training Loss: 0.0032362486235797405 Validation Loss: 0.004965190310031176\n",
      "6416 Training Loss: 0.0032138805836439133 Validation Loss: 0.005002584308385849\n",
      "6417 Training Loss: 0.004519885405898094 Validation Loss: 0.005015983711928129\n",
      "6418 Training Loss: 0.004866921342909336 Validation Loss: 0.005097365938127041\n",
      "6419 Training Loss: 0.003502524457871914 Validation Loss: 0.005147668533027172\n",
      "6420 Training Loss: 0.0041578542441129684 Validation Loss: 0.005252190865576267\n",
      "6421 Training Loss: 0.0036609945818781853 Validation Loss: 0.005263672210276127\n",
      "6422 Training Loss: 0.005293357186019421 Validation Loss: 0.0053972480818629265\n",
      "6423 Training Loss: 0.00342929782345891 Validation Loss: 0.005499463528394699\n",
      "6424 Training Loss: 0.0033506283070892096 Validation Loss: 0.00553513690829277\n",
      "6425 Training Loss: 0.003552625421434641 Validation Loss: 0.0054171825759112835\n",
      "6426 Training Loss: 0.0029999972321093082 Validation Loss: 0.005329463630914688\n",
      "6427 Training Loss: 0.003449121955782175 Validation Loss: 0.005253319628536701\n",
      "6428 Training Loss: 0.004020805936306715 Validation Loss: 0.005175342783331871\n",
      "6429 Training Loss: 0.003911239560693502 Validation Loss: 0.005127651151269674\n",
      "6430 Training Loss: 0.0034526586532592773 Validation Loss: 0.00507322559133172\n",
      "6431 Training Loss: 0.004372694995254278 Validation Loss: 0.005114560015499592\n",
      "6432 Training Loss: 0.00524452468380332 Validation Loss: 0.005185731220990419\n",
      "6433 Training Loss: 0.003405663650482893 Validation Loss: 0.00523744011297822\n",
      "6434 Training Loss: 0.005448165349662304 Validation Loss: 0.005336512811481953\n",
      "6435 Training Loss: 0.0035426963586360216 Validation Loss: 0.005296115763485432\n",
      "6436 Training Loss: 0.00492524541914463 Validation Loss: 0.005280060227960348\n",
      "6437 Training Loss: 0.0034409412182867527 Validation Loss: 0.005262870341539383\n",
      "6438 Training Loss: 0.0036307370755821466 Validation Loss: 0.005174908321350813\n",
      "6439 Training Loss: 0.003978921566158533 Validation Loss: 0.005011678207665682\n",
      "6440 Training Loss: 0.0031255844514817 Validation Loss: 0.004907131660729647\n",
      "6441 Training Loss: 0.00408532377332449 Validation Loss: 0.004889249801635742\n",
      "6442 Training Loss: 0.0063273487612605095 Validation Loss: 0.004946795757859945\n",
      "6443 Training Loss: 0.0043187569826841354 Validation Loss: 0.005000317934900522\n",
      "6444 Training Loss: 0.0035853241570293903 Validation Loss: 0.005103594623506069\n",
      "6445 Training Loss: 0.0030666468665003777 Validation Loss: 0.005232671275734901\n",
      "6446 Training Loss: 0.003321249969303608 Validation Loss: 0.005339778959751129\n",
      "6447 Training Loss: 0.004610479809343815 Validation Loss: 0.005510231014341116\n",
      "6448 Training Loss: 0.0039761858060956 Validation Loss: 0.005465839523822069\n",
      "6449 Training Loss: 0.004123132675886154 Validation Loss: 0.005284918937832117\n",
      "6450 Training Loss: 0.0032248792704194784 Validation Loss: 0.00512402318418026\n",
      "6451 Training Loss: 0.0037996345199644566 Validation Loss: 0.004986862652003765\n",
      "6452 Training Loss: 0.0035401652567088604 Validation Loss: 0.004904065281152725\n",
      "6453 Training Loss: 0.005007216706871986 Validation Loss: 0.004898943472653627\n",
      "6454 Training Loss: 0.00366386491805315 Validation Loss: 0.004917718470096588\n",
      "6455 Training Loss: 0.003296114504337311 Validation Loss: 0.004973731003701687\n",
      "6456 Training Loss: 0.003352563362568617 Validation Loss: 0.0050505781546235085\n",
      "6457 Training Loss: 0.003454600926488638 Validation Loss: 0.005114865954965353\n",
      "6458 Training Loss: 0.00311284139752388 Validation Loss: 0.005200671497732401\n",
      "6459 Training Loss: 0.003268820233643055 Validation Loss: 0.005229930393397808\n",
      "6460 Training Loss: 0.003439980559051037 Validation Loss: 0.0052764154970645905\n",
      "6461 Training Loss: 0.003452559933066368 Validation Loss: 0.005209208931773901\n",
      "6462 Training Loss: 0.003998083528131247 Validation Loss: 0.0051558250561356544\n",
      "6463 Training Loss: 0.0031629966106265783 Validation Loss: 0.005103699397295713\n",
      "6464 Training Loss: 0.003652296494692564 Validation Loss: 0.0049690622836351395\n",
      "6465 Training Loss: 0.003708997741341591 Validation Loss: 0.0048468466848134995\n",
      "6466 Training Loss: 0.004468874074518681 Validation Loss: 0.004798452835530043\n",
      "6467 Training Loss: 0.00313318008556962 Validation Loss: 0.004771451000124216\n",
      "6468 Training Loss: 0.004972751252353191 Validation Loss: 0.004780102055519819\n",
      "6469 Training Loss: 0.0037199342623353004 Validation Loss: 0.0048130229115486145\n",
      "6470 Training Loss: 0.004379921592772007 Validation Loss: 0.004838252440094948\n",
      "6471 Training Loss: 0.004445069469511509 Validation Loss: 0.004874959122389555\n",
      "6472 Training Loss: 0.004328284412622452 Validation Loss: 0.004983299411833286\n",
      "6473 Training Loss: 0.0034918435849249363 Validation Loss: 0.005045091267675161\n",
      "6474 Training Loss: 0.0034915870055556297 Validation Loss: 0.005010263528674841\n",
      "6475 Training Loss: 0.0042808400467038155 Validation Loss: 0.00497983256354928\n",
      "6476 Training Loss: 0.003604349447414279 Validation Loss: 0.004978743847459555\n",
      "6477 Training Loss: 0.003507400630041957 Validation Loss: 0.004964165389537811\n",
      "6478 Training Loss: 0.005303269252181053 Validation Loss: 0.005027683451771736\n",
      "6479 Training Loss: 0.0031711114570498466 Validation Loss: 0.005067391786724329\n",
      "6480 Training Loss: 0.00337666692212224 Validation Loss: 0.005054927431046963\n",
      "6481 Training Loss: 0.004177525639533997 Validation Loss: 0.005007715430110693\n",
      "6482 Training Loss: 0.0033789961598813534 Validation Loss: 0.004925573710352182\n",
      "6483 Training Loss: 0.0035403920337557793 Validation Loss: 0.004819449968636036\n",
      "6484 Training Loss: 0.003393924795091152 Validation Loss: 0.004706358537077904\n",
      "6485 Training Loss: 0.004147832281887531 Validation Loss: 0.004660569131374359\n",
      "6486 Training Loss: 0.0034409973304718733 Validation Loss: 0.0046248543076217175\n",
      "6487 Training Loss: 0.0030492753721773624 Validation Loss: 0.004637791775166988\n",
      "6488 Training Loss: 0.0033415681682527065 Validation Loss: 0.004649839363992214\n",
      "6489 Training Loss: 0.003502222243696451 Validation Loss: 0.004705138970166445\n",
      "6490 Training Loss: 0.003531609196215868 Validation Loss: 0.004719428718090057\n",
      "6491 Training Loss: 0.0031775443349033594 Validation Loss: 0.004724889062345028\n",
      "6492 Training Loss: 0.0031685002613812685 Validation Loss: 0.004682101774960756\n",
      "6493 Training Loss: 0.0039026853628456593 Validation Loss: 0.004680152516812086\n",
      "6494 Training Loss: 0.004953502211719751 Validation Loss: 0.004821015987545252\n",
      "6495 Training Loss: 0.0033796748612076044 Validation Loss: 0.005017554387450218\n",
      "6496 Training Loss: 0.003517645411193371 Validation Loss: 0.005136560648679733\n",
      "6497 Training Loss: 0.0035812286660075188 Validation Loss: 0.005169175565242767\n",
      "6498 Training Loss: 0.003999676555395126 Validation Loss: 0.005139671731740236\n",
      "6499 Training Loss: 0.003648690413683653 Validation Loss: 0.005027972627431154\n",
      "6500 Training Loss: 0.004200804978609085 Validation Loss: 0.004943694453686476\n",
      "6501 Training Loss: 0.0034056250005960464 Validation Loss: 0.004854429513216019\n",
      "6502 Training Loss: 0.003611371386796236 Validation Loss: 0.004819204099476337\n",
      "6503 Training Loss: 0.0037529547698795795 Validation Loss: 0.004737732466310263\n",
      "6504 Training Loss: 0.0034230737946927547 Validation Loss: 0.004685955122113228\n",
      "6505 Training Loss: 0.0033334658946841955 Validation Loss: 0.004639743361622095\n",
      "6506 Training Loss: 0.004054475110024214 Validation Loss: 0.004639552906155586\n",
      "6507 Training Loss: 0.003084083553403616 Validation Loss: 0.00469785975292325\n",
      "6508 Training Loss: 0.003875641617923975 Validation Loss: 0.0047726500779390335\n",
      "6509 Training Loss: 0.0032630807254463434 Validation Loss: 0.004888155031949282\n",
      "6510 Training Loss: 0.0032555661164224148 Validation Loss: 0.004921573214232922\n",
      "6511 Training Loss: 0.004606391303241253 Validation Loss: 0.0049378713592886925\n",
      "6512 Training Loss: 0.0034098285250365734 Validation Loss: 0.00486455112695694\n",
      "6513 Training Loss: 0.004749794490635395 Validation Loss: 0.004850081633776426\n",
      "6514 Training Loss: 0.004070001188665628 Validation Loss: 0.004875844344496727\n",
      "6515 Training Loss: 0.003299759002402425 Validation Loss: 0.004855593666434288\n",
      "6516 Training Loss: 0.003635155037045479 Validation Loss: 0.004841729532927275\n",
      "6517 Training Loss: 0.0039743697270751 Validation Loss: 0.004836009815335274\n",
      "6518 Training Loss: 0.00337003031745553 Validation Loss: 0.004787981044501066\n",
      "6519 Training Loss: 0.0033572351094335318 Validation Loss: 0.004737823735922575\n",
      "6520 Training Loss: 0.00436113215982914 Validation Loss: 0.004679282195866108\n",
      "6521 Training Loss: 0.0034238025546073914 Validation Loss: 0.004632581025362015\n",
      "6522 Training Loss: 0.0029572336934506893 Validation Loss: 0.004599801730364561\n",
      "6523 Training Loss: 0.0032727723009884357 Validation Loss: 0.004582268185913563\n",
      "6524 Training Loss: 0.0029830001294612885 Validation Loss: 0.004565902519971132\n",
      "6525 Training Loss: 0.003793908515945077 Validation Loss: 0.004485165234655142\n",
      "6526 Training Loss: 0.003907888196408749 Validation Loss: 0.0044630710035562515\n",
      "6527 Training Loss: 0.0036325124092400074 Validation Loss: 0.004452059045433998\n",
      "6528 Training Loss: 0.003301940392702818 Validation Loss: 0.004435998387634754\n",
      "6529 Training Loss: 0.003353809006512165 Validation Loss: 0.004453964531421661\n",
      "6530 Training Loss: 0.004508535843342543 Validation Loss: 0.004493528511375189\n",
      "6531 Training Loss: 0.003074673470109701 Validation Loss: 0.004590013064444065\n",
      "6532 Training Loss: 0.0032059785444289446 Validation Loss: 0.00464961351826787\n",
      "6533 Training Loss: 0.0033679723273962736 Validation Loss: 0.004657992627471685\n",
      "6534 Training Loss: 0.0035116637591272593 Validation Loss: 0.00460652494803071\n",
      "6535 Training Loss: 0.003974354825913906 Validation Loss: 0.004599498584866524\n",
      "6536 Training Loss: 0.0033550409134477377 Validation Loss: 0.004543145652860403\n",
      "6537 Training Loss: 0.003763879183679819 Validation Loss: 0.004466636572033167\n",
      "6538 Training Loss: 0.003113794606178999 Validation Loss: 0.004410761874169111\n",
      "6539 Training Loss: 0.004577817395329475 Validation Loss: 0.004432397428900003\n",
      "6540 Training Loss: 0.005083900410681963 Validation Loss: 0.0045495112426579\n",
      "6541 Training Loss: 0.003123039612546563 Validation Loss: 0.004646655637770891\n",
      "6542 Training Loss: 0.00336828688159585 Validation Loss: 0.004666422493755817\n",
      "6543 Training Loss: 0.003551050554960966 Validation Loss: 0.004574502818286419\n",
      "6544 Training Loss: 0.003113783663138747 Validation Loss: 0.004470100160688162\n",
      "6545 Training Loss: 0.003527725115418434 Validation Loss: 0.004387291613966227\n",
      "6546 Training Loss: 0.0032547698356211185 Validation Loss: 0.0043301829136908054\n",
      "6547 Training Loss: 0.0034513906575739384 Validation Loss: 0.004316739272326231\n",
      "6548 Training Loss: 0.004204710014164448 Validation Loss: 0.004350724630057812\n",
      "6549 Training Loss: 0.0030928729102015495 Validation Loss: 0.004405754618346691\n",
      "6550 Training Loss: 0.0032528871670365334 Validation Loss: 0.0044587645679712296\n",
      "6551 Training Loss: 0.003088642843067646 Validation Loss: 0.004491363652050495\n",
      "6552 Training Loss: 0.003115325467661023 Validation Loss: 0.004481659270823002\n",
      "6553 Training Loss: 0.00440254807472229 Validation Loss: 0.004503538366407156\n",
      "6554 Training Loss: 0.003523405874148011 Validation Loss: 0.0045157927088439465\n",
      "6555 Training Loss: 0.0030515119433403015 Validation Loss: 0.0045343441888689995\n",
      "6556 Training Loss: 0.003459255676716566 Validation Loss: 0.004535828251391649\n",
      "6557 Training Loss: 0.00329583790153265 Validation Loss: 0.00445572379976511\n",
      "6558 Training Loss: 0.0031027067452669144 Validation Loss: 0.004344504326581955\n",
      "6559 Training Loss: 0.00469457171857357 Validation Loss: 0.004287192597985268\n",
      "6560 Training Loss: 0.0030276549514383078 Validation Loss: 0.004257118795067072\n",
      "6561 Training Loss: 0.003006759099662304 Validation Loss: 0.004243422765284777\n",
      "6562 Training Loss: 0.0029097809456288815 Validation Loss: 0.0042321644723415375\n",
      "6563 Training Loss: 0.0028465990908443928 Validation Loss: 0.004229427315294743\n",
      "6564 Training Loss: 0.005891268141567707 Validation Loss: 0.004293450154364109\n",
      "6565 Training Loss: 0.003972289618104696 Validation Loss: 0.004456276074051857\n",
      "6566 Training Loss: 0.003577626310288906 Validation Loss: 0.004720605909824371\n",
      "6567 Training Loss: 0.0038067512214183807 Validation Loss: 0.004906307905912399\n",
      "6568 Training Loss: 0.002964252373203635 Validation Loss: 0.00497664138674736\n",
      "6569 Training Loss: 0.003072140971198678 Validation Loss: 0.004916347563266754\n",
      "6570 Training Loss: 0.0033269328996539116 Validation Loss: 0.004762550350278616\n",
      "6571 Training Loss: 0.003990919794887304 Validation Loss: 0.004669008776545525\n",
      "6572 Training Loss: 0.004806188866496086 Validation Loss: 0.004643514286726713\n",
      "6573 Training Loss: 0.0029649322386831045 Validation Loss: 0.00466703437268734\n",
      "6574 Training Loss: 0.0032399622723460197 Validation Loss: 0.004634604323655367\n",
      "6575 Training Loss: 0.004835929721593857 Validation Loss: 0.004652568604797125\n",
      "6576 Training Loss: 0.004145842976868153 Validation Loss: 0.004663494415581226\n",
      "6577 Training Loss: 0.004019952844828367 Validation Loss: 0.004613953642547131\n",
      "6578 Training Loss: 0.0037825442850589752 Validation Loss: 0.004587017465382814\n",
      "6579 Training Loss: 0.004443672485649586 Validation Loss: 0.004656713455915451\n",
      "6580 Training Loss: 0.0034425752237439156 Validation Loss: 0.004619649611413479\n",
      "6581 Training Loss: 0.0031572396401315928 Validation Loss: 0.004620587918907404\n",
      "6582 Training Loss: 0.004178536590188742 Validation Loss: 0.004626157693564892\n",
      "6583 Training Loss: 0.003174008335918188 Validation Loss: 0.004581065848469734\n",
      "6584 Training Loss: 0.0037919050082564354 Validation Loss: 0.00454334169626236\n",
      "6585 Training Loss: 0.0029441933147609234 Validation Loss: 0.00454778503626585\n",
      "6586 Training Loss: 0.003310279455035925 Validation Loss: 0.0045643639750778675\n",
      "6587 Training Loss: 0.003988620825111866 Validation Loss: 0.0046570785343647\n",
      "6588 Training Loss: 0.003007683204486966 Validation Loss: 0.004802342504262924\n",
      "6589 Training Loss: 0.003214404918253422 Validation Loss: 0.00491512194275856\n",
      "6590 Training Loss: 0.004604702815413475 Validation Loss: 0.005052605643868446\n",
      "6591 Training Loss: 0.004251166246831417 Validation Loss: 0.0051195137202739716\n",
      "6592 Training Loss: 0.0037798997946083546 Validation Loss: 0.005129024386405945\n",
      "6593 Training Loss: 0.0029595359228551388 Validation Loss: 0.005014935974031687\n",
      "6594 Training Loss: 0.003697175532579422 Validation Loss: 0.0048441169783473015\n",
      "6595 Training Loss: 0.005048460327088833 Validation Loss: 0.004715584684163332\n",
      "6596 Training Loss: 0.0033202548511326313 Validation Loss: 0.004565437790006399\n",
      "6597 Training Loss: 0.003899735864251852 Validation Loss: 0.004519473295658827\n",
      "6598 Training Loss: 0.0035386262461543083 Validation Loss: 0.00457999762147665\n",
      "6599 Training Loss: 0.0035715755075216293 Validation Loss: 0.004716602619737387\n",
      "6600 Training Loss: 0.0032829400151968002 Validation Loss: 0.00481615262106061\n",
      "6601 Training Loss: 0.003256740514189005 Validation Loss: 0.004855069797486067\n",
      "6602 Training Loss: 0.003187306225299835 Validation Loss: 0.004834000486880541\n",
      "6603 Training Loss: 0.0033323955722153187 Validation Loss: 0.004715526010841131\n",
      "6604 Training Loss: 0.002904578810557723 Validation Loss: 0.00459566805511713\n",
      "6605 Training Loss: 0.004335005767643452 Validation Loss: 0.0044965483248233795\n",
      "6606 Training Loss: 0.004846168681979179 Validation Loss: 0.004449285566806793\n",
      "6607 Training Loss: 0.0031619369983673096 Validation Loss: 0.00441783620044589\n",
      "6608 Training Loss: 0.003078070003539324 Validation Loss: 0.004421195015311241\n",
      "6609 Training Loss: 0.00356923951767385 Validation Loss: 0.004500765819102526\n",
      "6610 Training Loss: 0.003340835217386484 Validation Loss: 0.004583925474435091\n",
      "6611 Training Loss: 0.004200019873678684 Validation Loss: 0.004750815685838461\n",
      "6612 Training Loss: 0.0034911755938082933 Validation Loss: 0.004996730946004391\n",
      "6613 Training Loss: 0.003365039825439453 Validation Loss: 0.00507619883865118\n",
      "6614 Training Loss: 0.0034752918872982264 Validation Loss: 0.005015176255255938\n",
      "6615 Training Loss: 0.0030351392924785614 Validation Loss: 0.004887960851192474\n",
      "6616 Training Loss: 0.0031416667625308037 Validation Loss: 0.004749312996864319\n",
      "6617 Training Loss: 0.002837295876815915 Validation Loss: 0.004653575364500284\n",
      "6618 Training Loss: 0.0037751232739537954 Validation Loss: 0.0046303714625537395\n",
      "6619 Training Loss: 0.00410100445151329 Validation Loss: 0.004659305792301893\n",
      "6620 Training Loss: 0.002903214655816555 Validation Loss: 0.0047463770024478436\n",
      "6621 Training Loss: 0.003497365629300475 Validation Loss: 0.00473630428314209\n",
      "6622 Training Loss: 0.002948024543002248 Validation Loss: 0.0046911719255149364\n",
      "6623 Training Loss: 0.003030009102076292 Validation Loss: 0.004651286639273167\n",
      "6624 Training Loss: 0.003124465700238943 Validation Loss: 0.00455436808988452\n",
      "6625 Training Loss: 0.003195185214281082 Validation Loss: 0.0044015743769705296\n",
      "6626 Training Loss: 0.003930943552404642 Validation Loss: 0.0043065049685537815\n",
      "6627 Training Loss: 0.0030598719604313374 Validation Loss: 0.004268958233296871\n",
      "6628 Training Loss: 0.004792137537151575 Validation Loss: 0.0043425713665783405\n",
      "6629 Training Loss: 0.0031017656438052654 Validation Loss: 0.004460632801055908\n",
      "6630 Training Loss: 0.003070779610425234 Validation Loss: 0.004549063742160797\n",
      "6631 Training Loss: 0.003651450853794813 Validation Loss: 0.0045480504631996155\n",
      "6632 Training Loss: 0.0033690184354782104 Validation Loss: 0.004523790907114744\n",
      "6633 Training Loss: 0.003218600992113352 Validation Loss: 0.004541303962469101\n",
      "6634 Training Loss: 0.003755484940484166 Validation Loss: 0.004624417517334223\n",
      "6635 Training Loss: 0.0028839055448770523 Validation Loss: 0.00470097316429019\n",
      "6636 Training Loss: 0.003246316686272621 Validation Loss: 0.0046661291271448135\n",
      "6637 Training Loss: 0.0031426395289599895 Validation Loss: 0.004605032037943602\n",
      "6638 Training Loss: 0.0030151838436722755 Validation Loss: 0.0045317392796278\n",
      "6639 Training Loss: 0.004324192181229591 Validation Loss: 0.004477884154766798\n",
      "6640 Training Loss: 0.0035741273313760757 Validation Loss: 0.004381099715828896\n",
      "6641 Training Loss: 0.0032458538189530373 Validation Loss: 0.00430311169475317\n",
      "6642 Training Loss: 0.0029745528008788824 Validation Loss: 0.004259623121470213\n",
      "6643 Training Loss: 0.003418237203732133 Validation Loss: 0.004217858891934156\n",
      "6644 Training Loss: 0.0031507895328104496 Validation Loss: 0.004205753095448017\n",
      "6645 Training Loss: 0.00444065872579813 Validation Loss: 0.004226296208798885\n",
      "6646 Training Loss: 0.004753476940095425 Validation Loss: 0.00441609974950552\n",
      "6647 Training Loss: 0.0030204812064766884 Validation Loss: 0.004648404661566019\n",
      "6648 Training Loss: 0.003300241194665432 Validation Loss: 0.004821179900318384\n",
      "6649 Training Loss: 0.0031429119408130646 Validation Loss: 0.004975206218659878\n",
      "6650 Training Loss: 0.0030381635297089815 Validation Loss: 0.005000036209821701\n",
      "6651 Training Loss: 0.002694887574762106 Validation Loss: 0.005046509671956301\n",
      "6652 Training Loss: 0.003121292684227228 Validation Loss: 0.0051721795462071896\n",
      "6653 Training Loss: 0.003997261170297861 Validation Loss: 0.0051757763139903545\n",
      "6654 Training Loss: 0.003057065885514021 Validation Loss: 0.0051072146743535995\n",
      "6655 Training Loss: 0.003318910486996174 Validation Loss: 0.0048959990963339806\n",
      "6656 Training Loss: 0.003176604863256216 Validation Loss: 0.004681133199483156\n",
      "6657 Training Loss: 0.0026648747734725475 Validation Loss: 0.004506905097514391\n",
      "6658 Training Loss: 0.0036529945209622383 Validation Loss: 0.0043568238615989685\n",
      "6659 Training Loss: 0.0035582685377448797 Validation Loss: 0.004314684774726629\n",
      "6660 Training Loss: 0.004838623106479645 Validation Loss: 0.0043726456351578236\n",
      "6661 Training Loss: 0.004432953894138336 Validation Loss: 0.004583860281854868\n",
      "6662 Training Loss: 0.003240339457988739 Validation Loss: 0.004661949351429939\n",
      "6663 Training Loss: 0.004452560096979141 Validation Loss: 0.004744299221783876\n",
      "6664 Training Loss: 0.0028981773648411036 Validation Loss: 0.004743761382997036\n",
      "6665 Training Loss: 0.003402170492336154 Validation Loss: 0.004749148152768612\n",
      "6666 Training Loss: 0.0036758058704435825 Validation Loss: 0.0046239690855145454\n",
      "6667 Training Loss: 0.003293822519481182 Validation Loss: 0.004652030766010284\n",
      "6668 Training Loss: 0.003174289595335722 Validation Loss: 0.004684475250542164\n",
      "6669 Training Loss: 0.0033881927374750376 Validation Loss: 0.0046834684908390045\n",
      "6670 Training Loss: 0.0031576422043144703 Validation Loss: 0.004643160384148359\n",
      "6671 Training Loss: 0.0033704459201544523 Validation Loss: 0.004591844510287046\n",
      "6672 Training Loss: 0.003819359466433525 Validation Loss: 0.00450864527374506\n",
      "6673 Training Loss: 0.0031124844681471586 Validation Loss: 0.004484920762479305\n",
      "6674 Training Loss: 0.004979726858437061 Validation Loss: 0.004570734687149525\n",
      "6675 Training Loss: 0.0029165372252464294 Validation Loss: 0.004694192670285702\n",
      "6676 Training Loss: 0.0028072968125343323 Validation Loss: 0.004746347200125456\n",
      "6677 Training Loss: 0.0034623979590833187 Validation Loss: 0.0046586631797254086\n",
      "6678 Training Loss: 0.0032423166558146477 Validation Loss: 0.004529933910816908\n",
      "6679 Training Loss: 0.0028675736393779516 Validation Loss: 0.004408842418342829\n",
      "6680 Training Loss: 0.003153129480779171 Validation Loss: 0.004286290146410465\n",
      "6681 Training Loss: 0.002865293761715293 Validation Loss: 0.004216411150991917\n",
      "6682 Training Loss: 0.003524291329085827 Validation Loss: 0.004224312491714954\n",
      "6683 Training Loss: 0.0031456192955374718 Validation Loss: 0.0042321872897446156\n",
      "6684 Training Loss: 0.002805880270898342 Validation Loss: 0.0042701419442892075\n",
      "6685 Training Loss: 0.0036531398072838783 Validation Loss: 0.004295612685382366\n",
      "6686 Training Loss: 0.002743577817454934 Validation Loss: 0.0043497527949512005\n",
      "6687 Training Loss: 0.002691984875127673 Validation Loss: 0.00447210855782032\n",
      "6688 Training Loss: 0.003193566808477044 Validation Loss: 0.004508942365646362\n",
      "6689 Training Loss: 0.0027196425944566727 Validation Loss: 0.0045067667961120605\n",
      "6690 Training Loss: 0.004154449328780174 Validation Loss: 0.004485973156988621\n",
      "6691 Training Loss: 0.003422750625759363 Validation Loss: 0.004442266654223204\n",
      "6692 Training Loss: 0.003580861259251833 Validation Loss: 0.004360202234238386\n",
      "6693 Training Loss: 0.0028370541986078024 Validation Loss: 0.004313844721764326\n",
      "6694 Training Loss: 0.0028874315321445465 Validation Loss: 0.0042709591798484325\n",
      "6695 Training Loss: 0.0026540348771959543 Validation Loss: 0.004241661634296179\n",
      "6696 Training Loss: 0.0028013456612825394 Validation Loss: 0.0042329225689172745\n",
      "6697 Training Loss: 0.0033536269329488277 Validation Loss: 0.004194867797195911\n",
      "6698 Training Loss: 0.002636278048157692 Validation Loss: 0.004188019782304764\n",
      "6699 Training Loss: 0.004914044868201017 Validation Loss: 0.004253706429153681\n",
      "6700 Training Loss: 0.0027269814163446426 Validation Loss: 0.00433152262121439\n",
      "6701 Training Loss: 0.002928247209638357 Validation Loss: 0.004398368764668703\n",
      "6702 Training Loss: 0.003318951465189457 Validation Loss: 0.004412679933011532\n",
      "6703 Training Loss: 0.0029200254939496517 Validation Loss: 0.004429589956998825\n",
      "6704 Training Loss: 0.0033366575371474028 Validation Loss: 0.004299639258533716\n",
      "6705 Training Loss: 0.003957795910537243 Validation Loss: 0.004245626740157604\n",
      "6706 Training Loss: 0.0030495859682559967 Validation Loss: 0.0041748834773898125\n",
      "6707 Training Loss: 0.0029200464487075806 Validation Loss: 0.004141506738960743\n",
      "6708 Training Loss: 0.0032772542908787727 Validation Loss: 0.004134386777877808\n",
      "6709 Training Loss: 0.0029419222846627235 Validation Loss: 0.004181946627795696\n",
      "6710 Training Loss: 0.002881841268390417 Validation Loss: 0.004221691749989986\n",
      "6711 Training Loss: 0.00347950984723866 Validation Loss: 0.004350707866251469\n",
      "6712 Training Loss: 0.004265211522579193 Validation Loss: 0.004501997027546167\n",
      "6713 Training Loss: 0.0030656203161925077 Validation Loss: 0.004636411089450121\n",
      "6714 Training Loss: 0.0030053493101149797 Validation Loss: 0.004608573392033577\n",
      "6715 Training Loss: 0.0032984581775963306 Validation Loss: 0.004495684988796711\n",
      "6716 Training Loss: 0.004190665669739246 Validation Loss: 0.0044065844267606735\n",
      "6717 Training Loss: 0.0032270955853164196 Validation Loss: 0.004259680397808552\n",
      "6718 Training Loss: 0.003228418994694948 Validation Loss: 0.004143185447901487\n",
      "6719 Training Loss: 0.003052881918847561 Validation Loss: 0.004053891636431217\n",
      "6720 Training Loss: 0.0031319952104240656 Validation Loss: 0.004000985529273748\n",
      "6721 Training Loss: 0.003108386881649494 Validation Loss: 0.0039857905358076096\n",
      "6722 Training Loss: 0.0027727633714675903 Validation Loss: 0.003978998865932226\n",
      "6723 Training Loss: 0.003978520631790161 Validation Loss: 0.004030469339340925\n",
      "6724 Training Loss: 0.003757379250600934 Validation Loss: 0.004140729550272226\n",
      "6725 Training Loss: 0.002851328579708934 Validation Loss: 0.0042326608672738075\n",
      "6726 Training Loss: 0.003324680496007204 Validation Loss: 0.004381632898002863\n",
      "6727 Training Loss: 0.0043121580965816975 Validation Loss: 0.0044167363084852695\n",
      "6728 Training Loss: 0.002785617718473077 Validation Loss: 0.004434121772646904\n",
      "6729 Training Loss: 0.0036169206723570824 Validation Loss: 0.004567306023091078\n",
      "6730 Training Loss: 0.004203970544040203 Validation Loss: 0.004732327535748482\n",
      "6731 Training Loss: 0.0030821356922388077 Validation Loss: 0.004834601189941168\n",
      "6732 Training Loss: 0.0029845773242413998 Validation Loss: 0.00478364760056138\n",
      "6733 Training Loss: 0.003533302340656519 Validation Loss: 0.00468091294169426\n",
      "6734 Training Loss: 0.0034446583595126867 Validation Loss: 0.0045372359454631805\n",
      "6735 Training Loss: 0.0031838042195886374 Validation Loss: 0.004378369078040123\n",
      "6736 Training Loss: 0.006163734011352062 Validation Loss: 0.004329584073275328\n",
      "6737 Training Loss: 0.004486434627324343 Validation Loss: 0.004384191241115332\n",
      "6738 Training Loss: 0.0026203845627605915 Validation Loss: 0.0044943299144506454\n",
      "6739 Training Loss: 0.003042316995561123 Validation Loss: 0.0046002729795873165\n",
      "6740 Training Loss: 0.002954571507871151 Validation Loss: 0.004638779908418655\n",
      "6741 Training Loss: 0.0031829685904085636 Validation Loss: 0.004568027798086405\n",
      "6742 Training Loss: 0.003556582611054182 Validation Loss: 0.004399172030389309\n",
      "6743 Training Loss: 0.0029102431144565344 Validation Loss: 0.0043276469223201275\n",
      "6744 Training Loss: 0.0027986480854451656 Validation Loss: 0.0042994096875190735\n",
      "6745 Training Loss: 0.005259315948933363 Validation Loss: 0.004354284610599279\n",
      "6746 Training Loss: 0.002942926250398159 Validation Loss: 0.004416709765791893\n",
      "6747 Training Loss: 0.0027928168419748545 Validation Loss: 0.0045108008198440075\n",
      "6748 Training Loss: 0.002750048413872719 Validation Loss: 0.004601815715432167\n",
      "6749 Training Loss: 0.003028168808668852 Validation Loss: 0.004646828398108482\n",
      "6750 Training Loss: 0.003475154982879758 Validation Loss: 0.004777850117534399\n",
      "6751 Training Loss: 0.0032837805338203907 Validation Loss: 0.0047650327906012535\n",
      "6752 Training Loss: 0.002988615073263645 Validation Loss: 0.004679742269217968\n",
      "6753 Training Loss: 0.002925039269030094 Validation Loss: 0.004486465826630592\n",
      "6754 Training Loss: 0.0030026165768504143 Validation Loss: 0.004364439286291599\n",
      "6755 Training Loss: 0.003242919221520424 Validation Loss: 0.00429525738582015\n",
      "6756 Training Loss: 0.003092427970841527 Validation Loss: 0.00422063609585166\n",
      "6757 Training Loss: 0.0027513010427355766 Validation Loss: 0.004151985049247742\n",
      "6758 Training Loss: 0.0028613030444830656 Validation Loss: 0.004125018138438463\n",
      "6759 Training Loss: 0.0029608472250401974 Validation Loss: 0.004128534346818924\n",
      "6760 Training Loss: 0.0034991218708455563 Validation Loss: 0.004198089707642794\n",
      "6761 Training Loss: 0.0029606912285089493 Validation Loss: 0.004283163696527481\n",
      "6762 Training Loss: 0.002793723251670599 Validation Loss: 0.00432424433529377\n",
      "6763 Training Loss: 0.002835094230249524 Validation Loss: 0.004307649098336697\n",
      "6764 Training Loss: 0.004486360587179661 Validation Loss: 0.0043546343222260475\n",
      "6765 Training Loss: 0.0027864468283951283 Validation Loss: 0.004421932622790337\n",
      "6766 Training Loss: 0.002724230522289872 Validation Loss: 0.004436170682311058\n",
      "6767 Training Loss: 0.002604680135846138 Validation Loss: 0.004433474037796259\n",
      "6768 Training Loss: 0.0029549775645136833 Validation Loss: 0.004407994914799929\n",
      "6769 Training Loss: 0.0029587922617793083 Validation Loss: 0.004350463859736919\n",
      "6770 Training Loss: 0.003059788141399622 Validation Loss: 0.004272862337529659\n",
      "6771 Training Loss: 0.002738150767982006 Validation Loss: 0.004187497776001692\n",
      "6772 Training Loss: 0.0026646277401596308 Validation Loss: 0.004134998191148043\n",
      "6773 Training Loss: 0.002917909761890769 Validation Loss: 0.0040777819231152534\n",
      "6774 Training Loss: 0.0027585483621805906 Validation Loss: 0.004042024724185467\n",
      "6775 Training Loss: 0.0035590440966188908 Validation Loss: 0.004053572192788124\n",
      "6776 Training Loss: 0.0032585952430963516 Validation Loss: 0.004110909067094326\n",
      "6777 Training Loss: 0.0025446696672588587 Validation Loss: 0.004188882187008858\n",
      "6778 Training Loss: 0.0028556485194712877 Validation Loss: 0.004288388881832361\n",
      "6779 Training Loss: 0.00271009374409914 Validation Loss: 0.0043343547731637955\n",
      "6780 Training Loss: 0.002891733543947339 Validation Loss: 0.004298233427107334\n",
      "6781 Training Loss: 0.002758440561592579 Validation Loss: 0.004260645247995853\n",
      "6782 Training Loss: 0.0025668004527688026 Validation Loss: 0.0042365738190710545\n",
      "6783 Training Loss: 0.0032412416767328978 Validation Loss: 0.004241719376295805\n",
      "6784 Training Loss: 0.002967177890241146 Validation Loss: 0.004203056916594505\n",
      "6785 Training Loss: 0.0028371356893330812 Validation Loss: 0.004142218269407749\n",
      "6786 Training Loss: 0.002712829736992717 Validation Loss: 0.00410996051505208\n",
      "6787 Training Loss: 0.002801231574267149 Validation Loss: 0.004082853440195322\n",
      "6788 Training Loss: 0.002788216806948185 Validation Loss: 0.004062906373292208\n",
      "6789 Training Loss: 0.0034316317178308964 Validation Loss: 0.004015197977423668\n",
      "6790 Training Loss: 0.003278027754276991 Validation Loss: 0.004002867266535759\n",
      "6791 Training Loss: 0.003989835269749165 Validation Loss: 0.004104042891412973\n",
      "6792 Training Loss: 0.0026253536343574524 Validation Loss: 0.004160173237323761\n",
      "6793 Training Loss: 0.002966557163745165 Validation Loss: 0.0041330913081765175\n",
      "6794 Training Loss: 0.0029855091124773026 Validation Loss: 0.0040321736596524715\n",
      "6795 Training Loss: 0.004811692051589489 Validation Loss: 0.004030914977192879\n",
      "6796 Training Loss: 0.002937982091680169 Validation Loss: 0.004087627399712801\n",
      "6797 Training Loss: 0.0027792626060545444 Validation Loss: 0.004221650771796703\n",
      "6798 Training Loss: 0.00241232942789793 Validation Loss: 0.004364886321127415\n",
      "6799 Training Loss: 0.002871848875656724 Validation Loss: 0.004427066072821617\n",
      "6800 Training Loss: 0.0031880412716418505 Validation Loss: 0.0043684570118784904\n",
      "6801 Training Loss: 0.004528081510215998 Validation Loss: 0.004360560793429613\n",
      "6802 Training Loss: 0.002707653446123004 Validation Loss: 0.004343839827924967\n",
      "6803 Training Loss: 0.00278778700158 Validation Loss: 0.004348413553088903\n",
      "6804 Training Loss: 0.0027428162284195423 Validation Loss: 0.004304522182792425\n",
      "6805 Training Loss: 0.0033828711602836847 Validation Loss: 0.0042538633570075035\n",
      "6806 Training Loss: 0.0029845882672816515 Validation Loss: 0.004233199637383223\n",
      "6807 Training Loss: 0.0028153564780950546 Validation Loss: 0.004195756278932095\n",
      "6808 Training Loss: 0.0025685764849185944 Validation Loss: 0.004192209802567959\n",
      "6809 Training Loss: 0.002657972974702716 Validation Loss: 0.00413864990696311\n",
      "6810 Training Loss: 0.0046987696550786495 Validation Loss: 0.004172214772552252\n",
      "6811 Training Loss: 0.0035350648686289787 Validation Loss: 0.004279535263776779\n",
      "6812 Training Loss: 0.002589353360235691 Validation Loss: 0.004364171531051397\n",
      "6813 Training Loss: 0.0027297153137624264 Validation Loss: 0.004406536463648081\n",
      "6814 Training Loss: 0.002596051897853613 Validation Loss: 0.004397904500365257\n",
      "6815 Training Loss: 0.0037428801879286766 Validation Loss: 0.004372721072286367\n",
      "6816 Training Loss: 0.0025814345572143793 Validation Loss: 0.004294309765100479\n",
      "6817 Training Loss: 0.0031822004821151495 Validation Loss: 0.004163206554949284\n",
      "6818 Training Loss: 0.0034511126577854156 Validation Loss: 0.0040868422947824\n",
      "6819 Training Loss: 0.002945211250334978 Validation Loss: 0.003986968658864498\n",
      "6820 Training Loss: 0.0028196112252771854 Validation Loss: 0.0038996944203972816\n",
      "6821 Training Loss: 0.002765420824289322 Validation Loss: 0.003885014681145549\n",
      "6822 Training Loss: 0.0028088544495403767 Validation Loss: 0.003931709565222263\n",
      "6823 Training Loss: 0.002350390423089266 Validation Loss: 0.004019256215542555\n",
      "6824 Training Loss: 0.0025133048184216022 Validation Loss: 0.004096352495253086\n",
      "6825 Training Loss: 0.003983494825661182 Validation Loss: 0.0042237709276378155\n",
      "6826 Training Loss: 0.002660717349499464 Validation Loss: 0.004290809854865074\n",
      "6827 Training Loss: 0.0026306351646780968 Validation Loss: 0.0043244389817118645\n",
      "6828 Training Loss: 0.0029235039837658405 Validation Loss: 0.004271994344890118\n",
      "6829 Training Loss: 0.003048382233828306 Validation Loss: 0.0042412783950567245\n",
      "6830 Training Loss: 0.0037243047263473272 Validation Loss: 0.004243968054652214\n",
      "6831 Training Loss: 0.002733781933784485 Validation Loss: 0.004185881465673447\n",
      "6832 Training Loss: 0.0028977158945053816 Validation Loss: 0.004081169608980417\n",
      "6833 Training Loss: 0.003313913242891431 Validation Loss: 0.003935083281248808\n",
      "6834 Training Loss: 0.0026903552934527397 Validation Loss: 0.0038491461891680956\n",
      "6835 Training Loss: 0.0026616163086146116 Validation Loss: 0.0038043202366679907\n",
      "6836 Training Loss: 0.002753178821876645 Validation Loss: 0.0037948787212371826\n",
      "6837 Training Loss: 0.0028330893255770206 Validation Loss: 0.0037793314550071955\n",
      "6838 Training Loss: 0.004045366775244474 Validation Loss: 0.0038045430555939674\n",
      "6839 Training Loss: 0.0029242371674627066 Validation Loss: 0.0038728686049580574\n",
      "6840 Training Loss: 0.0024104169569909573 Validation Loss: 0.003969025332480669\n",
      "6841 Training Loss: 0.0031492351554334164 Validation Loss: 0.004042612388730049\n",
      "6842 Training Loss: 0.0031004250049591064 Validation Loss: 0.004081173334270716\n",
      "6843 Training Loss: 0.004531088285148144 Validation Loss: 0.004190495237708092\n",
      "6844 Training Loss: 0.0026925893034785986 Validation Loss: 0.004250630270689726\n",
      "6845 Training Loss: 0.003348280442878604 Validation Loss: 0.004365377128124237\n",
      "6846 Training Loss: 0.0032700675074011087 Validation Loss: 0.0043947878293693066\n",
      "6847 Training Loss: 0.0026355416048318148 Validation Loss: 0.00437379814684391\n",
      "6848 Training Loss: 0.002908402355387807 Validation Loss: 0.004388726782053709\n",
      "6849 Training Loss: 0.0029506448190659285 Validation Loss: 0.004346736706793308\n",
      "6850 Training Loss: 0.0031332005746662617 Validation Loss: 0.004283231683075428\n",
      "6851 Training Loss: 0.00324395508505404 Validation Loss: 0.004122878424823284\n",
      "6852 Training Loss: 0.004032858647406101 Validation Loss: 0.004067800939083099\n",
      "6853 Training Loss: 0.0029148273169994354 Validation Loss: 0.0039568208158016205\n",
      "6854 Training Loss: 0.0024757967330515385 Validation Loss: 0.0038925830740481615\n",
      "6855 Training Loss: 0.004226175136864185 Validation Loss: 0.003840371500700712\n",
      "6856 Training Loss: 0.002399907447397709 Validation Loss: 0.003816168522462249\n",
      "6857 Training Loss: 0.0026121470145881176 Validation Loss: 0.003786888439208269\n",
      "6858 Training Loss: 0.0028984551317989826 Validation Loss: 0.003760692896321416\n",
      "6859 Training Loss: 0.002648742403835058 Validation Loss: 0.0037512758281081915\n",
      "6860 Training Loss: 0.0034998529590666294 Validation Loss: 0.003770591923967004\n",
      "6861 Training Loss: 0.0035666613839566708 Validation Loss: 0.003866808954626322\n",
      "6862 Training Loss: 0.0026454173494130373 Validation Loss: 0.004050361458212137\n",
      "6863 Training Loss: 0.002828846452757716 Validation Loss: 0.004176056478172541\n",
      "6864 Training Loss: 0.00541389174759388 Validation Loss: 0.004352921154350042\n",
      "6865 Training Loss: 0.0027398811653256416 Validation Loss: 0.00443103164434433\n",
      "6866 Training Loss: 0.0029042111709713936 Validation Loss: 0.004387743305414915\n",
      "6867 Training Loss: 0.0035930313169956207 Validation Loss: 0.0043569584377110004\n",
      "6868 Training Loss: 0.002836009953171015 Validation Loss: 0.0042130788788199425\n",
      "6869 Training Loss: 0.004381735809147358 Validation Loss: 0.0042055705562233925\n",
      "6870 Training Loss: 0.003155930433422327 Validation Loss: 0.004071579780429602\n",
      "6871 Training Loss: 0.0027329404838383198 Validation Loss: 0.004052485339343548\n",
      "6872 Training Loss: 0.0026978678070008755 Validation Loss: 0.004036338068544865\n",
      "6873 Training Loss: 0.0025111865252256393 Validation Loss: 0.004016253165900707\n",
      "6874 Training Loss: 0.0024762090761214495 Validation Loss: 0.004002116620540619\n",
      "6875 Training Loss: 0.002582891145721078 Validation Loss: 0.003980221226811409\n",
      "6876 Training Loss: 0.002319621155038476 Validation Loss: 0.003977181855589151\n",
      "6877 Training Loss: 0.002537182532250881 Validation Loss: 0.003986703231930733\n",
      "6878 Training Loss: 0.0027517611160874367 Validation Loss: 0.004039652179926634\n",
      "6879 Training Loss: 0.003949730657041073 Validation Loss: 0.004231497645378113\n",
      "6880 Training Loss: 0.00341212609782815 Validation Loss: 0.004418548196554184\n",
      "6881 Training Loss: 0.0029330281540751457 Validation Loss: 0.004413773771375418\n",
      "6882 Training Loss: 0.0030594838317483664 Validation Loss: 0.004257512744516134\n",
      "6883 Training Loss: 0.0030430906917899847 Validation Loss: 0.004136829171329737\n",
      "6884 Training Loss: 0.004038890358060598 Validation Loss: 0.0042469194158911705\n",
      "6885 Training Loss: 0.003008573316037655 Validation Loss: 0.004355311393737793\n",
      "6886 Training Loss: 0.0052837491966784 Validation Loss: 0.004484044853597879\n",
      "6887 Training Loss: 0.0030110636726021767 Validation Loss: 0.004423334263265133\n",
      "6888 Training Loss: 0.00301345088519156 Validation Loss: 0.004246737342327833\n",
      "6889 Training Loss: 0.002480878494679928 Validation Loss: 0.004096055403351784\n",
      "6890 Training Loss: 0.002858315594494343 Validation Loss: 0.004031298216432333\n",
      "6891 Training Loss: 0.002646913519129157 Validation Loss: 0.004004265647381544\n",
      "6892 Training Loss: 0.0027919355779886246 Validation Loss: 0.0039586531929671764\n",
      "6893 Training Loss: 0.0023395814932882786 Validation Loss: 0.003943163901567459\n",
      "6894 Training Loss: 0.0032871770672500134 Validation Loss: 0.003933492582291365\n",
      "6895 Training Loss: 0.002934880554676056 Validation Loss: 0.003901885822415352\n",
      "6896 Training Loss: 0.0032998393289744854 Validation Loss: 0.003952132537961006\n",
      "6897 Training Loss: 0.0031750884372740984 Validation Loss: 0.004024271387606859\n",
      "6898 Training Loss: 0.0024746020790189505 Validation Loss: 0.004046539310365915\n",
      "6899 Training Loss: 0.002589989686384797 Validation Loss: 0.003980990964919329\n",
      "6900 Training Loss: 0.0027215941809117794 Validation Loss: 0.00387088512070477\n",
      "6901 Training Loss: 0.002608606591820717 Validation Loss: 0.0037800113204866648\n",
      "6902 Training Loss: 0.002592496108263731 Validation Loss: 0.003746853908523917\n",
      "6903 Training Loss: 0.0026710801757872105 Validation Loss: 0.003740409854799509\n",
      "6904 Training Loss: 0.002478374633938074 Validation Loss: 0.0037500406615436077\n",
      "6905 Training Loss: 0.002543787471950054 Validation Loss: 0.003762029344215989\n",
      "6906 Training Loss: 0.0027866396121680737 Validation Loss: 0.0037803149316459894\n",
      "6907 Training Loss: 0.002425556071102619 Validation Loss: 0.003833676688373089\n",
      "6908 Training Loss: 0.002708474174141884 Validation Loss: 0.003888011910021305\n",
      "6909 Training Loss: 0.0026455449406057596 Validation Loss: 0.003964846953749657\n",
      "6910 Training Loss: 0.002587631344795227 Validation Loss: 0.003976542502641678\n",
      "6911 Training Loss: 0.002286813920363784 Validation Loss: 0.003967153374105692\n",
      "6912 Training Loss: 0.002821299945935607 Validation Loss: 0.003975113853812218\n",
      "6913 Training Loss: 0.0025352919474244118 Validation Loss: 0.003930538427084684\n",
      "6914 Training Loss: 0.0029896541964262724 Validation Loss: 0.0038727151695638895\n",
      "6915 Training Loss: 0.002298584673553705 Validation Loss: 0.0038188081234693527\n",
      "6916 Training Loss: 0.0024320059455931187 Validation Loss: 0.0037536201998591423\n",
      "6917 Training Loss: 0.0031516458839178085 Validation Loss: 0.0037123598158359528\n",
      "6918 Training Loss: 0.0027995193377137184 Validation Loss: 0.003657147753983736\n",
      "6919 Training Loss: 0.002650090027600527 Validation Loss: 0.003619232214987278\n",
      "6920 Training Loss: 0.0024994693230837584 Validation Loss: 0.0036095448303967714\n",
      "6921 Training Loss: 0.0032683294266462326 Validation Loss: 0.003590438049286604\n",
      "6922 Training Loss: 0.002500498201698065 Validation Loss: 0.003575750393792987\n",
      "6923 Training Loss: 0.0025282532442361116 Validation Loss: 0.003569938475266099\n",
      "6924 Training Loss: 0.003389934077858925 Validation Loss: 0.0035802347119897604\n",
      "6925 Training Loss: 0.002366040600463748 Validation Loss: 0.0036152107641100883\n",
      "6926 Training Loss: 0.0042101116850972176 Validation Loss: 0.0037019371520727873\n",
      "6927 Training Loss: 0.0029167127795517445 Validation Loss: 0.003813778515905142\n",
      "6928 Training Loss: 0.002665708540007472 Validation Loss: 0.003842101665213704\n",
      "6929 Training Loss: 0.002864609472453594 Validation Loss: 0.0037913480773568153\n",
      "6930 Training Loss: 0.00260806642472744 Validation Loss: 0.003720482811331749\n",
      "6931 Training Loss: 0.002686389721930027 Validation Loss: 0.0036403408739715815\n",
      "6932 Training Loss: 0.002600063569843769 Validation Loss: 0.0035784775391221046\n",
      "6933 Training Loss: 0.004425690043717623 Validation Loss: 0.0035450980067253113\n",
      "6934 Training Loss: 0.0025280392728745937 Validation Loss: 0.0035228473134338856\n",
      "6935 Training Loss: 0.003320319578051567 Validation Loss: 0.003546783234924078\n",
      "6936 Training Loss: 0.004716820083558559 Validation Loss: 0.0037010449450463057\n",
      "6937 Training Loss: 0.00503825768828392 Validation Loss: 0.003883840050548315\n",
      "6938 Training Loss: 0.0027275956235826015 Validation Loss: 0.003918988164514303\n",
      "6939 Training Loss: 0.0025101301725953817 Validation Loss: 0.0038006906397640705\n",
      "6940 Training Loss: 0.0026297178119421005 Validation Loss: 0.00359906442463398\n",
      "6941 Training Loss: 0.0025211696047335863 Validation Loss: 0.003499330021440983\n",
      "6942 Training Loss: 0.0024610301479697227 Validation Loss: 0.00350214634090662\n",
      "6943 Training Loss: 0.0029900590889155865 Validation Loss: 0.0035304417833685875\n",
      "6944 Training Loss: 0.002778205554932356 Validation Loss: 0.0035545388236641884\n",
      "6945 Training Loss: 0.002886088564991951 Validation Loss: 0.00354858860373497\n",
      "6946 Training Loss: 0.0026350338011980057 Validation Loss: 0.0035454672761261463\n",
      "6947 Training Loss: 0.0023353160358965397 Validation Loss: 0.0035700828302651644\n",
      "6948 Training Loss: 0.0023948776070028543 Validation Loss: 0.0035992851480841637\n",
      "6949 Training Loss: 0.0034421985037624836 Validation Loss: 0.0036396305076777935\n",
      "6950 Training Loss: 0.002437345217913389 Validation Loss: 0.003679063869640231\n",
      "6951 Training Loss: 0.0024384367279708385 Validation Loss: 0.003698031883686781\n",
      "6952 Training Loss: 0.0026027574203908443 Validation Loss: 0.0036800859961658716\n",
      "6953 Training Loss: 0.0022991858422756195 Validation Loss: 0.003631121478974819\n",
      "6954 Training Loss: 0.002499302849173546 Validation Loss: 0.0035798109602183104\n",
      "6955 Training Loss: 0.002467110985890031 Validation Loss: 0.003558454103767872\n",
      "6956 Training Loss: 0.003640672191977501 Validation Loss: 0.003556837560608983\n",
      "6957 Training Loss: 0.003708970034494996 Validation Loss: 0.0035944716073572636\n",
      "6958 Training Loss: 0.003473315853625536 Validation Loss: 0.003727548522874713\n",
      "6959 Training Loss: 0.003754747798666358 Validation Loss: 0.003919375594705343\n",
      "6960 Training Loss: 0.0024838042445480824 Validation Loss: 0.004093836061656475\n",
      "6961 Training Loss: 0.003170065116137266 Validation Loss: 0.004107411950826645\n",
      "6962 Training Loss: 0.003261623438447714 Validation Loss: 0.003995062783360481\n",
      "6963 Training Loss: 0.0023144164588302374 Validation Loss: 0.003849729197099805\n",
      "6964 Training Loss: 0.0025541875511407852 Validation Loss: 0.0036965305916965008\n",
      "6965 Training Loss: 0.0025485530495643616 Validation Loss: 0.0036184091586619616\n",
      "6966 Training Loss: 0.0023565045557916164 Validation Loss: 0.0036042225547134876\n",
      "6967 Training Loss: 0.0030565178021788597 Validation Loss: 0.0036100514698773623\n",
      "6968 Training Loss: 0.002699561882764101 Validation Loss: 0.0036280809435993433\n",
      "6969 Training Loss: 0.00308180321007967 Validation Loss: 0.0036815220955759287\n",
      "6970 Training Loss: 0.002829202450811863 Validation Loss: 0.003889781190082431\n",
      "6971 Training Loss: 0.0026445379480719566 Validation Loss: 0.004084957297891378\n",
      "6972 Training Loss: 0.00300896936096251 Validation Loss: 0.004064479842782021\n",
      "6973 Training Loss: 0.0024725892581045628 Validation Loss: 0.003928015008568764\n",
      "6974 Training Loss: 0.002653878415003419 Validation Loss: 0.0037324782460927963\n",
      "6975 Training Loss: 0.002445467282086611 Validation Loss: 0.003619254333898425\n",
      "6976 Training Loss: 0.002569318749010563 Validation Loss: 0.0035731804091483355\n",
      "6977 Training Loss: 0.002576278755441308 Validation Loss: 0.003558701602742076\n",
      "6978 Training Loss: 0.0025757986586540937 Validation Loss: 0.0035615884698927402\n",
      "6979 Training Loss: 0.0029785584192723036 Validation Loss: 0.0035502773243933916\n",
      "6980 Training Loss: 0.0026366268284618855 Validation Loss: 0.0035421904176473618\n",
      "6981 Training Loss: 0.002588978037238121 Validation Loss: 0.003553398186340928\n",
      "6982 Training Loss: 0.002528906799852848 Validation Loss: 0.003592770779505372\n",
      "6983 Training Loss: 0.003062092699110508 Validation Loss: 0.003675265936180949\n",
      "6984 Training Loss: 0.002908668713644147 Validation Loss: 0.0037983874790370464\n",
      "6985 Training Loss: 0.0026355350855737925 Validation Loss: 0.003930131439119577\n",
      "6986 Training Loss: 0.002892686752602458 Validation Loss: 0.0038850875571370125\n",
      "6987 Training Loss: 0.002411182504147291 Validation Loss: 0.00379754276946187\n",
      "6988 Training Loss: 0.0032796887680888176 Validation Loss: 0.003800346050411463\n",
      "6989 Training Loss: 0.0028390586376190186 Validation Loss: 0.0037632258608937263\n",
      "6990 Training Loss: 0.0033641494810581207 Validation Loss: 0.003769303672015667\n",
      "6991 Training Loss: 0.004235638305544853 Validation Loss: 0.0038262533489614725\n",
      "6992 Training Loss: 0.002288973890244961 Validation Loss: 0.00390580203384161\n",
      "6993 Training Loss: 0.0028829590883105993 Validation Loss: 0.003971358295530081\n",
      "6994 Training Loss: 0.002595086582005024 Validation Loss: 0.0039738016203045845\n",
      "6995 Training Loss: 0.002548739779740572 Validation Loss: 0.003922380972653627\n",
      "6996 Training Loss: 0.0032816454768180847 Validation Loss: 0.003857116214931011\n",
      "6997 Training Loss: 0.0029319575987756252 Validation Loss: 0.003820992074906826\n",
      "6998 Training Loss: 0.0030844344291836023 Validation Loss: 0.00381309911608696\n",
      "6999 Training Loss: 0.004320438019931316 Validation Loss: 0.0038526810240000486\n",
      "7000 Training Loss: 0.0032604699954390526 Validation Loss: 0.0038884272798895836\n",
      "7001 Training Loss: 0.002612503245472908 Validation Loss: 0.0038465610705316067\n",
      "7002 Training Loss: 0.0025611398741602898 Validation Loss: 0.0038015455938875675\n",
      "7003 Training Loss: 0.0034518432803452015 Validation Loss: 0.003816382260993123\n",
      "7004 Training Loss: 0.0022538902703672647 Validation Loss: 0.003814834402874112\n",
      "7005 Training Loss: 0.0023811240680515766 Validation Loss: 0.003832113929092884\n",
      "7006 Training Loss: 0.0024157532025128603 Validation Loss: 0.003806257387623191\n",
      "7007 Training Loss: 0.002598752034828067 Validation Loss: 0.0038142672274261713\n",
      "7008 Training Loss: 0.002785090822726488 Validation Loss: 0.0038301588501781225\n",
      "7009 Training Loss: 0.0035537690855562687 Validation Loss: 0.003930666949599981\n",
      "7010 Training Loss: 0.0025161560624837875 Validation Loss: 0.003982705995440483\n",
      "7011 Training Loss: 0.002802052302286029 Validation Loss: 0.004002981353551149\n",
      "7012 Training Loss: 0.0025690747424960136 Validation Loss: 0.004004274029284716\n",
      "7013 Training Loss: 0.002567766699939966 Validation Loss: 0.00394732691347599\n",
      "7014 Training Loss: 0.0022088862024247646 Validation Loss: 0.003853169269859791\n",
      "7015 Training Loss: 0.002562479814514518 Validation Loss: 0.0037365478929132223\n",
      "7016 Training Loss: 0.0024285982362926006 Validation Loss: 0.00368694681674242\n",
      "7017 Training Loss: 0.00254134857095778 Validation Loss: 0.0036440782714635134\n",
      "7018 Training Loss: 0.0029741320759058 Validation Loss: 0.0036575961858034134\n",
      "7019 Training Loss: 0.0022688698954880238 Validation Loss: 0.003689583158120513\n",
      "7020 Training Loss: 0.002388635417446494 Validation Loss: 0.0037729672621935606\n",
      "7021 Training Loss: 0.0021769723389297724 Validation Loss: 0.0038408897817134857\n",
      "7022 Training Loss: 0.0022043290082365274 Validation Loss: 0.0038856049068272114\n",
      "7023 Training Loss: 0.002276466228067875 Validation Loss: 0.003968430683016777\n",
      "7024 Training Loss: 0.0026118550449609756 Validation Loss: 0.0039967941120266914\n",
      "7025 Training Loss: 0.0028618965297937393 Validation Loss: 0.00399058498442173\n",
      "7026 Training Loss: 0.0024505299516022205 Validation Loss: 0.0039876773953437805\n",
      "7027 Training Loss: 0.0022899219766259193 Validation Loss: 0.0039003861602395773\n",
      "7028 Training Loss: 0.0028236783109605312 Validation Loss: 0.003781473496928811\n",
      "7029 Training Loss: 0.002485766541212797 Validation Loss: 0.0037150478456169367\n",
      "7030 Training Loss: 0.002907849382609129 Validation Loss: 0.003675148356705904\n",
      "7031 Training Loss: 0.0033817929215729237 Validation Loss: 0.003678792854771018\n",
      "7032 Training Loss: 0.0021745949052274227 Validation Loss: 0.00368625414557755\n",
      "7033 Training Loss: 0.004947361536324024 Validation Loss: 0.003766469657421112\n",
      "7034 Training Loss: 0.0022286446765065193 Validation Loss: 0.003809093264862895\n",
      "7035 Training Loss: 0.003291551023721695 Validation Loss: 0.0038518800865858793\n",
      "7036 Training Loss: 0.0022874712012708187 Validation Loss: 0.0038421954959630966\n",
      "7037 Training Loss: 0.0026082624681293964 Validation Loss: 0.0037599196657538414\n",
      "7038 Training Loss: 0.0022022686898708344 Validation Loss: 0.0037013182882219553\n",
      "7039 Training Loss: 0.0023739717435091734 Validation Loss: 0.0036746319383382797\n",
      "7040 Training Loss: 0.0023379167541861534 Validation Loss: 0.0036679685581475496\n",
      "7041 Training Loss: 0.0025618914514780045 Validation Loss: 0.0036688356194645166\n",
      "7042 Training Loss: 0.0022887946106493473 Validation Loss: 0.0036616523284465075\n",
      "7043 Training Loss: 0.0021586408838629723 Validation Loss: 0.0036551395896822214\n",
      "7044 Training Loss: 0.0028770463541150093 Validation Loss: 0.003660575719550252\n",
      "7045 Training Loss: 0.003305416088551283 Validation Loss: 0.0037411334924399853\n",
      "7046 Training Loss: 0.00234966236166656 Validation Loss: 0.003774012438952923\n",
      "7047 Training Loss: 0.0030141088645905256 Validation Loss: 0.0037782120052725077\n",
      "7048 Training Loss: 0.002333727665245533 Validation Loss: 0.0037097481545060873\n",
      "7049 Training Loss: 0.0024388267192989588 Validation Loss: 0.0035887151025235653\n",
      "7050 Training Loss: 0.0021452968940138817 Validation Loss: 0.0034929150715470314\n",
      "7051 Training Loss: 0.0032524573616683483 Validation Loss: 0.0034753428772091866\n",
      "7052 Training Loss: 0.0028072642162442207 Validation Loss: 0.003461427055299282\n",
      "7053 Training Loss: 0.0029047271236777306 Validation Loss: 0.0034755661617964506\n",
      "7054 Training Loss: 0.002555305603891611 Validation Loss: 0.003489443100988865\n",
      "7055 Training Loss: 0.0027228565886616707 Validation Loss: 0.003516550175845623\n",
      "7056 Training Loss: 0.002232937840744853 Validation Loss: 0.003549428191035986\n",
      "7057 Training Loss: 0.0021016765385866165 Validation Loss: 0.003602160606533289\n",
      "7058 Training Loss: 0.0035774996504187584 Validation Loss: 0.0036567391362041235\n",
      "7059 Training Loss: 0.002237738110125065 Validation Loss: 0.0036540913861244917\n",
      "7060 Training Loss: 0.003528769128024578 Validation Loss: 0.003616432659327984\n",
      "7061 Training Loss: 0.0026686908677220345 Validation Loss: 0.0036161798052489758\n",
      "7062 Training Loss: 0.002141572069376707 Validation Loss: 0.003567364066839218\n",
      "7063 Training Loss: 0.0023273059632629156 Validation Loss: 0.0034969081170856953\n",
      "7064 Training Loss: 0.0022579608485102654 Validation Loss: 0.003454536898061633\n",
      "7065 Training Loss: 0.0023108399473130703 Validation Loss: 0.003422106383368373\n",
      "7066 Training Loss: 0.0030913474038243294 Validation Loss: 0.003413016442209482\n",
      "7067 Training Loss: 0.0031459624879062176 Validation Loss: 0.0034351444337517023\n",
      "7068 Training Loss: 0.004302230663597584 Validation Loss: 0.003552747657522559\n",
      "7069 Training Loss: 0.0022725097369402647 Validation Loss: 0.0036781523376703262\n",
      "7070 Training Loss: 0.0024324050173163414 Validation Loss: 0.003742836182937026\n",
      "7071 Training Loss: 0.0022814625408500433 Validation Loss: 0.0037306775338947773\n",
      "7072 Training Loss: 0.0024427222087979317 Validation Loss: 0.0036278634797781706\n",
      "7073 Training Loss: 0.002381484489887953 Validation Loss: 0.0035593362990766764\n",
      "7074 Training Loss: 0.002573132747784257 Validation Loss: 0.0035702399909496307\n",
      "7075 Training Loss: 0.0026945481076836586 Validation Loss: 0.0036538203712552786\n",
      "7076 Training Loss: 0.0020868461579084396 Validation Loss: 0.003745013615116477\n",
      "7077 Training Loss: 0.002258910331875086 Validation Loss: 0.0038097905926406384\n",
      "7078 Training Loss: 0.0023539550602436066 Validation Loss: 0.003807772882282734\n",
      "7079 Training Loss: 0.0033306810073554516 Validation Loss: 0.003804735839366913\n",
      "7080 Training Loss: 0.002463156823068857 Validation Loss: 0.003733504330739379\n",
      "7081 Training Loss: 0.0021787036675959826 Validation Loss: 0.003694775979965925\n",
      "7082 Training Loss: 0.0028779110871255398 Validation Loss: 0.003631944302469492\n",
      "7083 Training Loss: 0.00211973674595356 Validation Loss: 0.003580008167773485\n",
      "7084 Training Loss: 0.0023811087012290955 Validation Loss: 0.0035472146701067686\n",
      "7085 Training Loss: 0.0023629621136933565 Validation Loss: 0.003506785025820136\n",
      "7086 Training Loss: 0.0024774037301540375 Validation Loss: 0.0034662361722439528\n",
      "7087 Training Loss: 0.002759801922366023 Validation Loss: 0.0034978585317730904\n",
      "7088 Training Loss: 0.002510946709662676 Validation Loss: 0.0035431082360446453\n",
      "7089 Training Loss: 0.0028400670271366835 Validation Loss: 0.003603434655815363\n",
      "7090 Training Loss: 0.002739494666457176 Validation Loss: 0.003709286917001009\n",
      "7091 Training Loss: 0.002765218261629343 Validation Loss: 0.0038531532045453787\n",
      "7092 Training Loss: 0.0023027253337204456 Validation Loss: 0.0038882927037775517\n",
      "7093 Training Loss: 0.0025939056649804115 Validation Loss: 0.003850541776046157\n",
      "7094 Training Loss: 0.0029338225722312927 Validation Loss: 0.003842055331915617\n",
      "7095 Training Loss: 0.002380609977990389 Validation Loss: 0.003788772039115429\n",
      "7096 Training Loss: 0.0022318088449537754 Validation Loss: 0.0036965396720916033\n",
      "7097 Training Loss: 0.0021773886401206255 Validation Loss: 0.0036232275888323784\n",
      "7098 Training Loss: 0.0025594073813408613 Validation Loss: 0.0035352823324501514\n",
      "7099 Training Loss: 0.0022829563822597265 Validation Loss: 0.0034689693711698055\n",
      "7100 Training Loss: 0.0020026550628244877 Validation Loss: 0.00343270692974329\n",
      "7101 Training Loss: 0.00211407826282084 Validation Loss: 0.003421473316848278\n",
      "7102 Training Loss: 0.002643838059157133 Validation Loss: 0.0034292959608137608\n",
      "7103 Training Loss: 0.0024496293626725674 Validation Loss: 0.0034292545169591904\n",
      "7104 Training Loss: 0.00244909874163568 Validation Loss: 0.003461074084043503\n",
      "7105 Training Loss: 0.0025680402759462595 Validation Loss: 0.0035189762711524963\n",
      "7106 Training Loss: 0.0022399004083126783 Validation Loss: 0.0035646052565425634\n",
      "7107 Training Loss: 0.003451373428106308 Validation Loss: 0.003681745147332549\n",
      "7108 Training Loss: 0.0022895701695233583 Validation Loss: 0.003759767161682248\n",
      "7109 Training Loss: 0.002137501025572419 Validation Loss: 0.0038047591224312782\n",
      "7110 Training Loss: 0.0022297068499028683 Validation Loss: 0.003778667887672782\n",
      "7111 Training Loss: 0.003923749551177025 Validation Loss: 0.003797197015956044\n",
      "7112 Training Loss: 0.0020633493550121784 Validation Loss: 0.003789312206208706\n",
      "7113 Training Loss: 0.004007689654827118 Validation Loss: 0.003826051251962781\n",
      "7114 Training Loss: 0.002639802172780037 Validation Loss: 0.0038954189512878656\n",
      "7115 Training Loss: 0.0029151705093681812 Validation Loss: 0.0038165259175002575\n",
      "7116 Training Loss: 0.0022342498414218426 Validation Loss: 0.0037159721832722425\n",
      "7117 Training Loss: 0.001954111736267805 Validation Loss: 0.0036421092227101326\n",
      "7118 Training Loss: 0.0026316558942198753 Validation Loss: 0.00357234594412148\n",
      "7119 Training Loss: 0.0020862044766545296 Validation Loss: 0.0035185187589377165\n",
      "7120 Training Loss: 0.002586563117802143 Validation Loss: 0.0035056674387305975\n",
      "7121 Training Loss: 0.0023331185802817345 Validation Loss: 0.003526107408106327\n",
      "7122 Training Loss: 0.002260482171550393 Validation Loss: 0.0035626497119665146\n",
      "7123 Training Loss: 0.0021797427907586098 Validation Loss: 0.0036094554234296083\n",
      "7124 Training Loss: 0.0026106457225978374 Validation Loss: 0.0036306381225585938\n",
      "7125 Training Loss: 0.002258423948660493 Validation Loss: 0.003610159270465374\n",
      "7126 Training Loss: 0.002099171746522188 Validation Loss: 0.003590065985918045\n",
      "7127 Training Loss: 0.002136428840458393 Validation Loss: 0.0035830282140523195\n",
      "7128 Training Loss: 0.003075724933296442 Validation Loss: 0.0036153641995042562\n",
      "7129 Training Loss: 0.002397896721959114 Validation Loss: 0.003610029583796859\n",
      "7130 Training Loss: 0.0028501120395958424 Validation Loss: 0.0035232044756412506\n",
      "7131 Training Loss: 0.0023467065766453743 Validation Loss: 0.0034828095231205225\n",
      "7132 Training Loss: 0.002467128448188305 Validation Loss: 0.003439798951148987\n",
      "7133 Training Loss: 0.002835604827851057 Validation Loss: 0.0034136888571083546\n",
      "7134 Training Loss: 0.003878445830196142 Validation Loss: 0.003457547863945365\n",
      "7135 Training Loss: 0.002619038335978985 Validation Loss: 0.003467812668532133\n",
      "7136 Training Loss: 0.0033667830284684896 Validation Loss: 0.003549522254616022\n",
      "7137 Training Loss: 0.0021802217233926058 Validation Loss: 0.0035720565356314182\n",
      "7138 Training Loss: 0.002389907604083419 Validation Loss: 0.00357798277400434\n",
      "7139 Training Loss: 0.0023170635104179382 Validation Loss: 0.0035517909564077854\n",
      "7140 Training Loss: 0.0029564977157860994 Validation Loss: 0.00362217565998435\n",
      "7141 Training Loss: 0.0020286724902689457 Validation Loss: 0.003691771300509572\n",
      "7142 Training Loss: 0.0030990727245807648 Validation Loss: 0.0038354252465069294\n",
      "7143 Training Loss: 0.0024641132913529873 Validation Loss: 0.003880560165271163\n",
      "7144 Training Loss: 0.0020819969940930605 Validation Loss: 0.003911314997822046\n",
      "7145 Training Loss: 0.004692720249295235 Validation Loss: 0.003993728198111057\n",
      "7146 Training Loss: 0.002276637591421604 Validation Loss: 0.0040044356137514114\n",
      "7147 Training Loss: 0.0022645131684839725 Validation Loss: 0.003916650079190731\n",
      "7148 Training Loss: 0.0023024152033030987 Validation Loss: 0.00376273225992918\n",
      "7149 Training Loss: 0.0027161957696080208 Validation Loss: 0.0035812989808619022\n",
      "7150 Training Loss: 0.0031498917378485203 Validation Loss: 0.003516929689794779\n",
      "7151 Training Loss: 0.003214498981833458 Validation Loss: 0.0035164328292012215\n",
      "7152 Training Loss: 0.002245695563033223 Validation Loss: 0.0035397661849856377\n",
      "7153 Training Loss: 0.0024300941731780767 Validation Loss: 0.00354752317070961\n",
      "7154 Training Loss: 0.002352215116843581 Validation Loss: 0.003498546313494444\n",
      "7155 Training Loss: 0.002804855816066265 Validation Loss: 0.003484426299110055\n",
      "7156 Training Loss: 0.0023171394132077694 Validation Loss: 0.0034554852172732353\n",
      "7157 Training Loss: 0.003470049472525716 Validation Loss: 0.003455676604062319\n",
      "7158 Training Loss: 0.0024158041924238205 Validation Loss: 0.003495279001072049\n",
      "7159 Training Loss: 0.0023094862699508667 Validation Loss: 0.003534094663336873\n",
      "7160 Training Loss: 0.003089450066909194 Validation Loss: 0.0036330402363091707\n",
      "7161 Training Loss: 0.0020491434261202812 Validation Loss: 0.003688286989927292\n",
      "7162 Training Loss: 0.0021506743505597115 Validation Loss: 0.003680152352899313\n",
      "7163 Training Loss: 0.0020160803105682135 Validation Loss: 0.003637230722233653\n",
      "7164 Training Loss: 0.0021749676670879126 Validation Loss: 0.003603018121793866\n",
      "7165 Training Loss: 0.0020655496045947075 Validation Loss: 0.0035825285594910383\n",
      "7166 Training Loss: 0.0024294182658195496 Validation Loss: 0.003582174424082041\n",
      "7167 Training Loss: 0.0027854645159095526 Validation Loss: 0.003589901840314269\n",
      "7168 Training Loss: 0.0023418550845235586 Validation Loss: 0.0035604475997388363\n",
      "7169 Training Loss: 0.0019486984238028526 Validation Loss: 0.003551927162334323\n",
      "7170 Training Loss: 0.0029618442058563232 Validation Loss: 0.0035529984161257744\n",
      "7171 Training Loss: 0.0026160047855228186 Validation Loss: 0.003592149820178747\n",
      "7172 Training Loss: 0.0020464390981942415 Validation Loss: 0.0036192075349390507\n",
      "7173 Training Loss: 0.002725795144215226 Validation Loss: 0.0036647790111601353\n",
      "7174 Training Loss: 0.002410228829830885 Validation Loss: 0.0036258141044527292\n",
      "7175 Training Loss: 0.0023845324758440256 Validation Loss: 0.00352302985265851\n",
      "7176 Training Loss: 0.002268334850668907 Validation Loss: 0.003448298666626215\n",
      "7177 Training Loss: 0.0021331030875444412 Validation Loss: 0.0034112180583178997\n",
      "7178 Training Loss: 0.0021773369517177343 Validation Loss: 0.003403998911380768\n",
      "7179 Training Loss: 0.0018746983259916306 Validation Loss: 0.003416075138375163\n",
      "7180 Training Loss: 0.002148660598322749 Validation Loss: 0.0034402264282107353\n",
      "7181 Training Loss: 0.0022503784857690334 Validation Loss: 0.003495582612231374\n",
      "7182 Training Loss: 0.0027979903388768435 Validation Loss: 0.003556937910616398\n",
      "7183 Training Loss: 0.0022966754622757435 Validation Loss: 0.0036431371700018644\n",
      "7184 Training Loss: 0.0019907106179744005 Validation Loss: 0.0036832354962825775\n",
      "7185 Training Loss: 0.0026661213487386703 Validation Loss: 0.003772149793803692\n",
      "7186 Training Loss: 0.0020449189469218254 Validation Loss: 0.0038298661820590496\n",
      "7187 Training Loss: 0.00253630755469203 Validation Loss: 0.0037508399691432714\n",
      "7188 Training Loss: 0.0024402833078056574 Validation Loss: 0.003617202630266547\n",
      "7189 Training Loss: 0.0026410892605781555 Validation Loss: 0.0035396572202444077\n",
      "7190 Training Loss: 0.0024698758497834206 Validation Loss: 0.003520908299833536\n",
      "7191 Training Loss: 0.0022879252210259438 Validation Loss: 0.003467065282166004\n",
      "7192 Training Loss: 0.0035255197435617447 Validation Loss: 0.003466208465397358\n",
      "7193 Training Loss: 0.002128320513293147 Validation Loss: 0.003470543073490262\n",
      "7194 Training Loss: 0.0021032565273344517 Validation Loss: 0.00346006010659039\n",
      "7195 Training Loss: 0.002113612135872245 Validation Loss: 0.0034307939931750298\n",
      "7196 Training Loss: 0.0029208653140813112 Validation Loss: 0.0034286112058907747\n",
      "7197 Training Loss: 0.0020459287334233522 Validation Loss: 0.0034425861667841673\n",
      "7198 Training Loss: 0.00283998204395175 Validation Loss: 0.0034999048803001642\n",
      "7199 Training Loss: 0.003377098124474287 Validation Loss: 0.0036368619184941053\n",
      "7200 Training Loss: 0.0021115406416356564 Validation Loss: 0.0037247869186103344\n",
      "7201 Training Loss: 0.0020712330006062984 Validation Loss: 0.003718337742611766\n",
      "7202 Training Loss: 0.002063469961285591 Validation Loss: 0.003652404062449932\n",
      "7203 Training Loss: 0.0022380072623491287 Validation Loss: 0.0035824738442897797\n",
      "7204 Training Loss: 0.0019321765284985304 Validation Loss: 0.003518530400469899\n",
      "7205 Training Loss: 0.003016808070242405 Validation Loss: 0.0035552941262722015\n",
      "7206 Training Loss: 0.0022187926806509495 Validation Loss: 0.0035584252327680588\n",
      "7207 Training Loss: 0.0029154205694794655 Validation Loss: 0.003559269942343235\n",
      "7208 Training Loss: 0.002764425240457058 Validation Loss: 0.003719624597579241\n",
      "7209 Training Loss: 0.0022394685074687004 Validation Loss: 0.0037871061358600855\n",
      "7210 Training Loss: 0.002053387463092804 Validation Loss: 0.0037868660874664783\n",
      "7211 Training Loss: 0.0020368036348372698 Validation Loss: 0.0037144217640161514\n",
      "7212 Training Loss: 0.0021387843880802393 Validation Loss: 0.003645308082923293\n",
      "7213 Training Loss: 0.002249479293823242 Validation Loss: 0.00358036276884377\n",
      "7214 Training Loss: 0.002302310662344098 Validation Loss: 0.003502828534692526\n",
      "7215 Training Loss: 0.002232898259535432 Validation Loss: 0.0034312710631638765\n",
      "7216 Training Loss: 0.002815164625644684 Validation Loss: 0.0034431754611432552\n",
      "7217 Training Loss: 0.0019648014567792416 Validation Loss: 0.003485057968646288\n",
      "7218 Training Loss: 0.0033465188462287188 Validation Loss: 0.0036503784358501434\n",
      "7219 Training Loss: 0.002960909390822053 Validation Loss: 0.0038526069838553667\n",
      "7220 Training Loss: 0.002406094688922167 Validation Loss: 0.0039268964901566505\n",
      "7221 Training Loss: 0.002766659250482917 Validation Loss: 0.003978605382144451\n",
      "7222 Training Loss: 0.0022581324446946383 Validation Loss: 0.0039671640843153\n",
      "7223 Training Loss: 0.004100551828742027 Validation Loss: 0.0040052952244877815\n",
      "7224 Training Loss: 0.0028691308107227087 Validation Loss: 0.0038969393353909254\n",
      "7225 Training Loss: 0.0026539014652371407 Validation Loss: 0.0038741938769817352\n",
      "7226 Training Loss: 0.001953675877302885 Validation Loss: 0.003819000441581011\n",
      "7227 Training Loss: 0.0023550400510430336 Validation Loss: 0.0036783574614673853\n",
      "7228 Training Loss: 0.0020999193657189608 Validation Loss: 0.0035519679076969624\n",
      "7229 Training Loss: 0.003047916805371642 Validation Loss: 0.0034954259172081947\n",
      "7230 Training Loss: 0.00213568820618093 Validation Loss: 0.003458369290456176\n",
      "7231 Training Loss: 0.0020594738889485598 Validation Loss: 0.0034415260888636112\n",
      "7232 Training Loss: 0.00260325544513762 Validation Loss: 0.003500098129734397\n",
      "7233 Training Loss: 0.002318361774086952 Validation Loss: 0.003575020469725132\n",
      "7234 Training Loss: 0.0021599142346531153 Validation Loss: 0.003612852655351162\n",
      "7235 Training Loss: 0.0020776130259037018 Validation Loss: 0.003611251711845398\n",
      "7236 Training Loss: 0.0021230685524642467 Validation Loss: 0.0035688269417732954\n",
      "7237 Training Loss: 0.0020442737732082605 Validation Loss: 0.0035408204421401024\n",
      "7238 Training Loss: 0.0020017309579998255 Validation Loss: 0.003519444027915597\n",
      "7239 Training Loss: 0.0032948171719908714 Validation Loss: 0.0035289106890559196\n",
      "7240 Training Loss: 0.0022788280621170998 Validation Loss: 0.0035324126947671175\n",
      "7241 Training Loss: 0.0020438539795577526 Validation Loss: 0.00354798324406147\n",
      "7242 Training Loss: 0.0023238961584866047 Validation Loss: 0.0036180245224386454\n",
      "7243 Training Loss: 0.002735068090260029 Validation Loss: 0.00372025603428483\n",
      "7244 Training Loss: 0.0019352021627128124 Validation Loss: 0.0038068227004259825\n",
      "7245 Training Loss: 0.0024066586047410965 Validation Loss: 0.0038535972125828266\n",
      "7246 Training Loss: 0.002391634974628687 Validation Loss: 0.0037632212042808533\n",
      "7247 Training Loss: 0.002369082998484373 Validation Loss: 0.003618428949266672\n",
      "7248 Training Loss: 0.0021160244941711426 Validation Loss: 0.003497337456792593\n",
      "7249 Training Loss: 0.003235368523746729 Validation Loss: 0.0034795929677784443\n",
      "7250 Training Loss: 0.0023066981229931116 Validation Loss: 0.003436309052631259\n",
      "7251 Training Loss: 0.002873252145946026 Validation Loss: 0.003469869028776884\n",
      "7252 Training Loss: 0.0021197458263486624 Validation Loss: 0.00348210078664124\n",
      "7253 Training Loss: 0.00235131848603487 Validation Loss: 0.00352185545489192\n",
      "7254 Training Loss: 0.0032803774811327457 Validation Loss: 0.003593105124309659\n",
      "7255 Training Loss: 0.002316538942977786 Validation Loss: 0.0035992630291730165\n",
      "7256 Training Loss: 0.003399380948394537 Validation Loss: 0.003634990192949772\n",
      "7257 Training Loss: 0.0022452352568507195 Validation Loss: 0.003614431247115135\n",
      "7258 Training Loss: 0.003135125385597348 Validation Loss: 0.003615821013227105\n",
      "7259 Training Loss: 0.0021646395325660706 Validation Loss: 0.0035453946329653263\n",
      "7260 Training Loss: 0.0020503101404756308 Validation Loss: 0.0034635919146239758\n",
      "7261 Training Loss: 0.002165017882362008 Validation Loss: 0.003393168095499277\n",
      "7262 Training Loss: 0.0035939065273851156 Validation Loss: 0.0034181219525635242\n",
      "7263 Training Loss: 0.001992629375308752 Validation Loss: 0.0034601257648319006\n",
      "7264 Training Loss: 0.0023994632065296173 Validation Loss: 0.0035016248002648354\n",
      "7265 Training Loss: 0.0033663827925920486 Validation Loss: 0.0036789108999073505\n",
      "7266 Training Loss: 0.0028664073906838894 Validation Loss: 0.0038867099210619926\n",
      "7267 Training Loss: 0.002443446312099695 Validation Loss: 0.0038660787977278233\n",
      "7268 Training Loss: 0.0029502958059310913 Validation Loss: 0.003797577926889062\n",
      "7269 Training Loss: 0.0028919263277202845 Validation Loss: 0.003655682085081935\n",
      "7270 Training Loss: 0.003255886258557439 Validation Loss: 0.0035042925737798214\n",
      "7271 Training Loss: 0.00209415121935308 Validation Loss: 0.0034041530452668667\n",
      "7272 Training Loss: 0.002119209384545684 Validation Loss: 0.0033354847691953182\n",
      "7273 Training Loss: 0.002083917148411274 Validation Loss: 0.003324784804135561\n",
      "7274 Training Loss: 0.0037713521160185337 Validation Loss: 0.0033477293327450752\n",
      "7275 Training Loss: 0.0020524654537439346 Validation Loss: 0.0034417554270476103\n",
      "7276 Training Loss: 0.0021837365347892046 Validation Loss: 0.0036113462410867214\n",
      "7277 Training Loss: 0.002818724140524864 Validation Loss: 0.00383266294375062\n",
      "7278 Training Loss: 0.0026149279437959194 Validation Loss: 0.004005223512649536\n",
      "7279 Training Loss: 0.0019757067784667015 Validation Loss: 0.004040372092276812\n",
      "7280 Training Loss: 0.0022292970679700375 Validation Loss: 0.0038944988045841455\n",
      "7281 Training Loss: 0.002089437562972307 Validation Loss: 0.003817719640210271\n",
      "7282 Training Loss: 0.0020359065383672714 Validation Loss: 0.0036993783432990313\n",
      "7283 Training Loss: 0.002351554576307535 Validation Loss: 0.0036281270440667868\n",
      "7284 Training Loss: 0.0019816006533801556 Validation Loss: 0.003578233066946268\n",
      "7285 Training Loss: 0.0020978699903935194 Validation Loss: 0.003542900551110506\n",
      "7286 Training Loss: 0.0020784931257367134 Validation Loss: 0.0035428632982075214\n",
      "7287 Training Loss: 0.0019290333148092031 Validation Loss: 0.0035523828119039536\n",
      "7288 Training Loss: 0.002086607739329338 Validation Loss: 0.003524127649143338\n",
      "7289 Training Loss: 0.0025521633215248585 Validation Loss: 0.0034330005291849375\n",
      "7290 Training Loss: 0.004116936586797237 Validation Loss: 0.0034529308322817087\n",
      "7291 Training Loss: 0.0030523398891091347 Validation Loss: 0.0035167019814252853\n",
      "7292 Training Loss: 0.001978266518563032 Validation Loss: 0.003541508223861456\n",
      "7293 Training Loss: 0.001992803532630205 Validation Loss: 0.003533942624926567\n",
      "7294 Training Loss: 0.002369382418692112 Validation Loss: 0.0035541921388357878\n",
      "7295 Training Loss: 0.0020023479592055082 Validation Loss: 0.0035761825274676085\n",
      "7296 Training Loss: 0.0022933296859264374 Validation Loss: 0.0035529169254004955\n",
      "7297 Training Loss: 0.0023644762113690376 Validation Loss: 0.003565919818356633\n",
      "7298 Training Loss: 0.0024729003198444843 Validation Loss: 0.0035703389439731836\n",
      "7299 Training Loss: 0.002036253921687603 Validation Loss: 0.003608589991927147\n",
      "7300 Training Loss: 0.0025221193209290504 Validation Loss: 0.003672013757750392\n",
      "7301 Training Loss: 0.0020542012061923742 Validation Loss: 0.0037082729395478964\n",
      "7302 Training Loss: 0.002427753061056137 Validation Loss: 0.003710184246301651\n",
      "7303 Training Loss: 0.0020821935031563044 Validation Loss: 0.003668669145554304\n",
      "7304 Training Loss: 0.0020984478760510683 Validation Loss: 0.003559111151844263\n",
      "7305 Training Loss: 0.0035679973661899567 Validation Loss: 0.0035331074614077806\n",
      "7306 Training Loss: 0.002259942004457116 Validation Loss: 0.003427039133384824\n",
      "7307 Training Loss: 0.002308801980689168 Validation Loss: 0.0033167190849781036\n",
      "7308 Training Loss: 0.002022520639002323 Validation Loss: 0.0032262583263218403\n",
      "7309 Training Loss: 0.002512414939701557 Validation Loss: 0.0031859581358730793\n",
      "7310 Training Loss: 0.002229004632681608 Validation Loss: 0.0031795280519872904\n",
      "7311 Training Loss: 0.0029905992560088634 Validation Loss: 0.003248041495680809\n",
      "7312 Training Loss: 0.0017703345511108637 Validation Loss: 0.003377986140549183\n",
      "7313 Training Loss: 0.002915630117058754 Validation Loss: 0.003599964315071702\n",
      "7314 Training Loss: 0.0021585244685411453 Validation Loss: 0.0038183594588190317\n",
      "7315 Training Loss: 0.0023355039302259684 Validation Loss: 0.004040976986289024\n",
      "7316 Training Loss: 0.0023151279892772436 Validation Loss: 0.004002384841442108\n",
      "7317 Training Loss: 0.002218803623691201 Validation Loss: 0.003882697783410549\n",
      "7318 Training Loss: 0.0023190430365502834 Validation Loss: 0.0036748377606272697\n",
      "7319 Training Loss: 0.002040248131379485 Validation Loss: 0.003536821808665991\n",
      "7320 Training Loss: 0.0019544714596122503 Validation Loss: 0.003431689692661166\n",
      "7321 Training Loss: 0.002158588729798794 Validation Loss: 0.0033501063007861376\n",
      "7322 Training Loss: 0.0022265021689236164 Validation Loss: 0.0032715671695768833\n",
      "7323 Training Loss: 0.001937438384629786 Validation Loss: 0.0032326795626431704\n",
      "7324 Training Loss: 0.0017666942439973354 Validation Loss: 0.003244552295655012\n",
      "7325 Training Loss: 0.0027960576117038727 Validation Loss: 0.0032856762409210205\n",
      "7326 Training Loss: 0.002188545186072588 Validation Loss: 0.003309372579678893\n",
      "7327 Training Loss: 0.003053075633943081 Validation Loss: 0.0033857268281280994\n",
      "7328 Training Loss: 0.002334163524210453 Validation Loss: 0.0034680368844419718\n",
      "7329 Training Loss: 0.0019476094748824835 Validation Loss: 0.0034640945959836245\n",
      "7330 Training Loss: 0.002348716836422682 Validation Loss: 0.003452748991549015\n",
      "7331 Training Loss: 0.002721242606639862 Validation Loss: 0.003510399954393506\n",
      "7332 Training Loss: 0.0024260184727609158 Validation Loss: 0.003498789854347706\n",
      "7333 Training Loss: 0.0019066822715103626 Validation Loss: 0.0034621846862137318\n",
      "7334 Training Loss: 0.001915851142257452 Validation Loss: 0.003411343786865473\n",
      "7335 Training Loss: 0.0019765926990658045 Validation Loss: 0.0034094962757080793\n",
      "7336 Training Loss: 0.001995454076677561 Validation Loss: 0.003424492198973894\n",
      "7337 Training Loss: 0.0016957735642790794 Validation Loss: 0.0034875955898314714\n",
      "7338 Training Loss: 0.0019785959739238024 Validation Loss: 0.003528907662257552\n",
      "7339 Training Loss: 0.002774038352072239 Validation Loss: 0.0036021056585013866\n",
      "7340 Training Loss: 0.0020804887171834707 Validation Loss: 0.0036218808963894844\n",
      "7341 Training Loss: 0.0018072612583637238 Validation Loss: 0.003564000129699707\n",
      "7342 Training Loss: 0.0021325568668544292 Validation Loss: 0.0035076362546533346\n",
      "7343 Training Loss: 0.0018825202714651823 Validation Loss: 0.003410248551517725\n",
      "7344 Training Loss: 0.0018050591461360455 Validation Loss: 0.003351732390001416\n",
      "7345 Training Loss: 0.001910872757434845 Validation Loss: 0.0033360894303768873\n",
      "7346 Training Loss: 0.0019191560568287969 Validation Loss: 0.0033336258493363857\n",
      "7347 Training Loss: 0.0022353087551891804 Validation Loss: 0.003367844270542264\n",
      "7348 Training Loss: 0.0022718312684446573 Validation Loss: 0.003389490768313408\n",
      "7349 Training Loss: 0.0019107633270323277 Validation Loss: 0.0034310235641896725\n",
      "7350 Training Loss: 0.0019935290329158306 Validation Loss: 0.0035160493571311235\n",
      "7351 Training Loss: 0.002071692142635584 Validation Loss: 0.003489545313641429\n",
      "7352 Training Loss: 0.002058692742139101 Validation Loss: 0.0034115242306143045\n",
      "7353 Training Loss: 0.0018523597391322255 Validation Loss: 0.003323046024888754\n",
      "7354 Training Loss: 0.0021911521907895803 Validation Loss: 0.0032389736734330654\n",
      "7355 Training Loss: 0.002080026548355818 Validation Loss: 0.003202049992978573\n",
      "7356 Training Loss: 0.0018483346793800592 Validation Loss: 0.00317699508741498\n",
      "7357 Training Loss: 0.0020504684653133154 Validation Loss: 0.0031593742314726114\n",
      "7358 Training Loss: 0.00227098586037755 Validation Loss: 0.003161122789606452\n",
      "7359 Training Loss: 0.0023118113167583942 Validation Loss: 0.0032002595253288746\n",
      "7360 Training Loss: 0.0020375410094857216 Validation Loss: 0.0032566580921411514\n",
      "7361 Training Loss: 0.0019468513783067465 Validation Loss: 0.0032988323364406824\n",
      "7362 Training Loss: 0.0018031150102615356 Validation Loss: 0.003324101911857724\n",
      "7363 Training Loss: 0.0032628043554723263 Validation Loss: 0.0033790699671953917\n",
      "7364 Training Loss: 0.002366385655477643 Validation Loss: 0.0033414855133742094\n",
      "7365 Training Loss: 0.003559536300599575 Validation Loss: 0.00335113238543272\n",
      "7366 Training Loss: 0.0025984961539506912 Validation Loss: 0.003413161262869835\n",
      "7367 Training Loss: 0.0021813809871673584 Validation Loss: 0.003476588288322091\n",
      "7368 Training Loss: 0.0019025779329240322 Validation Loss: 0.0034501238260418177\n",
      "7369 Training Loss: 0.0019018255406990647 Validation Loss: 0.0033784345723688602\n",
      "7370 Training Loss: 0.0017535090446472168 Validation Loss: 0.003342599608004093\n",
      "7371 Training Loss: 0.0029681578744202852 Validation Loss: 0.003399302251636982\n",
      "7372 Training Loss: 0.0016686859307810664 Validation Loss: 0.003460837295278907\n",
      "7373 Training Loss: 0.002825431991368532 Validation Loss: 0.0035699852742254734\n",
      "7374 Training Loss: 0.002005200833082199 Validation Loss: 0.0036130112130194902\n",
      "7375 Training Loss: 0.0025456720031797886 Validation Loss: 0.0036322372034192085\n",
      "7376 Training Loss: 0.0020697852596640587 Validation Loss: 0.00353961787186563\n",
      "7377 Training Loss: 0.0019356142729520798 Validation Loss: 0.003392595099285245\n",
      "7378 Training Loss: 0.001957449596375227 Validation Loss: 0.0032534797210246325\n",
      "7379 Training Loss: 0.0021263721864670515 Validation Loss: 0.003162669949233532\n",
      "7380 Training Loss: 0.001810860587283969 Validation Loss: 0.0031176693737506866\n",
      "7381 Training Loss: 0.0024926450569182634 Validation Loss: 0.0031180274672806263\n",
      "7382 Training Loss: 0.002357995603233576 Validation Loss: 0.0031423664186149836\n",
      "7383 Training Loss: 0.0017369306879118085 Validation Loss: 0.003194978693500161\n",
      "7384 Training Loss: 0.0017015216872096062 Validation Loss: 0.003271140158176422\n",
      "7385 Training Loss: 0.0018276090268045664 Validation Loss: 0.003310937900096178\n",
      "7386 Training Loss: 0.0018226518295705318 Validation Loss: 0.003352182451635599\n",
      "7387 Training Loss: 0.002376984804868698 Validation Loss: 0.003392605111002922\n",
      "7388 Training Loss: 0.00195567705668509 Validation Loss: 0.0033902653958648443\n",
      "7389 Training Loss: 0.0026164092123508453 Validation Loss: 0.003360640024766326\n",
      "7390 Training Loss: 0.0019696142990142107 Validation Loss: 0.003300025826320052\n",
      "7391 Training Loss: 0.0018845809390768409 Validation Loss: 0.00325451185926795\n",
      "7392 Training Loss: 0.0027145857457071543 Validation Loss: 0.0032631868962198496\n",
      "7393 Training Loss: 0.0017788185505196452 Validation Loss: 0.003310643369331956\n",
      "7394 Training Loss: 0.0018026521429419518 Validation Loss: 0.003373050130903721\n",
      "7395 Training Loss: 0.00185494648758322 Validation Loss: 0.0034513503778725863\n",
      "7396 Training Loss: 0.0027310308068990707 Validation Loss: 0.003627908183261752\n",
      "7397 Training Loss: 0.0020083519630134106 Validation Loss: 0.0037774762604385614\n",
      "7398 Training Loss: 0.001859954558312893 Validation Loss: 0.003843741025775671\n",
      "7399 Training Loss: 0.0017911400645971298 Validation Loss: 0.0038121480029076338\n",
      "7400 Training Loss: 0.0019029723480343819 Validation Loss: 0.003681708127260208\n",
      "7401 Training Loss: 0.0020399820059537888 Validation Loss: 0.0035335859283804893\n",
      "7402 Training Loss: 0.002010075841099024 Validation Loss: 0.003394144121557474\n",
      "7403 Training Loss: 0.002267727628350258 Validation Loss: 0.0032513001933693886\n",
      "7404 Training Loss: 0.0019014868885278702 Validation Loss: 0.0031827809289097786\n",
      "7405 Training Loss: 0.0018349041929468513 Validation Loss: 0.0031461254693567753\n",
      "7406 Training Loss: 0.002594028366729617 Validation Loss: 0.003216404002159834\n",
      "7407 Training Loss: 0.0019485412631183863 Validation Loss: 0.0032954360358417034\n",
      "7408 Training Loss: 0.0031036571599543095 Validation Loss: 0.003523176768794656\n",
      "7409 Training Loss: 0.0020675521809607744 Validation Loss: 0.003607912687584758\n",
      "7410 Training Loss: 0.0033480357378721237 Validation Loss: 0.003691678401082754\n",
      "7411 Training Loss: 0.0020764691289514303 Validation Loss: 0.0036494715604931116\n",
      "7412 Training Loss: 0.0037918980233371258 Validation Loss: 0.0035418597981333733\n",
      "7413 Training Loss: 0.0020246803760528564 Validation Loss: 0.0034823184832930565\n",
      "7414 Training Loss: 0.0023049707524478436 Validation Loss: 0.003421392757445574\n",
      "7415 Training Loss: 0.0020853178575634956 Validation Loss: 0.0033442554995417595\n",
      "7416 Training Loss: 0.0019533068407326937 Validation Loss: 0.003312302054837346\n",
      "7417 Training Loss: 0.0018548029474914074 Validation Loss: 0.0032893558964133263\n",
      "7418 Training Loss: 0.0018038474954664707 Validation Loss: 0.0032838056795299053\n",
      "7419 Training Loss: 0.0026452303864061832 Validation Loss: 0.003356550820171833\n",
      "7420 Training Loss: 0.0025169462896883488 Validation Loss: 0.0035073691979050636\n",
      "7421 Training Loss: 0.0018983279587700963 Validation Loss: 0.003573110792785883\n",
      "7422 Training Loss: 0.0026417949702590704 Validation Loss: 0.003533178474754095\n",
      "7423 Training Loss: 0.0016659521497786045 Validation Loss: 0.0034733146894723177\n",
      "7424 Training Loss: 0.0019665719009935856 Validation Loss: 0.003339874092489481\n",
      "7425 Training Loss: 0.002294242847710848 Validation Loss: 0.003294636495411396\n",
      "7426 Training Loss: 0.0026832243893295527 Validation Loss: 0.0033377110958099365\n",
      "7427 Training Loss: 0.0018191963899880648 Validation Loss: 0.003405855968594551\n",
      "7428 Training Loss: 0.0018529375083744526 Validation Loss: 0.003445169422775507\n",
      "7429 Training Loss: 0.001820737263187766 Validation Loss: 0.0034862696193158627\n",
      "7430 Training Loss: 0.002046299399808049 Validation Loss: 0.0035278555005788803\n",
      "7431 Training Loss: 0.0018796201329678297 Validation Loss: 0.0035797799937427044\n",
      "7432 Training Loss: 0.0020703673362731934 Validation Loss: 0.0035832147113978863\n",
      "7433 Training Loss: 0.0019650107715278864 Validation Loss: 0.00348986079916358\n",
      "7434 Training Loss: 0.0016935616731643677 Validation Loss: 0.0034417957067489624\n",
      "7435 Training Loss: 0.0027214791625738144 Validation Loss: 0.003402765141800046\n",
      "7436 Training Loss: 0.001758606405928731 Validation Loss: 0.003361004637554288\n",
      "7437 Training Loss: 0.001875764224678278 Validation Loss: 0.0033246674574911594\n",
      "7438 Training Loss: 0.0024316690396517515 Validation Loss: 0.0033324456308037043\n",
      "7439 Training Loss: 0.001997845247387886 Validation Loss: 0.003354906802996993\n",
      "7440 Training Loss: 0.0020334261935204268 Validation Loss: 0.0034260465763509274\n",
      "7441 Training Loss: 0.0017451629973948002 Validation Loss: 0.0034628233406692743\n",
      "7442 Training Loss: 0.0017416325863450766 Validation Loss: 0.003480000887066126\n",
      "7443 Training Loss: 0.0018545710481703281 Validation Loss: 0.003451818600296974\n",
      "7444 Training Loss: 0.0021117383148521185 Validation Loss: 0.0033845913130789995\n",
      "7445 Training Loss: 0.0018826532177627087 Validation Loss: 0.0033401420805603266\n",
      "7446 Training Loss: 0.001799880526959896 Validation Loss: 0.003310950007289648\n",
      "7447 Training Loss: 0.001744884648360312 Validation Loss: 0.0033445535227656364\n",
      "7448 Training Loss: 0.0019653926137834787 Validation Loss: 0.003341569798067212\n",
      "7449 Training Loss: 0.0018251785077154636 Validation Loss: 0.0033280872739851475\n",
      "7450 Training Loss: 0.0021823046263307333 Validation Loss: 0.0032511488534510136\n",
      "7451 Training Loss: 0.0018701464869081974 Validation Loss: 0.0031715170480310917\n",
      "7452 Training Loss: 0.002515748143196106 Validation Loss: 0.003152183024212718\n",
      "7453 Training Loss: 0.0017220140434801579 Validation Loss: 0.0031581330113112926\n",
      "7454 Training Loss: 0.0018666093237698078 Validation Loss: 0.003146207192912698\n",
      "7455 Training Loss: 0.0018687506671994925 Validation Loss: 0.0031414709519594908\n",
      "7456 Training Loss: 0.0020609216298907995 Validation Loss: 0.0031009495723992586\n",
      "7457 Training Loss: 0.0017541898414492607 Validation Loss: 0.003065716475248337\n",
      "7458 Training Loss: 0.0018660086207091808 Validation Loss: 0.003054398111999035\n",
      "7459 Training Loss: 0.0018712397431954741 Validation Loss: 0.003043683711439371\n",
      "7460 Training Loss: 0.001895350287668407 Validation Loss: 0.003065078519284725\n",
      "7461 Training Loss: 0.001788730383850634 Validation Loss: 0.0030861604027450085\n",
      "7462 Training Loss: 0.0016908179968595505 Validation Loss: 0.0031069600954651833\n",
      "7463 Training Loss: 0.0029517642688006163 Validation Loss: 0.0031522491481155157\n",
      "7464 Training Loss: 0.0019946666434407234 Validation Loss: 0.0032249903306365013\n",
      "7465 Training Loss: 0.0022996203042566776 Validation Loss: 0.003344689030200243\n",
      "7466 Training Loss: 0.0017603070009499788 Validation Loss: 0.0033510320354253054\n",
      "7467 Training Loss: 0.0018446736503392458 Validation Loss: 0.00329953501932323\n",
      "7468 Training Loss: 0.00212445599026978 Validation Loss: 0.0032048439607024193\n",
      "7469 Training Loss: 0.0016970883589237928 Validation Loss: 0.0031385940965265036\n",
      "7470 Training Loss: 0.0023120101541280746 Validation Loss: 0.003084853757172823\n",
      "7471 Training Loss: 0.0018207142129540443 Validation Loss: 0.003052676096558571\n",
      "7472 Training Loss: 0.0018115135608240962 Validation Loss: 0.003027132013812661\n",
      "7473 Training Loss: 0.0017487631412222981 Validation Loss: 0.0030295599717646837\n",
      "7474 Training Loss: 0.0016010492108762264 Validation Loss: 0.003054381115362048\n",
      "7475 Training Loss: 0.003273248439654708 Validation Loss: 0.003147934330627322\n",
      "7476 Training Loss: 0.0016727797919884324 Validation Loss: 0.003232911927625537\n",
      "7477 Training Loss: 0.0021752414759248495 Validation Loss: 0.0033086580224335194\n",
      "7478 Training Loss: 0.002058688784018159 Validation Loss: 0.0032948204316198826\n",
      "7479 Training Loss: 0.0021601608023047447 Validation Loss: 0.0032493597827851772\n",
      "7480 Training Loss: 0.0020014364272356033 Validation Loss: 0.003149631666019559\n",
      "7481 Training Loss: 0.0040791514329612255 Validation Loss: 0.0031932538840919733\n",
      "7482 Training Loss: 0.003247130662202835 Validation Loss: 0.0032892455346882343\n",
      "7483 Training Loss: 0.002165090525522828 Validation Loss: 0.0032826580572873354\n",
      "7484 Training Loss: 0.0020021842792630196 Validation Loss: 0.003254412207752466\n",
      "7485 Training Loss: 0.003370116464793682 Validation Loss: 0.003357908222824335\n",
      "7486 Training Loss: 0.0017785942181944847 Validation Loss: 0.003400320652872324\n",
      "7487 Training Loss: 0.0016211257316172123 Validation Loss: 0.0033859750255942345\n",
      "7488 Training Loss: 0.0021900362335145473 Validation Loss: 0.003358683083206415\n",
      "7489 Training Loss: 0.0016258845571428537 Validation Loss: 0.0033443451393395662\n",
      "7490 Training Loss: 0.002127524930983782 Validation Loss: 0.0032762796618044376\n",
      "7491 Training Loss: 0.0019175985362380743 Validation Loss: 0.0031979456543922424\n",
      "7492 Training Loss: 0.0017967805033549666 Validation Loss: 0.0031497247982770205\n",
      "7493 Training Loss: 0.0019185475539416075 Validation Loss: 0.0031537250615656376\n",
      "7494 Training Loss: 0.003131438046693802 Validation Loss: 0.0032335291616618633\n",
      "7495 Training Loss: 0.0018750412855297327 Validation Loss: 0.0033193561248481274\n",
      "7496 Training Loss: 0.0017467978177592158 Validation Loss: 0.003351274412125349\n",
      "7497 Training Loss: 0.0017776013119146228 Validation Loss: 0.0033462336286902428\n",
      "7498 Training Loss: 0.0017305733636021614 Validation Loss: 0.003292778041213751\n",
      "7499 Training Loss: 0.0020105214789509773 Validation Loss: 0.0031924997456371784\n",
      "7500 Training Loss: 0.003188540693372488 Validation Loss: 0.003209472168236971\n",
      "7501 Training Loss: 0.001755421282723546 Validation Loss: 0.003206352237612009\n",
      "7502 Training Loss: 0.0019251533085480332 Validation Loss: 0.003186445450410247\n",
      "7503 Training Loss: 0.0021732249297201633 Validation Loss: 0.003160211956128478\n",
      "7504 Training Loss: 0.0021827281452715397 Validation Loss: 0.0031651246827095747\n",
      "7505 Training Loss: 0.0018533081747591496 Validation Loss: 0.0031842095777392387\n",
      "7506 Training Loss: 0.0017929543973878026 Validation Loss: 0.003198967082425952\n",
      "7507 Training Loss: 0.002883227076381445 Validation Loss: 0.003303572302684188\n",
      "7508 Training Loss: 0.0018538848962634802 Validation Loss: 0.0033244690857827663\n",
      "7509 Training Loss: 0.0017201162409037352 Validation Loss: 0.003279362805187702\n",
      "7510 Training Loss: 0.0019221252296119928 Validation Loss: 0.003178834216669202\n",
      "7511 Training Loss: 0.0018250180874019861 Validation Loss: 0.0031159038189798594\n",
      "7512 Training Loss: 0.0017401727382093668 Validation Loss: 0.0030858712270855904\n",
      "7513 Training Loss: 0.0019614174962043762 Validation Loss: 0.0030736324843019247\n",
      "7514 Training Loss: 0.0022784811444580555 Validation Loss: 0.003087506629526615\n",
      "7515 Training Loss: 0.0021586294751614332 Validation Loss: 0.003094503888860345\n",
      "7516 Training Loss: 0.00223466195166111 Validation Loss: 0.0032062828540802\n",
      "7517 Training Loss: 0.0020392113365232944 Validation Loss: 0.003309200517833233\n",
      "7518 Training Loss: 0.0018621142953634262 Validation Loss: 0.0033293822780251503\n",
      "7519 Training Loss: 0.0020276932045817375 Validation Loss: 0.00327923777513206\n",
      "7520 Training Loss: 0.0016943577211350203 Validation Loss: 0.0032279780134558678\n",
      "7521 Training Loss: 0.0019796330016106367 Validation Loss: 0.003191613592207432\n",
      "7522 Training Loss: 0.0020152893848717213 Validation Loss: 0.003164746332913637\n",
      "7523 Training Loss: 0.003172336146235466 Validation Loss: 0.0031925688963383436\n",
      "7524 Training Loss: 0.0015450329519808292 Validation Loss: 0.0032065287232398987\n",
      "7525 Training Loss: 0.001728161470964551 Validation Loss: 0.0031761215068399906\n",
      "7526 Training Loss: 0.0018048809142783284 Validation Loss: 0.003126719733700156\n",
      "7527 Training Loss: 0.0020688872318714857 Validation Loss: 0.0031169038265943527\n",
      "7528 Training Loss: 0.002706133760511875 Validation Loss: 0.0031422011088579893\n",
      "7529 Training Loss: 0.002755817025899887 Validation Loss: 0.003255641320720315\n",
      "7530 Training Loss: 0.0023955265060067177 Validation Loss: 0.003433546517044306\n",
      "7531 Training Loss: 0.002509169280529022 Validation Loss: 0.0036111322697252035\n",
      "7532 Training Loss: 0.0024884920567274094 Validation Loss: 0.003746395232155919\n",
      "7533 Training Loss: 0.002199210226535797 Validation Loss: 0.003611018881201744\n",
      "7534 Training Loss: 0.001723483670502901 Validation Loss: 0.003401105757802725\n",
      "7535 Training Loss: 0.0017944984138011932 Validation Loss: 0.0032883905805647373\n",
      "7536 Training Loss: 0.0017670702654868364 Validation Loss: 0.0032077941577881575\n",
      "7537 Training Loss: 0.0018357071094214916 Validation Loss: 0.003177184844389558\n",
      "7538 Training Loss: 0.0018914000829681754 Validation Loss: 0.0031655575148761272\n",
      "7539 Training Loss: 0.0015724916011095047 Validation Loss: 0.003214787459000945\n",
      "7540 Training Loss: 0.0018142606131732464 Validation Loss: 0.003299244912341237\n",
      "7541 Training Loss: 0.0014677507570013404 Validation Loss: 0.003381626680493355\n",
      "7542 Training Loss: 0.0015746322460472584 Validation Loss: 0.003412158228456974\n",
      "7543 Training Loss: 0.0016989023424685001 Validation Loss: 0.003355176653712988\n",
      "7544 Training Loss: 0.001757695572450757 Validation Loss: 0.00328409974463284\n",
      "7545 Training Loss: 0.002139550866559148 Validation Loss: 0.003272720379754901\n",
      "7546 Training Loss: 0.0018194057047367096 Validation Loss: 0.0032519111409783363\n",
      "7547 Training Loss: 0.0019615215715020895 Validation Loss: 0.0031807164195924997\n",
      "7548 Training Loss: 0.0018659525085240602 Validation Loss: 0.0031257665250450373\n",
      "7549 Training Loss: 0.0018403390422463417 Validation Loss: 0.0030724024400115013\n",
      "7550 Training Loss: 0.0016548698768019676 Validation Loss: 0.0030644438229501247\n",
      "7551 Training Loss: 0.00176397361792624 Validation Loss: 0.003067938145250082\n",
      "7552 Training Loss: 0.0018189501715824008 Validation Loss: 0.0030813126359134912\n",
      "7553 Training Loss: 0.0022683318238705397 Validation Loss: 0.0031030888203531504\n",
      "7554 Training Loss: 0.0016731084324419498 Validation Loss: 0.0031124495435506105\n",
      "7555 Training Loss: 0.0016736674588173628 Validation Loss: 0.0031006401404738426\n",
      "7556 Training Loss: 0.001574530266225338 Validation Loss: 0.003084474243223667\n",
      "7557 Training Loss: 0.0017319482285529375 Validation Loss: 0.003087076358497143\n",
      "7558 Training Loss: 0.0016168563161045313 Validation Loss: 0.0031074436847120523\n",
      "7559 Training Loss: 0.0021755776833742857 Validation Loss: 0.0031362411100417376\n",
      "7560 Training Loss: 0.0016239414690062404 Validation Loss: 0.003224774729460478\n",
      "7561 Training Loss: 0.0018325645942240953 Validation Loss: 0.0033268744591623545\n",
      "7562 Training Loss: 0.0019086631946265697 Validation Loss: 0.00336597952991724\n",
      "7563 Training Loss: 0.0021678253542631865 Validation Loss: 0.0034433931577950716\n",
      "7564 Training Loss: 0.002194411586970091 Validation Loss: 0.003531117457896471\n",
      "7565 Training Loss: 0.0034497990272939205 Validation Loss: 0.003489128313958645\n",
      "7566 Training Loss: 0.0016229473985731602 Validation Loss: 0.0033871291670948267\n",
      "7567 Training Loss: 0.001567075029015541 Validation Loss: 0.0032557405065745115\n",
      "7568 Training Loss: 0.0031060900073498487 Validation Loss: 0.0032073133625090122\n",
      "7569 Training Loss: 0.002130216918885708 Validation Loss: 0.0031564284581691027\n",
      "7570 Training Loss: 0.0020078010857105255 Validation Loss: 0.00311992596834898\n",
      "7571 Training Loss: 0.001853875000961125 Validation Loss: 0.0030777680221945047\n",
      "7572 Training Loss: 0.0017127140890806913 Validation Loss: 0.003069889498874545\n",
      "7573 Training Loss: 0.0016261187847703695 Validation Loss: 0.0030744250398129225\n",
      "7574 Training Loss: 0.0019657828379422426 Validation Loss: 0.003144406247884035\n",
      "7575 Training Loss: 0.0018627385143190622 Validation Loss: 0.003289585467427969\n",
      "7576 Training Loss: 0.0015942896716296673 Validation Loss: 0.003390450496226549\n",
      "7577 Training Loss: 0.001867306767962873 Validation Loss: 0.003444975707679987\n",
      "7578 Training Loss: 0.0020617558620870113 Validation Loss: 0.003504214808344841\n",
      "7579 Training Loss: 0.002073599025607109 Validation Loss: 0.0034329048357903957\n",
      "7580 Training Loss: 0.001715049846097827 Validation Loss: 0.003339023794978857\n",
      "7581 Training Loss: 0.001629330450668931 Validation Loss: 0.0032519542146474123\n",
      "7582 Training Loss: 0.0018579509342089295 Validation Loss: 0.0031594084575772285\n",
      "7583 Training Loss: 0.00158814643509686 Validation Loss: 0.0030877741519361734\n",
      "7584 Training Loss: 0.0017084197606891394 Validation Loss: 0.0030252255965024233\n",
      "7585 Training Loss: 0.0017577169928699732 Validation Loss: 0.0029840166680514812\n",
      "7586 Training Loss: 0.0015810823533684015 Validation Loss: 0.0029591484926640987\n",
      "7587 Training Loss: 0.001587477745488286 Validation Loss: 0.002949014538899064\n",
      "7588 Training Loss: 0.0019001036416739225 Validation Loss: 0.002950391499325633\n",
      "7589 Training Loss: 0.0015476413536816835 Validation Loss: 0.0029483067337423563\n",
      "7590 Training Loss: 0.0018863388104364276 Validation Loss: 0.002925753826275468\n",
      "7591 Training Loss: 0.0018373711500316858 Validation Loss: 0.002917718142271042\n",
      "7592 Training Loss: 0.0019173745531588793 Validation Loss: 0.0029382642824202776\n",
      "7593 Training Loss: 0.0025707241147756577 Validation Loss: 0.0030670790001749992\n",
      "7594 Training Loss: 0.0019930261187255383 Validation Loss: 0.0031985093373805285\n",
      "7595 Training Loss: 0.0015897824196144938 Validation Loss: 0.0033310491126030684\n",
      "7596 Training Loss: 0.002076650969684124 Validation Loss: 0.0034323392901569605\n",
      "7597 Training Loss: 0.001621197909116745 Validation Loss: 0.0034528204705566168\n",
      "7598 Training Loss: 0.0016745442990213633 Validation Loss: 0.0033504017628729343\n",
      "7599 Training Loss: 0.0017891686875373125 Validation Loss: 0.003209176240488887\n",
      "7600 Training Loss: 0.0017168030608445406 Validation Loss: 0.0030717921908944845\n",
      "7601 Training Loss: 0.0016521381912752986 Validation Loss: 0.002985218074172735\n",
      "7602 Training Loss: 0.0017317789606750011 Validation Loss: 0.002923195715993643\n",
      "7603 Training Loss: 0.0019272053614258766 Validation Loss: 0.00291221821680665\n",
      "7604 Training Loss: 0.001775733777321875 Validation Loss: 0.0029178191907703876\n",
      "7605 Training Loss: 0.0018728106515482068 Validation Loss: 0.0029098913073539734\n",
      "7606 Training Loss: 0.0022477307356894016 Validation Loss: 0.0029530671890825033\n",
      "7607 Training Loss: 0.0016501295613124967 Validation Loss: 0.0029745299834758043\n",
      "7608 Training Loss: 0.0015797840896993876 Validation Loss: 0.0029634234961122274\n",
      "7609 Training Loss: 0.0015376168303191662 Validation Loss: 0.002965163439512253\n",
      "7610 Training Loss: 0.001725654467009008 Validation Loss: 0.0029933166224509478\n",
      "7611 Training Loss: 0.0016377830179408193 Validation Loss: 0.0030220651533454657\n",
      "7612 Training Loss: 0.0021118747536092997 Validation Loss: 0.003060123883187771\n",
      "7613 Training Loss: 0.002198105212301016 Validation Loss: 0.003072546562179923\n",
      "7614 Training Loss: 0.0016413661651313305 Validation Loss: 0.0030400636605918407\n",
      "7615 Training Loss: 0.0017265148926526308 Validation Loss: 0.0030013471841812134\n",
      "7616 Training Loss: 0.0017970447661355138 Validation Loss: 0.002937341807410121\n",
      "7617 Training Loss: 0.0016669232863932848 Validation Loss: 0.002894147764891386\n",
      "7618 Training Loss: 0.0015057213604450226 Validation Loss: 0.002871379954740405\n",
      "7619 Training Loss: 0.0038668483030050993 Validation Loss: 0.002979972865432501\n",
      "7620 Training Loss: 0.0018590810941532254 Validation Loss: 0.0030257529579102993\n",
      "7621 Training Loss: 0.0016454021679237485 Validation Loss: 0.0030173729173839092\n",
      "7622 Training Loss: 0.0020306468941271305 Validation Loss: 0.002990530803799629\n",
      "7623 Training Loss: 0.0017505791038274765 Validation Loss: 0.002912204246968031\n",
      "7624 Training Loss: 0.0016554112080484629 Validation Loss: 0.00285515864379704\n",
      "7625 Training Loss: 0.0017975422088056803 Validation Loss: 0.002843971597030759\n",
      "7626 Training Loss: 0.002982964040711522 Validation Loss: 0.002887250389903784\n",
      "7627 Training Loss: 0.0017448589205741882 Validation Loss: 0.003010628977790475\n",
      "7628 Training Loss: 0.0031485927756875753 Validation Loss: 0.003266292857006192\n",
      "7629 Training Loss: 0.0028116335161030293 Validation Loss: 0.0036619629245251417\n",
      "7630 Training Loss: 0.0017126135062426329 Validation Loss: 0.003845393657684326\n",
      "7631 Training Loss: 0.0021582208573818207 Validation Loss: 0.003676612628623843\n",
      "7632 Training Loss: 0.002966873114928603 Validation Loss: 0.003399487351998687\n",
      "7633 Training Loss: 0.001655016327276826 Validation Loss: 0.0031856463756412268\n",
      "7634 Training Loss: 0.0015396545641124249 Validation Loss: 0.0030576223507523537\n",
      "7635 Training Loss: 0.001849265885539353 Validation Loss: 0.0029937473591417074\n",
      "7636 Training Loss: 0.001593816326931119 Validation Loss: 0.002963968785479665\n",
      "7637 Training Loss: 0.002630369272083044 Validation Loss: 0.0029737192671746016\n",
      "7638 Training Loss: 0.001509080408141017 Validation Loss: 0.003021662123501301\n",
      "7639 Training Loss: 0.0015873077791184187 Validation Loss: 0.0030861999839544296\n",
      "7640 Training Loss: 0.0016675940714776516 Validation Loss: 0.0031415156554430723\n",
      "7641 Training Loss: 0.0015251081204041839 Validation Loss: 0.0031448802910745144\n",
      "7642 Training Loss: 0.0016656710067763925 Validation Loss: 0.0031257320661097765\n",
      "7643 Training Loss: 0.0016323640011250973 Validation Loss: 0.0030861524865031242\n",
      "7644 Training Loss: 0.0020051058381795883 Validation Loss: 0.003042292781174183\n",
      "7645 Training Loss: 0.0026268959045410156 Validation Loss: 0.003028623526915908\n",
      "7646 Training Loss: 0.0018397835083305836 Validation Loss: 0.0030424660071730614\n",
      "7647 Training Loss: 0.0018830863991752267 Validation Loss: 0.0030577334109693766\n",
      "7648 Training Loss: 0.0017008066643029451 Validation Loss: 0.003069947473704815\n",
      "7649 Training Loss: 0.0015794269274920225 Validation Loss: 0.0030400941614061594\n",
      "7650 Training Loss: 0.0017981687560677528 Validation Loss: 0.003054057015106082\n",
      "7651 Training Loss: 0.0034269485622644424 Validation Loss: 0.0031322252470999956\n",
      "7652 Training Loss: 0.0035048772115260363 Validation Loss: 0.0033711388241499662\n",
      "7653 Training Loss: 0.0017687189392745495 Validation Loss: 0.0034786800388246775\n",
      "7654 Training Loss: 0.002126009203493595 Validation Loss: 0.003338162787258625\n",
      "7655 Training Loss: 0.0015948988730087876 Validation Loss: 0.00315543869510293\n",
      "7656 Training Loss: 0.0017602569423615932 Validation Loss: 0.003022190649062395\n",
      "7657 Training Loss: 0.00282842549495399 Validation Loss: 0.002997535979375243\n",
      "7658 Training Loss: 0.002295896876603365 Validation Loss: 0.0030206628143787384\n",
      "7659 Training Loss: 0.0017047717701643705 Validation Loss: 0.0030306729022413492\n",
      "7660 Training Loss: 0.002698060590773821 Validation Loss: 0.0031035500578582287\n",
      "7661 Training Loss: 0.0020099165849387646 Validation Loss: 0.0032656684052199125\n",
      "7662 Training Loss: 0.0017478831578046083 Validation Loss: 0.003390634199604392\n",
      "7663 Training Loss: 0.0021635584998875856 Validation Loss: 0.003484116168692708\n",
      "7664 Training Loss: 0.0016975952312350273 Validation Loss: 0.0034361956641077995\n",
      "7665 Training Loss: 0.0017571933567523956 Validation Loss: 0.0033289988059550524\n",
      "7666 Training Loss: 0.0021197430323809385 Validation Loss: 0.003285166108980775\n",
      "7667 Training Loss: 0.0017851836746558547 Validation Loss: 0.0031938226893544197\n",
      "7668 Training Loss: 0.0013930753339082003 Validation Loss: 0.0031829182989895344\n",
      "7669 Training Loss: 0.0018393045756965876 Validation Loss: 0.003203474683687091\n",
      "7670 Training Loss: 0.0017254115082323551 Validation Loss: 0.003235765267163515\n",
      "7671 Training Loss: 0.0032073843758553267 Validation Loss: 0.003347832476720214\n",
      "7672 Training Loss: 0.0015321492683142424 Validation Loss: 0.003425269853323698\n",
      "7673 Training Loss: 0.002254841150715947 Validation Loss: 0.003451011376455426\n",
      "7674 Training Loss: 0.001821789424866438 Validation Loss: 0.003450513817369938\n",
      "7675 Training Loss: 0.0016559760551899672 Validation Loss: 0.003315343288704753\n",
      "7676 Training Loss: 0.0029648151248693466 Validation Loss: 0.0032503092661499977\n",
      "7677 Training Loss: 0.0018775423523038626 Validation Loss: 0.0031544025987386703\n",
      "7678 Training Loss: 0.0018357721855863929 Validation Loss: 0.0030860011465847492\n",
      "7679 Training Loss: 0.001455922843888402 Validation Loss: 0.003060190938413143\n",
      "7680 Training Loss: 0.0019049901748076081 Validation Loss: 0.0030572868417948484\n",
      "7681 Training Loss: 0.0015857871621847153 Validation Loss: 0.0030738108325749636\n",
      "7682 Training Loss: 0.001629112521186471 Validation Loss: 0.003134292084723711\n",
      "7683 Training Loss: 0.0015563014894723892 Validation Loss: 0.0031826712656766176\n",
      "7684 Training Loss: 0.001556655508466065 Validation Loss: 0.003202298656105995\n",
      "7685 Training Loss: 0.0015398007817566395 Validation Loss: 0.003193129552528262\n",
      "7686 Training Loss: 0.0015086979838088155 Validation Loss: 0.0031755217351019382\n",
      "7687 Training Loss: 0.001747646601870656 Validation Loss: 0.00315068569034338\n",
      "7688 Training Loss: 0.002563165035098791 Validation Loss: 0.0031265285797417164\n",
      "7689 Training Loss: 0.0017457667272537947 Validation Loss: 0.003058403730392456\n",
      "7690 Training Loss: 0.0014925787691026926 Validation Loss: 0.003021528944373131\n",
      "7691 Training Loss: 0.005086919292807579 Validation Loss: 0.0031377694103866816\n",
      "7692 Training Loss: 0.0015985649079084396 Validation Loss: 0.003256957046687603\n",
      "7693 Training Loss: 0.0015971023822203279 Validation Loss: 0.0033947452902793884\n",
      "7694 Training Loss: 0.001704398775473237 Validation Loss: 0.0035221304278820753\n",
      "7695 Training Loss: 0.0023246065247803926 Validation Loss: 0.003652552142739296\n",
      "7696 Training Loss: 0.002028551883995533 Validation Loss: 0.003592794993892312\n",
      "7697 Training Loss: 0.0015847939066588879 Validation Loss: 0.003504611784592271\n",
      "7698 Training Loss: 0.0015090520028024912 Validation Loss: 0.003392447717487812\n",
      "7699 Training Loss: 0.0015225093811750412 Validation Loss: 0.00331226852722466\n",
      "7700 Training Loss: 0.0018264797981828451 Validation Loss: 0.003191746771335602\n",
      "7701 Training Loss: 0.0017195928376168013 Validation Loss: 0.003105408512055874\n",
      "7702 Training Loss: 0.001572612440213561 Validation Loss: 0.003052324987947941\n",
      "7703 Training Loss: 0.0018846644088625908 Validation Loss: 0.0030053304508328438\n",
      "7704 Training Loss: 0.0014955955557525158 Validation Loss: 0.0029907955322414637\n",
      "7705 Training Loss: 0.0014708155067637563 Validation Loss: 0.0029848190024495125\n",
      "7706 Training Loss: 0.0016767685301601887 Validation Loss: 0.002971608191728592\n",
      "7707 Training Loss: 0.0014840394724160433 Validation Loss: 0.00293037761002779\n",
      "7708 Training Loss: 0.0016986194532364607 Validation Loss: 0.002921865088865161\n",
      "7709 Training Loss: 0.001558437361381948 Validation Loss: 0.0029391173738986254\n",
      "7710 Training Loss: 0.0025395608972758055 Validation Loss: 0.0030069765634834766\n",
      "7711 Training Loss: 0.001556642702780664 Validation Loss: 0.0030397281516343355\n",
      "7712 Training Loss: 0.0015385758597403765 Validation Loss: 0.0030616833828389645\n",
      "7713 Training Loss: 0.001486895838752389 Validation Loss: 0.003059577662497759\n",
      "7714 Training Loss: 0.0017118460964411497 Validation Loss: 0.003031254978850484\n",
      "7715 Training Loss: 0.0017893686890602112 Validation Loss: 0.002985413884744048\n",
      "7716 Training Loss: 0.0016882545314729214 Validation Loss: 0.002951202681288123\n",
      "7717 Training Loss: 0.001575779402628541 Validation Loss: 0.0029136547818779945\n",
      "7718 Training Loss: 0.001658432767726481 Validation Loss: 0.0029245095793157816\n",
      "7719 Training Loss: 0.0027577667497098446 Validation Loss: 0.003038827795535326\n",
      "7720 Training Loss: 0.0016501662321388721 Validation Loss: 0.0031539895571768284\n",
      "7721 Training Loss: 0.0018289531581103802 Validation Loss: 0.0032239879947155714\n",
      "7722 Training Loss: 0.0015083618927747011 Validation Loss: 0.00320004322566092\n",
      "7723 Training Loss: 0.0017271393444389105 Validation Loss: 0.0030399777460843325\n",
      "7724 Training Loss: 0.0017932176124304533 Validation Loss: 0.0029043464455753565\n",
      "7725 Training Loss: 0.0025870471727102995 Validation Loss: 0.0028606161940842867\n",
      "7726 Training Loss: 0.0015970382373780012 Validation Loss: 0.0028835018165409565\n",
      "7727 Training Loss: 0.0015402010176330805 Validation Loss: 0.0029234925750643015\n",
      "7728 Training Loss: 0.001937743043527007 Validation Loss: 0.003048225538805127\n",
      "7729 Training Loss: 0.0020094532519578934 Validation Loss: 0.0031233043409883976\n",
      "7730 Training Loss: 0.0017768576508387923 Validation Loss: 0.0030741733498871326\n",
      "7731 Training Loss: 0.0017007335554808378 Validation Loss: 0.002942492952570319\n",
      "7732 Training Loss: 0.0021295773331075907 Validation Loss: 0.0028804547619074583\n",
      "7733 Training Loss: 0.0015132618136703968 Validation Loss: 0.002828033873811364\n",
      "7734 Training Loss: 0.0014148603659123182 Validation Loss: 0.0028054893482476473\n",
      "7735 Training Loss: 0.0019400411983951926 Validation Loss: 0.002850215882062912\n",
      "7736 Training Loss: 0.0016658258391544223 Validation Loss: 0.0028566967230290174\n",
      "7737 Training Loss: 0.001439317362383008 Validation Loss: 0.002854288322851062\n",
      "7738 Training Loss: 0.0018270171713083982 Validation Loss: 0.002871189033612609\n",
      "7739 Training Loss: 0.0013792733661830425 Validation Loss: 0.002900149207562208\n",
      "7740 Training Loss: 0.0016533201560378075 Validation Loss: 0.0028776333201676607\n",
      "7741 Training Loss: 0.0019143503159284592 Validation Loss: 0.0029307259246706963\n",
      "7742 Training Loss: 0.0015328950248658657 Validation Loss: 0.0029760925099253654\n",
      "7743 Training Loss: 0.0016423700144514441 Validation Loss: 0.0029395404271781445\n",
      "7744 Training Loss: 0.0013705675955861807 Validation Loss: 0.002885215450078249\n",
      "7745 Training Loss: 0.001525762607343495 Validation Loss: 0.0028281884733587503\n",
      "7746 Training Loss: 0.0014811239670962095 Validation Loss: 0.0027794777415692806\n",
      "7747 Training Loss: 0.0023607646580785513 Validation Loss: 0.002768915146589279\n",
      "7748 Training Loss: 0.0014927689917385578 Validation Loss: 0.002784347627311945\n",
      "7749 Training Loss: 0.0022405509371310472 Validation Loss: 0.002859152154996991\n",
      "7750 Training Loss: 0.0015734334010630846 Validation Loss: 0.0029073026962578297\n",
      "7751 Training Loss: 0.001847999868914485 Validation Loss: 0.0029016989283263683\n",
      "7752 Training Loss: 0.0014282343909144402 Validation Loss: 0.0028757809195667505\n",
      "7753 Training Loss: 0.0015609480906277895 Validation Loss: 0.0028662364929914474\n",
      "7754 Training Loss: 0.001547118416056037 Validation Loss: 0.0028360867872834206\n",
      "7755 Training Loss: 0.0014457053039222956 Validation Loss: 0.0028334585949778557\n",
      "7756 Training Loss: 0.0014773561852052808 Validation Loss: 0.00282591232098639\n",
      "7757 Training Loss: 0.001498047960922122 Validation Loss: 0.002830980811268091\n",
      "7758 Training Loss: 0.001651404774747789 Validation Loss: 0.002836524276062846\n",
      "7759 Training Loss: 0.0017303023487329483 Validation Loss: 0.0028244361747056246\n",
      "7760 Training Loss: 0.0017097201198339462 Validation Loss: 0.0027643281500786543\n",
      "7761 Training Loss: 0.0014425611589103937 Validation Loss: 0.0027174940332770348\n",
      "7762 Training Loss: 0.0017003798857331276 Validation Loss: 0.0026624626480042934\n",
      "7763 Training Loss: 0.0014213582035154104 Validation Loss: 0.0026322498451918364\n",
      "7764 Training Loss: 0.0030249501578509808 Validation Loss: 0.0026390706188976765\n",
      "7765 Training Loss: 0.0015615031588822603 Validation Loss: 0.0026636654511094093\n",
      "7766 Training Loss: 0.0016283720033243299 Validation Loss: 0.002718504751101136\n",
      "7767 Training Loss: 0.0015273152384907007 Validation Loss: 0.002747919177636504\n",
      "7768 Training Loss: 0.0017181180883198977 Validation Loss: 0.0027489177882671356\n",
      "7769 Training Loss: 0.00150857784319669 Validation Loss: 0.002762772375717759\n",
      "7770 Training Loss: 0.0016142323147505522 Validation Loss: 0.002768329344689846\n",
      "7771 Training Loss: 0.0027147880755364895 Validation Loss: 0.002789734862744808\n",
      "7772 Training Loss: 0.0014487199950963259 Validation Loss: 0.002789286896586418\n",
      "7773 Training Loss: 0.00158813560847193 Validation Loss: 0.002763556782156229\n",
      "7774 Training Loss: 0.0013065030798316002 Validation Loss: 0.0027426264714449644\n",
      "7775 Training Loss: 0.0026006996631622314 Validation Loss: 0.002801614347845316\n",
      "7776 Training Loss: 0.0015727702993899584 Validation Loss: 0.002787916222587228\n",
      "7777 Training Loss: 0.002060295781120658 Validation Loss: 0.0027587669901549816\n",
      "7778 Training Loss: 0.002197200432419777 Validation Loss: 0.0026548709720373154\n",
      "7779 Training Loss: 0.0021057440899312496 Validation Loss: 0.002627604641020298\n",
      "7780 Training Loss: 0.0017758419271558523 Validation Loss: 0.0026055064518004656\n",
      "7781 Training Loss: 0.001462810207158327 Validation Loss: 0.0025852713733911514\n",
      "7782 Training Loss: 0.0015280795050784945 Validation Loss: 0.002587077207863331\n",
      "7783 Training Loss: 0.0014176922850310802 Validation Loss: 0.0026030284352600574\n",
      "7784 Training Loss: 0.0014611021615564823 Validation Loss: 0.002637076424434781\n",
      "7785 Training Loss: 0.002121551427990198 Validation Loss: 0.0027535362169146538\n",
      "7786 Training Loss: 0.0015769705642014742 Validation Loss: 0.002848966047167778\n",
      "7787 Training Loss: 0.0013381813187152147 Validation Loss: 0.0029380940832197666\n",
      "7788 Training Loss: 0.0016842717304825783 Validation Loss: 0.003015159862115979\n",
      "7789 Training Loss: 0.0014516300288960338 Validation Loss: 0.003010975196957588\n",
      "7790 Training Loss: 0.0017427282873541117 Validation Loss: 0.0029250497464090586\n",
      "7791 Training Loss: 0.001885732519440353 Validation Loss: 0.0028317426331341267\n",
      "7792 Training Loss: 0.0015685707330703735 Validation Loss: 0.002713360358029604\n",
      "7793 Training Loss: 0.0021357389632612467 Validation Loss: 0.002684202743694186\n",
      "7794 Training Loss: 0.001888474216684699 Validation Loss: 0.002694981172680855\n",
      "7795 Training Loss: 0.0017754361033439636 Validation Loss: 0.0027653989382088184\n",
      "7796 Training Loss: 0.0020939770620316267 Validation Loss: 0.00283108395524323\n",
      "7797 Training Loss: 0.0015666704857721925 Validation Loss: 0.0028332029469311237\n",
      "7798 Training Loss: 0.0015759395901113749 Validation Loss: 0.0028122514486312866\n",
      "7799 Training Loss: 0.0014205493498593569 Validation Loss: 0.0027955740224570036\n",
      "7800 Training Loss: 0.0014454895863309503 Validation Loss: 0.002807418815791607\n",
      "7801 Training Loss: 0.0014628816861659288 Validation Loss: 0.0028252494521439075\n",
      "7802 Training Loss: 0.002615807345137 Validation Loss: 0.0029606649186462164\n",
      "7803 Training Loss: 0.0015891892835497856 Validation Loss: 0.0030972720123827457\n",
      "7804 Training Loss: 0.0015571010299026966 Validation Loss: 0.003200685139745474\n",
      "7805 Training Loss: 0.0016358131542801857 Validation Loss: 0.0032258955761790276\n",
      "7806 Training Loss: 0.0019503096118569374 Validation Loss: 0.0031989486888051033\n",
      "7807 Training Loss: 0.0017655312549322844 Validation Loss: 0.003062101313844323\n",
      "7808 Training Loss: 0.0014563890872523189 Validation Loss: 0.002925439737737179\n",
      "7809 Training Loss: 0.001868454273790121 Validation Loss: 0.002859710017219186\n",
      "7810 Training Loss: 0.0016793478280305862 Validation Loss: 0.0028448663651943207\n",
      "7811 Training Loss: 0.0014425148256123066 Validation Loss: 0.0028559532947838306\n",
      "7812 Training Loss: 0.0013936841860413551 Validation Loss: 0.002879785606637597\n",
      "7813 Training Loss: 0.001581884571351111 Validation Loss: 0.0028574562165886164\n",
      "7814 Training Loss: 0.0015230242861434817 Validation Loss: 0.00283906445838511\n",
      "7815 Training Loss: 0.0013527111150324345 Validation Loss: 0.002845988841727376\n",
      "7816 Training Loss: 0.0017911663744598627 Validation Loss: 0.002933778567239642\n",
      "7817 Training Loss: 0.0022552821319550276 Validation Loss: 0.0029818175826221704\n",
      "7818 Training Loss: 0.0013125583063811064 Validation Loss: 0.003032247070223093\n",
      "7819 Training Loss: 0.0014176766853779554 Validation Loss: 0.003040805459022522\n",
      "7820 Training Loss: 0.0015675623435527086 Validation Loss: 0.0030501908622682095\n",
      "7821 Training Loss: 0.00140002416446805 Validation Loss: 0.0030273469164967537\n",
      "7822 Training Loss: 0.0016302240546792746 Validation Loss: 0.0029601510614156723\n",
      "7823 Training Loss: 0.0016667087329551578 Validation Loss: 0.0029374866280704737\n",
      "7824 Training Loss: 0.0032518580555915833 Validation Loss: 0.003005126491189003\n",
      "7825 Training Loss: 0.001617393922060728 Validation Loss: 0.0030691009014844894\n",
      "7826 Training Loss: 0.0014477160293608904 Validation Loss: 0.0030812828335911036\n",
      "7827 Training Loss: 0.001447988091968 Validation Loss: 0.0030357525683939457\n",
      "7828 Training Loss: 0.0015126869548112154 Validation Loss: 0.0029895741026848555\n",
      "7829 Training Loss: 0.0014243540354073048 Validation Loss: 0.0029527833685278893\n",
      "7830 Training Loss: 0.0017120805568993092 Validation Loss: 0.0028721659909933805\n",
      "7831 Training Loss: 0.0014553170185536146 Validation Loss: 0.002812265418469906\n",
      "7832 Training Loss: 0.0013648637104779482 Validation Loss: 0.002783228876069188\n",
      "7833 Training Loss: 0.0015124775236472487 Validation Loss: 0.002756299916654825\n",
      "7834 Training Loss: 0.002544783055782318 Validation Loss: 0.00282782013528049\n",
      "7835 Training Loss: 0.0016071673016995192 Validation Loss: 0.0028976411558687687\n",
      "7836 Training Loss: 0.0016563963145017624 Validation Loss: 0.0028897805605083704\n",
      "7837 Training Loss: 0.0016081008361652493 Validation Loss: 0.0028488109819591045\n",
      "7838 Training Loss: 0.0015320370439440012 Validation Loss: 0.002741106553003192\n",
      "7839 Training Loss: 0.0014383818488568068 Validation Loss: 0.0026797696482390165\n",
      "7840 Training Loss: 0.0013954028254374862 Validation Loss: 0.0026710997335612774\n",
      "7841 Training Loss: 0.0013657977106049657 Validation Loss: 0.002668964210897684\n",
      "7842 Training Loss: 0.0013936262112110853 Validation Loss: 0.002698504365980625\n",
      "7843 Training Loss: 0.003380073234438896 Validation Loss: 0.0027861380949616432\n",
      "7844 Training Loss: 0.0027053807862102985 Validation Loss: 0.0029740710742771626\n",
      "7845 Training Loss: 0.0018664037343114614 Validation Loss: 0.003102562390267849\n",
      "7846 Training Loss: 0.001761013874784112 Validation Loss: 0.003099774243310094\n",
      "7847 Training Loss: 0.0013765939511358738 Validation Loss: 0.0029620896093547344\n",
      "7848 Training Loss: 0.0016168251167982817 Validation Loss: 0.002784298500046134\n",
      "7849 Training Loss: 0.0013786070048809052 Validation Loss: 0.0026831503491848707\n",
      "7850 Training Loss: 0.0017317950259894133 Validation Loss: 0.0026276877615600824\n",
      "7851 Training Loss: 0.0016224496066570282 Validation Loss: 0.00261726975440979\n",
      "7852 Training Loss: 0.002389800501987338 Validation Loss: 0.002668430097401142\n",
      "7853 Training Loss: 0.0014691094402223825 Validation Loss: 0.002830804791301489\n",
      "7854 Training Loss: 0.0014559078263118863 Validation Loss: 0.003003024496138096\n",
      "7855 Training Loss: 0.001692319754511118 Validation Loss: 0.0030292219016700983\n",
      "7856 Training Loss: 0.002017504535615444 Validation Loss: 0.0030195240397006273\n",
      "7857 Training Loss: 0.001441062893718481 Validation Loss: 0.0028940769843757153\n",
      "7858 Training Loss: 0.0012411682400852442 Validation Loss: 0.0027630620170384645\n",
      "7859 Training Loss: 0.0015601877821609378 Validation Loss: 0.002642577514052391\n",
      "7860 Training Loss: 0.0013157821958884597 Validation Loss: 0.0026082084514200687\n",
      "7861 Training Loss: 0.001382034970447421 Validation Loss: 0.0025971948634833097\n",
      "7862 Training Loss: 0.0013962569646537304 Validation Loss: 0.0026022049132734537\n",
      "7863 Training Loss: 0.0014178226701915264 Validation Loss: 0.0026373097207397223\n",
      "7864 Training Loss: 0.0029586274176836014 Validation Loss: 0.0028284601867198944\n",
      "7865 Training Loss: 0.0015117144212126732 Validation Loss: 0.003061621682718396\n",
      "7866 Training Loss: 0.0016064029186964035 Validation Loss: 0.0031383968889713287\n",
      "7867 Training Loss: 0.001783212530426681 Validation Loss: 0.002993836533278227\n",
      "7868 Training Loss: 0.0014679641462862492 Validation Loss: 0.002801776397973299\n",
      "7869 Training Loss: 0.001977707026526332 Validation Loss: 0.0026980421971529722\n",
      "7870 Training Loss: 0.0022960302885621786 Validation Loss: 0.002681756392121315\n",
      "7871 Training Loss: 0.0028602038510143757 Validation Loss: 0.002753355773165822\n",
      "7872 Training Loss: 0.001278485869988799 Validation Loss: 0.002859389642253518\n",
      "7873 Training Loss: 0.0031730206683278084 Validation Loss: 0.003113202517852187\n",
      "7874 Training Loss: 0.0016589275328442454 Validation Loss: 0.0033257193863391876\n",
      "7875 Training Loss: 0.0018541014287620783 Validation Loss: 0.0033881638664752245\n",
      "7876 Training Loss: 0.0016929253470152617 Validation Loss: 0.003297073533758521\n",
      "7877 Training Loss: 0.002231151796877384 Validation Loss: 0.003056003013625741\n",
      "7878 Training Loss: 0.0020532289054244757 Validation Loss: 0.0028426300268620253\n",
      "7879 Training Loss: 0.0015010142233222723 Validation Loss: 0.002714528003707528\n",
      "7880 Training Loss: 0.0016725747846066952 Validation Loss: 0.002689553890377283\n",
      "7881 Training Loss: 0.0013576701749116182 Validation Loss: 0.0026852269656956196\n",
      "7882 Training Loss: 0.001964361174032092 Validation Loss: 0.002694453578442335\n",
      "7883 Training Loss: 0.001958338776603341 Validation Loss: 0.0027756989002227783\n",
      "7884 Training Loss: 0.001301526790484786 Validation Loss: 0.002879709703847766\n",
      "7885 Training Loss: 0.0015746878925710917 Validation Loss: 0.0030020896811038256\n",
      "7886 Training Loss: 0.0014528310857713223 Validation Loss: 0.0030327511485666037\n",
      "7887 Training Loss: 0.0017793932929635048 Validation Loss: 0.0028952332213521004\n",
      "7888 Training Loss: 0.0014466543216258287 Validation Loss: 0.002769165439531207\n",
      "7889 Training Loss: 0.002229755511507392 Validation Loss: 0.0027375505305826664\n",
      "7890 Training Loss: 0.001502126338891685 Validation Loss: 0.0027205708902329206\n",
      "7891 Training Loss: 0.0014256937429308891 Validation Loss: 0.0027289874851703644\n",
      "7892 Training Loss: 0.0014660300221294165 Validation Loss: 0.0027364089619368315\n",
      "7893 Training Loss: 0.002205892000347376 Validation Loss: 0.0027990362141281366\n",
      "7894 Training Loss: 0.0017775516025722027 Validation Loss: 0.0029255645349621773\n",
      "7895 Training Loss: 0.0016286888858303428 Validation Loss: 0.0029724501073360443\n",
      "7896 Training Loss: 0.0016143966931849718 Validation Loss: 0.002911725314334035\n",
      "7897 Training Loss: 0.0014407453127205372 Validation Loss: 0.002812677761539817\n",
      "7898 Training Loss: 0.0014810336288064718 Validation Loss: 0.002736614551395178\n",
      "7899 Training Loss: 0.0014533514622598886 Validation Loss: 0.0027253704611212015\n",
      "7900 Training Loss: 0.0014136971440166235 Validation Loss: 0.002732312073931098\n",
      "7901 Training Loss: 0.0017258146544918418 Validation Loss: 0.002770061604678631\n",
      "7902 Training Loss: 0.0014076222432777286 Validation Loss: 0.0028344658203423023\n",
      "7903 Training Loss: 0.0018749539740383625 Validation Loss: 0.0029007322154939175\n",
      "7904 Training Loss: 0.0015987309161573648 Validation Loss: 0.002858848078176379\n",
      "7905 Training Loss: 0.0015530306845903397 Validation Loss: 0.0028366425540298223\n",
      "7906 Training Loss: 0.0013932149158790708 Validation Loss: 0.0027778102084994316\n",
      "7907 Training Loss: 0.0022963532246649265 Validation Loss: 0.0027441754937171936\n",
      "7908 Training Loss: 0.0015299920924007893 Validation Loss: 0.0027617542073130608\n",
      "7909 Training Loss: 0.0013844443019479513 Validation Loss: 0.0027522060554474592\n",
      "7910 Training Loss: 0.002120847348123789 Validation Loss: 0.0027880275156348944\n",
      "7911 Training Loss: 0.0015199128538370132 Validation Loss: 0.0028641088865697384\n",
      "7912 Training Loss: 0.0026648358907550573 Validation Loss: 0.0030422997660934925\n",
      "7913 Training Loss: 0.0014092270284891129 Validation Loss: 0.003161697182804346\n",
      "7914 Training Loss: 0.0020855506882071495 Validation Loss: 0.003226066706702113\n",
      "7915 Training Loss: 0.0019077144097536802 Validation Loss: 0.0032117937225848436\n",
      "7916 Training Loss: 0.0013896527234464884 Validation Loss: 0.003120790235698223\n",
      "7917 Training Loss: 0.0013403190532699227 Validation Loss: 0.003042649943381548\n",
      "7918 Training Loss: 0.0014567463658750057 Validation Loss: 0.0029973459895700216\n",
      "7919 Training Loss: 0.001560793025419116 Validation Loss: 0.002916771685704589\n",
      "7920 Training Loss: 0.0022141924127936363 Validation Loss: 0.002969991182908416\n",
      "7921 Training Loss: 0.0013621679972857237 Validation Loss: 0.0030232174322009087\n",
      "7922 Training Loss: 0.0014611922670155764 Validation Loss: 0.003024160396307707\n",
      "7923 Training Loss: 0.001368996687233448 Validation Loss: 0.0029840166680514812\n",
      "7924 Training Loss: 0.002050724346190691 Validation Loss: 0.0029713320545852184\n",
      "7925 Training Loss: 0.001328076934441924 Validation Loss: 0.002949122106656432\n",
      "7926 Training Loss: 0.0016520004719495773 Validation Loss: 0.002854559337720275\n",
      "7927 Training Loss: 0.0014568525366485119 Validation Loss: 0.0028242238331586123\n",
      "7928 Training Loss: 0.0014288369566202164 Validation Loss: 0.002821494359523058\n",
      "7929 Training Loss: 0.0015473779058083892 Validation Loss: 0.0028380376752465963\n",
      "7930 Training Loss: 0.0013727741315960884 Validation Loss: 0.002888886258006096\n",
      "7931 Training Loss: 0.0016502940561622381 Validation Loss: 0.002867561997845769\n",
      "7932 Training Loss: 0.0015277268830686808 Validation Loss: 0.0028311291243880987\n",
      "7933 Training Loss: 0.0017656765412539244 Validation Loss: 0.002769177546724677\n",
      "7934 Training Loss: 0.001377401640638709 Validation Loss: 0.002714933827519417\n",
      "7935 Training Loss: 0.0013895409647375345 Validation Loss: 0.0026671881787478924\n",
      "7936 Training Loss: 0.0016317176632583141 Validation Loss: 0.002646476263180375\n",
      "7937 Training Loss: 0.001401435350999236 Validation Loss: 0.0026184185408055782\n",
      "7938 Training Loss: 0.0012842821888625622 Validation Loss: 0.002591855125501752\n",
      "7939 Training Loss: 0.0025454959832131863 Validation Loss: 0.0026221382431685925\n",
      "7940 Training Loss: 0.0012396196834743023 Validation Loss: 0.0026688259094953537\n",
      "7941 Training Loss: 0.001322813332080841 Validation Loss: 0.002728257095441222\n",
      "7942 Training Loss: 0.0022647238802164793 Validation Loss: 0.002800712361931801\n",
      "7943 Training Loss: 0.0014381742803379893 Validation Loss: 0.002808847464621067\n",
      "7944 Training Loss: 0.0016362696187570691 Validation Loss: 0.0027243546210229397\n",
      "7945 Training Loss: 0.001342779491096735 Validation Loss: 0.002730395644903183\n",
      "7946 Training Loss: 0.0013412083499133587 Validation Loss: 0.0027355370111763477\n",
      "7947 Training Loss: 0.0012804875150322914 Validation Loss: 0.0027514712419360876\n",
      "7948 Training Loss: 0.0012901483569294214 Validation Loss: 0.0027411114424467087\n",
      "7949 Training Loss: 0.001577524933964014 Validation Loss: 0.002683668863028288\n",
      "7950 Training Loss: 0.0014962053392082453 Validation Loss: 0.002598041668534279\n",
      "7951 Training Loss: 0.0014699187595397234 Validation Loss: 0.0025317715480923653\n",
      "7952 Training Loss: 0.0013189308810979128 Validation Loss: 0.002493963809683919\n",
      "7953 Training Loss: 0.0015981423202902079 Validation Loss: 0.0024896813556551933\n",
      "7954 Training Loss: 0.0013136579655110836 Validation Loss: 0.0024961521849036217\n",
      "7955 Training Loss: 0.0013395557180047035 Validation Loss: 0.002505286131054163\n",
      "7956 Training Loss: 0.0014080875553190708 Validation Loss: 0.00251089152880013\n",
      "7957 Training Loss: 0.0014778624754399061 Validation Loss: 0.002553488127887249\n",
      "7958 Training Loss: 0.0013006692752242088 Validation Loss: 0.002613387070596218\n",
      "7959 Training Loss: 0.0016589449951425195 Validation Loss: 0.0026397835463285446\n",
      "7960 Training Loss: 0.0016776781994849443 Validation Loss: 0.002695969305932522\n",
      "7961 Training Loss: 0.001374905463308096 Validation Loss: 0.0027244018856436014\n",
      "7962 Training Loss: 0.001945612020790577 Validation Loss: 0.0027921132277697325\n",
      "7963 Training Loss: 0.0012833508662879467 Validation Loss: 0.002882939763367176\n",
      "7964 Training Loss: 0.0015568165108561516 Validation Loss: 0.002890807343646884\n",
      "7965 Training Loss: 0.0017065871506929398 Validation Loss: 0.002865611808374524\n",
      "7966 Training Loss: 0.0014004056574776769 Validation Loss: 0.0027991123497486115\n",
      "7967 Training Loss: 0.0020152684301137924 Validation Loss: 0.0027328762225806713\n",
      "7968 Training Loss: 0.0013718688860535622 Validation Loss: 0.0026621196884661913\n",
      "7969 Training Loss: 0.0013956483453512192 Validation Loss: 0.0026098424568772316\n",
      "7970 Training Loss: 0.0012414449593052268 Validation Loss: 0.0026093386113643646\n",
      "7971 Training Loss: 0.001345161348581314 Validation Loss: 0.0026069392915815115\n",
      "7972 Training Loss: 0.0012494619004428387 Validation Loss: 0.0026180522982031107\n",
      "7973 Training Loss: 0.0029612116049975157 Validation Loss: 0.002758294576779008\n",
      "7974 Training Loss: 0.0013593584299087524 Validation Loss: 0.002884496934711933\n",
      "7975 Training Loss: 0.001305988640524447 Validation Loss: 0.0029194785747677088\n",
      "7976 Training Loss: 0.001281161094084382 Validation Loss: 0.0028579896315932274\n",
      "7977 Training Loss: 0.0014198720455169678 Validation Loss: 0.0027152278926223516\n",
      "7978 Training Loss: 0.001974507700651884 Validation Loss: 0.0026479302905499935\n",
      "7979 Training Loss: 0.0016974059399217367 Validation Loss: 0.002654364798218012\n",
      "7980 Training Loss: 0.0013208086602389812 Validation Loss: 0.0026788380928337574\n",
      "7981 Training Loss: 0.0014945752918720245 Validation Loss: 0.002668888308107853\n",
      "7982 Training Loss: 0.0014498068485409021 Validation Loss: 0.002677750773727894\n",
      "7983 Training Loss: 0.0013956923503428698 Validation Loss: 0.0026591585483402014\n",
      "7984 Training Loss: 0.0017582009313628078 Validation Loss: 0.002659064717590809\n",
      "7985 Training Loss: 0.001212964067235589 Validation Loss: 0.0026256435085088015\n",
      "7986 Training Loss: 0.0014507898595184088 Validation Loss: 0.002549049211665988\n",
      "7987 Training Loss: 0.0020325416699051857 Validation Loss: 0.002547824289649725\n",
      "7988 Training Loss: 0.0020361491478979588 Validation Loss: 0.0025667245499789715\n",
      "7989 Training Loss: 0.0013200538232922554 Validation Loss: 0.0025798329152166843\n",
      "7990 Training Loss: 0.0026699602603912354 Validation Loss: 0.0027252682484686375\n",
      "7991 Training Loss: 0.0013435716973617673 Validation Loss: 0.0028114302549511194\n",
      "7992 Training Loss: 0.001260547200217843 Validation Loss: 0.002805995987728238\n",
      "7993 Training Loss: 0.0024198824539780617 Validation Loss: 0.0028110977727919817\n",
      "7994 Training Loss: 0.0015790103934705257 Validation Loss: 0.0027529699727892876\n",
      "7995 Training Loss: 0.002273452002555132 Validation Loss: 0.0027024198789149523\n",
      "7996 Training Loss: 0.0014070288743823767 Validation Loss: 0.0026728990487754345\n",
      "7997 Training Loss: 0.0013405372155830264 Validation Loss: 0.00264105387032032\n",
      "7998 Training Loss: 0.0012197974137961864 Validation Loss: 0.0026371392887085676\n",
      "7999 Training Loss: 0.0030466285534203053 Validation Loss: 0.002803650451824069\n",
      "8000 Training Loss: 0.0014933107886463404 Validation Loss: 0.002912757685407996\n",
      "8001 Training Loss: 0.0013062795624136925 Validation Loss: 0.002910392824560404\n",
      "8002 Training Loss: 0.0014544602017849684 Validation Loss: 0.0027946524787694216\n",
      "8003 Training Loss: 0.0013397953007370234 Validation Loss: 0.002655243733897805\n",
      "8004 Training Loss: 0.0018304947298020124 Validation Loss: 0.002596758073195815\n",
      "8005 Training Loss: 0.0013246494345366955 Validation Loss: 0.002576439641416073\n",
      "8006 Training Loss: 0.0013231935445219278 Validation Loss: 0.002562962006777525\n",
      "8007 Training Loss: 0.0019414495909586549 Validation Loss: 0.002572552300989628\n",
      "8008 Training Loss: 0.0017743280623108149 Validation Loss: 0.0025924735236912966\n",
      "8009 Training Loss: 0.0013597453944385052 Validation Loss: 0.0026352719869464636\n",
      "8010 Training Loss: 0.001301534241065383 Validation Loss: 0.0026577662210911512\n",
      "8011 Training Loss: 0.001365888281725347 Validation Loss: 0.0026349208783358335\n",
      "8012 Training Loss: 0.0013581912498921156 Validation Loss: 0.002583877183496952\n",
      "8013 Training Loss: 0.001430125324986875 Validation Loss: 0.0025391376111656427\n",
      "8014 Training Loss: 0.0013776876730844378 Validation Loss: 0.0025189328007400036\n",
      "8015 Training Loss: 0.0026269443333148956 Validation Loss: 0.0025463576894253492\n",
      "8016 Training Loss: 0.0013546256814152002 Validation Loss: 0.0025711976923048496\n",
      "8017 Training Loss: 0.0014801910147070885 Validation Loss: 0.0025940292980521917\n",
      "8018 Training Loss: 0.0012297795619815588 Validation Loss: 0.002612574491649866\n",
      "8019 Training Loss: 0.0016258296091109514 Validation Loss: 0.002595449099317193\n",
      "8020 Training Loss: 0.0013033193536102772 Validation Loss: 0.002561025321483612\n",
      "8021 Training Loss: 0.0014388859272003174 Validation Loss: 0.0025037687737494707\n",
      "8022 Training Loss: 0.002425305312499404 Validation Loss: 0.002502400428056717\n",
      "8023 Training Loss: 0.001482351217418909 Validation Loss: 0.002490515122190118\n",
      "8024 Training Loss: 0.0013402958866208792 Validation Loss: 0.002466363599523902\n",
      "8025 Training Loss: 0.0011938291136175394 Validation Loss: 0.0024536196142435074\n",
      "8026 Training Loss: 0.0016813678666949272 Validation Loss: 0.002473002765327692\n",
      "8027 Training Loss: 0.0022468315437436104 Validation Loss: 0.002539367415010929\n",
      "8028 Training Loss: 0.0013587841531261802 Validation Loss: 0.002590301213786006\n",
      "8029 Training Loss: 0.0012563576456159353 Validation Loss: 0.00262476340867579\n",
      "8030 Training Loss: 0.001892510219477117 Validation Loss: 0.0027420700062066317\n",
      "8031 Training Loss: 0.0013016255106776953 Validation Loss: 0.002836358966305852\n",
      "8032 Training Loss: 0.0013199604582041502 Validation Loss: 0.002873376477509737\n",
      "8033 Training Loss: 0.0014196161646395922 Validation Loss: 0.0028764375019818544\n",
      "8034 Training Loss: 0.0012745517306029797 Validation Loss: 0.0028347368352115154\n",
      "8035 Training Loss: 0.0015368126332759857 Validation Loss: 0.002749455627053976\n",
      "8036 Training Loss: 0.0014175210380926728 Validation Loss: 0.0026912319008260965\n",
      "8037 Training Loss: 0.0015320989768952131 Validation Loss: 0.002605926478281617\n",
      "8038 Training Loss: 0.0016148569993674755 Validation Loss: 0.0025699222460389137\n",
      "8039 Training Loss: 0.0013126374687999487 Validation Loss: 0.002541966736316681\n",
      "8040 Training Loss: 0.0017055796924978495 Validation Loss: 0.002562978072091937\n",
      "8041 Training Loss: 0.001644663279876113 Validation Loss: 0.002593457233160734\n",
      "8042 Training Loss: 0.0013336814008653164 Validation Loss: 0.0025791062507778406\n",
      "8043 Training Loss: 0.0015769945457577705 Validation Loss: 0.002500467002391815\n",
      "8044 Training Loss: 0.001471104333177209 Validation Loss: 0.0024411166086792946\n",
      "8045 Training Loss: 0.0012714652111753821 Validation Loss: 0.0024138083681464195\n",
      "8046 Training Loss: 0.003727608360350132 Validation Loss: 0.0024842547718435526\n",
      "8047 Training Loss: 0.0014384574024006724 Validation Loss: 0.002585143083706498\n",
      "8048 Training Loss: 0.0012611227575689554 Validation Loss: 0.0027139217127114534\n",
      "8049 Training Loss: 0.0014157562982290983 Validation Loss: 0.0027434767689555883\n",
      "8050 Training Loss: 0.0017203493043780327 Validation Loss: 0.0028144821990281343\n",
      "8051 Training Loss: 0.001342502422630787 Validation Loss: 0.0028015743009746075\n",
      "8052 Training Loss: 0.001527826301753521 Validation Loss: 0.002688420470803976\n",
      "8053 Training Loss: 0.0012414184166118503 Validation Loss: 0.002602984895929694\n",
      "8054 Training Loss: 0.0014883847907185555 Validation Loss: 0.0025600632652640343\n",
      "8055 Training Loss: 0.001159911509603262 Validation Loss: 0.0025562485679984093\n",
      "8056 Training Loss: 0.0019662759732455015 Validation Loss: 0.002635376527905464\n",
      "8057 Training Loss: 0.0012163207866251469 Validation Loss: 0.0027339854277670383\n",
      "8058 Training Loss: 0.0015460671856999397 Validation Loss: 0.0027400923427194357\n",
      "8059 Training Loss: 0.0015814797952771187 Validation Loss: 0.0027368906885385513\n",
      "8060 Training Loss: 0.0013047545216977596 Validation Loss: 0.0026954161003232002\n",
      "8061 Training Loss: 0.002034747740253806 Validation Loss: 0.002690452616661787\n",
      "8062 Training Loss: 0.0014991842908784747 Validation Loss: 0.00260150246322155\n",
      "8063 Training Loss: 0.0015839674742892385 Validation Loss: 0.0025886560324579477\n",
      "8064 Training Loss: 0.0015440606512129307 Validation Loss: 0.0025349154602736235\n",
      "8065 Training Loss: 0.0019349843496456742 Validation Loss: 0.002542279427871108\n",
      "8066 Training Loss: 0.001876411261036992 Validation Loss: 0.0026516064535826445\n",
      "8067 Training Loss: 0.0013099350035190582 Validation Loss: 0.002747562248259783\n",
      "8068 Training Loss: 0.0019048680551350117 Validation Loss: 0.0027552859392017126\n",
      "8069 Training Loss: 0.0014854171313345432 Validation Loss: 0.0026900465600192547\n",
      "8070 Training Loss: 0.0013859958853572607 Validation Loss: 0.002596140606328845\n",
      "8071 Training Loss: 0.0026460732333362103 Validation Loss: 0.002634666161611676\n",
      "8072 Training Loss: 0.001226885593496263 Validation Loss: 0.002645829925313592\n",
      "8073 Training Loss: 0.0013049310073256493 Validation Loss: 0.0026565894950181246\n",
      "8074 Training Loss: 0.0013348282082006335 Validation Loss: 0.0026303085032850504\n",
      "8075 Training Loss: 0.001769153866916895 Validation Loss: 0.0026776131708174944\n",
      "8076 Training Loss: 0.0013431916013360023 Validation Loss: 0.002668617991730571\n",
      "8077 Training Loss: 0.0013447351520881057 Validation Loss: 0.002632365096360445\n",
      "8078 Training Loss: 0.0012929916847497225 Validation Loss: 0.0025856164284050465\n",
      "8079 Training Loss: 0.0012299674563109875 Validation Loss: 0.002539214910939336\n",
      "8080 Training Loss: 0.001411456847563386 Validation Loss: 0.00246517825871706\n",
      "8081 Training Loss: 0.00130224390886724 Validation Loss: 0.002426950028166175\n",
      "8082 Training Loss: 0.0012439291458576918 Validation Loss: 0.002408107742667198\n",
      "8083 Training Loss: 0.0017629230860620737 Validation Loss: 0.0024629845283925533\n",
      "8084 Training Loss: 0.0012345649302005768 Validation Loss: 0.002506632823497057\n",
      "8085 Training Loss: 0.002654701005667448 Validation Loss: 0.0026521978434175253\n",
      "8086 Training Loss: 0.0013302266597747803 Validation Loss: 0.0027675163000822067\n",
      "8087 Training Loss: 0.0014545454178005457 Validation Loss: 0.002767786383628845\n",
      "8088 Training Loss: 0.001365332747809589 Validation Loss: 0.002700401470065117\n",
      "8089 Training Loss: 0.001213450450450182 Validation Loss: 0.002641566563397646\n",
      "8090 Training Loss: 0.0013419510796666145 Validation Loss: 0.002606970025226474\n",
      "8091 Training Loss: 0.0013370894594118 Validation Loss: 0.002584915840998292\n",
      "8092 Training Loss: 0.001955920597538352 Validation Loss: 0.0025666041765362024\n",
      "8093 Training Loss: 0.0017739300383254886 Validation Loss: 0.0026245557237416506\n",
      "8094 Training Loss: 0.0012458892306312919 Validation Loss: 0.0026876889169216156\n",
      "8095 Training Loss: 0.0013501885114237666 Validation Loss: 0.0026884502731263638\n",
      "8096 Training Loss: 0.0012308668810874224 Validation Loss: 0.0026024202816188335\n",
      "8097 Training Loss: 0.002399322111159563 Validation Loss: 0.002620426705107093\n",
      "8098 Training Loss: 0.0013817469589412212 Validation Loss: 0.0025992479640990496\n",
      "8099 Training Loss: 0.0013979310169816017 Validation Loss: 0.002550995210185647\n",
      "8100 Training Loss: 0.00171976862475276 Validation Loss: 0.0025237444788217545\n",
      "8101 Training Loss: 0.0017387368716299534 Validation Loss: 0.002538405591621995\n",
      "8102 Training Loss: 0.001436414197087288 Validation Loss: 0.0025200918316841125\n",
      "8103 Training Loss: 0.0014783813385292888 Validation Loss: 0.0025346637703478336\n",
      "8104 Training Loss: 0.0012504623737186193 Validation Loss: 0.0025465586222708225\n",
      "8105 Training Loss: 0.002545751631259918 Validation Loss: 0.002600794192403555\n",
      "8106 Training Loss: 0.0014843865064904094 Validation Loss: 0.002637209603562951\n",
      "8107 Training Loss: 0.001570806372910738 Validation Loss: 0.002670356072485447\n",
      "8108 Training Loss: 0.0012016904074698687 Validation Loss: 0.0026322994381189346\n",
      "8109 Training Loss: 0.0013699792325496674 Validation Loss: 0.0025895119179040194\n",
      "8110 Training Loss: 0.0014080286491662264 Validation Loss: 0.0025214797351509333\n",
      "8111 Training Loss: 0.003855661256238818 Validation Loss: 0.0026014463510364294\n",
      "8112 Training Loss: 0.0012117878068238497 Validation Loss: 0.002684688428416848\n",
      "8113 Training Loss: 0.0011784181697294116 Validation Loss: 0.0027160991448909044\n",
      "8114 Training Loss: 0.0011931227054446936 Validation Loss: 0.0026820392813533545\n",
      "8115 Training Loss: 0.0013347889762371778 Validation Loss: 0.0026030561421066523\n",
      "8116 Training Loss: 0.0011861270759254694 Validation Loss: 0.0025476242881268263\n",
      "8117 Training Loss: 0.0013711510691791773 Validation Loss: 0.002510780468583107\n",
      "8118 Training Loss: 0.0012524172198027372 Validation Loss: 0.0024954427499324083\n",
      "8119 Training Loss: 0.002509467303752899 Validation Loss: 0.0025198408402502537\n",
      "8120 Training Loss: 0.0012233038432896137 Validation Loss: 0.002551507670432329\n",
      "8121 Training Loss: 0.001438927836716175 Validation Loss: 0.002568025840446353\n",
      "8122 Training Loss: 0.0019073227886110544 Validation Loss: 0.0026191389188170433\n",
      "8123 Training Loss: 0.001406559837050736 Validation Loss: 0.002640294609591365\n",
      "8124 Training Loss: 0.002157593844458461 Validation Loss: 0.0027072420343756676\n",
      "8125 Training Loss: 0.0012502417666837573 Validation Loss: 0.0027015802916139364\n",
      "8126 Training Loss: 0.0013387325452640653 Validation Loss: 0.0026608796324580908\n",
      "8127 Training Loss: 0.001170937903225422 Validation Loss: 0.0026161707937717438\n",
      "8128 Training Loss: 0.001405052375048399 Validation Loss: 0.0025502305943518877\n",
      "8129 Training Loss: 0.0013716056710109115 Validation Loss: 0.0025479195173829794\n",
      "8130 Training Loss: 0.001307165832258761 Validation Loss: 0.002554988954216242\n",
      "8131 Training Loss: 0.001106145209632814 Validation Loss: 0.002598590450361371\n",
      "8132 Training Loss: 0.001477160956710577 Validation Loss: 0.0026753784622997046\n",
      "8133 Training Loss: 0.0013291279319673777 Validation Loss: 0.002757895737886429\n",
      "8134 Training Loss: 0.0017640332225710154 Validation Loss: 0.0028005007188767195\n",
      "8135 Training Loss: 0.0017317095771431923 Validation Loss: 0.002794824540615082\n",
      "8136 Training Loss: 0.001193965901620686 Validation Loss: 0.0027426290325820446\n",
      "8137 Training Loss: 0.0013633796479552984 Validation Loss: 0.0026510742027312517\n",
      "8138 Training Loss: 0.0012552880216389894 Validation Loss: 0.0025735986419022083\n",
      "8139 Training Loss: 0.0012293196050450206 Validation Loss: 0.002544813323765993\n",
      "8140 Training Loss: 0.0013091980945318937 Validation Loss: 0.0025454426649957895\n",
      "8141 Training Loss: 0.00212005153298378 Validation Loss: 0.0025529067497700453\n",
      "8142 Training Loss: 0.0012966671492904425 Validation Loss: 0.0025939070619642735\n",
      "8143 Training Loss: 0.0017617021221667528 Validation Loss: 0.002668824279680848\n",
      "8144 Training Loss: 0.0013174375053495169 Validation Loss: 0.0026738003361970186\n",
      "8145 Training Loss: 0.0014737793244421482 Validation Loss: 0.0025969811249524355\n",
      "8146 Training Loss: 0.0013154391199350357 Validation Loss: 0.0024965174961835146\n",
      "8147 Training Loss: 0.0014128116890788078 Validation Loss: 0.0024400739930570126\n",
      "8148 Training Loss: 0.001677756430581212 Validation Loss: 0.0024391107726842165\n",
      "8149 Training Loss: 0.0013099710922688246 Validation Loss: 0.0024634781293570995\n",
      "8150 Training Loss: 0.0015289286384359002 Validation Loss: 0.0025561631191521883\n",
      "8151 Training Loss: 0.0011528232134878635 Validation Loss: 0.0026243801694363356\n",
      "8152 Training Loss: 0.0022403602488338947 Validation Loss: 0.0027327691204845905\n",
      "8153 Training Loss: 0.0015839384868741035 Validation Loss: 0.0028275498189032078\n",
      "8154 Training Loss: 0.0013137869536876678 Validation Loss: 0.0027968541253358126\n",
      "8155 Training Loss: 0.0016625244170427322 Validation Loss: 0.00274119945243001\n",
      "8156 Training Loss: 0.001278960844501853 Validation Loss: 0.0026229042559862137\n",
      "8157 Training Loss: 0.0012736900243908167 Validation Loss: 0.0025083436630666256\n",
      "8158 Training Loss: 0.0012710855808109045 Validation Loss: 0.0024734868202358484\n",
      "8159 Training Loss: 0.0024065147154033184 Validation Loss: 0.0025086188688874245\n",
      "8160 Training Loss: 0.0016616374487057328 Validation Loss: 0.002614060416817665\n",
      "8161 Training Loss: 0.0015731265302747488 Validation Loss: 0.0026394689921289682\n",
      "8162 Training Loss: 0.0012041637673974037 Validation Loss: 0.0026182536967098713\n",
      "8163 Training Loss: 0.001433948869816959 Validation Loss: 0.002635757904499769\n",
      "8164 Training Loss: 0.001592470332980156 Validation Loss: 0.0026945662684738636\n",
      "8165 Training Loss: 0.001255064969882369 Validation Loss: 0.002678743563592434\n",
      "8166 Training Loss: 0.0011450315359979868 Validation Loss: 0.002634349511936307\n",
      "8167 Training Loss: 0.001158061670139432 Validation Loss: 0.0026383348740637302\n",
      "8168 Training Loss: 0.0019857236184179783 Validation Loss: 0.002693520626053214\n",
      "8169 Training Loss: 0.0012670702999457717 Validation Loss: 0.0027124928310513496\n",
      "8170 Training Loss: 0.0011611559893935919 Validation Loss: 0.002688548294827342\n",
      "8171 Training Loss: 0.0012222002260386944 Validation Loss: 0.002681199461221695\n",
      "8172 Training Loss: 0.002128701191395521 Validation Loss: 0.002760985167697072\n",
      "8173 Training Loss: 0.0013431115075945854 Validation Loss: 0.0027281539514660835\n",
      "8174 Training Loss: 0.0012321220710873604 Validation Loss: 0.002659318968653679\n",
      "8175 Training Loss: 0.001359283458441496 Validation Loss: 0.002575495047494769\n",
      "8176 Training Loss: 0.0013121949741616845 Validation Loss: 0.002467791084200144\n",
      "8177 Training Loss: 0.0013502173824235797 Validation Loss: 0.0024137040600180626\n",
      "8178 Training Loss: 0.0019862554036080837 Validation Loss: 0.002461264608427882\n",
      "8179 Training Loss: 0.0012303187977522612 Validation Loss: 0.00257885898463428\n",
      "8180 Training Loss: 0.0012996559962630272 Validation Loss: 0.002714258385822177\n",
      "8181 Training Loss: 0.0016945216339081526 Validation Loss: 0.0028199581429362297\n",
      "8182 Training Loss: 0.001165222842246294 Validation Loss: 0.0028498598840087652\n",
      "8183 Training Loss: 0.001095813000574708 Validation Loss: 0.0028207702562212944\n",
      "8184 Training Loss: 0.0012667246628552675 Validation Loss: 0.0027251860592514277\n",
      "8185 Training Loss: 0.0013093200977891684 Validation Loss: 0.002643452025949955\n",
      "8186 Training Loss: 0.0012622023932635784 Validation Loss: 0.0025746305473148823\n",
      "8187 Training Loss: 0.0011325294617563486 Validation Loss: 0.0025747912004590034\n",
      "8188 Training Loss: 0.001298741903156042 Validation Loss: 0.002568537835031748\n",
      "8189 Training Loss: 0.0013015982694923878 Validation Loss: 0.0025740922428667545\n",
      "8190 Training Loss: 0.0011933816131204367 Validation Loss: 0.0026028910651803017\n",
      "8191 Training Loss: 0.0013432323466986418 Validation Loss: 0.0026101002003997564\n",
      "8192 Training Loss: 0.0012147389352321625 Validation Loss: 0.002577319974079728\n",
      "8193 Training Loss: 0.0010169628076255322 Validation Loss: 0.0025443728081882\n",
      "8194 Training Loss: 0.0013845504727214575 Validation Loss: 0.0024724509567022324\n",
      "8195 Training Loss: 0.0012371151242405176 Validation Loss: 0.0024477140977978706\n",
      "8196 Training Loss: 0.0012395557714626193 Validation Loss: 0.002428201260045171\n",
      "8197 Training Loss: 0.0015976293943822384 Validation Loss: 0.0024196512531489134\n",
      "8198 Training Loss: 0.0017519904067739844 Validation Loss: 0.002505409764125943\n",
      "8199 Training Loss: 0.001558996271342039 Validation Loss: 0.0026557734236121178\n",
      "8200 Training Loss: 0.0015003122389316559 Validation Loss: 0.002750254236161709\n",
      "8201 Training Loss: 0.002018628641963005 Validation Loss: 0.002923354273661971\n",
      "8202 Training Loss: 0.0011909438762813807 Validation Loss: 0.002979043871164322\n",
      "8203 Training Loss: 0.0013365107588469982 Validation Loss: 0.0028448845259845257\n",
      "8204 Training Loss: 0.0011996729299426079 Validation Loss: 0.0027136774733662605\n",
      "8205 Training Loss: 0.0011199567234143615 Validation Loss: 0.00262463022954762\n",
      "8206 Training Loss: 0.0013545108959078789 Validation Loss: 0.002595694735646248\n",
      "8207 Training Loss: 0.001326809055171907 Validation Loss: 0.002605412621051073\n",
      "8208 Training Loss: 0.0011546381283551455 Validation Loss: 0.0026287990622222424\n",
      "8209 Training Loss: 0.001169347669929266 Validation Loss: 0.0026846863329410553\n",
      "8210 Training Loss: 0.0012295516207814217 Validation Loss: 0.0027094618417322636\n",
      "8211 Training Loss: 0.0016299267299473286 Validation Loss: 0.002740669995546341\n",
      "8212 Training Loss: 0.0013829665258526802 Validation Loss: 0.0026367479003965855\n",
      "8213 Training Loss: 0.0017039049416780472 Validation Loss: 0.002566033275797963\n",
      "8214 Training Loss: 0.0011506003793329 Validation Loss: 0.002498714020475745\n",
      "8215 Training Loss: 0.0019459354225546122 Validation Loss: 0.0024667493999004364\n",
      "8216 Training Loss: 0.001267249695956707 Validation Loss: 0.002482713432982564\n",
      "8217 Training Loss: 0.001072324113920331 Validation Loss: 0.0025422812905162573\n",
      "8218 Training Loss: 0.0028947419486939907 Validation Loss: 0.002711627632379532\n",
      "8219 Training Loss: 0.0010799316223710775 Validation Loss: 0.002846329938620329\n",
      "8220 Training Loss: 0.0014776935568079352 Validation Loss: 0.0027793878689408302\n",
      "8221 Training Loss: 0.0013603679835796356 Validation Loss: 0.0026168986223638058\n",
      "8222 Training Loss: 0.0013740285066887736 Validation Loss: 0.002559802494943142\n",
      "8223 Training Loss: 0.001107882591895759 Validation Loss: 0.0025180098600685596\n",
      "8224 Training Loss: 0.0011075446382164955 Validation Loss: 0.002509795129299164\n",
      "8225 Training Loss: 0.0011939675314351916 Validation Loss: 0.0025213316548615694\n",
      "8226 Training Loss: 0.0012332689948379993 Validation Loss: 0.0025144501123577356\n",
      "8227 Training Loss: 0.001707183662801981 Validation Loss: 0.0025576730258762836\n",
      "8228 Training Loss: 0.001361299306154251 Validation Loss: 0.002571703866124153\n",
      "8229 Training Loss: 0.002031132811680436 Validation Loss: 0.002660742960870266\n",
      "8230 Training Loss: 0.001324532669968903 Validation Loss: 0.0027507562190294266\n",
      "8231 Training Loss: 0.0015920461155474186 Validation Loss: 0.0027640659827739\n",
      "8232 Training Loss: 0.0013961708173155785 Validation Loss: 0.002686396474018693\n",
      "8233 Training Loss: 0.0011959569528698921 Validation Loss: 0.0025977869518101215\n",
      "8234 Training Loss: 0.001109267002902925 Validation Loss: 0.0025244206190109253\n",
      "8235 Training Loss: 0.0012328096199780703 Validation Loss: 0.0024843928404152393\n",
      "8236 Training Loss: 0.0011892281472682953 Validation Loss: 0.00248711952008307\n",
      "8237 Training Loss: 0.001064573647454381 Validation Loss: 0.0025310188066214323\n",
      "8238 Training Loss: 0.0010745759354904294 Validation Loss: 0.0026283063925802708\n",
      "8239 Training Loss: 0.0013303568121045828 Validation Loss: 0.0027746884152293205\n",
      "8240 Training Loss: 0.0012365089496597648 Validation Loss: 0.002810709411278367\n",
      "8241 Training Loss: 0.0010744689498096704 Validation Loss: 0.002791614970192313\n",
      "8242 Training Loss: 0.0012421744177117944 Validation Loss: 0.002778976457193494\n",
      "8243 Training Loss: 0.0011961968848481774 Validation Loss: 0.002681644633412361\n",
      "8244 Training Loss: 0.0015391904162243009 Validation Loss: 0.0026100855320692062\n",
      "8245 Training Loss: 0.0013490794226527214 Validation Loss: 0.0024915935937315226\n",
      "8246 Training Loss: 0.0012410158524289727 Validation Loss: 0.002434769179672003\n",
      "8247 Training Loss: 0.0013234924990683794 Validation Loss: 0.0024144479539245367\n",
      "8248 Training Loss: 0.0011494990903884172 Validation Loss: 0.002400250406935811\n",
      "8249 Training Loss: 0.001142874825745821 Validation Loss: 0.002434043912217021\n",
      "8250 Training Loss: 0.0011715588625520468 Validation Loss: 0.0024817301891744137\n",
      "8251 Training Loss: 0.0013597800862044096 Validation Loss: 0.0025028055533766747\n",
      "8252 Training Loss: 0.0015672150766476989 Validation Loss: 0.002495406661182642\n",
      "8253 Training Loss: 0.0011345245875418186 Validation Loss: 0.002455680398270488\n",
      "8254 Training Loss: 0.001429133815690875 Validation Loss: 0.0024638890754431486\n",
      "8255 Training Loss: 0.0011025776620954275 Validation Loss: 0.0024823255371302366\n",
      "8256 Training Loss: 0.0010675570229068398 Validation Loss: 0.002523548901081085\n",
      "8257 Training Loss: 0.001178874634206295 Validation Loss: 0.0025617529172450304\n",
      "8258 Training Loss: 0.0011578109115362167 Validation Loss: 0.002579021267592907\n",
      "8259 Training Loss: 0.0012611814308911562 Validation Loss: 0.0025134345050901175\n",
      "8260 Training Loss: 0.0011508159805089235 Validation Loss: 0.0024998618755489588\n",
      "8261 Training Loss: 0.0013398942537605762 Validation Loss: 0.002485979814082384\n",
      "8262 Training Loss: 0.001086357980966568 Validation Loss: 0.0024707578122615814\n",
      "8263 Training Loss: 0.00146321184001863 Validation Loss: 0.0024476826656609774\n",
      "8264 Training Loss: 0.0025297696702182293 Validation Loss: 0.0025184047408401966\n",
      "8265 Training Loss: 0.0011614463292062283 Validation Loss: 0.002569134347140789\n",
      "8266 Training Loss: 0.00149453931953758 Validation Loss: 0.002589393872767687\n",
      "8267 Training Loss: 0.0012566191144287586 Validation Loss: 0.0025178748182952404\n",
      "8268 Training Loss: 0.0015253755263984203 Validation Loss: 0.0024625954683870077\n",
      "8269 Training Loss: 0.0015943202888593078 Validation Loss: 0.002479089191183448\n",
      "8270 Training Loss: 0.0010452932910993695 Validation Loss: 0.0025135986506938934\n",
      "8271 Training Loss: 0.0010856896406039596 Validation Loss: 0.002578578656539321\n",
      "8272 Training Loss: 0.0011979325208812952 Validation Loss: 0.0026734066195786\n",
      "8273 Training Loss: 0.0011173115344718099 Validation Loss: 0.0027434369549155235\n",
      "8274 Training Loss: 0.0014518979005515575 Validation Loss: 0.002644527470692992\n",
      "8275 Training Loss: 0.0010948735289275646 Validation Loss: 0.002539569977670908\n",
      "8276 Training Loss: 0.0011020952370017767 Validation Loss: 0.002443890320137143\n",
      "8277 Training Loss: 0.0010441343765705824 Validation Loss: 0.0023716753348708153\n",
      "8278 Training Loss: 0.001385891460813582 Validation Loss: 0.002363271778449416\n",
      "8279 Training Loss: 0.001068578101694584 Validation Loss: 0.002358735306188464\n",
      "8280 Training Loss: 0.0011617304990068078 Validation Loss: 0.0023585320450365543\n",
      "8281 Training Loss: 0.001127559575252235 Validation Loss: 0.002361099934205413\n",
      "8282 Training Loss: 0.0013292856747284532 Validation Loss: 0.002396502997726202\n",
      "8283 Training Loss: 0.0011256933212280273 Validation Loss: 0.002428986132144928\n",
      "8284 Training Loss: 0.0014078004751354456 Validation Loss: 0.0024098807480186224\n",
      "8285 Training Loss: 0.0012091435492038727 Validation Loss: 0.0024201611522585154\n",
      "8286 Training Loss: 0.001133729238063097 Validation Loss: 0.002434066729620099\n",
      "8287 Training Loss: 0.002804463030770421 Validation Loss: 0.0025436377618461847\n",
      "8288 Training Loss: 0.0011416706256568432 Validation Loss: 0.002593875164166093\n",
      "8289 Training Loss: 0.0012103503104299307 Validation Loss: 0.0025829803198575974\n",
      "8290 Training Loss: 0.0012581621995195746 Validation Loss: 0.0024708728305995464\n",
      "8291 Training Loss: 0.0012241055956110358 Validation Loss: 0.002338255289942026\n",
      "8292 Training Loss: 0.0012235681060701609 Validation Loss: 0.002243654103949666\n",
      "8293 Training Loss: 0.0010722590377554297 Validation Loss: 0.002209702506661415\n",
      "8294 Training Loss: 0.0010264992015436292 Validation Loss: 0.002196005778387189\n",
      "8295 Training Loss: 0.001728809205815196 Validation Loss: 0.0022309364285320044\n",
      "8296 Training Loss: 0.0011032482143491507 Validation Loss: 0.002303873421624303\n",
      "8297 Training Loss: 0.0010792186949402094 Validation Loss: 0.0023564628791064024\n",
      "8298 Training Loss: 0.0010936888866126537 Validation Loss: 0.0023638613056391478\n",
      "8299 Training Loss: 0.0012622594367712736 Validation Loss: 0.0023010943550616503\n",
      "8300 Training Loss: 0.0011735373409464955 Validation Loss: 0.0022551645524799824\n",
      "8301 Training Loss: 0.001100241905078292 Validation Loss: 0.0022212257608771324\n",
      "8302 Training Loss: 0.0010940078645944595 Validation Loss: 0.002204533899202943\n",
      "8303 Training Loss: 0.0011741812340915203 Validation Loss: 0.002217925153672695\n",
      "8304 Training Loss: 0.0018041583243757486 Validation Loss: 0.002302580513060093\n",
      "8305 Training Loss: 0.0016841073520481586 Validation Loss: 0.002486982150003314\n",
      "8306 Training Loss: 0.0011588286142796278 Validation Loss: 0.0025621536187827587\n",
      "8307 Training Loss: 0.0011553058866411448 Validation Loss: 0.0025247482117265463\n",
      "8308 Training Loss: 0.0012672303710132837 Validation Loss: 0.002375053707510233\n",
      "8309 Training Loss: 0.0012152371928095818 Validation Loss: 0.0023217517882585526\n",
      "8310 Training Loss: 0.00129705888684839 Validation Loss: 0.002312718890607357\n",
      "8311 Training Loss: 0.0011408230056986213 Validation Loss: 0.002333165844902396\n",
      "8312 Training Loss: 0.0014109313488006592 Validation Loss: 0.0023462220560759306\n",
      "8313 Training Loss: 0.0012153522111475468 Validation Loss: 0.00237343180924654\n",
      "8314 Training Loss: 0.001881654025055468 Validation Loss: 0.0024886708706617355\n",
      "8315 Training Loss: 0.0009676517802290618 Validation Loss: 0.0025821200106292963\n",
      "8316 Training Loss: 0.001851609442383051 Validation Loss: 0.0025722153950482607\n",
      "8317 Training Loss: 0.0012011289363726974 Validation Loss: 0.0025566841941326857\n",
      "8318 Training Loss: 0.001191429328173399 Validation Loss: 0.002446254249662161\n",
      "8319 Training Loss: 0.0011195472907274961 Validation Loss: 0.0023347262758761644\n",
      "8320 Training Loss: 0.0018317436333745718 Validation Loss: 0.0022848094813525677\n",
      "8321 Training Loss: 0.001153256045654416 Validation Loss: 0.0023093626368790865\n",
      "8322 Training Loss: 0.0012058981228619814 Validation Loss: 0.002375939628109336\n",
      "8323 Training Loss: 0.0012889825738966465 Validation Loss: 0.00251455744728446\n",
      "8324 Training Loss: 0.0012179617770016193 Validation Loss: 0.0026090191677212715\n",
      "8325 Training Loss: 0.001041823998093605 Validation Loss: 0.00264306110329926\n",
      "8326 Training Loss: 0.001095247222110629 Validation Loss: 0.0026251173112541437\n",
      "8327 Training Loss: 0.0012541147880256176 Validation Loss: 0.002546262461692095\n",
      "8328 Training Loss: 0.0011932996567338705 Validation Loss: 0.0024368795566260815\n",
      "8329 Training Loss: 0.001023234915919602 Validation Loss: 0.0023611150681972504\n",
      "8330 Training Loss: 0.001155021833255887 Validation Loss: 0.0023071174509823322\n",
      "8331 Training Loss: 0.0011193982791155577 Validation Loss: 0.0022681807167828083\n",
      "8332 Training Loss: 0.001013904926367104 Validation Loss: 0.002253992483019829\n",
      "8333 Training Loss: 0.0011830860748887062 Validation Loss: 0.0022592367604374886\n",
      "8334 Training Loss: 0.001087429467588663 Validation Loss: 0.0022691835183650255\n",
      "8335 Training Loss: 0.001463084714487195 Validation Loss: 0.002301344880834222\n",
      "8336 Training Loss: 0.0011282769264653325 Validation Loss: 0.002309114206582308\n",
      "8337 Training Loss: 0.001337019493803382 Validation Loss: 0.0023113915231078863\n",
      "8338 Training Loss: 0.001059680012986064 Validation Loss: 0.0023195056710392237\n",
      "8339 Training Loss: 0.00104132026899606 Validation Loss: 0.0023356331512331963\n",
      "8340 Training Loss: 0.0011522448621690273 Validation Loss: 0.002334202639758587\n",
      "8341 Training Loss: 0.0018309527076780796 Validation Loss: 0.002357599325478077\n",
      "8342 Training Loss: 0.0010640358086675406 Validation Loss: 0.002374023664742708\n",
      "8343 Training Loss: 0.0015304451808333397 Validation Loss: 0.0023519659880548716\n",
      "8344 Training Loss: 0.0011264132335782051 Validation Loss: 0.002316000172868371\n",
      "8345 Training Loss: 0.001168225659057498 Validation Loss: 0.0022984188981354237\n",
      "8346 Training Loss: 0.0014133399818092585 Validation Loss: 0.0023154739756137133\n",
      "8347 Training Loss: 0.0011540051782503724 Validation Loss: 0.0022819330915808678\n",
      "8348 Training Loss: 0.0017069759778678417 Validation Loss: 0.002282592933624983\n",
      "8349 Training Loss: 0.0011475635692477226 Validation Loss: 0.002243714639917016\n",
      "8350 Training Loss: 0.0013796580024063587 Validation Loss: 0.0022035427391529083\n",
      "8351 Training Loss: 0.001176678342744708 Validation Loss: 0.0021815230138599873\n",
      "8352 Training Loss: 0.0017318420577794313 Validation Loss: 0.0022002568002790213\n",
      "8353 Training Loss: 0.0010995455086231232 Validation Loss: 0.002249633427709341\n",
      "8354 Training Loss: 0.0011345136445015669 Validation Loss: 0.002362961880862713\n",
      "8355 Training Loss: 0.0010100475046783686 Validation Loss: 0.0024485611356794834\n",
      "8356 Training Loss: 0.0025250480975955725 Validation Loss: 0.0026229042559862137\n",
      "8357 Training Loss: 0.00115370680578053 Validation Loss: 0.0026450480800122023\n",
      "8358 Training Loss: 0.0012940277811139822 Validation Loss: 0.0025014947168529034\n",
      "8359 Training Loss: 0.0009833977092057467 Validation Loss: 0.0023649970535188913\n",
      "8360 Training Loss: 0.0010568283032625914 Validation Loss: 0.0022888644598424435\n",
      "8361 Training Loss: 0.001079688547179103 Validation Loss: 0.0022381364833563566\n",
      "8362 Training Loss: 0.0030463594011962414 Validation Loss: 0.0022875298745930195\n",
      "8363 Training Loss: 0.0020052760373800993 Validation Loss: 0.002485069911926985\n",
      "8364 Training Loss: 0.00186553702224046 Validation Loss: 0.00268055428750813\n",
      "8365 Training Loss: 0.0013965056277811527 Validation Loss: 0.0026858001947402954\n",
      "8366 Training Loss: 0.0017574348021298647 Validation Loss: 0.002543022856116295\n",
      "8367 Training Loss: 0.0012494882103055716 Validation Loss: 0.0024339063093066216\n",
      "8368 Training Loss: 0.0011712056584656239 Validation Loss: 0.0023575059603899717\n",
      "8369 Training Loss: 0.0010038630571216345 Validation Loss: 0.0023496029898524284\n",
      "8370 Training Loss: 0.0011040405370295048 Validation Loss: 0.0023534272331744432\n",
      "8371 Training Loss: 0.001385396346449852 Validation Loss: 0.0023676869459450245\n",
      "8372 Training Loss: 0.0010944015812128782 Validation Loss: 0.0024231981951743364\n",
      "8373 Training Loss: 0.0009718602523207664 Validation Loss: 0.0025393893010914326\n",
      "8374 Training Loss: 0.001159680774435401 Validation Loss: 0.0026773284189403057\n",
      "8375 Training Loss: 0.0012574180727824569 Validation Loss: 0.0026495170313864946\n",
      "8376 Training Loss: 0.0012854293454438448 Validation Loss: 0.0026222295127809048\n",
      "8377 Training Loss: 0.001119422260671854 Validation Loss: 0.0025046817027032375\n",
      "8378 Training Loss: 0.001092114020138979 Validation Loss: 0.002390253823250532\n",
      "8379 Training Loss: 0.0016739813145250082 Validation Loss: 0.0023064841516315937\n",
      "8380 Training Loss: 0.0012750159949064255 Validation Loss: 0.0022576143965125084\n",
      "8381 Training Loss: 0.001145398709923029 Validation Loss: 0.002218619454652071\n",
      "8382 Training Loss: 0.0018652344588190317 Validation Loss: 0.0022206997964531183\n",
      "8383 Training Loss: 0.0010186939034610987 Validation Loss: 0.0022797773126512766\n",
      "8384 Training Loss: 0.001106772804632783 Validation Loss: 0.0023687684442847967\n",
      "8385 Training Loss: 0.0013814663980156183 Validation Loss: 0.0024517078418284655\n",
      "8386 Training Loss: 0.0010916853789240122 Validation Loss: 0.0024473052471876144\n",
      "8387 Training Loss: 0.0010269705671817064 Validation Loss: 0.002372146351262927\n",
      "8388 Training Loss: 0.0010272020008414984 Validation Loss: 0.0023014952894300222\n",
      "8389 Training Loss: 0.0017342744395136833 Validation Loss: 0.0023100438993424177\n",
      "8390 Training Loss: 0.0011441619135439396 Validation Loss: 0.002322491491213441\n",
      "8391 Training Loss: 0.000993206980638206 Validation Loss: 0.0023556523956358433\n",
      "8392 Training Loss: 0.0011449167504906654 Validation Loss: 0.002381101716309786\n",
      "8393 Training Loss: 0.0011525817681103945 Validation Loss: 0.002439031144604087\n",
      "8394 Training Loss: 0.0014664443442597985 Validation Loss: 0.0024314261972904205\n",
      "8395 Training Loss: 0.0011120926355943084 Validation Loss: 0.0023949232418090105\n",
      "8396 Training Loss: 0.0011929792817682028 Validation Loss: 0.002359720878303051\n",
      "8397 Training Loss: 0.0010379813611507416 Validation Loss: 0.002301881555467844\n",
      "8398 Training Loss: 0.0011766892857849598 Validation Loss: 0.002213375875726342\n",
      "8399 Training Loss: 0.0010476462775841355 Validation Loss: 0.0021492475643754005\n",
      "8400 Training Loss: 0.0019512646831572056 Validation Loss: 0.002164188539609313\n",
      "8401 Training Loss: 0.0017866373527795076 Validation Loss: 0.002268960466608405\n",
      "8402 Training Loss: 0.0011192611418664455 Validation Loss: 0.002391456626355648\n",
      "8403 Training Loss: 0.0011131332721561193 Validation Loss: 0.002442382276058197\n",
      "8404 Training Loss: 0.0009633558802306652 Validation Loss: 0.0024455038364976645\n",
      "8405 Training Loss: 0.002489721868187189 Validation Loss: 0.002581120003014803\n",
      "8406 Training Loss: 0.0010460782796144485 Validation Loss: 0.0026631171349436045\n",
      "8407 Training Loss: 0.0013114798348397017 Validation Loss: 0.0027682017534971237\n",
      "8408 Training Loss: 0.0016547271516174078 Validation Loss: 0.002790517406538129\n",
      "8409 Training Loss: 0.001249768421985209 Validation Loss: 0.002782220719382167\n",
      "8410 Training Loss: 0.0010783779434859753 Validation Loss: 0.002731826389208436\n",
      "8411 Training Loss: 0.001821066252887249 Validation Loss: 0.0026932586915791035\n",
      "8412 Training Loss: 0.002654942451044917 Validation Loss: 0.0028744840528815985\n",
      "8413 Training Loss: 0.0011777118779718876 Validation Loss: 0.0030443756841123104\n",
      "8414 Training Loss: 0.001503829611465335 Validation Loss: 0.003030361607670784\n",
      "8415 Training Loss: 0.0014039275702089071 Validation Loss: 0.002777157351374626\n",
      "8416 Training Loss: 0.0019387585343793035 Validation Loss: 0.0026558544486761093\n",
      "8417 Training Loss: 0.001673240214586258 Validation Loss: 0.0025273633655160666\n",
      "8418 Training Loss: 0.0012146418448537588 Validation Loss: 0.002430408261716366\n",
      "8419 Training Loss: 0.0011077134404331446 Validation Loss: 0.002363446867093444\n",
      "8420 Training Loss: 0.0011380952782928944 Validation Loss: 0.002340809442102909\n",
      "8421 Training Loss: 0.001090765930712223 Validation Loss: 0.0023613437078893185\n",
      "8422 Training Loss: 0.0014046331634745002 Validation Loss: 0.002519020112231374\n",
      "8423 Training Loss: 0.0013125112745910883 Validation Loss: 0.0026902565732598305\n",
      "8424 Training Loss: 0.001251690206117928 Validation Loss: 0.0026971600018441677\n",
      "8425 Training Loss: 0.0015862856525927782 Validation Loss: 0.0027182884514331818\n",
      "8426 Training Loss: 0.0034235960338264704 Validation Loss: 0.002740684198215604\n",
      "8427 Training Loss: 0.0010448028333485126 Validation Loss: 0.0026660659350454807\n",
      "8428 Training Loss: 0.0011000602971762419 Validation Loss: 0.002517940243706107\n",
      "8429 Training Loss: 0.0012654130114242435 Validation Loss: 0.0023782411590218544\n",
      "8430 Training Loss: 0.0011425968259572983 Validation Loss: 0.0023009730502963066\n",
      "8431 Training Loss: 0.0011687679216265678 Validation Loss: 0.0022802711464464664\n",
      "8432 Training Loss: 0.0011986999306827784 Validation Loss: 0.0022862411569803953\n",
      "8433 Training Loss: 0.001934833824634552 Validation Loss: 0.0023948282469063997\n",
      "8434 Training Loss: 0.0010156865464523435 Validation Loss: 0.002560830907896161\n",
      "8435 Training Loss: 0.001331877545453608 Validation Loss: 0.0026925888378173113\n",
      "8436 Training Loss: 0.0011245820205658674 Validation Loss: 0.002668642206117511\n",
      "8437 Training Loss: 0.0013151973253116012 Validation Loss: 0.0025100121274590492\n",
      "8438 Training Loss: 0.001856455230154097 Validation Loss: 0.0024490072391927242\n",
      "8439 Training Loss: 0.001547546125948429 Validation Loss: 0.00242883013561368\n",
      "8440 Training Loss: 0.0012797270901501179 Validation Loss: 0.002389407716691494\n",
      "8441 Training Loss: 0.0010695226956158876 Validation Loss: 0.002365616150200367\n",
      "8442 Training Loss: 0.0011279131285846233 Validation Loss: 0.002399719087406993\n",
      "8443 Training Loss: 0.0010433108545839787 Validation Loss: 0.002453440800309181\n",
      "8444 Training Loss: 0.0010906733805313706 Validation Loss: 0.002585191046819091\n",
      "8445 Training Loss: 0.0011535503435879946 Validation Loss: 0.0026804974768310785\n",
      "8446 Training Loss: 0.0010133595205843449 Validation Loss: 0.002676467876881361\n",
      "8447 Training Loss: 0.0013600121019408107 Validation Loss: 0.002603301778435707\n",
      "8448 Training Loss: 0.0010995331685990095 Validation Loss: 0.0024682101793587208\n",
      "8449 Training Loss: 0.00112541439011693 Validation Loss: 0.0023573138751089573\n",
      "8450 Training Loss: 0.001007281825877726 Validation Loss: 0.002316064201295376\n",
      "8451 Training Loss: 0.0013202750124037266 Validation Loss: 0.002324278699234128\n",
      "8452 Training Loss: 0.0011152916122227907 Validation Loss: 0.002375399461016059\n",
      "8453 Training Loss: 0.001716875471174717 Validation Loss: 0.002567015355452895\n",
      "8454 Training Loss: 0.0014613321982324123 Validation Loss: 0.0027726138941943645\n",
      "8455 Training Loss: 0.0013347580097615719 Validation Loss: 0.00289919413626194\n",
      "8456 Training Loss: 0.001341349445283413 Validation Loss: 0.0029486254788935184\n",
      "8457 Training Loss: 0.0009874891256913543 Validation Loss: 0.0029244115576148033\n",
      "8458 Training Loss: 0.0012041064910590649 Validation Loss: 0.0027671055868268013\n",
      "8459 Training Loss: 0.0012948845978826284 Validation Loss: 0.0027187238447368145\n",
      "8460 Training Loss: 0.001211037510074675 Validation Loss: 0.0026359115727245808\n",
      "8461 Training Loss: 0.0010250136256217957 Validation Loss: 0.00258281035348773\n",
      "8462 Training Loss: 0.001365420874208212 Validation Loss: 0.002482773968949914\n",
      "8463 Training Loss: 0.001071127480827272 Validation Loss: 0.002386522712185979\n",
      "8464 Training Loss: 0.0011271823896095157 Validation Loss: 0.0022962489165365696\n",
      "8465 Training Loss: 0.0013352485839277506 Validation Loss: 0.0021955124102532864\n",
      "8466 Training Loss: 0.0011197634739801288 Validation Loss: 0.0021562641486525536\n",
      "8467 Training Loss: 0.0010039105545729399 Validation Loss: 0.0021456326358020306\n",
      "8468 Training Loss: 0.0013277872931212187 Validation Loss: 0.002141444943845272\n",
      "8469 Training Loss: 0.001424579182639718 Validation Loss: 0.002147361868992448\n",
      "8470 Training Loss: 0.0017047664150595665 Validation Loss: 0.002213009400293231\n",
      "8471 Training Loss: 0.001185346394777298 Validation Loss: 0.0022761370055377483\n",
      "8472 Training Loss: 0.0011925011640414596 Validation Loss: 0.0023569364566355944\n",
      "8473 Training Loss: 0.0012374937068670988 Validation Loss: 0.0023628228809684515\n",
      "8474 Training Loss: 0.0012470914516597986 Validation Loss: 0.0023172753863036633\n",
      "8475 Training Loss: 0.0009478593128733337 Validation Loss: 0.0022688554599881172\n",
      "8476 Training Loss: 0.0012885276228189468 Validation Loss: 0.00220677861943841\n",
      "8477 Training Loss: 0.001782246632501483 Validation Loss: 0.002191989915445447\n",
      "8478 Training Loss: 0.0009315491188317537 Validation Loss: 0.002214613137766719\n",
      "8479 Training Loss: 0.0011994910892099142 Validation Loss: 0.002267681062221527\n",
      "8480 Training Loss: 0.0010036700405180454 Validation Loss: 0.0022775514516979456\n",
      "8481 Training Loss: 0.0010848181555047631 Validation Loss: 0.0022240160033106804\n",
      "8482 Training Loss: 0.001076046610251069 Validation Loss: 0.0021670556161552668\n",
      "8483 Training Loss: 0.001269710948690772 Validation Loss: 0.0021013112273067236\n",
      "8484 Training Loss: 0.0011620125733315945 Validation Loss: 0.0020602380391210318\n",
      "8485 Training Loss: 0.0010704846354201436 Validation Loss: 0.0020327193196862936\n",
      "8486 Training Loss: 0.0011941788252443075 Validation Loss: 0.002024389337748289\n",
      "8487 Training Loss: 0.001421181601472199 Validation Loss: 0.002092301845550537\n",
      "8488 Training Loss: 0.0009817247046157718 Validation Loss: 0.002190199214965105\n",
      "8489 Training Loss: 0.0009919307194650173 Validation Loss: 0.0022634188644587994\n",
      "8490 Training Loss: 0.000973345129750669 Validation Loss: 0.0022496161982417107\n",
      "8491 Training Loss: 0.0010051534045487642 Validation Loss: 0.002187559148296714\n",
      "8492 Training Loss: 0.000979770440608263 Validation Loss: 0.0021258515771478415\n",
      "8493 Training Loss: 0.0010709157213568687 Validation Loss: 0.0020731077529489994\n",
      "8494 Training Loss: 0.0011720196343958378 Validation Loss: 0.00206162640824914\n",
      "8495 Training Loss: 0.0012798593379557133 Validation Loss: 0.0020848028361797333\n",
      "8496 Training Loss: 0.0011441161623224616 Validation Loss: 0.0021473648957908154\n",
      "8497 Training Loss: 0.0008717260789126158 Validation Loss: 0.0022200262174010277\n",
      "8498 Training Loss: 0.001199974212795496 Validation Loss: 0.0022578835487365723\n",
      "8499 Training Loss: 0.0011150218779221177 Validation Loss: 0.0022157293278723955\n",
      "8500 Training Loss: 0.0011531987693160772 Validation Loss: 0.0022277969401329756\n",
      "8501 Training Loss: 0.0011426768032833934 Validation Loss: 0.0022130627185106277\n",
      "8502 Training Loss: 0.0013615055941045284 Validation Loss: 0.0022102983202785254\n",
      "8503 Training Loss: 0.0012409724295139313 Validation Loss: 0.002207475947216153\n",
      "8504 Training Loss: 0.001424045069143176 Validation Loss: 0.0021928157657384872\n",
      "8505 Training Loss: 0.0010737248230725527 Validation Loss: 0.002133408095687628\n",
      "8506 Training Loss: 0.0011175873223692179 Validation Loss: 0.0020837620832026005\n",
      "8507 Training Loss: 0.0010246073361486197 Validation Loss: 0.002037505153566599\n",
      "8508 Training Loss: 0.002159488620236516 Validation Loss: 0.0020938722882419825\n",
      "8509 Training Loss: 0.0010182005353271961 Validation Loss: 0.002161144046112895\n",
      "8510 Training Loss: 0.0009770046453922987 Validation Loss: 0.0021962595637887716\n",
      "8511 Training Loss: 0.001527163665741682 Validation Loss: 0.0021858958061784506\n",
      "8512 Training Loss: 0.0011498132953420281 Validation Loss: 0.002109514782205224\n",
      "8513 Training Loss: 0.0009774476056918502 Validation Loss: 0.0020462553948163986\n",
      "8514 Training Loss: 0.0009242823580279946 Validation Loss: 0.002025752095505595\n",
      "8515 Training Loss: 0.0019606510177254677 Validation Loss: 0.002031793352216482\n",
      "8516 Training Loss: 0.0009289482259191573 Validation Loss: 0.0020682422909885645\n",
      "8517 Training Loss: 0.0012919290456920862 Validation Loss: 0.0021457341499626637\n",
      "8518 Training Loss: 0.0012782324338331819 Validation Loss: 0.0022351047955453396\n",
      "8519 Training Loss: 0.0009728584554977715 Validation Loss: 0.002246675081551075\n",
      "8520 Training Loss: 0.0010577160865068436 Validation Loss: 0.0021928586065769196\n",
      "8521 Training Loss: 0.0010991485323756933 Validation Loss: 0.0021015098318457603\n",
      "8522 Training Loss: 0.0009988171514123678 Validation Loss: 0.002052904339507222\n",
      "8523 Training Loss: 0.0012664301320910454 Validation Loss: 0.0020539776887744665\n",
      "8524 Training Loss: 0.0010188115993514657 Validation Loss: 0.0020946201402693987\n",
      "8525 Training Loss: 0.0008554699597880244 Validation Loss: 0.002147560939192772\n",
      "8526 Training Loss: 0.0009365518344566226 Validation Loss: 0.0022168096620589495\n",
      "8527 Training Loss: 0.0012602376518771052 Validation Loss: 0.0022185128182172775\n",
      "8528 Training Loss: 0.0009240194340236485 Validation Loss: 0.0021957221906632185\n",
      "8529 Training Loss: 0.000988196348771453 Validation Loss: 0.002160080010071397\n",
      "8530 Training Loss: 0.0015286949928849936 Validation Loss: 0.002117317635565996\n",
      "8531 Training Loss: 0.0011188548523932695 Validation Loss: 0.0020923372358083725\n",
      "8532 Training Loss: 0.001024424098432064 Validation Loss: 0.0020664003677666187\n",
      "8533 Training Loss: 0.0011019014054909348 Validation Loss: 0.0020639419090002775\n",
      "8534 Training Loss: 0.001012942986562848 Validation Loss: 0.0020752856507897377\n",
      "8535 Training Loss: 0.0010681074345484376 Validation Loss: 0.0020846130792051554\n",
      "8536 Training Loss: 0.0009590012487024069 Validation Loss: 0.002082384657114744\n",
      "8537 Training Loss: 0.0009696866618469357 Validation Loss: 0.0020600110292434692\n",
      "8538 Training Loss: 0.0009247221751138568 Validation Loss: 0.0020375370513647795\n",
      "8539 Training Loss: 0.0010155353229492903 Validation Loss: 0.0020117347594350576\n",
      "8540 Training Loss: 0.000942047918215394 Validation Loss: 0.001996567938476801\n",
      "8541 Training Loss: 0.0009311030153185129 Validation Loss: 0.0019888700917363167\n",
      "8542 Training Loss: 0.0010742491576820612 Validation Loss: 0.001990359043702483\n",
      "8543 Training Loss: 0.0009706873679533601 Validation Loss: 0.0019864302594214678\n",
      "8544 Training Loss: 0.001146944472566247 Validation Loss: 0.0019749277271330357\n",
      "8545 Training Loss: 0.0011432202300056815 Validation Loss: 0.001999255968257785\n",
      "8546 Training Loss: 0.0010150526650249958 Validation Loss: 0.0020154081284999847\n",
      "8547 Training Loss: 0.0008831340819597244 Validation Loss: 0.0020385158713907003\n",
      "8548 Training Loss: 0.001076115993782878 Validation Loss: 0.002032320713624358\n",
      "8549 Training Loss: 0.0009340501273982227 Validation Loss: 0.002025130670517683\n",
      "8550 Training Loss: 0.0010712782386690378 Validation Loss: 0.0020532323978841305\n",
      "8551 Training Loss: 0.0010662126587703824 Validation Loss: 0.002061569830402732\n",
      "8552 Training Loss: 0.0009489604271948338 Validation Loss: 0.0021033207885921\n",
      "8553 Training Loss: 0.001930174883455038 Validation Loss: 0.002230189274996519\n",
      "8554 Training Loss: 0.001830432447604835 Validation Loss: 0.0024322348181158304\n",
      "8555 Training Loss: 0.0012054898543283343 Validation Loss: 0.002507224213331938\n",
      "8556 Training Loss: 0.001136909006163478 Validation Loss: 0.002412682631984353\n",
      "8557 Training Loss: 0.0011442701797932386 Validation Loss: 0.002207572106271982\n",
      "8558 Training Loss: 0.0021297968924045563 Validation Loss: 0.0021334446500986814\n",
      "8559 Training Loss: 0.00094475073274225 Validation Loss: 0.0021077056881040335\n",
      "8560 Training Loss: 0.0011496790684759617 Validation Loss: 0.0021454193629324436\n",
      "8561 Training Loss: 0.0014643745962530375 Validation Loss: 0.002247020835056901\n",
      "8562 Training Loss: 0.0009977646404877305 Validation Loss: 0.0023365318775177\n",
      "8563 Training Loss: 0.0014862737152725458 Validation Loss: 0.0024706630501896143\n",
      "8564 Training Loss: 0.0010618926025927067 Validation Loss: 0.0024786111898720264\n",
      "8565 Training Loss: 0.0011683395132422447 Validation Loss: 0.002338619437068701\n",
      "8566 Training Loss: 0.0009478188585489988 Validation Loss: 0.0022235820069909096\n",
      "8567 Training Loss: 0.0012288389261811972 Validation Loss: 0.0021458931732922792\n",
      "8568 Training Loss: 0.00104661681689322 Validation Loss: 0.0020822130609303713\n",
      "8569 Training Loss: 0.0009534216951578856 Validation Loss: 0.00204135081730783\n",
      "8570 Training Loss: 0.0010362997418269515 Validation Loss: 0.00201025209389627\n",
      "8571 Training Loss: 0.0009477452840656042 Validation Loss: 0.002007352886721492\n",
      "8572 Training Loss: 0.0011172585655003786 Validation Loss: 0.002031130250543356\n",
      "8573 Training Loss: 0.0010417441371828318 Validation Loss: 0.0020409312564879656\n",
      "8574 Training Loss: 0.0010684317676350474 Validation Loss: 0.0020350604318082333\n",
      "8575 Training Loss: 0.0010133247124031186 Validation Loss: 0.0019985968247056007\n",
      "8576 Training Loss: 0.001219838741235435 Validation Loss: 0.0019833550322800875\n",
      "8577 Training Loss: 0.001486009219661355 Validation Loss: 0.0019865622743964195\n",
      "8578 Training Loss: 0.001715686172246933 Validation Loss: 0.0020429077558219433\n",
      "8579 Training Loss: 0.0018609367543831468 Validation Loss: 0.002144032157957554\n",
      "8580 Training Loss: 0.0008783193770796061 Validation Loss: 0.0022256439551711082\n",
      "8581 Training Loss: 0.0009071988752111793 Validation Loss: 0.002229957841336727\n",
      "8582 Training Loss: 0.0009129386162385345 Validation Loss: 0.002213258296251297\n",
      "8583 Training Loss: 0.0011852012248709798 Validation Loss: 0.0021796131040900946\n",
      "8584 Training Loss: 0.0010218502720817924 Validation Loss: 0.0021390242036432028\n",
      "8585 Training Loss: 0.000989326392300427 Validation Loss: 0.0021208550315350294\n",
      "8586 Training Loss: 0.0009603923535905778 Validation Loss: 0.0021203928627073765\n",
      "8587 Training Loss: 0.0013669608160853386 Validation Loss: 0.0022407248616218567\n",
      "8588 Training Loss: 0.001485245069488883 Validation Loss: 0.002374594798311591\n",
      "8589 Training Loss: 0.0010311567457392812 Validation Loss: 0.002485176082700491\n",
      "8590 Training Loss: 0.0009483537869527936 Validation Loss: 0.0024628504179418087\n",
      "8591 Training Loss: 0.0009581672493368387 Validation Loss: 0.002338943537324667\n",
      "8592 Training Loss: 0.0010945219546556473 Validation Loss: 0.002179146045818925\n",
      "8593 Training Loss: 0.0012332940241321921 Validation Loss: 0.0021092144306749105\n",
      "8594 Training Loss: 0.0009655865142121911 Validation Loss: 0.0020804463420063257\n",
      "8595 Training Loss: 0.0011498116655275226 Validation Loss: 0.00204887124709785\n",
      "8596 Training Loss: 0.0010222697164863348 Validation Loss: 0.002072020899504423\n",
      "8597 Training Loss: 0.0020435152109712362 Validation Loss: 0.0022343990858644247\n",
      "8598 Training Loss: 0.0008956853416748345 Validation Loss: 0.0023813543375581503\n",
      "8599 Training Loss: 0.0012792431516572833 Validation Loss: 0.0023286768700927496\n",
      "8600 Training Loss: 0.0009518645238131285 Validation Loss: 0.0021870045457035303\n",
      "8601 Training Loss: 0.0011554565280675888 Validation Loss: 0.002058864338323474\n",
      "8602 Training Loss: 0.0011551930801942945 Validation Loss: 0.002013505669310689\n",
      "8603 Training Loss: 0.000975635542999953 Validation Loss: 0.001990389311686158\n",
      "8604 Training Loss: 0.0012599261244758964 Validation Loss: 0.001997225219383836\n",
      "8605 Training Loss: 0.001320499461144209 Validation Loss: 0.0020727752707898617\n",
      "8606 Training Loss: 0.0010108144488185644 Validation Loss: 0.002172109205275774\n",
      "8607 Training Loss: 0.0011993309017270803 Validation Loss: 0.0021998814772814512\n",
      "8608 Training Loss: 0.0009349656756967306 Validation Loss: 0.0021589326206594706\n",
      "8609 Training Loss: 0.0022716792300343513 Validation Loss: 0.002225651405751705\n",
      "8610 Training Loss: 0.0010080246720463037 Validation Loss: 0.002264467068016529\n",
      "8611 Training Loss: 0.001248250948265195 Validation Loss: 0.0022852234542369843\n",
      "8612 Training Loss: 0.0012265268014743924 Validation Loss: 0.002308392431586981\n",
      "8613 Training Loss: 0.0009854977251961827 Validation Loss: 0.0022853189148008823\n",
      "8614 Training Loss: 0.0008971781935542822 Validation Loss: 0.00225897622294724\n",
      "8615 Training Loss: 0.0008639881270937622 Validation Loss: 0.0022459416650235653\n",
      "8616 Training Loss: 0.0011032684706151485 Validation Loss: 0.0022615576162934303\n",
      "8617 Training Loss: 0.0014883518451824784 Validation Loss: 0.0023251993115991354\n",
      "8618 Training Loss: 0.0010179674718528986 Validation Loss: 0.002320375991985202\n",
      "8619 Training Loss: 0.001368607860058546 Validation Loss: 0.0023284670896828175\n",
      "8620 Training Loss: 0.0010068324627354741 Validation Loss: 0.002280882326886058\n",
      "8621 Training Loss: 0.00093619036488235 Validation Loss: 0.0022050761617720127\n",
      "8622 Training Loss: 0.0012747552245855331 Validation Loss: 0.0021687853150069714\n",
      "8623 Training Loss: 0.0009344732388854027 Validation Loss: 0.00214365404099226\n",
      "8624 Training Loss: 0.0012252862798050046 Validation Loss: 0.0021368139423429966\n",
      "8625 Training Loss: 0.0010516056790947914 Validation Loss: 0.0021037706173956394\n",
      "8626 Training Loss: 0.0009590131230652332 Validation Loss: 0.0020731815602630377\n",
      "8627 Training Loss: 0.0009221253567375243 Validation Loss: 0.0020644234027713537\n",
      "8628 Training Loss: 0.0010781509336084127 Validation Loss: 0.0020902492105960846\n",
      "8629 Training Loss: 0.0009187400573864579 Validation Loss: 0.0021119266748428345\n",
      "8630 Training Loss: 0.000918959965929389 Validation Loss: 0.0021244571544229984\n",
      "8631 Training Loss: 0.0009860498830676079 Validation Loss: 0.0021142554469406605\n",
      "8632 Training Loss: 0.0023176090326160192 Validation Loss: 0.002142830053344369\n",
      "8633 Training Loss: 0.000981247634626925 Validation Loss: 0.002186167985200882\n",
      "8634 Training Loss: 0.0010163048282265663 Validation Loss: 0.0021793728228658438\n",
      "8635 Training Loss: 0.0010682441061362624 Validation Loss: 0.002188971731811762\n",
      "8636 Training Loss: 0.001461525447666645 Validation Loss: 0.0022428815718740225\n",
      "8637 Training Loss: 0.0011950978077948093 Validation Loss: 0.002173386514186859\n",
      "8638 Training Loss: 0.0009706158307380974 Validation Loss: 0.002097155200317502\n",
      "8639 Training Loss: 0.0008547436445951462 Validation Loss: 0.0020469503942877054\n",
      "8640 Training Loss: 0.001001253491267562 Validation Loss: 0.0020047659054398537\n",
      "8641 Training Loss: 0.0010231495834887028 Validation Loss: 0.00202080886811018\n",
      "8642 Training Loss: 0.0010100995423272252 Validation Loss: 0.002078947378322482\n",
      "8643 Training Loss: 0.0008976479293778539 Validation Loss: 0.0021454046946018934\n",
      "8644 Training Loss: 0.0009745192946866155 Validation Loss: 0.0021858331747353077\n",
      "8645 Training Loss: 0.0009193209698423743 Validation Loss: 0.0022348174825310707\n",
      "8646 Training Loss: 0.0009945217752829194 Validation Loss: 0.002212581457570195\n",
      "8647 Training Loss: 0.0010071394499391317 Validation Loss: 0.00215513096190989\n",
      "8648 Training Loss: 0.004407593514770269 Validation Loss: 0.0023556798696517944\n",
      "8649 Training Loss: 0.000930680544115603 Validation Loss: 0.002508762525394559\n",
      "8650 Training Loss: 0.0010732340160757303 Validation Loss: 0.0024788787122815847\n",
      "8651 Training Loss: 0.0011793304001912475 Validation Loss: 0.002275297651067376\n",
      "8652 Training Loss: 0.0009888834320008755 Validation Loss: 0.002082281280308962\n",
      "8653 Training Loss: 0.0012074003461748362 Validation Loss: 0.0019909203983843327\n",
      "8654 Training Loss: 0.0009180563502013683 Validation Loss: 0.0019672720227390528\n",
      "8655 Training Loss: 0.0013350825756788254 Validation Loss: 0.001982961082831025\n",
      "8656 Training Loss: 0.001088474877178669 Validation Loss: 0.002030308824032545\n",
      "8657 Training Loss: 0.0008663436165079474 Validation Loss: 0.002128240652382374\n",
      "8658 Training Loss: 0.001088021555915475 Validation Loss: 0.0022599580697715282\n",
      "8659 Training Loss: 0.0009984426433220506 Validation Loss: 0.002308322349563241\n",
      "8660 Training Loss: 0.0010440220357850194 Validation Loss: 0.0022223331034183502\n",
      "8661 Training Loss: 0.001106408191844821 Validation Loss: 0.0020647484343498945\n",
      "8662 Training Loss: 0.001032013213261962 Validation Loss: 0.0019898104947060347\n",
      "8663 Training Loss: 0.0016830275999382138 Validation Loss: 0.0019785352051258087\n",
      "8664 Training Loss: 0.001152855227701366 Validation Loss: 0.0019584528636187315\n",
      "8665 Training Loss: 0.0009474365506321192 Validation Loss: 0.001977086067199707\n",
      "8666 Training Loss: 0.0008405732223764062 Validation Loss: 0.002005911897867918\n",
      "8667 Training Loss: 0.000996312010101974 Validation Loss: 0.001991488505154848\n",
      "8668 Training Loss: 0.001073541701771319 Validation Loss: 0.0019655395299196243\n",
      "8669 Training Loss: 0.0009333520429208875 Validation Loss: 0.001928440062329173\n",
      "8670 Training Loss: 0.0009461149456910789 Validation Loss: 0.0019071497954428196\n",
      "8671 Training Loss: 0.00086464814376086 Validation Loss: 0.0019090670393779874\n",
      "8672 Training Loss: 0.0012222679797559977 Validation Loss: 0.0019366202177479863\n",
      "8673 Training Loss: 0.0008774837478995323 Validation Loss: 0.001984222326427698\n",
      "8674 Training Loss: 0.0009824058506637812 Validation Loss: 0.0020581914577633142\n",
      "8675 Training Loss: 0.0018596237059682608 Validation Loss: 0.0022214099299162626\n",
      "8676 Training Loss: 0.0009372615022584796 Validation Loss: 0.0023330706171691418\n",
      "8677 Training Loss: 0.0011147825280204415 Validation Loss: 0.0022507021203637123\n",
      "8678 Training Loss: 0.0008730603149160743 Validation Loss: 0.002147690625861287\n",
      "8679 Training Loss: 0.0010490301065146923 Validation Loss: 0.002025624504312873\n",
      "8680 Training Loss: 0.0009870874928310513 Validation Loss: 0.001962529495358467\n",
      "8681 Training Loss: 0.001445326954126358 Validation Loss: 0.0019420197932049632\n",
      "8682 Training Loss: 0.0008434102637693286 Validation Loss: 0.0019415509887039661\n",
      "8683 Training Loss: 0.000997872673906386 Validation Loss: 0.0019981772638857365\n",
      "8684 Training Loss: 0.0011922596022486687 Validation Loss: 0.002002541907131672\n",
      "8685 Training Loss: 0.0011954931542277336 Validation Loss: 0.0020211858209222555\n",
      "8686 Training Loss: 0.000982261961326003 Validation Loss: 0.001974168000742793\n",
      "8687 Training Loss: 0.000910059898160398 Validation Loss: 0.0019200702663511038\n",
      "8688 Training Loss: 0.002061558421701193 Validation Loss: 0.001972696278244257\n",
      "8689 Training Loss: 0.001028621569275856 Validation Loss: 0.002027001464739442\n",
      "8690 Training Loss: 0.000871369382366538 Validation Loss: 0.0020766984671354294\n",
      "8691 Training Loss: 0.0010406699730083346 Validation Loss: 0.0021119534503668547\n",
      "8692 Training Loss: 0.0010335789993405342 Validation Loss: 0.0021234573796391487\n",
      "8693 Training Loss: 0.001270585460588336 Validation Loss: 0.0021243419032543898\n",
      "8694 Training Loss: 0.0009817610261961818 Validation Loss: 0.0020737359300255775\n",
      "8695 Training Loss: 0.001480725361034274 Validation Loss: 0.0021208496764302254\n",
      "8696 Training Loss: 0.0011631380766630173 Validation Loss: 0.002067350083962083\n",
      "8697 Training Loss: 0.0009986142395064235 Validation Loss: 0.001978556625545025\n",
      "8698 Training Loss: 0.0010290310019627213 Validation Loss: 0.0019420081516727805\n",
      "8699 Training Loss: 0.001546488725580275 Validation Loss: 0.0019757759291678667\n",
      "8700 Training Loss: 0.0010810823878273368 Validation Loss: 0.002050691284239292\n",
      "8701 Training Loss: 0.0010623050620779395 Validation Loss: 0.0021657950710505247\n",
      "8702 Training Loss: 0.001179330050945282 Validation Loss: 0.002190222265198827\n",
      "8703 Training Loss: 0.0009192338911816478 Validation Loss: 0.002171926200389862\n",
      "8704 Training Loss: 0.000887132715433836 Validation Loss: 0.002131393179297447\n",
      "8705 Training Loss: 0.0017306730151176453 Validation Loss: 0.00217501912266016\n",
      "8706 Training Loss: 0.0009064648766070604 Validation Loss: 0.002204522956162691\n",
      "8707 Training Loss: 0.0009577573509886861 Validation Loss: 0.002181139774620533\n",
      "8708 Training Loss: 0.0008997119148261845 Validation Loss: 0.002134655835106969\n",
      "8709 Training Loss: 0.001574047259055078 Validation Loss: 0.0021494117099791765\n",
      "8710 Training Loss: 0.0012814674992114305 Validation Loss: 0.00213986961171031\n",
      "8711 Training Loss: 0.00086285884026438 Validation Loss: 0.0021000774577260017\n",
      "8712 Training Loss: 0.000989703112281859 Validation Loss: 0.00205611577257514\n",
      "8713 Training Loss: 0.0009172670543193817 Validation Loss: 0.002012657467275858\n",
      "8714 Training Loss: 0.000986365950666368 Validation Loss: 0.00197742716409266\n",
      "8715 Training Loss: 0.0009344558930024505 Validation Loss: 0.001968089258298278\n",
      "8716 Training Loss: 0.0010108519345521927 Validation Loss: 0.0019582926761358976\n",
      "8717 Training Loss: 0.0008255923166871071 Validation Loss: 0.0019714797381311655\n",
      "8718 Training Loss: 0.0010911559220403433 Validation Loss: 0.0020167501643300056\n",
      "8719 Training Loss: 0.0009257706115022302 Validation Loss: 0.0021172156557440758\n",
      "8720 Training Loss: 0.0009241756633855402 Validation Loss: 0.0021821509581059217\n",
      "8721 Training Loss: 0.0009922321187332273 Validation Loss: 0.002173857530578971\n",
      "8722 Training Loss: 0.0008968517649918795 Validation Loss: 0.00207716366276145\n",
      "8723 Training Loss: 0.0008186172926798463 Validation Loss: 0.0019988096319139004\n",
      "8724 Training Loss: 0.0008664289489388466 Validation Loss: 0.0019555578473955393\n",
      "8725 Training Loss: 0.0009637178736738861 Validation Loss: 0.0019352005328983068\n",
      "8726 Training Loss: 0.000948225730098784 Validation Loss: 0.0019262530840933323\n",
      "8727 Training Loss: 0.0009604173246771097 Validation Loss: 0.001960122724995017\n",
      "8728 Training Loss: 0.001018337905406952 Validation Loss: 0.001984464703127742\n",
      "8729 Training Loss: 0.0010264783632010221 Validation Loss: 0.0020449995063245296\n",
      "8730 Training Loss: 0.001390612917020917 Validation Loss: 0.002099247183650732\n",
      "8731 Training Loss: 0.0009348104358650744 Validation Loss: 0.002093511400744319\n",
      "8732 Training Loss: 0.0016486810054630041 Validation Loss: 0.002075986471027136\n",
      "8733 Training Loss: 0.0009032649686560035 Validation Loss: 0.002011957811191678\n",
      "8734 Training Loss: 0.0010865343501791358 Validation Loss: 0.0020126691088080406\n",
      "8735 Training Loss: 0.000988015322946012 Validation Loss: 0.002020519692450762\n",
      "8736 Training Loss: 0.0015659296186640859 Validation Loss: 0.002148814732208848\n",
      "8737 Training Loss: 0.0012955938000231981 Validation Loss: 0.0023652384988963604\n",
      "8738 Training Loss: 0.0011989130871370435 Validation Loss: 0.0025922160129994154\n",
      "8739 Training Loss: 0.0014745895750820637 Validation Loss: 0.002429892309010029\n",
      "8740 Training Loss: 0.001092819613404572 Validation Loss: 0.002112234476953745\n",
      "8741 Training Loss: 0.001012065215036273 Validation Loss: 0.0019314833916723728\n",
      "8742 Training Loss: 0.0018585029756650329 Validation Loss: 0.0018496380653232336\n",
      "8743 Training Loss: 0.0009627995314076543 Validation Loss: 0.001815060735680163\n",
      "8744 Training Loss: 0.0009881387231871486 Validation Loss: 0.001811268157325685\n",
      "8745 Training Loss: 0.000942099082749337 Validation Loss: 0.0018470925278961658\n",
      "8746 Training Loss: 0.0009061628952622414 Validation Loss: 0.0018982342444360256\n",
      "8747 Training Loss: 0.0009756920626387 Validation Loss: 0.0019306869944557548\n",
      "8748 Training Loss: 0.0008855051128193736 Validation Loss: 0.001954572042450309\n",
      "8749 Training Loss: 0.0009308460867032409 Validation Loss: 0.001964262453839183\n",
      "8750 Training Loss: 0.0008829155704006553 Validation Loss: 0.0019806157797574997\n",
      "8751 Training Loss: 0.0009096083231270313 Validation Loss: 0.0019683048594743013\n",
      "8752 Training Loss: 0.0008685896173119545 Validation Loss: 0.0019340573344379663\n",
      "8753 Training Loss: 0.0010218690149486065 Validation Loss: 0.0018980627646669745\n",
      "8754 Training Loss: 0.0014787368709221482 Validation Loss: 0.0019231050973758101\n",
      "8755 Training Loss: 0.0009331995970569551 Validation Loss: 0.001938134664669633\n",
      "8756 Training Loss: 0.0012689144350588322 Validation Loss: 0.0019830423407256603\n",
      "8757 Training Loss: 0.001008203369565308 Validation Loss: 0.0019654096104204655\n",
      "8758 Training Loss: 0.0009383622091263533 Validation Loss: 0.0018863099394366145\n",
      "8759 Training Loss: 0.001121725421398878 Validation Loss: 0.0018537782598286867\n",
      "8760 Training Loss: 0.0008897256338968873 Validation Loss: 0.0018649677513167262\n",
      "8761 Training Loss: 0.0009198745246976614 Validation Loss: 0.0018946932395920157\n",
      "8762 Training Loss: 0.0009216641774401069 Validation Loss: 0.0019347353372722864\n",
      "8763 Training Loss: 0.0010224286234006286 Validation Loss: 0.0020306252408772707\n",
      "8764 Training Loss: 0.0009997233282774687 Validation Loss: 0.002170420251786709\n",
      "8765 Training Loss: 0.001453675446100533 Validation Loss: 0.002286771545186639\n",
      "8766 Training Loss: 0.0010232955683022738 Validation Loss: 0.002319755032658577\n",
      "8767 Training Loss: 0.0019366048509255052 Validation Loss: 0.002249708864837885\n",
      "8768 Training Loss: 0.0009051986271515489 Validation Loss: 0.0020818940829485655\n",
      "8769 Training Loss: 0.000885121407918632 Validation Loss: 0.001960564171895385\n",
      "8770 Training Loss: 0.0009385135490447283 Validation Loss: 0.0018955657724291086\n",
      "8771 Training Loss: 0.0008925158181227744 Validation Loss: 0.0018578933086246252\n",
      "8772 Training Loss: 0.0012212364235892892 Validation Loss: 0.0019167097052559257\n",
      "8773 Training Loss: 0.0007908951956778765 Validation Loss: 0.0020283290650695562\n",
      "8774 Training Loss: 0.000841829227283597 Validation Loss: 0.0021455413661897182\n",
      "8775 Training Loss: 0.0009672286105342209 Validation Loss: 0.0021601011976599693\n",
      "8776 Training Loss: 0.0020852854941040277 Validation Loss: 0.0021965934429317713\n",
      "8777 Training Loss: 0.0008770959684625268 Validation Loss: 0.0021411459892988205\n",
      "8778 Training Loss: 0.001499829231761396 Validation Loss: 0.0021480019204318523\n",
      "8779 Training Loss: 0.0009062498575076461 Validation Loss: 0.002117783296853304\n",
      "8780 Training Loss: 0.0009670255240052938 Validation Loss: 0.0020628736820071936\n",
      "8781 Training Loss: 0.0020952599588781595 Validation Loss: 0.0021276308689266443\n",
      "8782 Training Loss: 0.0010594193590804935 Validation Loss: 0.0021835428196936846\n",
      "8783 Training Loss: 0.0008309471886605024 Validation Loss: 0.0021881861612200737\n",
      "8784 Training Loss: 0.0009762616828083992 Validation Loss: 0.002137822099030018\n",
      "8785 Training Loss: 0.001031216117553413 Validation Loss: 0.00210148049518466\n",
      "8786 Training Loss: 0.0009997027227655053 Validation Loss: 0.0020614638924598694\n",
      "8787 Training Loss: 0.0008164590690284967 Validation Loss: 0.00202626409009099\n",
      "8788 Training Loss: 0.0009439962450414896 Validation Loss: 0.001956589985638857\n",
      "8789 Training Loss: 0.0008933031349442899 Validation Loss: 0.0019294761586934328\n",
      "8790 Training Loss: 0.001158763887360692 Validation Loss: 0.0019391132518649101\n",
      "8791 Training Loss: 0.0012905667535960674 Validation Loss: 0.001989050768315792\n",
      "8792 Training Loss: 0.0008542661089450121 Validation Loss: 0.002034032717347145\n",
      "8793 Training Loss: 0.0010861456394195557 Validation Loss: 0.002111477544531226\n",
      "8794 Training Loss: 0.0009821985149756074 Validation Loss: 0.0021279463544487953\n",
      "8795 Training Loss: 0.0009347415762022138 Validation Loss: 0.002078403253108263\n",
      "8796 Training Loss: 0.0009659991483204067 Validation Loss: 0.002009422518312931\n",
      "8797 Training Loss: 0.000835880171507597 Validation Loss: 0.001974705373868346\n",
      "8798 Training Loss: 0.0034740508999675512 Validation Loss: 0.002220452530309558\n",
      "8799 Training Loss: 0.0010389296803623438 Validation Loss: 0.0024988858494907618\n",
      "8800 Training Loss: 0.0014089690521359444 Validation Loss: 0.002681855345144868\n",
      "8801 Training Loss: 0.0010661195265129209 Validation Loss: 0.0025695234071463346\n",
      "8802 Training Loss: 0.001008906401693821 Validation Loss: 0.002335142809897661\n",
      "8803 Training Loss: 0.0009604666847735643 Validation Loss: 0.002190725179389119\n",
      "8804 Training Loss: 0.0012355090584605932 Validation Loss: 0.002142252866178751\n",
      "8805 Training Loss: 0.001064741867594421 Validation Loss: 0.002117525553330779\n",
      "8806 Training Loss: 0.0009648463455960155 Validation Loss: 0.002115765353664756\n",
      "8807 Training Loss: 0.0009199721971526742 Validation Loss: 0.0021558136213570833\n",
      "8808 Training Loss: 0.002448881044983864 Validation Loss: 0.0024122095201164484\n",
      "8809 Training Loss: 0.0008279696921817958 Validation Loss: 0.0025828450452536345\n",
      "8810 Training Loss: 0.0010935894679278135 Validation Loss: 0.0025109986308962107\n",
      "8811 Training Loss: 0.0012241699732840061 Validation Loss: 0.002192834159359336\n",
      "8812 Training Loss: 0.0009981335606426 Validation Loss: 0.001970797311514616\n",
      "8813 Training Loss: 0.0007783898035995662 Validation Loss: 0.0019248550524935126\n",
      "8814 Training Loss: 0.0013935138704255223 Validation Loss: 0.0019173022592440248\n",
      "8815 Training Loss: 0.00112711894325912 Validation Loss: 0.0019384780898690224\n",
      "8816 Training Loss: 0.0008053341298364103 Validation Loss: 0.0020681791938841343\n",
      "8817 Training Loss: 0.00097890745382756 Validation Loss: 0.0022265182342380285\n",
      "8818 Training Loss: 0.0008899859385564923 Validation Loss: 0.002257422311231494\n",
      "8819 Training Loss: 0.0022470392286777496 Validation Loss: 0.0024370725732296705\n",
      "8820 Training Loss: 0.0010595772182568908 Validation Loss: 0.0023767806123942137\n",
      "8821 Training Loss: 0.0009067117935046554 Validation Loss: 0.0022571890149265528\n",
      "8822 Training Loss: 0.0008858974324539304 Validation Loss: 0.0021633135620504618\n",
      "8823 Training Loss: 0.0014647560892626643 Validation Loss: 0.0022505454253405333\n",
      "8824 Training Loss: 0.0009517662692815065 Validation Loss: 0.0023036689963191748\n",
      "8825 Training Loss: 0.0011976880487054586 Validation Loss: 0.0022345951292663813\n",
      "8826 Training Loss: 0.000866384245455265 Validation Loss: 0.002196704037487507\n",
      "8827 Training Loss: 0.0010087178088724613 Validation Loss: 0.0022087725810706615\n",
      "8828 Training Loss: 0.0009257425554096699 Validation Loss: 0.002198989037424326\n",
      "8829 Training Loss: 0.0008960595587268472 Validation Loss: 0.0021562871988862753\n",
      "8830 Training Loss: 0.0008668155642226338 Validation Loss: 0.0020556265953928232\n",
      "8831 Training Loss: 0.0009720370871946216 Validation Loss: 0.001957387663424015\n",
      "8832 Training Loss: 0.0015242265071719885 Validation Loss: 0.0019272034987807274\n",
      "8833 Training Loss: 0.002348590176552534 Validation Loss: 0.002017147606238723\n",
      "8834 Training Loss: 0.000881201820448041 Validation Loss: 0.002072233473882079\n",
      "8835 Training Loss: 0.0008419656660407782 Validation Loss: 0.0021080642472952604\n",
      "8836 Training Loss: 0.001078002154827118 Validation Loss: 0.0020277968142181635\n",
      "8837 Training Loss: 0.0018650954589247704 Validation Loss: 0.0020667831413447857\n",
      "8838 Training Loss: 0.0008441534591838717 Validation Loss: 0.0020777953322976828\n",
      "8839 Training Loss: 0.0008493761997669935 Validation Loss: 0.002096716780215502\n",
      "8840 Training Loss: 0.0009593680733814836 Validation Loss: 0.0021068446803838015\n",
      "8841 Training Loss: 0.0007974365726113319 Validation Loss: 0.0021166717633605003\n",
      "8842 Training Loss: 0.0008495750371366739 Validation Loss: 0.0021261314395815134\n",
      "8843 Training Loss: 0.0009513802942819893 Validation Loss: 0.002092605223879218\n",
      "8844 Training Loss: 0.0007641663542017341 Validation Loss: 0.0020570659544318914\n",
      "8845 Training Loss: 0.0010967784328386188 Validation Loss: 0.00195795064792037\n",
      "8846 Training Loss: 0.0009143813513219357 Validation Loss: 0.0019099541241303086\n",
      "8847 Training Loss: 0.0008702979539521039 Validation Loss: 0.001860872725956142\n",
      "8848 Training Loss: 0.0008549309568479657 Validation Loss: 0.0018394802464172244\n",
      "8849 Training Loss: 0.0017114756628870964 Validation Loss: 0.0018954372499138117\n",
      "8850 Training Loss: 0.000887197267729789 Validation Loss: 0.0019656720105558634\n",
      "8851 Training Loss: 0.000810715660918504 Validation Loss: 0.002020585350692272\n",
      "8852 Training Loss: 0.0011989139020442963 Validation Loss: 0.0020369996782392263\n",
      "8853 Training Loss: 0.0009733212646096945 Validation Loss: 0.002036489313468337\n",
      "8854 Training Loss: 0.0014722931664437056 Validation Loss: 0.0020132374484091997\n",
      "8855 Training Loss: 0.0007712069782428443 Validation Loss: 0.0020002888049930334\n",
      "8856 Training Loss: 0.0016323562012985349 Validation Loss: 0.0019992757588624954\n",
      "8857 Training Loss: 0.0007946511614136398 Validation Loss: 0.001981231849640608\n",
      "8858 Training Loss: 0.000971680972725153 Validation Loss: 0.0019953621085733175\n",
      "8859 Training Loss: 0.0008254745043814182 Validation Loss: 0.0020009151194244623\n",
      "8860 Training Loss: 0.0010336703853681684 Validation Loss: 0.0019331664079800248\n",
      "8861 Training Loss: 0.0010412217816337943 Validation Loss: 0.001891759573481977\n",
      "8862 Training Loss: 0.0008959068800322711 Validation Loss: 0.00187587714754045\n",
      "8863 Training Loss: 0.0010038537438958883 Validation Loss: 0.001817504409700632\n",
      "8864 Training Loss: 0.0009202283690683544 Validation Loss: 0.0017758579924702644\n",
      "8865 Training Loss: 0.0008487029117532074 Validation Loss: 0.001750578754581511\n",
      "8866 Training Loss: 0.001312663429416716 Validation Loss: 0.001752230222336948\n",
      "8867 Training Loss: 0.0008487547747790813 Validation Loss: 0.0017724840436130762\n",
      "8868 Training Loss: 0.0009763208217918873 Validation Loss: 0.0018094154074788094\n",
      "8869 Training Loss: 0.0008513802313245833 Validation Loss: 0.0018214015290141106\n",
      "8870 Training Loss: 0.0008283627103082836 Validation Loss: 0.0017924834974110126\n",
      "8871 Training Loss: 0.0008778884075582027 Validation Loss: 0.001760515384376049\n",
      "8872 Training Loss: 0.000808248296380043 Validation Loss: 0.001743451226502657\n",
      "8873 Training Loss: 0.0008943510474637151 Validation Loss: 0.0017350594280287623\n",
      "8874 Training Loss: 0.0008955911034718156 Validation Loss: 0.0017230430385097861\n",
      "8875 Training Loss: 0.0015303584514185786 Validation Loss: 0.001737770508043468\n",
      "8876 Training Loss: 0.0019061511848121881 Validation Loss: 0.0018872215878218412\n",
      "8877 Training Loss: 0.0009204244124703109 Validation Loss: 0.002057899022474885\n",
      "8878 Training Loss: 0.0011503451969474554 Validation Loss: 0.002102682599797845\n",
      "8879 Training Loss: 0.0010401338804513216 Validation Loss: 0.002047626068815589\n",
      "8880 Training Loss: 0.001000810880213976 Validation Loss: 0.001949204015545547\n",
      "8881 Training Loss: 0.0009018346900120378 Validation Loss: 0.0018603139324113727\n",
      "8882 Training Loss: 0.0008655331912450492 Validation Loss: 0.0018160594627261162\n",
      "8883 Training Loss: 0.0009210377465933561 Validation Loss: 0.0017813749145716429\n",
      "8884 Training Loss: 0.0008779412601143122 Validation Loss: 0.0017563377041369677\n",
      "8885 Training Loss: 0.0008484488353133202 Validation Loss: 0.0017745933728292584\n",
      "8886 Training Loss: 0.0010163342813029885 Validation Loss: 0.0018356023356318474\n",
      "8887 Training Loss: 0.0009506916394457221 Validation Loss: 0.0018418863182887435\n",
      "8888 Training Loss: 0.0008915953221730888 Validation Loss: 0.0017939095851033926\n",
      "8889 Training Loss: 0.000961091136559844 Validation Loss: 0.0017643803730607033\n",
      "8890 Training Loss: 0.0008758928161114454 Validation Loss: 0.001726282644085586\n",
      "8891 Training Loss: 0.0007797915022820234 Validation Loss: 0.0017128533218055964\n",
      "8892 Training Loss: 0.0013460488989949226 Validation Loss: 0.0017134102527052164\n",
      "8893 Training Loss: 0.0008726323721930385 Validation Loss: 0.0017173740779981017\n",
      "8894 Training Loss: 0.0009427469922229648 Validation Loss: 0.0017124902224168181\n",
      "8895 Training Loss: 0.0008772008586674929 Validation Loss: 0.0017158335540443659\n",
      "8896 Training Loss: 0.0014319696929305792 Validation Loss: 0.001785857486538589\n",
      "8897 Training Loss: 0.0008151748916134238 Validation Loss: 0.001843410194851458\n",
      "8898 Training Loss: 0.001562956953421235 Validation Loss: 0.0019162899116054177\n",
      "8899 Training Loss: 0.0008500298717990518 Validation Loss: 0.0018830104963853955\n",
      "8900 Training Loss: 0.0010126125998795033 Validation Loss: 0.0018008062615990639\n",
      "8901 Training Loss: 0.0008815607288852334 Validation Loss: 0.0017413010355085135\n",
      "8902 Training Loss: 0.0007514224853366613 Validation Loss: 0.0017288400558754802\n",
      "8903 Training Loss: 0.0009510343661531806 Validation Loss: 0.0017170015489682555\n",
      "8904 Training Loss: 0.0012512271059677005 Validation Loss: 0.0017638086574152112\n",
      "8905 Training Loss: 0.0007832619594410062 Validation Loss: 0.001850769971497357\n",
      "8906 Training Loss: 0.0008999457932077348 Validation Loss: 0.0019203682895749807\n",
      "8907 Training Loss: 0.0007777487626299262 Validation Loss: 0.001965183299034834\n",
      "8908 Training Loss: 0.0008490456384606659 Validation Loss: 0.0019165878184139729\n",
      "8909 Training Loss: 0.0007584801060147583 Validation Loss: 0.0018383109709247947\n",
      "8910 Training Loss: 0.0009157803724519908 Validation Loss: 0.0017721819458529353\n",
      "8911 Training Loss: 0.0007818988524377346 Validation Loss: 0.0017442224780097604\n",
      "8912 Training Loss: 0.000818289932794869 Validation Loss: 0.0017408207058906555\n",
      "8913 Training Loss: 0.000856674974784255 Validation Loss: 0.0017503282288089395\n",
      "8914 Training Loss: 0.0008512279018759727 Validation Loss: 0.00176677864510566\n",
      "8915 Training Loss: 0.0007531825685873628 Validation Loss: 0.0017970142653211951\n",
      "8916 Training Loss: 0.0008243399206548929 Validation Loss: 0.0018308666767552495\n",
      "8917 Training Loss: 0.001984220929443836 Validation Loss: 0.0019425144419074059\n",
      "8918 Training Loss: 0.001155546517111361 Validation Loss: 0.0019203824922442436\n",
      "8919 Training Loss: 0.0008261195034720004 Validation Loss: 0.0018214944284409285\n",
      "8920 Training Loss: 0.0008676489815115929 Validation Loss: 0.001752400305122137\n",
      "8921 Training Loss: 0.0008004161645658314 Validation Loss: 0.0017509197350591421\n",
      "8922 Training Loss: 0.0012239895295351744 Validation Loss: 0.0017884597182273865\n",
      "8923 Training Loss: 0.0007800920866429806 Validation Loss: 0.0018439774867147207\n",
      "8924 Training Loss: 0.0012768254382535815 Validation Loss: 0.0020318967290222645\n",
      "8925 Training Loss: 0.0007707735639996827 Validation Loss: 0.0022197470534592867\n",
      "8926 Training Loss: 0.0008442506659775972 Validation Loss: 0.0023647958878427744\n",
      "8927 Training Loss: 0.002084048930555582 Validation Loss: 0.002441057236865163\n",
      "8928 Training Loss: 0.0014219677541404963 Validation Loss: 0.002365635707974434\n",
      "8929 Training Loss: 0.0008190737571567297 Validation Loss: 0.0021821295376867056\n",
      "8930 Training Loss: 0.001162138069048524 Validation Loss: 0.0019799801521003246\n",
      "8931 Training Loss: 0.0009127839002758265 Validation Loss: 0.0018716276390478015\n",
      "8932 Training Loss: 0.001517693279311061 Validation Loss: 0.001869308645837009\n",
      "8933 Training Loss: 0.0009279223158955574 Validation Loss: 0.0018938581924885511\n",
      "8934 Training Loss: 0.0010107482085004449 Validation Loss: 0.0019703793805092573\n",
      "8935 Training Loss: 0.000832575315143913 Validation Loss: 0.002003163332119584\n",
      "8936 Training Loss: 0.0007974112522788346 Validation Loss: 0.0020173729863017797\n",
      "8937 Training Loss: 0.0007762524764984846 Validation Loss: 0.002009975491091609\n",
      "8938 Training Loss: 0.0010030765552073717 Validation Loss: 0.0019553641323000193\n",
      "8939 Training Loss: 0.0009490634547546506 Validation Loss: 0.0019167127320542932\n",
      "8940 Training Loss: 0.0008764574304223061 Validation Loss: 0.001870558364316821\n",
      "8941 Training Loss: 0.0007439147448167205 Validation Loss: 0.0018513404065743089\n",
      "8942 Training Loss: 0.0008303619106300175 Validation Loss: 0.0018523591570556164\n",
      "8943 Training Loss: 0.0008155915420502424 Validation Loss: 0.0018805593717843294\n",
      "8944 Training Loss: 0.0012777503579854965 Validation Loss: 0.001986637245863676\n",
      "8945 Training Loss: 0.000979241798631847 Validation Loss: 0.0020253167022019625\n",
      "8946 Training Loss: 0.0008114232332445681 Validation Loss: 0.0020290405955165625\n",
      "8947 Training Loss: 0.0008358941413462162 Validation Loss: 0.002007785253226757\n",
      "8948 Training Loss: 0.0008897326770238578 Validation Loss: 0.0019495986634865403\n",
      "8949 Training Loss: 0.0007373082917183638 Validation Loss: 0.0019377589924260974\n",
      "8950 Training Loss: 0.0010465183295309544 Validation Loss: 0.0019320000428706408\n",
      "8951 Training Loss: 0.0008627880597487092 Validation Loss: 0.0019316970137879252\n",
      "8952 Training Loss: 0.0008193739922717214 Validation Loss: 0.0019465398509055376\n",
      "8953 Training Loss: 0.0009203022345900536 Validation Loss: 0.0019050786504521966\n",
      "8954 Training Loss: 0.0007385602220892906 Validation Loss: 0.0018877355614677072\n",
      "8955 Training Loss: 0.0009302095859311521 Validation Loss: 0.0018274937756359577\n",
      "8956 Training Loss: 0.001199000864289701 Validation Loss: 0.001803282299079001\n",
      "8957 Training Loss: 0.0010762667516246438 Validation Loss: 0.0017620293656364083\n",
      "8958 Training Loss: 0.000925131025724113 Validation Loss: 0.0017680453602224588\n",
      "8959 Training Loss: 0.0008826209232211113 Validation Loss: 0.0017856736667454243\n",
      "8960 Training Loss: 0.0007416447624564171 Validation Loss: 0.0018137249862775207\n",
      "8961 Training Loss: 0.0007612199988216162 Validation Loss: 0.0018458351260051131\n",
      "8962 Training Loss: 0.0013832999393343925 Validation Loss: 0.0019088146509602666\n",
      "8963 Training Loss: 0.0008447880391031504 Validation Loss: 0.0019174832850694656\n",
      "8964 Training Loss: 0.0008275883737951517 Validation Loss: 0.001881840405985713\n",
      "8965 Training Loss: 0.0012988550588488579 Validation Loss: 0.0018844502046704292\n",
      "8966 Training Loss: 0.0007079645292833447 Validation Loss: 0.0018745160195976496\n",
      "8967 Training Loss: 0.0010498373303562403 Validation Loss: 0.0018938151188194752\n",
      "8968 Training Loss: 0.0008055035723373294 Validation Loss: 0.001878655981272459\n",
      "8969 Training Loss: 0.0007301124860532582 Validation Loss: 0.0018550024833530188\n",
      "8970 Training Loss: 0.0012937287101522088 Validation Loss: 0.0018614623695611954\n",
      "8971 Training Loss: 0.0009739683009684086 Validation Loss: 0.0018522172467783093\n",
      "8972 Training Loss: 0.0007966053672134876 Validation Loss: 0.0018433097284287214\n",
      "8973 Training Loss: 0.0018073442624881864 Validation Loss: 0.0018772026523947716\n",
      "8974 Training Loss: 0.0007627346203662455 Validation Loss: 0.0019080035854130983\n",
      "8975 Training Loss: 0.0008734231814742088 Validation Loss: 0.0018980063032358885\n",
      "8976 Training Loss: 0.0012430741917341948 Validation Loss: 0.0018692509038373828\n",
      "8977 Training Loss: 0.0009580993792042136 Validation Loss: 0.0018246693070977926\n",
      "8978 Training Loss: 0.000819607637822628 Validation Loss: 0.001790741109289229\n",
      "8979 Training Loss: 0.0009504089248366654 Validation Loss: 0.0017741259653121233\n",
      "8980 Training Loss: 0.0009639241034165025 Validation Loss: 0.0017571208300068974\n",
      "8981 Training Loss: 0.0007951636798679829 Validation Loss: 0.0017409956781193614\n",
      "8982 Training Loss: 0.0015504142502322793 Validation Loss: 0.0017961682751774788\n",
      "8983 Training Loss: 0.0022593627218157053 Validation Loss: 0.0019676389638334513\n",
      "8984 Training Loss: 0.0009940809104591608 Validation Loss: 0.0020533944480121136\n",
      "8985 Training Loss: 0.0007989234291017056 Validation Loss: 0.0020342932548373938\n",
      "8986 Training Loss: 0.0007177528459578753 Validation Loss: 0.001948114950209856\n",
      "8987 Training Loss: 0.0011835021432489157 Validation Loss: 0.001953580416738987\n",
      "8988 Training Loss: 0.0007905906531959772 Validation Loss: 0.001951028942130506\n",
      "8989 Training Loss: 0.0008205575868487358 Validation Loss: 0.0019522046204656363\n",
      "8990 Training Loss: 0.0010824790224432945 Validation Loss: 0.001973434817045927\n",
      "8991 Training Loss: 0.0009327934822067618 Validation Loss: 0.001977891195565462\n",
      "8992 Training Loss: 0.0010290170321241021 Validation Loss: 0.002041271887719631\n",
      "8993 Training Loss: 0.0010105562396347523 Validation Loss: 0.0020830375142395496\n",
      "8994 Training Loss: 0.0008692328119650483 Validation Loss: 0.002025413326919079\n",
      "8995 Training Loss: 0.0008477737428620458 Validation Loss: 0.0019254385260865092\n",
      "8996 Training Loss: 0.0007124794647097588 Validation Loss: 0.001847335253842175\n",
      "8997 Training Loss: 0.0013085679383948445 Validation Loss: 0.0018381900154054165\n",
      "8998 Training Loss: 0.0009671230218373239 Validation Loss: 0.0018074368126690388\n",
      "8999 Training Loss: 0.0008097060490399599 Validation Loss: 0.0017955179791897535\n",
      "9000 Training Loss: 0.0009431291255168617 Validation Loss: 0.0017966527957469225\n",
      "9001 Training Loss: 0.000818669970612973 Validation Loss: 0.0018143611960113049\n",
      "9002 Training Loss: 0.001026930520310998 Validation Loss: 0.001913621323183179\n",
      "9003 Training Loss: 0.0009062173776328564 Validation Loss: 0.0020164228044450283\n",
      "9004 Training Loss: 0.0007135107880458236 Validation Loss: 0.002037134487181902\n",
      "9005 Training Loss: 0.001156867598183453 Validation Loss: 0.001961567671969533\n",
      "9006 Training Loss: 0.0009764640126377344 Validation Loss: 0.0018607578240334988\n",
      "9007 Training Loss: 0.000681468693073839 Validation Loss: 0.0018018543487414718\n",
      "9008 Training Loss: 0.0008918166859075427 Validation Loss: 0.0017527920426800847\n",
      "9009 Training Loss: 0.000816181069239974 Validation Loss: 0.0017463633557781577\n",
      "9010 Training Loss: 0.0008013059850782156 Validation Loss: 0.0017581278225407004\n",
      "9011 Training Loss: 0.000753855099901557 Validation Loss: 0.0017985057784244418\n",
      "9012 Training Loss: 0.0007488061091862619 Validation Loss: 0.0018398452084511518\n",
      "9013 Training Loss: 0.0007604664424434304 Validation Loss: 0.0018528804648667574\n",
      "9014 Training Loss: 0.0008595825638622046 Validation Loss: 0.0018088541692122817\n",
      "9015 Training Loss: 0.0016974803293123841 Validation Loss: 0.0018518425058573484\n",
      "9016 Training Loss: 0.0008294851868413389 Validation Loss: 0.001884771278128028\n",
      "9017 Training Loss: 0.0010441291378811002 Validation Loss: 0.0019356266129761934\n",
      "9018 Training Loss: 0.0008442176040261984 Validation Loss: 0.0019535559695214033\n",
      "9019 Training Loss: 0.0007096958579495549 Validation Loss: 0.001964582595974207\n",
      "9020 Training Loss: 0.0012591230915859342 Validation Loss: 0.002033747499808669\n",
      "9021 Training Loss: 0.0007746007759124041 Validation Loss: 0.0020427147392183542\n",
      "9022 Training Loss: 0.0008004826959222555 Validation Loss: 0.0019504351075738668\n",
      "9023 Training Loss: 0.0007978947833180428 Validation Loss: 0.001860041287727654\n",
      "9024 Training Loss: 0.0010105357505381107 Validation Loss: 0.0018331039464101195\n",
      "9025 Training Loss: 0.0011368765262886882 Validation Loss: 0.001848009997047484\n",
      "9026 Training Loss: 0.000874837045557797 Validation Loss: 0.0018978514708578587\n",
      "9027 Training Loss: 0.0009082321776077151 Validation Loss: 0.0019156401976943016\n",
      "9028 Training Loss: 0.000715046189725399 Validation Loss: 0.001886030426248908\n",
      "9029 Training Loss: 0.0007264246232807636 Validation Loss: 0.001863121404312551\n",
      "9030 Training Loss: 0.0008905494469217956 Validation Loss: 0.001852567307651043\n",
      "9031 Training Loss: 0.0007728425553068519 Validation Loss: 0.0018180054612457752\n",
      "9032 Training Loss: 0.0010521915974095464 Validation Loss: 0.001731755561195314\n",
      "9033 Training Loss: 0.0008831482846289873 Validation Loss: 0.0016918263863772154\n",
      "9034 Training Loss: 0.0007824540371075273 Validation Loss: 0.0016796310665085912\n",
      "9035 Training Loss: 0.0008038897067308426 Validation Loss: 0.0016956074396148324\n",
      "9036 Training Loss: 0.0008722471538931131 Validation Loss: 0.0017072134651243687\n",
      "9037 Training Loss: 0.0008941384148783982 Validation Loss: 0.0016889377729967237\n",
      "9038 Training Loss: 0.0008763686055317521 Validation Loss: 0.0016545429825782776\n",
      "9039 Training Loss: 0.0009955910500138998 Validation Loss: 0.0016374054830521345\n",
      "9040 Training Loss: 0.0007952485466375947 Validation Loss: 0.0016380853485316038\n",
      "9041 Training Loss: 0.0006764486897736788 Validation Loss: 0.0016509633278474212\n",
      "9042 Training Loss: 0.0006897446000948548 Validation Loss: 0.0016686106100678444\n",
      "9043 Training Loss: 0.0009190675336867571 Validation Loss: 0.0016992749879136682\n",
      "9044 Training Loss: 0.0008512010681442916 Validation Loss: 0.0017448898870497942\n",
      "9045 Training Loss: 0.0007954068132676184 Validation Loss: 0.0017230607336387038\n",
      "9046 Training Loss: 0.0011879145167768002 Validation Loss: 0.0017256868304684758\n",
      "9047 Training Loss: 0.0007549124420620501 Validation Loss: 0.0017196736298501492\n",
      "9048 Training Loss: 0.0008132194634526968 Validation Loss: 0.0017313953721895814\n",
      "9049 Training Loss: 0.001545396400615573 Validation Loss: 0.0018803230486810207\n",
      "9050 Training Loss: 0.0007876657182350755 Validation Loss: 0.0019922498613595963\n",
      "9051 Training Loss: 0.0009406592580489814 Validation Loss: 0.0019671067129820585\n",
      "9052 Training Loss: 0.0008027753792703152 Validation Loss: 0.0018745907582342625\n",
      "9053 Training Loss: 0.0007222220301628113 Validation Loss: 0.0018168289680033922\n",
      "9054 Training Loss: 0.000923875137232244 Validation Loss: 0.0017434849869459867\n",
      "9055 Training Loss: 0.00127445999532938 Validation Loss: 0.0017415505135431886\n",
      "9056 Training Loss: 0.0007450784323737025 Validation Loss: 0.001774309785105288\n",
      "9057 Training Loss: 0.0008905020076781511 Validation Loss: 0.0017970396438613534\n",
      "9058 Training Loss: 0.0008022619877010584 Validation Loss: 0.0017828433774411678\n",
      "9059 Training Loss: 0.0007940856157802045 Validation Loss: 0.0017363333608955145\n",
      "9060 Training Loss: 0.0006930166855454445 Validation Loss: 0.0016913734143599868\n",
      "9061 Training Loss: 0.0009751273319125175 Validation Loss: 0.0017027592984959483\n",
      "9062 Training Loss: 0.0008717442397028208 Validation Loss: 0.0017517775995656848\n",
      "9063 Training Loss: 0.0008090825285762548 Validation Loss: 0.001786325010471046\n",
      "9064 Training Loss: 0.000744349614251405 Validation Loss: 0.0018099489388987422\n",
      "9065 Training Loss: 0.0007893310394138098 Validation Loss: 0.0017925711581483483\n",
      "9066 Training Loss: 0.0007507521659135818 Validation Loss: 0.0017627521883696318\n",
      "9067 Training Loss: 0.0009164155926555395 Validation Loss: 0.0017038278747349977\n",
      "9068 Training Loss: 0.001046696095727384 Validation Loss: 0.0017001531086862087\n",
      "9069 Training Loss: 0.0008031765464693308 Validation Loss: 0.0017059814417734742\n",
      "9070 Training Loss: 0.000942606944590807 Validation Loss: 0.001742038642987609\n",
      "9071 Training Loss: 0.0012867189943790436 Validation Loss: 0.0017978923860937357\n",
      "9072 Training Loss: 0.0007947703124955297 Validation Loss: 0.0017979132244363427\n",
      "9073 Training Loss: 0.0008848605211824179 Validation Loss: 0.001789213391020894\n",
      "9074 Training Loss: 0.0007440742338076234 Validation Loss: 0.0017399569042026997\n",
      "9075 Training Loss: 0.0007574445335194468 Validation Loss: 0.0017099498072639108\n",
      "9076 Training Loss: 0.001536419615149498 Validation Loss: 0.0017868963768705726\n",
      "9077 Training Loss: 0.0009553792187944055 Validation Loss: 0.0019730988424271345\n",
      "9078 Training Loss: 0.0008534989319741726 Validation Loss: 0.0021706554107367992\n",
      "9079 Training Loss: 0.0008444748818874359 Validation Loss: 0.0022509340196847916\n",
      "9080 Training Loss: 0.0010720565915107727 Validation Loss: 0.002186818979680538\n",
      "9081 Training Loss: 0.0006753747584298253 Validation Loss: 0.002081844722852111\n",
      "9082 Training Loss: 0.0007361746393144131 Validation Loss: 0.0019516430329531431\n",
      "9083 Training Loss: 0.0008620495209470391 Validation Loss: 0.0018974251579493284\n",
      "9084 Training Loss: 0.0009526038775220513 Validation Loss: 0.0018233137670904398\n",
      "9085 Training Loss: 0.0008201937889680266 Validation Loss: 0.0017599670682102442\n",
      "9086 Training Loss: 0.0008309372351504862 Validation Loss: 0.001724673667922616\n",
      "9087 Training Loss: 0.0007206411683000624 Validation Loss: 0.001714579644612968\n",
      "9088 Training Loss: 0.0008568136254325509 Validation Loss: 0.0017383004305884242\n",
      "9089 Training Loss: 0.0008666132343932986 Validation Loss: 0.001737401238642633\n",
      "9090 Training Loss: 0.00098695931956172 Validation Loss: 0.0017235752893611789\n",
      "9091 Training Loss: 0.0008033196208998561 Validation Loss: 0.0016951763536781073\n",
      "9092 Training Loss: 0.0012404457665979862 Validation Loss: 0.0017071975162252784\n",
      "9093 Training Loss: 0.0024750423617661 Validation Loss: 0.0018332768231630325\n",
      "9094 Training Loss: 0.0008114944212138653 Validation Loss: 0.0019197065848857164\n",
      "9095 Training Loss: 0.0008193558314815164 Validation Loss: 0.0019374149851500988\n",
      "9096 Training Loss: 0.0007631955086253583 Validation Loss: 0.0019040709594264627\n",
      "9097 Training Loss: 0.000865224632434547 Validation Loss: 0.0017816508188843727\n",
      "9098 Training Loss: 0.0006635799072682858 Validation Loss: 0.001719442312605679\n",
      "9099 Training Loss: 0.0009123284835368395 Validation Loss: 0.0016900827176868916\n",
      "9100 Training Loss: 0.0006829382618889213 Validation Loss: 0.001686283154413104\n",
      "9101 Training Loss: 0.0013648252934217453 Validation Loss: 0.00181824981700629\n",
      "9102 Training Loss: 0.0007611807086504996 Validation Loss: 0.001918340683914721\n",
      "9103 Training Loss: 0.0011417288333177567 Validation Loss: 0.0019921332132071257\n",
      "9104 Training Loss: 0.0011040891986340284 Validation Loss: 0.0020025528501719236\n",
      "9105 Training Loss: 0.0007293937960639596 Validation Loss: 0.001933290739543736\n",
      "9106 Training Loss: 0.0007803022162988782 Validation Loss: 0.001854532863944769\n",
      "9107 Training Loss: 0.0007836867589503527 Validation Loss: 0.0017846392001956701\n",
      "9108 Training Loss: 0.0017192782834172249 Validation Loss: 0.0017785682575777173\n",
      "9109 Training Loss: 0.0009484185138717294 Validation Loss: 0.0018180343322455883\n",
      "9110 Training Loss: 0.0013313812669366598 Validation Loss: 0.001955365063622594\n",
      "9111 Training Loss: 0.0009282812243327498 Validation Loss: 0.0019869962707161903\n",
      "9112 Training Loss: 0.0008892008918337524 Validation Loss: 0.001918666996061802\n",
      "9113 Training Loss: 0.0007522545056417584 Validation Loss: 0.001795729505829513\n",
      "9114 Training Loss: 0.000639573554508388 Validation Loss: 0.0017378245247527957\n",
      "9115 Training Loss: 0.0007859286852180958 Validation Loss: 0.0017360058845952153\n",
      "9116 Training Loss: 0.0008589464705437422 Validation Loss: 0.0017566051101312041\n",
      "9117 Training Loss: 0.0008154984680004418 Validation Loss: 0.001795850577764213\n",
      "9118 Training Loss: 0.000916691729798913 Validation Loss: 0.0018440107814967632\n",
      "9119 Training Loss: 0.0007719374843873084 Validation Loss: 0.0018400689586997032\n",
      "9120 Training Loss: 0.0008741413475945592 Validation Loss: 0.0017777926987037063\n",
      "9121 Training Loss: 0.0007133720209822059 Validation Loss: 0.0017364451196044683\n",
      "9122 Training Loss: 0.0018446469912305474 Validation Loss: 0.001723600784316659\n",
      "9123 Training Loss: 0.0008745471714064479 Validation Loss: 0.0017050865571945906\n",
      "9124 Training Loss: 0.0008646340575069189 Validation Loss: 0.001660281210206449\n",
      "9125 Training Loss: 0.000691881577949971 Validation Loss: 0.0016255986411124468\n",
      "9126 Training Loss: 0.00079294916940853 Validation Loss: 0.001636190339922905\n",
      "9127 Training Loss: 0.000805416377261281 Validation Loss: 0.0016998708015307784\n",
      "9128 Training Loss: 0.0007551976013928652 Validation Loss: 0.001735039404593408\n",
      "9129 Training Loss: 0.0007560413796454668 Validation Loss: 0.0017468513688072562\n",
      "9130 Training Loss: 0.0009156687883660197 Validation Loss: 0.0016983458772301674\n",
      "9131 Training Loss: 0.0008296985179185867 Validation Loss: 0.0016880608163774014\n",
      "9132 Training Loss: 0.0007293559610843658 Validation Loss: 0.0016663041897118092\n",
      "9133 Training Loss: 0.0012107247021049261 Validation Loss: 0.0016862474149093032\n",
      "9134 Training Loss: 0.0009369935723952949 Validation Loss: 0.0016952042933553457\n",
      "9135 Training Loss: 0.0007935476023703814 Validation Loss: 0.0016643046401441097\n",
      "9136 Training Loss: 0.0007054263260215521 Validation Loss: 0.001643979805521667\n",
      "9137 Training Loss: 0.0007521290681324899 Validation Loss: 0.0016096782637760043\n",
      "9138 Training Loss: 0.00101001828443259 Validation Loss: 0.0016117760678753257\n",
      "9139 Training Loss: 0.0007669974002055824 Validation Loss: 0.0016348006902262568\n",
      "9140 Training Loss: 0.0013624050188809633 Validation Loss: 0.001713931793347001\n",
      "9141 Training Loss: 0.0010974290780723095 Validation Loss: 0.0017979040276259184\n",
      "9142 Training Loss: 0.0008557660039514303 Validation Loss: 0.001858799485489726\n",
      "9143 Training Loss: 0.0007810620008967817 Validation Loss: 0.0018177424790337682\n",
      "9144 Training Loss: 0.0007966669509187341 Validation Loss: 0.0017288692761212587\n",
      "9145 Training Loss: 0.0007192267803475261 Validation Loss: 0.0016761180013418198\n",
      "9146 Training Loss: 0.0011203344911336899 Validation Loss: 0.0016810111701488495\n",
      "9147 Training Loss: 0.0007135040359571576 Validation Loss: 0.0017055700300261378\n",
      "9148 Training Loss: 0.0007208941387943923 Validation Loss: 0.0017422165255993605\n",
      "9149 Training Loss: 0.0007539969519712031 Validation Loss: 0.0017514585051685572\n",
      "9150 Training Loss: 0.0006426650797948241 Validation Loss: 0.0017715571448206902\n",
      "9151 Training Loss: 0.0007665677112527192 Validation Loss: 0.001736728590913117\n",
      "9152 Training Loss: 0.0008395424229092896 Validation Loss: 0.0016878846799954772\n",
      "9153 Training Loss: 0.000934396986849606 Validation Loss: 0.001615597982890904\n",
      "9154 Training Loss: 0.001169427065178752 Validation Loss: 0.0016149984439834952\n",
      "9155 Training Loss: 0.0006646706606261432 Validation Loss: 0.0016331461956724524\n",
      "9156 Training Loss: 0.0010486636310815811 Validation Loss: 0.001645491225644946\n",
      "9157 Training Loss: 0.0007847838569432497 Validation Loss: 0.0016267562750726938\n",
      "9158 Training Loss: 0.0008202218450605869 Validation Loss: 0.001603093696758151\n",
      "9159 Training Loss: 0.0006589738186448812 Validation Loss: 0.0015976754948496819\n",
      "9160 Training Loss: 0.0007784276967868209 Validation Loss: 0.0016111875884234905\n",
      "9161 Training Loss: 0.0007203040295280516 Validation Loss: 0.0016402825713157654\n",
      "9162 Training Loss: 0.0010964086977764964 Validation Loss: 0.001735605881549418\n",
      "9163 Training Loss: 0.0009560855687595904 Validation Loss: 0.0018177872989326715\n",
      "9164 Training Loss: 0.001014902489259839 Validation Loss: 0.001855871407315135\n",
      "9165 Training Loss: 0.0008204363402910531 Validation Loss: 0.0017697821604087949\n",
      "9166 Training Loss: 0.0006881959270685911 Validation Loss: 0.0016719978302717209\n",
      "9167 Training Loss: 0.0006606908282265067 Validation Loss: 0.0016059697372838855\n",
      "9168 Training Loss: 0.0007159574306569993 Validation Loss: 0.0015978269511833787\n",
      "9169 Training Loss: 0.00075317028677091 Validation Loss: 0.00160360021982342\n",
      "9170 Training Loss: 0.0007906150422059 Validation Loss: 0.0016406713984906673\n",
      "9171 Training Loss: 0.0008646337082609534 Validation Loss: 0.0016897930763661861\n",
      "9172 Training Loss: 0.0008120823767967522 Validation Loss: 0.0016852326225489378\n",
      "9173 Training Loss: 0.000979041331447661 Validation Loss: 0.0016891113482415676\n",
      "9174 Training Loss: 0.0008884776616469026 Validation Loss: 0.0017025517299771309\n",
      "9175 Training Loss: 0.0007812719559296966 Validation Loss: 0.001681868452578783\n",
      "9176 Training Loss: 0.002131923334673047 Validation Loss: 0.0017590777715668082\n",
      "9177 Training Loss: 0.0007687228498980403 Validation Loss: 0.0018604922806844115\n",
      "9178 Training Loss: 0.0009057505521923304 Validation Loss: 0.0018052109517157078\n",
      "9179 Training Loss: 0.001094688312150538 Validation Loss: 0.0017449684673920274\n",
      "9180 Training Loss: 0.0007708225166425109 Validation Loss: 0.0016799106961116195\n",
      "9181 Training Loss: 0.0007882346981205046 Validation Loss: 0.0016519264318048954\n",
      "9182 Training Loss: 0.0012894140090793371 Validation Loss: 0.001677720807492733\n",
      "9183 Training Loss: 0.0007521915249526501 Validation Loss: 0.0017700858879834414\n",
      "9184 Training Loss: 0.0008115521632134914 Validation Loss: 0.001835281029343605\n",
      "9185 Training Loss: 0.0011524425353854895 Validation Loss: 0.0019348063506186008\n",
      "9186 Training Loss: 0.0007725839386694133 Validation Loss: 0.002003422472625971\n",
      "9187 Training Loss: 0.0007909185951575637 Validation Loss: 0.001956778112798929\n",
      "9188 Training Loss: 0.0012942124158143997 Validation Loss: 0.001924346201121807\n",
      "9189 Training Loss: 0.0007925818208605051 Validation Loss: 0.0018491530790925026\n",
      "9190 Training Loss: 0.000767075689509511 Validation Loss: 0.0017637755954638124\n",
      "9191 Training Loss: 0.0007797478465363383 Validation Loss: 0.0016976320184767246\n",
      "9192 Training Loss: 0.0006910820375196636 Validation Loss: 0.001665684743784368\n",
      "9193 Training Loss: 0.0007138299406506121 Validation Loss: 0.0016888396348804235\n",
      "9194 Training Loss: 0.0008826027042232454 Validation Loss: 0.0016790528316050768\n",
      "9195 Training Loss: 0.0008380699437111616 Validation Loss: 0.0016603812109678984\n",
      "9196 Training Loss: 0.0007153503829613328 Validation Loss: 0.001643311115913093\n",
      "9197 Training Loss: 0.0007780492305755615 Validation Loss: 0.0016598361544311047\n",
      "9198 Training Loss: 0.0006475709960795939 Validation Loss: 0.0016881432384252548\n",
      "9199 Training Loss: 0.0006804697914049029 Validation Loss: 0.001723201246932149\n",
      "9200 Training Loss: 0.000697569630574435 Validation Loss: 0.001786986249499023\n",
      "9201 Training Loss: 0.0014863891992717981 Validation Loss: 0.0019276115344837308\n",
      "9202 Training Loss: 0.0007956214831210673 Validation Loss: 0.001983060734346509\n",
      "9203 Training Loss: 0.0006760939722880721 Validation Loss: 0.0019772741943597794\n",
      "9204 Training Loss: 0.0008096482488326728 Validation Loss: 0.0018940416630357504\n",
      "9205 Training Loss: 0.0007086963742040098 Validation Loss: 0.0017951549962162971\n",
      "9206 Training Loss: 0.0007460061460733414 Validation Loss: 0.0017188278725370765\n",
      "9207 Training Loss: 0.0007613381603732705 Validation Loss: 0.001692538964562118\n",
      "9208 Training Loss: 0.0006836355896666646 Validation Loss: 0.0017219803994521499\n",
      "9209 Training Loss: 0.0006913550314493477 Validation Loss: 0.0017736167646944523\n",
      "9210 Training Loss: 0.0008695940487086773 Validation Loss: 0.0018025761237367988\n",
      "9211 Training Loss: 0.001405063783749938 Validation Loss: 0.0018562665209174156\n",
      "9212 Training Loss: 0.0008178888238035142 Validation Loss: 0.001839115866459906\n",
      "9213 Training Loss: 0.0007619243115186691 Validation Loss: 0.001747960806824267\n",
      "9214 Training Loss: 0.0009092534892261028 Validation Loss: 0.0017065878491848707\n",
      "9215 Training Loss: 0.0007894796435721219 Validation Loss: 0.0016707879258319736\n",
      "9216 Training Loss: 0.0008176882984116673 Validation Loss: 0.0016218788223341107\n",
      "9217 Training Loss: 0.0008095804369077086 Validation Loss: 0.0016097384504973888\n",
      "9218 Training Loss: 0.0006814883090555668 Validation Loss: 0.0016128208953887224\n",
      "9219 Training Loss: 0.0007141462992876768 Validation Loss: 0.0016099321655929089\n",
      "9220 Training Loss: 0.000718827242963016 Validation Loss: 0.0015928653301671147\n",
      "9221 Training Loss: 0.0007025577942840755 Validation Loss: 0.0015594128053635359\n",
      "9222 Training Loss: 0.0006959166494198143 Validation Loss: 0.0015360001707449555\n",
      "9223 Training Loss: 0.0006651862058788538 Validation Loss: 0.0015162950148805976\n",
      "9224 Training Loss: 0.0007339761359617114 Validation Loss: 0.0015012889634817839\n",
      "9225 Training Loss: 0.0021254729945212603 Validation Loss: 0.0015671688597649336\n",
      "9226 Training Loss: 0.0006836229003965855 Validation Loss: 0.0016964850947260857\n",
      "9227 Training Loss: 0.0007666669553145766 Validation Loss: 0.0017688951920717955\n",
      "9228 Training Loss: 0.000746473902836442 Validation Loss: 0.0017448334256187081\n",
      "9229 Training Loss: 0.0008112352807074785 Validation Loss: 0.0016689244657754898\n",
      "9230 Training Loss: 0.0011189235374331474 Validation Loss: 0.001625605276785791\n",
      "9231 Training Loss: 0.0008306078379973769 Validation Loss: 0.001620377181097865\n",
      "9232 Training Loss: 0.0007378762238658965 Validation Loss: 0.0016104039968922734\n",
      "9233 Training Loss: 0.0007955268956720829 Validation Loss: 0.0016171704046428204\n",
      "9234 Training Loss: 0.0006608171388506889 Validation Loss: 0.001620047609321773\n",
      "9235 Training Loss: 0.0012178997276350856 Validation Loss: 0.001657359767705202\n",
      "9236 Training Loss: 0.001173345372080803 Validation Loss: 0.001709505682811141\n",
      "9237 Training Loss: 0.000731157953850925 Validation Loss: 0.0016885953955352306\n",
      "9238 Training Loss: 0.0007768584182485938 Validation Loss: 0.001610023551620543\n",
      "9239 Training Loss: 0.0009558594902046025 Validation Loss: 0.001619575428776443\n",
      "9240 Training Loss: 0.0012812644708901644 Validation Loss: 0.0016774240648373961\n",
      "9241 Training Loss: 0.0007248286856338382 Validation Loss: 0.0017330646514892578\n",
      "9242 Training Loss: 0.0009810320334509015 Validation Loss: 0.0018753418698906898\n",
      "9243 Training Loss: 0.001392366481013596 Validation Loss: 0.002098888624459505\n",
      "9244 Training Loss: 0.0007318758871406317 Validation Loss: 0.0022060112096369267\n",
      "9245 Training Loss: 0.0007140201050788164 Validation Loss: 0.0021497125271707773\n",
      "9246 Training Loss: 0.0009471501689404249 Validation Loss: 0.0019449818646535277\n",
      "9247 Training Loss: 0.0007827740046195686 Validation Loss: 0.0017882754327729344\n",
      "9248 Training Loss: 0.0008720934274606407 Validation Loss: 0.0016744447639212012\n",
      "9249 Training Loss: 0.0006993926363065839 Validation Loss: 0.0016259819967672229\n",
      "9250 Training Loss: 0.0015631142305210233 Validation Loss: 0.0016629883321002126\n",
      "9251 Training Loss: 0.0009623299119994044 Validation Loss: 0.0017908106092363596\n",
      "9252 Training Loss: 0.0009889891371130943 Validation Loss: 0.0018571014516055584\n",
      "9253 Training Loss: 0.0007456500898115337 Validation Loss: 0.0018200508784502745\n",
      "9254 Training Loss: 0.0007898842450231314 Validation Loss: 0.0017151932697743177\n",
      "9255 Training Loss: 0.0007225568988360465 Validation Loss: 0.0016577932983636856\n",
      "9256 Training Loss: 0.0010895016603171825 Validation Loss: 0.0016578671056777239\n",
      "9257 Training Loss: 0.0007494519231840968 Validation Loss: 0.0016733629163354635\n",
      "9258 Training Loss: 0.0006875934777781367 Validation Loss: 0.0017075772630050778\n",
      "9259 Training Loss: 0.0006836673710495234 Validation Loss: 0.001794923096895218\n",
      "9260 Training Loss: 0.000680598255712539 Validation Loss: 0.0018724248511716723\n",
      "9261 Training Loss: 0.0008169521461240947 Validation Loss: 0.001914359163492918\n",
      "9262 Training Loss: 0.0011694654822349548 Validation Loss: 0.0019150425214320421\n",
      "9263 Training Loss: 0.0007362958858720958 Validation Loss: 0.001827614731155336\n",
      "9264 Training Loss: 0.0006803105934523046 Validation Loss: 0.0017199419671669602\n",
      "9265 Training Loss: 0.0007307023042812943 Validation Loss: 0.0016475613228976727\n",
      "9266 Training Loss: 0.0006952545372769237 Validation Loss: 0.001617371803149581\n",
      "9267 Training Loss: 0.0007266635657288134 Validation Loss: 0.0016123632667586207\n",
      "9268 Training Loss: 0.0007542382809333503 Validation Loss: 0.0016546169063076377\n",
      "9269 Training Loss: 0.0007128532161004841 Validation Loss: 0.0017174610402435064\n",
      "9270 Training Loss: 0.0007835380965843797 Validation Loss: 0.0017813502345234156\n",
      "9271 Training Loss: 0.0008471650071442127 Validation Loss: 0.0018486008048057556\n",
      "9272 Training Loss: 0.0006941034225746989 Validation Loss: 0.0018197329482063651\n",
      "9273 Training Loss: 0.0006524288328364491 Validation Loss: 0.0017760461196303368\n",
      "9274 Training Loss: 0.00074788584606722 Validation Loss: 0.0017021711682900786\n",
      "9275 Training Loss: 0.0011665901402011514 Validation Loss: 0.0016904388321563601\n",
      "9276 Training Loss: 0.0008423950057476759 Validation Loss: 0.0016828898806124926\n",
      "9277 Training Loss: 0.000818692147731781 Validation Loss: 0.0016441976185888052\n",
      "9278 Training Loss: 0.0007767822244204581 Validation Loss: 0.0016261122655123472\n",
      "9279 Training Loss: 0.001286298967897892 Validation Loss: 0.00166822609025985\n",
      "9280 Training Loss: 0.000747727055568248 Validation Loss: 0.0017103792633861303\n",
      "9281 Training Loss: 0.0009606776293367147 Validation Loss: 0.0017474633641541004\n",
      "9282 Training Loss: 0.0007561279344372451 Validation Loss: 0.0017247989308089018\n",
      "9283 Training Loss: 0.002357583027333021 Validation Loss: 0.0018719708314165473\n",
      "9284 Training Loss: 0.000720353564247489 Validation Loss: 0.0019287467002868652\n",
      "9285 Training Loss: 0.0013497993350028992 Validation Loss: 0.0020158367697149515\n",
      "9286 Training Loss: 0.0006527050863951445 Validation Loss: 0.002037528669461608\n",
      "9287 Training Loss: 0.000979772419668734 Validation Loss: 0.0019004986388608813\n",
      "9288 Training Loss: 0.0007605348946526647 Validation Loss: 0.0018148379167541862\n",
      "9289 Training Loss: 0.0011091690976172686 Validation Loss: 0.0017860138323158026\n",
      "9290 Training Loss: 0.0009281325619667768 Validation Loss: 0.0017818016931414604\n",
      "9291 Training Loss: 0.0007779389852657914 Validation Loss: 0.0018254645401611924\n",
      "9292 Training Loss: 0.0007256263052113354 Validation Loss: 0.0017814773600548506\n",
      "9293 Training Loss: 0.0006684876279905438 Validation Loss: 0.001695423386991024\n",
      "9294 Training Loss: 0.0008186219492927194 Validation Loss: 0.0016155706252902746\n",
      "9295 Training Loss: 0.0006988345412537456 Validation Loss: 0.001576215261593461\n",
      "9296 Training Loss: 0.0006639780476689339 Validation Loss: 0.0015698694624006748\n",
      "9297 Training Loss: 0.000707445724401623 Validation Loss: 0.0015834327787160873\n",
      "9298 Training Loss: 0.0006699387449771166 Validation Loss: 0.001618826761841774\n",
      "9299 Training Loss: 0.0007303247693926096 Validation Loss: 0.0016655217623338103\n",
      "9300 Training Loss: 0.0007732505910098553 Validation Loss: 0.0017241978785023093\n",
      "9301 Training Loss: 0.0008099573897197843 Validation Loss: 0.001757620950229466\n",
      "9302 Training Loss: 0.0007064755191095173 Validation Loss: 0.0017144600860774517\n",
      "9303 Training Loss: 0.0006641339277848601 Validation Loss: 0.0016707165632396936\n",
      "9304 Training Loss: 0.0006998798344284296 Validation Loss: 0.0016526358667761087\n",
      "9305 Training Loss: 0.0006296624196693301 Validation Loss: 0.0016577651258558035\n",
      "9306 Training Loss: 0.0013950681313872337 Validation Loss: 0.0017297990852966905\n",
      "9307 Training Loss: 0.0006410865462385118 Validation Loss: 0.0017915788339450955\n",
      "9308 Training Loss: 0.0007285652682185173 Validation Loss: 0.0018556599970906973\n",
      "9309 Training Loss: 0.0008012847974896431 Validation Loss: 0.0018442267319187522\n",
      "9310 Training Loss: 0.0010277330875396729 Validation Loss: 0.0018952840473502874\n",
      "9311 Training Loss: 0.0006941402098163962 Validation Loss: 0.00187286629807204\n",
      "9312 Training Loss: 0.0014192105736583471 Validation Loss: 0.0019405913772061467\n",
      "9313 Training Loss: 0.0007589971646666527 Validation Loss: 0.0019967250991612673\n",
      "9314 Training Loss: 0.0008484707213938236 Validation Loss: 0.001906946417875588\n",
      "9315 Training Loss: 0.0007409841637127101 Validation Loss: 0.0018098191358149052\n",
      "9316 Training Loss: 0.0006529990932904184 Validation Loss: 0.0017435812624171376\n",
      "9317 Training Loss: 0.0005684761563315988 Validation Loss: 0.0017160017741844058\n",
      "9318 Training Loss: 0.0007208966417238116 Validation Loss: 0.0017062572296708822\n",
      "9319 Training Loss: 0.0006717947544530034 Validation Loss: 0.00169320497661829\n",
      "9320 Training Loss: 0.000753473024815321 Validation Loss: 0.0017168766353279352\n",
      "9321 Training Loss: 0.000604153610765934 Validation Loss: 0.001736834878101945\n",
      "9322 Training Loss: 0.0007041943026706576 Validation Loss: 0.0016896040178835392\n",
      "9323 Training Loss: 0.0009529086528345942 Validation Loss: 0.0016575180925428867\n",
      "9324 Training Loss: 0.0009140013135038316 Validation Loss: 0.0016365862684324384\n",
      "9325 Training Loss: 0.000722863245755434 Validation Loss: 0.001628725789487362\n",
      "9326 Training Loss: 0.0013219171669334173 Validation Loss: 0.0016854555578902364\n",
      "9327 Training Loss: 0.0007623218698427081 Validation Loss: 0.0017439320217818022\n",
      "9328 Training Loss: 0.0006588100222870708 Validation Loss: 0.0017820141511037946\n",
      "9329 Training Loss: 0.0007011158159002662 Validation Loss: 0.0017728288657963276\n",
      "9330 Training Loss: 0.0006965480279177427 Validation Loss: 0.001728457398712635\n",
      "9331 Training Loss: 0.0007550769951194525 Validation Loss: 0.0016691742930561304\n",
      "9332 Training Loss: 0.0010260071139782667 Validation Loss: 0.001692323130555451\n",
      "9333 Training Loss: 0.000735628476832062 Validation Loss: 0.0017709198873490095\n",
      "9334 Training Loss: 0.0008526615565642715 Validation Loss: 0.0018243466038256884\n",
      "9335 Training Loss: 0.0009220748324878514 Validation Loss: 0.0018801072146743536\n",
      "9336 Training Loss: 0.0008499763207510114 Validation Loss: 0.001826450927183032\n",
      "9337 Training Loss: 0.0006579841719940305 Validation Loss: 0.0017506497679278255\n",
      "9338 Training Loss: 0.0006507206126116216 Validation Loss: 0.0017019195947796106\n",
      "9339 Training Loss: 0.0005958431866019964 Validation Loss: 0.0016699280822649598\n",
      "9340 Training Loss: 0.000663597253151238 Validation Loss: 0.001625414122827351\n",
      "9341 Training Loss: 0.000673607166390866 Validation Loss: 0.0015842104330658913\n",
      "9342 Training Loss: 0.0007284987368620932 Validation Loss: 0.0015774024650454521\n",
      "9343 Training Loss: 0.0006437180563807487 Validation Loss: 0.0015873115044087172\n",
      "9344 Training Loss: 0.0007340413285419345 Validation Loss: 0.0015781488036736846\n",
      "9345 Training Loss: 0.0006955609424039721 Validation Loss: 0.0015487121418118477\n",
      "9346 Training Loss: 0.0006757475202903152 Validation Loss: 0.0015054774703457952\n",
      "9347 Training Loss: 0.0010466950479894876 Validation Loss: 0.0014976938255131245\n",
      "9348 Training Loss: 0.0007819237653166056 Validation Loss: 0.0014833570457994938\n",
      "9349 Training Loss: 0.000821772264316678 Validation Loss: 0.0014843273675069213\n",
      "9350 Training Loss: 0.000648561748676002 Validation Loss: 0.0014862564858049154\n",
      "9351 Training Loss: 0.0007369454251602292 Validation Loss: 0.0014805995160713792\n",
      "9352 Training Loss: 0.0006459682481363416 Validation Loss: 0.001470243907533586\n",
      "9353 Training Loss: 0.0006263199611566961 Validation Loss: 0.0014699131716042757\n",
      "9354 Training Loss: 0.0015917614800855517 Validation Loss: 0.0015368617605417967\n",
      "9355 Training Loss: 0.0006954565178602934 Validation Loss: 0.0016129316063597798\n",
      "9356 Training Loss: 0.0006855829851701856 Validation Loss: 0.001649983343668282\n",
      "9357 Training Loss: 0.0008001457317732275 Validation Loss: 0.001597238820977509\n",
      "9358 Training Loss: 0.0008816855261102319 Validation Loss: 0.001538971089757979\n",
      "9359 Training Loss: 0.000824633170850575 Validation Loss: 0.0014987732283771038\n",
      "9360 Training Loss: 0.0006334616336971521 Validation Loss: 0.0014562890864908695\n",
      "9361 Training Loss: 0.0008172560483217239 Validation Loss: 0.0014544890727847815\n",
      "9362 Training Loss: 0.0005946207675151527 Validation Loss: 0.0014693259727209806\n",
      "9363 Training Loss: 0.0011560452403500676 Validation Loss: 0.0015580244362354279\n",
      "9364 Training Loss: 0.0006030765362083912 Validation Loss: 0.0016279533738270402\n",
      "9365 Training Loss: 0.0012875773245468736 Validation Loss: 0.0016536167822778225\n",
      "9366 Training Loss: 0.0012796360533684492 Validation Loss: 0.0016225469298660755\n",
      "9367 Training Loss: 0.0006923514883965254 Validation Loss: 0.0015660342760384083\n",
      "9368 Training Loss: 0.000676806434057653 Validation Loss: 0.001528894412331283\n",
      "9369 Training Loss: 0.0006953809061087668 Validation Loss: 0.001550690969452262\n",
      "9370 Training Loss: 0.0011554565280675888 Validation Loss: 0.0016147168353199959\n",
      "9371 Training Loss: 0.0006428301567211747 Validation Loss: 0.0016816295683383942\n",
      "9372 Training Loss: 0.0006362866843119264 Validation Loss: 0.0017236367566511035\n",
      "9373 Training Loss: 0.0006261991802603006 Validation Loss: 0.0017232586396858096\n",
      "9374 Training Loss: 0.000747364480048418 Validation Loss: 0.0016515855677425861\n",
      "9375 Training Loss: 0.0006514095584861934 Validation Loss: 0.0015903308521956205\n",
      "9376 Training Loss: 0.0007434963481500745 Validation Loss: 0.0015478956047445536\n",
      "9377 Training Loss: 0.0007131103775463998 Validation Loss: 0.0015183684881776571\n",
      "9378 Training Loss: 0.0009003746090456843 Validation Loss: 0.0015294865006580949\n",
      "9379 Training Loss: 0.0007738528656773269 Validation Loss: 0.0016312396619468927\n",
      "9380 Training Loss: 0.0009586338419467211 Validation Loss: 0.00177472154609859\n",
      "9381 Training Loss: 0.0010772093664854765 Validation Loss: 0.0018869758350774646\n",
      "9382 Training Loss: 0.0007189603056758642 Validation Loss: 0.0018742781830951571\n",
      "9383 Training Loss: 0.0009191221324726939 Validation Loss: 0.0017052649054676294\n",
      "9384 Training Loss: 0.0008240579045377672 Validation Loss: 0.0015562435146421194\n",
      "9385 Training Loss: 0.0006197239272296429 Validation Loss: 0.0015009419294074178\n",
      "9386 Training Loss: 0.0024437394458800554 Validation Loss: 0.0014861177187412977\n",
      "9387 Training Loss: 0.0006153867579996586 Validation Loss: 0.0015577517915517092\n",
      "9388 Training Loss: 0.0008205517660826445 Validation Loss: 0.0016135645564645529\n",
      "9389 Training Loss: 0.0012954281410202384 Validation Loss: 0.0016356866108253598\n",
      "9390 Training Loss: 0.0009321358520537615 Validation Loss: 0.0015972356777638197\n",
      "9391 Training Loss: 0.0007186494767665863 Validation Loss: 0.0015239451313391328\n",
      "9392 Training Loss: 0.0007064021192491055 Validation Loss: 0.001476180856116116\n",
      "9393 Training Loss: 0.0006263761315494776 Validation Loss: 0.0014843462267890573\n",
      "9394 Training Loss: 0.0020115324296057224 Validation Loss: 0.001547176856547594\n",
      "9395 Training Loss: 0.0006970408139750361 Validation Loss: 0.0016346729826182127\n",
      "9396 Training Loss: 0.0007564297411590815 Validation Loss: 0.0016601851675659418\n",
      "9397 Training Loss: 0.0011611084919422865 Validation Loss: 0.0016680328408256173\n",
      "9398 Training Loss: 0.0007703278679400682 Validation Loss: 0.0015997859882190824\n",
      "9399 Training Loss: 0.0006115860887803137 Validation Loss: 0.0015177911845967174\n",
      "9400 Training Loss: 0.0005992873338982463 Validation Loss: 0.0014807403786107898\n",
      "9401 Training Loss: 0.0006683133542537689 Validation Loss: 0.0014790223212912679\n",
      "9402 Training Loss: 0.000605372479185462 Validation Loss: 0.0014834442408755422\n",
      "9403 Training Loss: 0.0008022702531889081 Validation Loss: 0.0015407097525894642\n",
      "9404 Training Loss: 0.0006922662723809481 Validation Loss: 0.0016037541208788753\n",
      "9405 Training Loss: 0.0006824730662629008 Validation Loss: 0.0016266641905531287\n",
      "9406 Training Loss: 0.0007109852158464491 Validation Loss: 0.001610245555639267\n",
      "9407 Training Loss: 0.0007208772003650665 Validation Loss: 0.001579479081556201\n",
      "9408 Training Loss: 0.0006601950153708458 Validation Loss: 0.0015219728229567409\n",
      "9409 Training Loss: 0.0008053833735175431 Validation Loss: 0.0015112010296434164\n",
      "9410 Training Loss: 0.0006287377909757197 Validation Loss: 0.0015179499750956893\n",
      "9411 Training Loss: 0.0007614113274030387 Validation Loss: 0.001516107004135847\n",
      "9412 Training Loss: 0.0005462982226163149 Validation Loss: 0.001531383371911943\n",
      "9413 Training Loss: 0.001360066351480782 Validation Loss: 0.001637737383134663\n",
      "9414 Training Loss: 0.000686214305460453 Validation Loss: 0.0017576934769749641\n",
      "9415 Training Loss: 0.000716291950084269 Validation Loss: 0.0017550393240526319\n",
      "9416 Training Loss: 0.0005650807870551944 Validation Loss: 0.001710238284431398\n",
      "9417 Training Loss: 0.0012405789457261562 Validation Loss: 0.0017532027559354901\n",
      "9418 Training Loss: 0.0006236179615370929 Validation Loss: 0.0017842586385086179\n",
      "9419 Training Loss: 0.0006181655917316675 Validation Loss: 0.0017758499598130584\n",
      "9420 Training Loss: 0.0007417930755764246 Validation Loss: 0.0017329833935946226\n",
      "9421 Training Loss: 0.0007638840470463037 Validation Loss: 0.0016846617218106985\n",
      "9422 Training Loss: 0.001040191389620304 Validation Loss: 0.001683108159340918\n",
      "9423 Training Loss: 0.0008036885410547256 Validation Loss: 0.0016795031260699034\n",
      "9424 Training Loss: 0.0008231853134930134 Validation Loss: 0.0015898804413154721\n",
      "9425 Training Loss: 0.001029690494760871 Validation Loss: 0.0015317886136472225\n",
      "9426 Training Loss: 0.0006585063529200852 Validation Loss: 0.0014821616932749748\n",
      "9427 Training Loss: 0.0007439557812176645 Validation Loss: 0.0014411110896617174\n",
      "9428 Training Loss: 0.0011112138163298368 Validation Loss: 0.0014248557854443789\n",
      "9429 Training Loss: 0.0006618384504690766 Validation Loss: 0.0014202094171196222\n",
      "9430 Training Loss: 0.0006586738163605332 Validation Loss: 0.0014321057824417949\n",
      "9431 Training Loss: 0.0006522807525470853 Validation Loss: 0.0014778808690607548\n",
      "9432 Training Loss: 0.0007845942163839936 Validation Loss: 0.0015457447152584791\n",
      "9433 Training Loss: 0.0007431929698213935 Validation Loss: 0.0015564674977213144\n",
      "9434 Training Loss: 0.0006602891953662038 Validation Loss: 0.0015318852383643389\n",
      "9435 Training Loss: 0.0006844487506896257 Validation Loss: 0.0014722754713147879\n",
      "9436 Training Loss: 0.0007332292152568698 Validation Loss: 0.0014151587383821607\n",
      "9437 Training Loss: 0.0006593625294044614 Validation Loss: 0.001371448510326445\n",
      "9438 Training Loss: 0.0006528990343213081 Validation Loss: 0.001364949974231422\n",
      "9439 Training Loss: 0.0006237752386368811 Validation Loss: 0.0013846983201801777\n",
      "9440 Training Loss: 0.0006768977036699653 Validation Loss: 0.001397696090862155\n",
      "9441 Training Loss: 0.0006364731816574931 Validation Loss: 0.0014106315793469548\n",
      "9442 Training Loss: 0.0006464992766268551 Validation Loss: 0.0014058463275432587\n",
      "9443 Training Loss: 0.0005957521498203278 Validation Loss: 0.0013927643885836005\n",
      "9444 Training Loss: 0.000638522207736969 Validation Loss: 0.0013976938789710402\n",
      "9445 Training Loss: 0.001393703161738813 Validation Loss: 0.0014831870794296265\n",
      "9446 Training Loss: 0.0006571360281668603 Validation Loss: 0.0015573474811390042\n",
      "9447 Training Loss: 0.0007836384465917945 Validation Loss: 0.0015943435719236732\n",
      "9448 Training Loss: 0.0006144129438325763 Validation Loss: 0.0015602577477693558\n",
      "9449 Training Loss: 0.0007543403189629316 Validation Loss: 0.001465570880100131\n",
      "9450 Training Loss: 0.0005813033785670996 Validation Loss: 0.0013983548851683736\n",
      "9451 Training Loss: 0.0006171875866129994 Validation Loss: 0.001382230082526803\n",
      "9452 Training Loss: 0.0006436004769057035 Validation Loss: 0.001385809970088303\n",
      "9453 Training Loss: 0.0012838360853493214 Validation Loss: 0.0014754222938790917\n",
      "9454 Training Loss: 0.0006753639318048954 Validation Loss: 0.0015883061569184065\n",
      "9455 Training Loss: 0.0005833788309246302 Validation Loss: 0.0016449264949187636\n",
      "9456 Training Loss: 0.0006914126570336521 Validation Loss: 0.0016224690480157733\n",
      "9457 Training Loss: 0.0005938677350059152 Validation Loss: 0.001581016113050282\n",
      "9458 Training Loss: 0.001025626203045249 Validation Loss: 0.001548071508295834\n",
      "9459 Training Loss: 0.000616554927546531 Validation Loss: 0.0015187158714979887\n",
      "9460 Training Loss: 0.0008020949317142367 Validation Loss: 0.0014956198865547776\n",
      "9461 Training Loss: 0.000695974740665406 Validation Loss: 0.001474382122978568\n",
      "9462 Training Loss: 0.0007455303566530347 Validation Loss: 0.0014926317380741239\n",
      "9463 Training Loss: 0.0006924116751179099 Validation Loss: 0.0015096443239599466\n",
      "9464 Training Loss: 0.0007175913779065013 Validation Loss: 0.0015217415057122707\n",
      "9465 Training Loss: 0.0011448408477008343 Validation Loss: 0.0015224923845380545\n",
      "9466 Training Loss: 0.0006472738459706306 Validation Loss: 0.0015191946877166629\n",
      "9467 Training Loss: 0.0007209945470094681 Validation Loss: 0.0014778308104723692\n",
      "9468 Training Loss: 0.0007243993459269404 Validation Loss: 0.0014747562818229198\n",
      "9469 Training Loss: 0.0009521091706119478 Validation Loss: 0.0014745985390618443\n",
      "9470 Training Loss: 0.0005443852860480547 Validation Loss: 0.0014846065314486623\n",
      "9471 Training Loss: 0.0006720946403220296 Validation Loss: 0.0014664741465821862\n",
      "9472 Training Loss: 0.0005846306448802352 Validation Loss: 0.00145624834112823\n",
      "9473 Training Loss: 0.0005965968011878431 Validation Loss: 0.0014353778678923845\n",
      "9474 Training Loss: 0.0007838585879653692 Validation Loss: 0.0013798816362395883\n",
      "9475 Training Loss: 0.0006822384893894196 Validation Loss: 0.0013558880891650915\n",
      "9476 Training Loss: 0.0006380942650139332 Validation Loss: 0.0013416701694950461\n",
      "9477 Training Loss: 0.0006832167855463922 Validation Loss: 0.0013353766407817602\n",
      "9478 Training Loss: 0.0006931615062057972 Validation Loss: 0.0013380642049014568\n",
      "9479 Training Loss: 0.001280798576772213 Validation Loss: 0.0013872416457161307\n",
      "9480 Training Loss: 0.0005598999559879303 Validation Loss: 0.0014533235225826502\n",
      "9481 Training Loss: 0.0006077182479202747 Validation Loss: 0.0014835722977295518\n",
      "9482 Training Loss: 0.0006832759245298803 Validation Loss: 0.0014380748616531491\n",
      "9483 Training Loss: 0.0007167948642745614 Validation Loss: 0.0013980872463434935\n",
      "9484 Training Loss: 0.0006219946080818772 Validation Loss: 0.0013669657055288553\n",
      "9485 Training Loss: 0.0006507441285066307 Validation Loss: 0.001359590096399188\n",
      "9486 Training Loss: 0.0006943263579159975 Validation Loss: 0.0013489763950929046\n",
      "9487 Training Loss: 0.0005899817915633321 Validation Loss: 0.0013402204494923353\n",
      "9488 Training Loss: 0.0006265423726290464 Validation Loss: 0.0013314104871824384\n",
      "9489 Training Loss: 0.0006075546843931079 Validation Loss: 0.0013196372892707586\n",
      "9490 Training Loss: 0.0005680567119270563 Validation Loss: 0.0013111080043017864\n",
      "9491 Training Loss: 0.0006364224245771766 Validation Loss: 0.0013117230264469981\n",
      "9492 Training Loss: 0.0007548438152298331 Validation Loss: 0.0013273111544549465\n",
      "9493 Training Loss: 0.0006429002387449145 Validation Loss: 0.0013316370313987136\n",
      "9494 Training Loss: 0.0005710203549824655 Validation Loss: 0.0013347796630114317\n",
      "9495 Training Loss: 0.0007364160846918821 Validation Loss: 0.0013366012135520577\n",
      "9496 Training Loss: 0.0005927552119828761 Validation Loss: 0.0013359112199395895\n",
      "9497 Training Loss: 0.000603219261392951 Validation Loss: 0.001334988046437502\n",
      "9498 Training Loss: 0.0007729232311248779 Validation Loss: 0.0013354518450796604\n",
      "9499 Training Loss: 0.000573372992221266 Validation Loss: 0.0013202406698837876\n",
      "9500 Training Loss: 0.0006349257309921086 Validation Loss: 0.0012957621365785599\n",
      "9501 Training Loss: 0.0007339381263591349 Validation Loss: 0.0012640411732718349\n",
      "9502 Training Loss: 0.0007504990790039301 Validation Loss: 0.001251768204383552\n",
      "9503 Training Loss: 0.0006269257282838225 Validation Loss: 0.0012505047488957644\n",
      "9504 Training Loss: 0.0007548974826931953 Validation Loss: 0.0012588336830958724\n",
      "9505 Training Loss: 0.0007760510197840631 Validation Loss: 0.0012983722845092416\n",
      "9506 Training Loss: 0.0006543235504068434 Validation Loss: 0.0013545644469559193\n",
      "9507 Training Loss: 0.0005848378059454262 Validation Loss: 0.0014007216086611152\n",
      "9508 Training Loss: 0.0006724452250637114 Validation Loss: 0.0014451409224420786\n",
      "9509 Training Loss: 0.0005728048272430897 Validation Loss: 0.0014680178137496114\n",
      "9510 Training Loss: 0.0012210230343043804 Validation Loss: 0.0015357360243797302\n",
      "9511 Training Loss: 0.000799282337538898 Validation Loss: 0.001542325597256422\n",
      "9512 Training Loss: 0.0006163803627714515 Validation Loss: 0.0015112808905541897\n",
      "9513 Training Loss: 0.0006518767913803458 Validation Loss: 0.0014499995158985257\n",
      "9514 Training Loss: 0.0007436102023348212 Validation Loss: 0.0013687207829207182\n",
      "9515 Training Loss: 0.0010201497934758663 Validation Loss: 0.001339426962658763\n",
      "9516 Training Loss: 0.000625950051471591 Validation Loss: 0.00132167327683419\n",
      "9517 Training Loss: 0.0007462562061846256 Validation Loss: 0.0013014652067795396\n",
      "9518 Training Loss: 0.0005603699246421456 Validation Loss: 0.0012973216362297535\n",
      "9519 Training Loss: 0.0006360615370795131 Validation Loss: 0.001307017169892788\n",
      "9520 Training Loss: 0.000649458437692374 Validation Loss: 0.001313942251726985\n",
      "9521 Training Loss: 0.0006935851415619254 Validation Loss: 0.0013293096562847495\n",
      "9522 Training Loss: 0.0007885080412961543 Validation Loss: 0.001386907882988453\n",
      "9523 Training Loss: 0.0006429711356759071 Validation Loss: 0.0014304510550573468\n",
      "9524 Training Loss: 0.0005773441516794264 Validation Loss: 0.0014404987450689077\n",
      "9525 Training Loss: 0.0013180531095713377 Validation Loss: 0.001462776679545641\n",
      "9526 Training Loss: 0.0005864914273843169 Validation Loss: 0.0014671458629891276\n",
      "9527 Training Loss: 0.0006073205731809139 Validation Loss: 0.0014731333358213305\n",
      "9528 Training Loss: 0.001098509645089507 Validation Loss: 0.0015028177294880152\n",
      "9529 Training Loss: 0.0006097139557823539 Validation Loss: 0.0014792957808822393\n",
      "9530 Training Loss: 0.0006933101685717702 Validation Loss: 0.0014169481582939625\n",
      "9531 Training Loss: 0.0006599484477192163 Validation Loss: 0.001377847627736628\n",
      "9532 Training Loss: 0.000606355257332325 Validation Loss: 0.0013753410894423723\n",
      "9533 Training Loss: 0.000724523386452347 Validation Loss: 0.0013657920062541962\n",
      "9534 Training Loss: 0.0010971958981826901 Validation Loss: 0.0014310276601463556\n",
      "9535 Training Loss: 0.0007816323777660728 Validation Loss: 0.001542358659207821\n",
      "9536 Training Loss: 0.0006753823254257441 Validation Loss: 0.0016479212790727615\n",
      "9537 Training Loss: 0.0008804438402876258 Validation Loss: 0.0015948809450492263\n",
      "9538 Training Loss: 0.0006816777167841792 Validation Loss: 0.0014878170331940055\n",
      "9539 Training Loss: 0.0005779498023912311 Validation Loss: 0.0014406666159629822\n",
      "9540 Training Loss: 0.0005742238136008382 Validation Loss: 0.0014115053927525878\n",
      "9541 Training Loss: 0.0006073687109164894 Validation Loss: 0.001395083381794393\n",
      "9542 Training Loss: 0.0005979568231850863 Validation Loss: 0.0013990262523293495\n",
      "9543 Training Loss: 0.0006388311740010977 Validation Loss: 0.0014270329847931862\n",
      "9544 Training Loss: 0.0005425303243100643 Validation Loss: 0.0014520821860060096\n",
      "9545 Training Loss: 0.0006450063665397465 Validation Loss: 0.0014571113279089332\n",
      "9546 Training Loss: 0.0007641845149919391 Validation Loss: 0.001442472916096449\n",
      "9547 Training Loss: 0.0008938204264268279 Validation Loss: 0.0014833981404080987\n",
      "9548 Training Loss: 0.0005947269964963198 Validation Loss: 0.0014865369303151965\n",
      "9549 Training Loss: 0.0007618381641805172 Validation Loss: 0.0014829954598098993\n",
      "9550 Training Loss: 0.0006093262345530093 Validation Loss: 0.00149507075548172\n",
      "9551 Training Loss: 0.000591023825109005 Validation Loss: 0.0015021594008430839\n",
      "9552 Training Loss: 0.0006500488379970193 Validation Loss: 0.0014919245149940252\n",
      "9553 Training Loss: 0.0005472812335938215 Validation Loss: 0.0014890816528350115\n",
      "9554 Training Loss: 0.0005718071479350328 Validation Loss: 0.001505511929281056\n",
      "9555 Training Loss: 0.0006007665651850402 Validation Loss: 0.0015081882011145353\n",
      "9556 Training Loss: 0.0007543458486907184 Validation Loss: 0.0014576776884496212\n",
      "9557 Training Loss: 0.0005526940803974867 Validation Loss: 0.0014110682532191277\n",
      "9558 Training Loss: 0.0017109803156927228 Validation Loss: 0.001466433866880834\n",
      "9559 Training Loss: 0.0005288069369271398 Validation Loss: 0.0015195219311863184\n",
      "9560 Training Loss: 0.0005869801389053464 Validation Loss: 0.0015375636285170913\n",
      "9561 Training Loss: 0.0013396956492215395 Validation Loss: 0.0015686543192714453\n",
      "9562 Training Loss: 0.0009883235907182097 Validation Loss: 0.0015832590870559216\n",
      "9563 Training Loss: 0.0006249743746593595 Validation Loss: 0.0015482963062822819\n",
      "9564 Training Loss: 0.0007422696216963232 Validation Loss: 0.0014683788176625967\n",
      "9565 Training Loss: 0.0005933736683800817 Validation Loss: 0.0014394018799066544\n",
      "9566 Training Loss: 0.0010634997161105275 Validation Loss: 0.0014498450327664614\n",
      "9567 Training Loss: 0.0006097953882999718 Validation Loss: 0.0014729519607499242\n",
      "9568 Training Loss: 0.0005339214112609625 Validation Loss: 0.0015111231477931142\n",
      "9569 Training Loss: 0.0005965907475911081 Validation Loss: 0.0015278708888217807\n",
      "9570 Training Loss: 0.001039396389387548 Validation Loss: 0.0015225616516545415\n",
      "9571 Training Loss: 0.000961695855949074 Validation Loss: 0.0015132967382669449\n",
      "9572 Training Loss: 0.000601631123572588 Validation Loss: 0.0014663668116554618\n",
      "9573 Training Loss: 0.0006453043897636235 Validation Loss: 0.0014199831057339907\n",
      "9574 Training Loss: 0.0008497360395267606 Validation Loss: 0.0013960279757156968\n",
      "9575 Training Loss: 0.001162826782092452 Validation Loss: 0.0014348397962749004\n",
      "9576 Training Loss: 0.0008694737916812301 Validation Loss: 0.0014659014996141195\n",
      "9577 Training Loss: 0.0007304883911274374 Validation Loss: 0.001435140031389892\n",
      "9578 Training Loss: 0.0011337645119056106 Validation Loss: 0.0014721081824973226\n",
      "9579 Training Loss: 0.0007163448026403785 Validation Loss: 0.0015160954790189862\n",
      "9580 Training Loss: 0.0008570668869651854 Validation Loss: 0.001569171086885035\n",
      "9581 Training Loss: 0.0005323659861460328 Validation Loss: 0.0016165361739695072\n",
      "9582 Training Loss: 0.0006231029983609915 Validation Loss: 0.0016172491014003754\n",
      "9583 Training Loss: 0.0011205084156244993 Validation Loss: 0.0016445863293483853\n",
      "9584 Training Loss: 0.0005406491691246629 Validation Loss: 0.0016913121799007058\n",
      "9585 Training Loss: 0.0005447466392070055 Validation Loss: 0.001764520420692861\n",
      "9586 Training Loss: 0.0006545865908265114 Validation Loss: 0.0017940305406227708\n",
      "9587 Training Loss: 0.0006259440560825169 Validation Loss: 0.0017389619024470448\n",
      "9588 Training Loss: 0.0009355051442980766 Validation Loss: 0.0017746771918609738\n",
      "9589 Training Loss: 0.0006361012347042561 Validation Loss: 0.0017270849784836173\n",
      "9590 Training Loss: 0.000623545260168612 Validation Loss: 0.0016429831739515066\n",
      "9591 Training Loss: 0.0007072282023727894 Validation Loss: 0.0015491003869101405\n",
      "9592 Training Loss: 0.0006786114536225796 Validation Loss: 0.0014892241451889277\n",
      "9593 Training Loss: 0.000658459379337728 Validation Loss: 0.0014447355642914772\n",
      "9594 Training Loss: 0.0006413058144971728 Validation Loss: 0.0014206685591489077\n",
      "9595 Training Loss: 0.0006287349970079958 Validation Loss: 0.0014183929888531566\n",
      "9596 Training Loss: 0.0005920607363805175 Validation Loss: 0.0014326940290629864\n",
      "9597 Training Loss: 0.0006001030560582876 Validation Loss: 0.001441520405933261\n",
      "9598 Training Loss: 0.0009298902004957199 Validation Loss: 0.0014883746625855565\n",
      "9599 Training Loss: 0.0007651113555766642 Validation Loss: 0.0015287559945136309\n",
      "9600 Training Loss: 0.0006511171814054251 Validation Loss: 0.0015137610025703907\n",
      "9601 Training Loss: 0.0006750059546902776 Validation Loss: 0.0014399167848750949\n",
      "9602 Training Loss: 0.0006481553427875042 Validation Loss: 0.001379739143885672\n",
      "9603 Training Loss: 0.0006100033642724156 Validation Loss: 0.0013366976054385304\n",
      "9604 Training Loss: 0.0005886363214813173 Validation Loss: 0.0013152649626135826\n",
      "9605 Training Loss: 0.0006084870547056198 Validation Loss: 0.0013433170970529318\n",
      "9606 Training Loss: 0.0006233883323147893 Validation Loss: 0.001399504137225449\n",
      "9607 Training Loss: 0.0009382987627759576 Validation Loss: 0.0014899398665875196\n",
      "9608 Training Loss: 0.0006761150434613228 Validation Loss: 0.0015009563649073243\n",
      "9609 Training Loss: 0.0006094749551266432 Validation Loss: 0.0014316632878035307\n",
      "9610 Training Loss: 0.0005671126418747008 Validation Loss: 0.0013798018917441368\n",
      "9611 Training Loss: 0.0005257559241726995 Validation Loss: 0.0013729044003412127\n",
      "9612 Training Loss: 0.0008451426983810961 Validation Loss: 0.0013733382802456617\n",
      "9613 Training Loss: 0.0008846789132803679 Validation Loss: 0.0013977705966681242\n",
      "9614 Training Loss: 0.0006278469809331 Validation Loss: 0.0014162905281409621\n",
      "9615 Training Loss: 0.0005724667571485043 Validation Loss: 0.001401505433022976\n",
      "9616 Training Loss: 0.0006726220017299056 Validation Loss: 0.0013179694069549441\n",
      "9617 Training Loss: 0.0005750358104705811 Validation Loss: 0.0012554971035569906\n",
      "9618 Training Loss: 0.0007545589469373226 Validation Loss: 0.0012469892390072346\n",
      "9619 Training Loss: 0.0006145431543700397 Validation Loss: 0.0012521500466391444\n",
      "9620 Training Loss: 0.0007370511302724481 Validation Loss: 0.0013038469478487968\n",
      "9621 Training Loss: 0.0005206164787523448 Validation Loss: 0.0013859232421964407\n",
      "9622 Training Loss: 0.0007346307393163443 Validation Loss: 0.001496866112574935\n",
      "9623 Training Loss: 0.0007402931223623455 Validation Loss: 0.0015339828096330166\n",
      "9624 Training Loss: 0.0007501437794417143 Validation Loss: 0.0014933268539607525\n",
      "9625 Training Loss: 0.0007047793478704989 Validation Loss: 0.0014440527884289622\n",
      "9626 Training Loss: 0.0005585162434726954 Validation Loss: 0.0014103909488767385\n",
      "9627 Training Loss: 0.0006361219566315413 Validation Loss: 0.001396134844981134\n",
      "9628 Training Loss: 0.000501454109326005 Validation Loss: 0.0014187071938067675\n",
      "9629 Training Loss: 0.0006435117102228105 Validation Loss: 0.0014131763018667698\n",
      "9630 Training Loss: 0.0007874687435105443 Validation Loss: 0.0014118424151092768\n",
      "9631 Training Loss: 0.0006610807031393051 Validation Loss: 0.0013674830552190542\n",
      "9632 Training Loss: 0.0007669879123568535 Validation Loss: 0.001332647050730884\n",
      "9633 Training Loss: 0.0005546757020056248 Validation Loss: 0.0013062035432085395\n",
      "9634 Training Loss: 0.0007628327002748847 Validation Loss: 0.0013222306733950973\n",
      "9635 Training Loss: 0.0006172551074996591 Validation Loss: 0.0013519839849323034\n",
      "9636 Training Loss: 0.0005709797842428088 Validation Loss: 0.0014044911367818713\n",
      "9637 Training Loss: 0.0005514995427802205 Validation Loss: 0.0014291484840214252\n",
      "9638 Training Loss: 0.000576262769754976 Validation Loss: 0.0014281404437497258\n",
      "9639 Training Loss: 0.00055971450638026 Validation Loss: 0.0014089103788137436\n",
      "9640 Training Loss: 0.0007348982617259026 Validation Loss: 0.0014008971629664302\n",
      "9641 Training Loss: 0.001044971402734518 Validation Loss: 0.0013970425352454185\n",
      "9642 Training Loss: 0.0005219069425947964 Validation Loss: 0.001399879576638341\n",
      "9643 Training Loss: 0.0010987737914547324 Validation Loss: 0.0014464535051956773\n",
      "9644 Training Loss: 0.00063101458363235 Validation Loss: 0.001456648693419993\n",
      "9645 Training Loss: 0.0007408626843243837 Validation Loss: 0.0014418507926166058\n",
      "9646 Training Loss: 0.0006616096943616867 Validation Loss: 0.0013845143839716911\n",
      "9647 Training Loss: 0.0005289982073009014 Validation Loss: 0.0013722474686801434\n",
      "9648 Training Loss: 0.0006841887952759862 Validation Loss: 0.0013894089497625828\n",
      "9649 Training Loss: 0.0006316367071121931 Validation Loss: 0.0014026996213942766\n",
      "9650 Training Loss: 0.0008574251551181078 Validation Loss: 0.0014739499893039465\n",
      "9651 Training Loss: 0.0005417707725428045 Validation Loss: 0.001518716337159276\n",
      "9652 Training Loss: 0.000618303834926337 Validation Loss: 0.0014887835131958127\n",
      "9653 Training Loss: 0.0007446797681041062 Validation Loss: 0.0014496195362880826\n",
      "9654 Training Loss: 0.0006291554309427738 Validation Loss: 0.0013755029067397118\n",
      "9655 Training Loss: 0.0006523524643853307 Validation Loss: 0.0013119550421833992\n",
      "9656 Training Loss: 0.0005842929822392762 Validation Loss: 0.0012941905297338963\n",
      "9657 Training Loss: 0.0009613436413928866 Validation Loss: 0.0013161583337932825\n",
      "9658 Training Loss: 0.0006972321425564587 Validation Loss: 0.001368941506370902\n",
      "9659 Training Loss: 0.000624610111117363 Validation Loss: 0.0014375484315678477\n",
      "9660 Training Loss: 0.000695088820066303 Validation Loss: 0.0014642024179920554\n",
      "9661 Training Loss: 0.0006497063441202044 Validation Loss: 0.001381846028380096\n",
      "9662 Training Loss: 0.0007526071858592331 Validation Loss: 0.0013055640738457441\n",
      "9663 Training Loss: 0.0006287561263889074 Validation Loss: 0.0012835105881094933\n",
      "9664 Training Loss: 0.00064560875762254 Validation Loss: 0.0012801274424418807\n",
      "9665 Training Loss: 0.0008949904004111886 Validation Loss: 0.0013614012859761715\n",
      "9666 Training Loss: 0.0008325573289766908 Validation Loss: 0.0015718613285571337\n",
      "9667 Training Loss: 0.0006520167808048427 Validation Loss: 0.0016716951504349709\n",
      "9668 Training Loss: 0.0007397293811663985 Validation Loss: 0.0015485938638448715\n",
      "9669 Training Loss: 0.0005876895738765597 Validation Loss: 0.0014022819232195616\n",
      "9670 Training Loss: 0.0005096715176478028 Validation Loss: 0.0013373458059504628\n",
      "9671 Training Loss: 0.0006566309602931142 Validation Loss: 0.0012977378210052848\n",
      "9672 Training Loss: 0.0008337917388416827 Validation Loss: 0.0012671271106228232\n",
      "9673 Training Loss: 0.0006751406472176313 Validation Loss: 0.0012997706653550267\n",
      "9674 Training Loss: 0.0016449415124952793 Validation Loss: 0.001511693000793457\n",
      "9675 Training Loss: 0.0008904646383598447 Validation Loss: 0.0016669577453285456\n",
      "9676 Training Loss: 0.0007339046569541097 Validation Loss: 0.0016134455800056458\n",
      "9677 Training Loss: 0.0007423643837682903 Validation Loss: 0.0014897020300850272\n",
      "9678 Training Loss: 0.0005749124684371054 Validation Loss: 0.0014144767774268985\n",
      "9679 Training Loss: 0.0006021613953635097 Validation Loss: 0.0014227309729903936\n",
      "9680 Training Loss: 0.0006674338364973664 Validation Loss: 0.0014268959639593959\n",
      "9681 Training Loss: 0.0006657473277300596 Validation Loss: 0.0014646168565377593\n",
      "9682 Training Loss: 0.0005854660412296653 Validation Loss: 0.0015373554779216647\n",
      "9683 Training Loss: 0.000637925521004945 Validation Loss: 0.001627122052013874\n",
      "9684 Training Loss: 0.0006658383645117283 Validation Loss: 0.0015800531255081296\n",
      "9685 Training Loss: 0.0007908818079158664 Validation Loss: 0.0015041542937979102\n",
      "9686 Training Loss: 0.0006491077365353703 Validation Loss: 0.0013914809096604586\n",
      "9687 Training Loss: 0.0005529858754016459 Validation Loss: 0.0013469477416947484\n",
      "9688 Training Loss: 0.0005512613570317626 Validation Loss: 0.0013318880228325725\n",
      "9689 Training Loss: 0.0005610783118754625 Validation Loss: 0.0013184401905164123\n",
      "9690 Training Loss: 0.0007967165438458323 Validation Loss: 0.001349655445665121\n",
      "9691 Training Loss: 0.0006537314038723707 Validation Loss: 0.0014839362120255828\n",
      "9692 Training Loss: 0.000665694591589272 Validation Loss: 0.0015310985036194324\n",
      "9693 Training Loss: 0.000741276191547513 Validation Loss: 0.0014490931062027812\n",
      "9694 Training Loss: 0.000912358402274549 Validation Loss: 0.0013715291861444712\n",
      "9695 Training Loss: 0.0006112668197602034 Validation Loss: 0.0013135583139955997\n",
      "9696 Training Loss: 0.0005210518720559776 Validation Loss: 0.0012904999312013388\n",
      "9697 Training Loss: 0.0006370008923113346 Validation Loss: 0.0012688969727605581\n",
      "9698 Training Loss: 0.0005450629978440702 Validation Loss: 0.0012683868408203125\n",
      "9699 Training Loss: 0.001157792517915368 Validation Loss: 0.0013343332102522254\n",
      "9700 Training Loss: 0.0009421050199307501 Validation Loss: 0.001453607575967908\n",
      "9701 Training Loss: 0.0006354991928674281 Validation Loss: 0.0014853691682219505\n",
      "9702 Training Loss: 0.0006345552392303944 Validation Loss: 0.0014036563225090504\n",
      "9703 Training Loss: 0.000581857399083674 Validation Loss: 0.0013156551867723465\n",
      "9704 Training Loss: 0.0005933275097049773 Validation Loss: 0.0012954345438629389\n",
      "9705 Training Loss: 0.0005715540028177202 Validation Loss: 0.0012807780876755714\n",
      "9706 Training Loss: 0.0007071130676195025 Validation Loss: 0.001259406330063939\n",
      "9707 Training Loss: 0.0005416012136265635 Validation Loss: 0.0012976950965821743\n",
      "9708 Training Loss: 0.000511588470544666 Validation Loss: 0.0013705611927434802\n",
      "9709 Training Loss: 0.000533490558154881 Validation Loss: 0.001402204274199903\n",
      "9710 Training Loss: 0.0006505429628305137 Validation Loss: 0.0013746193144470453\n",
      "9711 Training Loss: 0.0007736096740700305 Validation Loss: 0.0013450022088363767\n",
      "9712 Training Loss: 0.0005503114080056548 Validation Loss: 0.0013029557885602117\n",
      "9713 Training Loss: 0.0006313661579042673 Validation Loss: 0.0012746455613523722\n",
      "9714 Training Loss: 0.000770556041970849 Validation Loss: 0.0012821574928238988\n",
      "9715 Training Loss: 0.0005732515128329396 Validation Loss: 0.0012925092596560717\n",
      "9716 Training Loss: 0.0004957952187396586 Validation Loss: 0.0013186082942411304\n",
      "9717 Training Loss: 0.0008280195761471987 Validation Loss: 0.0013772203819826245\n",
      "9718 Training Loss: 0.000780323171056807 Validation Loss: 0.001417276682332158\n",
      "9719 Training Loss: 0.000542003836017102 Validation Loss: 0.0014031395548954606\n",
      "9720 Training Loss: 0.0006169842672534287 Validation Loss: 0.00135809148196131\n",
      "9721 Training Loss: 0.0006493676919490099 Validation Loss: 0.0013131697196513414\n",
      "9722 Training Loss: 0.0006797208916395903 Validation Loss: 0.0013035725569352508\n",
      "9723 Training Loss: 0.0005433144979178905 Validation Loss: 0.001310361665673554\n",
      "9724 Training Loss: 0.0005992569494992495 Validation Loss: 0.0013624380808323622\n",
      "9725 Training Loss: 0.0007135222549550235 Validation Loss: 0.0014266425278037786\n",
      "9726 Training Loss: 0.000926516717299819 Validation Loss: 0.0015135214198380709\n",
      "9727 Training Loss: 0.0007909687119536102 Validation Loss: 0.0015332048060372472\n",
      "9728 Training Loss: 0.0006870284560136497 Validation Loss: 0.0014232391258701682\n",
      "9729 Training Loss: 0.0005874736234545708 Validation Loss: 0.0013256506063044071\n",
      "9730 Training Loss: 0.0005369841819629073 Validation Loss: 0.0012933643301948905\n",
      "9731 Training Loss: 0.0005318273324519396 Validation Loss: 0.0012776643270626664\n",
      "9732 Training Loss: 0.0006198963383212686 Validation Loss: 0.001282617449760437\n",
      "9733 Training Loss: 0.00048224953934550285 Validation Loss: 0.001327129197306931\n",
      "9734 Training Loss: 0.0005627726204693317 Validation Loss: 0.001403552363626659\n",
      "9735 Training Loss: 0.0006199849885888398 Validation Loss: 0.0014229340013116598\n",
      "9736 Training Loss: 0.0009159587207250297 Validation Loss: 0.001407782663591206\n",
      "9737 Training Loss: 0.0008348753908649087 Validation Loss: 0.0014263687189668417\n",
      "9738 Training Loss: 0.0005552046932280064 Validation Loss: 0.0013774384278804064\n",
      "9739 Training Loss: 0.001000316347926855 Validation Loss: 0.001380910980515182\n",
      "9740 Training Loss: 0.00057508290046826 Validation Loss: 0.0013716373359784484\n",
      "9741 Training Loss: 0.0008087895112112164 Validation Loss: 0.0013948874548077583\n",
      "9742 Training Loss: 0.0006103417254053056 Validation Loss: 0.001398321590386331\n",
      "9743 Training Loss: 0.0005787740228697658 Validation Loss: 0.0014080553082749248\n",
      "9744 Training Loss: 0.0009324365528300405 Validation Loss: 0.001462256070226431\n",
      "9745 Training Loss: 0.0005123716546222568 Validation Loss: 0.0014933199854567647\n",
      "9746 Training Loss: 0.0007196309161372483 Validation Loss: 0.0014706971123814583\n",
      "9747 Training Loss: 0.0005460572429001331 Validation Loss: 0.001440127962268889\n",
      "9748 Training Loss: 0.0005969165358692408 Validation Loss: 0.0014102911809459329\n",
      "9749 Training Loss: 0.0005771692376583815 Validation Loss: 0.0014225681079551578\n",
      "9750 Training Loss: 0.0005184803740121424 Validation Loss: 0.0014599710702896118\n",
      "9751 Training Loss: 0.0008491454645991325 Validation Loss: 0.0015438481932505965\n",
      "9752 Training Loss: 0.00046242319513112307 Validation Loss: 0.0016296879621222615\n",
      "9753 Training Loss: 0.0006537065492011607 Validation Loss: 0.0015665835235267878\n",
      "9754 Training Loss: 0.0006772223860025406 Validation Loss: 0.0014326031086966395\n",
      "9755 Training Loss: 0.0005509951733984053 Validation Loss: 0.0013245122972875834\n",
      "9756 Training Loss: 0.0005606114282272756 Validation Loss: 0.0012795033399015665\n",
      "9757 Training Loss: 0.0005366788245737553 Validation Loss: 0.0012614468578249216\n",
      "9758 Training Loss: 0.000858317653182894 Validation Loss: 0.001264232792891562\n",
      "9759 Training Loss: 0.0005794379394501448 Validation Loss: 0.0013024144573137164\n",
      "9760 Training Loss: 0.0006561271729879081 Validation Loss: 0.0013303105952218175\n",
      "9761 Training Loss: 0.0005710085388273001 Validation Loss: 0.0013407578226178885\n",
      "9762 Training Loss: 0.0006324354908429086 Validation Loss: 0.001348211895674467\n",
      "9763 Training Loss: 0.0004845626244787127 Validation Loss: 0.0013746600598096848\n",
      "9764 Training Loss: 0.0006440912839025259 Validation Loss: 0.0013888078974559903\n",
      "9765 Training Loss: 0.0005959899281151593 Validation Loss: 0.0013974738540127873\n",
      "9766 Training Loss: 0.0007957711350172758 Validation Loss: 0.0014607268385589123\n",
      "9767 Training Loss: 0.0007051305146887898 Validation Loss: 0.0014717610320076346\n",
      "9768 Training Loss: 0.0005970444181002676 Validation Loss: 0.0014884964330121875\n",
      "9769 Training Loss: 0.000567586743272841 Validation Loss: 0.0014869602164253592\n",
      "9770 Training Loss: 0.0005949335172772408 Validation Loss: 0.0014068507589399815\n",
      "9771 Training Loss: 0.0005215005949139595 Validation Loss: 0.0013412123080343008\n",
      "9772 Training Loss: 0.0005743583897128701 Validation Loss: 0.001291734864935279\n",
      "9773 Training Loss: 0.0005098183173686266 Validation Loss: 0.00126337178517133\n",
      "9774 Training Loss: 0.0011503114365041256 Validation Loss: 0.0012739734956994653\n",
      "9775 Training Loss: 0.0008774358429946005 Validation Loss: 0.0013424674980342388\n",
      "9776 Training Loss: 0.0005679361056536436 Validation Loss: 0.001383924507535994\n",
      "9777 Training Loss: 0.0007810362731106579 Validation Loss: 0.0014124145964160562\n",
      "9778 Training Loss: 0.000698093615937978 Validation Loss: 0.001404440845362842\n",
      "9779 Training Loss: 0.0013116286136209965 Validation Loss: 0.001444188877940178\n",
      "9780 Training Loss: 0.0005301649798639119 Validation Loss: 0.0014271928230300546\n",
      "9781 Training Loss: 0.0005147948395460844 Validation Loss: 0.001402761321514845\n",
      "9782 Training Loss: 0.0005441780085675418 Validation Loss: 0.0013830794487148523\n",
      "9783 Training Loss: 0.000576837919652462 Validation Loss: 0.0013505311217159033\n",
      "9784 Training Loss: 0.0005301158525981009 Validation Loss: 0.001330130035057664\n",
      "9785 Training Loss: 0.001245724270120263 Validation Loss: 0.0014139065751805902\n",
      "9786 Training Loss: 0.000514926970936358 Validation Loss: 0.0014782120706513524\n",
      "9787 Training Loss: 0.000606799905654043 Validation Loss: 0.0014510053442791104\n",
      "9788 Training Loss: 0.0006286106072366238 Validation Loss: 0.0013444145442917943\n",
      "9789 Training Loss: 0.0005701587069779634 Validation Loss: 0.0012650929857045412\n",
      "9790 Training Loss: 0.0005118809640407562 Validation Loss: 0.0012426769826561213\n",
      "9791 Training Loss: 0.0006361637497320771 Validation Loss: 0.0012295711785554886\n",
      "9792 Training Loss: 0.0009398835827596486 Validation Loss: 0.0012602810747921467\n",
      "9793 Training Loss: 0.0005528589827008545 Validation Loss: 0.0013774926774203777\n",
      "9794 Training Loss: 0.0005993673112243414 Validation Loss: 0.0014592414954677224\n",
      "9795 Training Loss: 0.0006178688490763307 Validation Loss: 0.001415987964719534\n",
      "9796 Training Loss: 0.0007332575041800737 Validation Loss: 0.0013776648556813598\n",
      "9797 Training Loss: 0.0005495899240486324 Validation Loss: 0.0013271431671455503\n",
      "9798 Training Loss: 0.0015048002824187279 Validation Loss: 0.0013827498769387603\n",
      "9799 Training Loss: 0.0006486818892881274 Validation Loss: 0.001380531000904739\n",
      "9800 Training Loss: 0.0005240383325144649 Validation Loss: 0.0013538063503801823\n",
      "9801 Training Loss: 0.0006313669146038592 Validation Loss: 0.0013217476662248373\n",
      "9802 Training Loss: 0.0009511218522675335 Validation Loss: 0.0013230631593614817\n",
      "9803 Training Loss: 0.001053697895258665 Validation Loss: 0.001339439069852233\n",
      "9804 Training Loss: 0.0008504260913468897 Validation Loss: 0.0013751748483628035\n",
      "9805 Training Loss: 0.000788603094406426 Validation Loss: 0.0014072301564738154\n",
      "9806 Training Loss: 0.0007235273369587958 Validation Loss: 0.0013436147710308433\n",
      "9807 Training Loss: 0.0010672332718968391 Validation Loss: 0.0013864198699593544\n",
      "9808 Training Loss: 0.0005555038806051016 Validation Loss: 0.0014122489374130964\n",
      "9809 Training Loss: 0.0008202116587199271 Validation Loss: 0.0014816983602941036\n",
      "9810 Training Loss: 0.0005840671365149319 Validation Loss: 0.001494617317803204\n",
      "9811 Training Loss: 0.0005905122961848974 Validation Loss: 0.001451920485123992\n",
      "9812 Training Loss: 0.0006970434333197773 Validation Loss: 0.0013531246222555637\n",
      "9813 Training Loss: 0.0005790923605673015 Validation Loss: 0.0012973941629752517\n",
      "9814 Training Loss: 0.0005355491302907467 Validation Loss: 0.0012713498435914516\n",
      "9815 Training Loss: 0.0007886881940066814 Validation Loss: 0.001280409749597311\n",
      "9816 Training Loss: 0.0005176184931769967 Validation Loss: 0.0013022676575928926\n",
      "9817 Training Loss: 0.0006441497826017439 Validation Loss: 0.0013449752004817128\n",
      "9818 Training Loss: 0.0006490657688118517 Validation Loss: 0.0013708752812817693\n",
      "9819 Training Loss: 0.0006394363008439541 Validation Loss: 0.0013332534581422806\n",
      "9820 Training Loss: 0.0006239866488613188 Validation Loss: 0.0012919580331072211\n",
      "9821 Training Loss: 0.0006134689901955426 Validation Loss: 0.0012669124407693744\n",
      "9822 Training Loss: 0.0008264535572379827 Validation Loss: 0.0012875800020992756\n",
      "9823 Training Loss: 0.0005493367789313197 Validation Loss: 0.0013108619023114443\n",
      "9824 Training Loss: 0.0005672264378517866 Validation Loss: 0.0013541404623538256\n",
      "9825 Training Loss: 0.0006125655490905046 Validation Loss: 0.0013530149590224028\n",
      "9826 Training Loss: 0.0005640856688842177 Validation Loss: 0.0013488346012309194\n",
      "9827 Training Loss: 0.0007602466503158212 Validation Loss: 0.0013323607854545116\n",
      "9828 Training Loss: 0.0006194241577759385 Validation Loss: 0.0013017588062211871\n",
      "9829 Training Loss: 0.0005086379824206233 Validation Loss: 0.0012808556202799082\n",
      "9830 Training Loss: 0.0006304936832748353 Validation Loss: 0.0012863271404057741\n",
      "9831 Training Loss: 0.00046003476018086076 Validation Loss: 0.0013133687898516655\n",
      "9832 Training Loss: 0.0005405863630585372 Validation Loss: 0.0013399426825344563\n",
      "9833 Training Loss: 0.0005567887565121055 Validation Loss: 0.0013516106409952044\n",
      "9834 Training Loss: 0.000532661797478795 Validation Loss: 0.0013176945503801107\n",
      "9835 Training Loss: 0.001294005778618157 Validation Loss: 0.0013404506025835872\n",
      "9836 Training Loss: 0.0005558478296734393 Validation Loss: 0.0013366836355999112\n",
      "9837 Training Loss: 0.0006529488018713892 Validation Loss: 0.0013162216637283564\n",
      "9838 Training Loss: 0.0004954917822033167 Validation Loss: 0.0012874298263341188\n",
      "9839 Training Loss: 0.0006082302425056696 Validation Loss: 0.0012498450232669711\n",
      "9840 Training Loss: 0.0005213027470745146 Validation Loss: 0.0012223150115460157\n",
      "9841 Training Loss: 0.0006430730572901666 Validation Loss: 0.0012250938452780247\n",
      "9842 Training Loss: 0.0005439205560833216 Validation Loss: 0.0012331597972661257\n",
      "9843 Training Loss: 0.0006232883897610009 Validation Loss: 0.0012803995050489902\n",
      "9844 Training Loss: 0.0004989723674952984 Validation Loss: 0.0013047675602138042\n",
      "9845 Training Loss: 0.0005106891039758921 Validation Loss: 0.00128670793492347\n",
      "9846 Training Loss: 0.0005940631963312626 Validation Loss: 0.0012472656089812517\n",
      "9847 Training Loss: 0.0005075865192338824 Validation Loss: 0.0012121654581278563\n",
      "9848 Training Loss: 0.0007814278360456228 Validation Loss: 0.0012098457664251328\n",
      "9849 Training Loss: 0.0006668413989245892 Validation Loss: 0.0012329013552516699\n",
      "9850 Training Loss: 0.0009051094530150294 Validation Loss: 0.0012790007749572396\n",
      "9851 Training Loss: 0.0004908086266368628 Validation Loss: 0.0013107024133205414\n",
      "9852 Training Loss: 0.0004998377989977598 Validation Loss: 0.0013016915181651711\n",
      "9853 Training Loss: 0.0005664384225383401 Validation Loss: 0.0012524087214842439\n",
      "9854 Training Loss: 0.0007905318634584546 Validation Loss: 0.001257818192243576\n",
      "9855 Training Loss: 0.000724692246876657 Validation Loss: 0.0012913011014461517\n",
      "9856 Training Loss: 0.0005863323458470404 Validation Loss: 0.0012932720128446817\n",
      "9857 Training Loss: 0.0007069425191730261 Validation Loss: 0.001312162959948182\n",
      "9858 Training Loss: 0.0004769788356497884 Validation Loss: 0.001322834868915379\n",
      "9859 Training Loss: 0.0005211748066358268 Validation Loss: 0.0013229644391685724\n",
      "9860 Training Loss: 0.0005179998697713017 Validation Loss: 0.0013094994938001037\n",
      "9861 Training Loss: 0.0007609243621118367 Validation Loss: 0.0012871254002675414\n",
      "9862 Training Loss: 0.0005255111027508974 Validation Loss: 0.0012566670775413513\n",
      "9863 Training Loss: 0.0006778734386898577 Validation Loss: 0.001203416846692562\n",
      "9864 Training Loss: 0.0006144648650661111 Validation Loss: 0.0011737080058082938\n",
      "9865 Training Loss: 0.000506806536577642 Validation Loss: 0.0011659578885883093\n",
      "9866 Training Loss: 0.0005912334891036153 Validation Loss: 0.0011575687676668167\n",
      "9867 Training Loss: 0.0005575572140514851 Validation Loss: 0.0011656599817797542\n",
      "9868 Training Loss: 0.0005532036884687841 Validation Loss: 0.0011792521690949798\n",
      "9869 Training Loss: 0.0005135043757036328 Validation Loss: 0.0011924757855013013\n",
      "9870 Training Loss: 0.0005243627820163965 Validation Loss: 0.0012079033767804503\n",
      "9871 Training Loss: 0.0006670008879154921 Validation Loss: 0.001210574759170413\n",
      "9872 Training Loss: 0.000521552050486207 Validation Loss: 0.0012012876104563475\n",
      "9873 Training Loss: 0.0007840953767299652 Validation Loss: 0.0011996683897450566\n",
      "9874 Training Loss: 0.0004980179946869612 Validation Loss: 0.0012256733607500792\n",
      "9875 Training Loss: 0.0005441567627713084 Validation Loss: 0.001274678623303771\n",
      "9876 Training Loss: 0.0004878598847426474 Validation Loss: 0.0013071238063275814\n",
      "9877 Training Loss: 0.0005034841015003622 Validation Loss: 0.0012984556378796697\n",
      "9878 Training Loss: 0.0006083105690777302 Validation Loss: 0.0012752374168485403\n",
      "9879 Training Loss: 0.000583822256885469 Validation Loss: 0.0012510132510215044\n",
      "9880 Training Loss: 0.0005903829005546868 Validation Loss: 0.0012386342277750373\n",
      "9881 Training Loss: 0.0005515402881428599 Validation Loss: 0.0012237478513270617\n",
      "9882 Training Loss: 0.000469049671664834 Validation Loss: 0.00121650705114007\n",
      "9883 Training Loss: 0.0005126807373017073 Validation Loss: 0.0012162262573838234\n",
      "9884 Training Loss: 0.0005741720669902861 Validation Loss: 0.0011744521325454116\n",
      "9885 Training Loss: 0.0005095514352433383 Validation Loss: 0.001155529054813087\n",
      "9886 Training Loss: 0.0004752638633362949 Validation Loss: 0.0011556490790098906\n",
      "9887 Training Loss: 0.0004966931883245707 Validation Loss: 0.0011570150963962078\n",
      "9888 Training Loss: 0.00044840946793556213 Validation Loss: 0.0011566299945116043\n",
      "9889 Training Loss: 0.0004786151694133878 Validation Loss: 0.0011685355566442013\n",
      "9890 Training Loss: 0.001307659549638629 Validation Loss: 0.0012606001691892743\n",
      "9891 Training Loss: 0.0005608006613329053 Validation Loss: 0.0013047725660726428\n",
      "9892 Training Loss: 0.0005598909338004887 Validation Loss: 0.001253663096576929\n",
      "9893 Training Loss: 0.000489105936139822 Validation Loss: 0.0012118093436583877\n",
      "9894 Training Loss: 0.00048778532072901726 Validation Loss: 0.001197123434394598\n",
      "9895 Training Loss: 0.0008672376861795783 Validation Loss: 0.0011958300601691008\n",
      "9896 Training Loss: 0.0006219620117917657 Validation Loss: 0.001171811018139124\n",
      "9897 Training Loss: 0.0005604037432931364 Validation Loss: 0.0011525563895702362\n",
      "9898 Training Loss: 0.0004972632159478962 Validation Loss: 0.0011373698944225907\n",
      "9899 Training Loss: 0.0010337476851418614 Validation Loss: 0.001156805083155632\n",
      "9900 Training Loss: 0.001145113492384553 Validation Loss: 0.0012652178993448615\n",
      "9901 Training Loss: 0.0005285483202897012 Validation Loss: 0.0012869125930592418\n",
      "9902 Training Loss: 0.0005396063206717372 Validation Loss: 0.0012569429818540812\n",
      "9903 Training Loss: 0.0005349459825083613 Validation Loss: 0.0012141410261392593\n",
      "9904 Training Loss: 0.0005722515052184463 Validation Loss: 0.0012230966240167618\n",
      "9905 Training Loss: 0.0005722123896703124 Validation Loss: 0.0012475935509428382\n",
      "9906 Training Loss: 0.0005293517606332898 Validation Loss: 0.001293959910981357\n",
      "9907 Training Loss: 0.0006023584865033627 Validation Loss: 0.001402423600666225\n",
      "9908 Training Loss: 0.0012396416859701276 Validation Loss: 0.0015617015305906534\n",
      "9909 Training Loss: 0.0005810814909636974 Validation Loss: 0.0015218802727758884\n",
      "9910 Training Loss: 0.0007640058756805956 Validation Loss: 0.001411563833244145\n",
      "9911 Training Loss: 0.0004950726288370788 Validation Loss: 0.0012977354926988482\n",
      "9912 Training Loss: 0.0008860108209773898 Validation Loss: 0.0012864717282354832\n",
      "9913 Training Loss: 0.000544360198546201 Validation Loss: 0.001302298391237855\n",
      "9914 Training Loss: 0.0004879052867181599 Validation Loss: 0.0013431599363684654\n",
      "9915 Training Loss: 0.000524379254784435 Validation Loss: 0.0013888406101614237\n",
      "9916 Training Loss: 0.0005215026903897524 Validation Loss: 0.0014185087056830525\n",
      "9917 Training Loss: 0.000613826559856534 Validation Loss: 0.0014098223764449358\n",
      "9918 Training Loss: 0.0005122375441715121 Validation Loss: 0.0013700678246095777\n",
      "9919 Training Loss: 0.0008449510205537081 Validation Loss: 0.001357493456453085\n",
      "9920 Training Loss: 0.0005247966619208455 Validation Loss: 0.0013219948159530759\n",
      "9921 Training Loss: 0.0005073733627796173 Validation Loss: 0.001307712635025382\n",
      "9922 Training Loss: 0.0005367229459807277 Validation Loss: 0.0012770380126312375\n",
      "9923 Training Loss: 0.0005281849880702794 Validation Loss: 0.0012840564595535398\n",
      "9924 Training Loss: 0.0005695632426068187 Validation Loss: 0.0012971111573278904\n",
      "9925 Training Loss: 0.0005311219138093293 Validation Loss: 0.0012878647539764643\n",
      "9926 Training Loss: 0.0005062504205852747 Validation Loss: 0.0012584184296429157\n",
      "9927 Training Loss: 0.0004829650861211121 Validation Loss: 0.0012335511855781078\n",
      "9928 Training Loss: 0.0005740925553254783 Validation Loss: 0.0012060711160302162\n",
      "9929 Training Loss: 0.0007057278417050838 Validation Loss: 0.0012282627867534757\n",
      "9930 Training Loss: 0.0006526506040245295 Validation Loss: 0.0012697960482910275\n",
      "9931 Training Loss: 0.0007356416899710894 Validation Loss: 0.0012727892026305199\n",
      "9932 Training Loss: 0.0005412406753748655 Validation Loss: 0.0012523019686341286\n",
      "9933 Training Loss: 0.0006656366167590022 Validation Loss: 0.0012235059402883053\n",
      "9934 Training Loss: 0.00048643420450389385 Validation Loss: 0.0012268363498151302\n",
      "9935 Training Loss: 0.0005383162060752511 Validation Loss: 0.0012401532148942351\n",
      "9936 Training Loss: 0.000539576169103384 Validation Loss: 0.0012444210005924106\n",
      "9937 Training Loss: 0.0008974627708084881 Validation Loss: 0.0013008022215217352\n",
      "9938 Training Loss: 0.00048441439867019653 Validation Loss: 0.0013283059233799577\n",
      "9939 Training Loss: 0.0007222476415336132 Validation Loss: 0.0013281333958730102\n",
      "9940 Training Loss: 0.0005133731756359339 Validation Loss: 0.0012976618018001318\n",
      "9941 Training Loss: 0.0012079859152436256 Validation Loss: 0.0013413119595497847\n",
      "9942 Training Loss: 0.0010020725894719362 Validation Loss: 0.001411080826073885\n",
      "9943 Training Loss: 0.0006509618833661079 Validation Loss: 0.0013576979981735349\n",
      "9944 Training Loss: 0.0005341873038560152 Validation Loss: 0.0013210446340963244\n",
      "9945 Training Loss: 0.0006303722620941699 Validation Loss: 0.0012385548325255513\n",
      "9946 Training Loss: 0.000610393297392875 Validation Loss: 0.0012071597157046199\n",
      "9947 Training Loss: 0.0005685050273314118 Validation Loss: 0.001197009813040495\n",
      "9948 Training Loss: 0.0005919724353589118 Validation Loss: 0.001248641056008637\n",
      "9949 Training Loss: 0.0005336771719157696 Validation Loss: 0.0013086923863738775\n",
      "9950 Training Loss: 0.0004922254011034966 Validation Loss: 0.0013445403892546892\n",
      "9951 Training Loss: 0.0006103066261857748 Validation Loss: 0.0012812991626560688\n",
      "9952 Training Loss: 0.0004950056900270283 Validation Loss: 0.0012242611264809966\n",
      "9953 Training Loss: 0.0005652201361954212 Validation Loss: 0.0011889177840203047\n",
      "9954 Training Loss: 0.00134650943800807 Validation Loss: 0.0012049722718074918\n",
      "9955 Training Loss: 0.00044972021714784205 Validation Loss: 0.0012477698037400842\n",
      "9956 Training Loss: 0.0004834372957702726 Validation Loss: 0.0012788972817361355\n",
      "9957 Training Loss: 0.0005357791669666767 Validation Loss: 0.0012803360586985946\n",
      "9958 Training Loss: 0.0005304900696501136 Validation Loss: 0.0012502755271270871\n",
      "9959 Training Loss: 0.0005317606264725327 Validation Loss: 0.001222615479491651\n",
      "9960 Training Loss: 0.0005906972801312804 Validation Loss: 0.0012409986229613423\n",
      "9961 Training Loss: 0.0005449486779980361 Validation Loss: 0.0012473989045247436\n",
      "9962 Training Loss: 0.0009935717098414898 Validation Loss: 0.0013092431472614408\n",
      "9963 Training Loss: 0.0011617114068940282 Validation Loss: 0.0014675016282126307\n",
      "9964 Training Loss: 0.0005630699452012777 Validation Loss: 0.0014946931041777134\n",
      "9965 Training Loss: 0.0005522452993318439 Validation Loss: 0.0014708887320011854\n",
      "9966 Training Loss: 0.000507886172272265 Validation Loss: 0.0013845175271853805\n",
      "9967 Training Loss: 0.000670771230943501 Validation Loss: 0.0013475908199325204\n",
      "9968 Training Loss: 0.0005918334936723113 Validation Loss: 0.0013535533798858523\n",
      "9969 Training Loss: 0.0006091119721531868 Validation Loss: 0.0013305054744705558\n",
      "9970 Training Loss: 0.0005753289442509413 Validation Loss: 0.0012986594811081886\n",
      "9971 Training Loss: 0.0007138889050111175 Validation Loss: 0.001332078012637794\n",
      "9972 Training Loss: 0.000619138590991497 Validation Loss: 0.0012964531779289246\n",
      "9973 Training Loss: 0.0004672379291150719 Validation Loss: 0.0012271020095795393\n",
      "9974 Training Loss: 0.0005882572149857879 Validation Loss: 0.0011737929889932275\n",
      "9975 Training Loss: 0.0005667837103828788 Validation Loss: 0.0011501772096380591\n",
      "9976 Training Loss: 0.0005042857374064624 Validation Loss: 0.0011385756079107523\n",
      "9977 Training Loss: 0.0004939822829328477 Validation Loss: 0.001148513169027865\n",
      "9978 Training Loss: 0.0004745499463751912 Validation Loss: 0.0011882878607138991\n",
      "9979 Training Loss: 0.00046686106361448765 Validation Loss: 0.001261401572264731\n",
      "9980 Training Loss: 0.0004893618170171976 Validation Loss: 0.0013412046246230602\n",
      "9981 Training Loss: 0.000552926620002836 Validation Loss: 0.0013104153331369162\n",
      "9982 Training Loss: 0.0005284270737320185 Validation Loss: 0.0012381569249555469\n",
      "9983 Training Loss: 0.00047748946235515177 Validation Loss: 0.0011776359751820564\n",
      "9984 Training Loss: 0.0004871078417636454 Validation Loss: 0.0011390651343390346\n",
      "9985 Training Loss: 0.00046012047096155584 Validation Loss: 0.0011205330956727266\n",
      "9986 Training Loss: 0.0006145728984847665 Validation Loss: 0.0011135645909234881\n",
      "9987 Training Loss: 0.0005702490452677011 Validation Loss: 0.00114307866897434\n",
      "9988 Training Loss: 0.0005460825632326305 Validation Loss: 0.0011655095731839538\n",
      "9989 Training Loss: 0.0004929640563204885 Validation Loss: 0.0011653817491605878\n",
      "9990 Training Loss: 0.0009107380174100399 Validation Loss: 0.0011687454534694552\n",
      "9991 Training Loss: 0.0011419302318245173 Validation Loss: 0.0012311202008277178\n",
      "9992 Training Loss: 0.00048275699373334646 Validation Loss: 0.0012566469376906753\n",
      "9993 Training Loss: 0.00048233638517558575 Validation Loss: 0.0012905765324831009\n",
      "9994 Training Loss: 0.0006753630586899817 Validation Loss: 0.0012552127009257674\n",
      "9995 Training Loss: 0.00048101478023454547 Validation Loss: 0.0012210968416184187\n",
      "9996 Training Loss: 0.00046810059575363994 Validation Loss: 0.0012172225397080183\n",
      "9997 Training Loss: 0.0010901734931394458 Validation Loss: 0.0012529210653156042\n",
      "9998 Training Loss: 0.0005755667225457728 Validation Loss: 0.0012504353653639555\n",
      "9999 Training Loss: 0.0005348833510652184 Validation Loss: 0.0012042759917676449\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "previous_validation_loss = torch.tensor(float('inf'))\n",
    "for epoch in range(iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pt_x_bc = Variable(torch.from_numpy(x_bc).float(), requires_grad=False).to(device)\n",
    "    pt_t_bc = Variable(torch.from_numpy(t_bc).float(), requires_grad=False).to(device)\n",
    "    pt_u_bc = Variable(torch.from_numpy(u_bc).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    net_bc_out = net(pt_x_bc, pt_t_bc)\n",
    "    mse_u = mse_cost_function(net_bc_out, pt_u_bc)\n",
    "    \n",
    "    x_collocation = np.random.uniform(low=0.0, high=2.0, size=(500,1))\n",
    "    t_collocation = np.random.uniform(low=0.0, high=1.0, size=(500,1))\n",
    "    all_zeros = np.zeros((500,1))\n",
    "    \n",
    "    \n",
    "    pt_x_collocation = Variable(torch.from_numpy(x_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_t_collocation = Variable(torch.from_numpy(t_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_all_zeros = Variable(torch.from_numpy(all_zeros).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    f_out = f(pt_x_collocation, pt_t_collocation, net)\n",
    "    mse_f = mse_cost_function(f_out, pt_all_zeros)\n",
    "    \n",
    "    loss = mse_u + mse_f\n",
    "    training_loss.append(float(loss))\n",
    "    \n",
    "    \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    # with torch.autograd.no_grad():\n",
    "    net.eval()\n",
    "    val_pred = net(pt_x_val, pt_t_val)\n",
    "    val_loss_u = mse_cost_function(val_pred, pt_u_val)\n",
    "    f_out = f(pt_x_val, pt_t_val, net)\n",
    "    val_loss_f = mse_cost_function(f_out, pt_all_zeros[:100, :])\n",
    "    val_loss = val_loss_u + val_loss_f\n",
    "    validation_loss.append(float(val_loss))\n",
    "    print(epoch,\"Training Loss:\", float(loss.data), \"Validation Loss:\", float(val_loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACLMklEQVR4nOzdd3wUdf7H8dfsZrObHmpCCUXg6CBdsKF0EEU9xHaAZzkVbPxs3FlATlHUUxTFLjYsWLAhElBEBaUIShEEpUPoSUjbbHbn98cmS0ISkoUks4H38/HYx87Ofmfms5uvmHe+M98xTNM0ERERERERkVLZrC5AREREREQk1Ck4iYiIiIiIlEHBSUREREREpAwKTiIiIiIiImVQcBIRERERESmDgpOIiIiIiEgZFJxERERERETKoOAkIiIiIiJSBgUnERERERGRMig4iYicIkaPHk2TJk2Oa9sJEyZgGEbFFmSRhQsXYhgGCxcuDKwr73ezZcsWDMNgxowZFVpTkyZNGD16dIXuszxmzJiBYRhs2bKlyo8tIlLdKDiJiFjMMIxyPQr/on+ye/bZZ4mLi8Pj8VhdSoVZvHgxEyZMIDU11epSRETkOIRZXYCIyKnurbfeKvL6zTffJDk5udj61q1bn9BxXn75ZXw+33Fte99993Hvvfee0PGD8eWXX9K/f38cDkeVHO9EvpvyWrx4MRMnTmT06NHEx8cXeW/Dhg3YbPpbpohIKFNwEhGx2NVXX13k9U8//URycnKx9UfLysoiMjKy3Mc5kRASFhZGWFjV/C8jKyuL7777junTp1fJ8eDEvpuK4HQ6LT2+iIiUTX/eEhGpBnr37k27du1YsWIF55xzDpGRkfz73/8G4NNPP2XIkCHUr18fp9NJs2bNmDRpEl6vt8g+jr6Op+B6nSeeeIKXXnqJZs2a4XQ66datG8uWLSuybUnXOBmGwdixY5k9ezbt2rXD6XTStm1b5s6dW6z+hQsX0rVrV1wuF82aNePFF18s9bqpBQsW4Ha7GTRoEMuXL8cwDN54441i7b7++msMw+CLL74AYOvWrdx88820bNmSiIgIatWqxfDhw8t1/U5J1zilpqYyevRo4uLiiI+PZ9SoUSWeZvfbb78xevRoTjvtNFwuF4mJifzzn//kwIEDRb6/u+66C4CmTZsGTr8sqK2ka5z++usvhg8fTs2aNYmMjOSMM87gyy+/LNKm4HqtDz74gIcffpiGDRvicrno06cPmzZtKvNzl+b555+nbdu2OJ1O6tevz5gxY4p99o0bN3LppZeSmJiIy+WiYcOGXH755aSlpQXaJCcnc9ZZZxEfH090dDQtW7YM9FsRkepGI04iItXEgQMHGDRoEJdffjlXX301CQkJgP8C/+joaMaNG0d0dDTffPMNDzzwAOnp6Tz++ONl7nfmzJkcPnyYf/3rXxiGwZQpU7jkkkv466+/yhyJ+eGHH/j444+5+eabiYmJ4ZlnnuHSSy9l27Zt1KpVC4CVK1cycOBA6tWrx8SJE/F6vTz00EPUqVOnxH3OmTOHLl26kJCQQEJCAqeddhoffPABo0aNKtLu/fffp0aNGgwYMACAZcuWsXjxYi6//HIaNmzIli1bmD59Or1792bdunVBjc6ZpslFF13EDz/8wI033kjr1q355JNPitUA/nDw119/cc0115CYmMjatWt56aWXWLt2LT/99BOGYXDJJZfwxx9/8O677/LUU09Ru3ZtgFK/gz179tCrVy+ysrK49dZbqVWrFm+88QYXXnghH374IRdffHGR9o8++ig2m40777yTtLQ0pkyZwlVXXcXPP/9c7s9cYMKECUycOJG+ffty0003sWHDBqZPn86yZcv48ccfcTgc5ObmMmDAANxuN7fccguJiYns3LmTL774gtTUVOLi4li7di0XXHABHTp04KGHHsLpdLJp0yZ+/PHHoGsSEQkJpoiIhJQxY8aYR//zfO6555qA+cILLxRrn5WVVWzdv/71LzMyMtLMyckJrBs1apTZuHHjwOvNmzebgFmrVi3z4MGDgfWffvqpCZiff/55YN2DDz5YrCbADA8PNzdt2hRY9+uvv5qA+eyzzwbWDR061IyMjDR37twZWLdx40YzLCys2D5N0zQbNWpkPvjgg4HX48ePNx0OR5Ea3W63GR8fb/7zn/885vewZMkSEzDffPPNwLpvv/3WBMxvv/221O9m9uzZJmBOmTIlsC4vL888++yzTcB8/fXXj3ncd9991wTMRYsWBdY9/vjjJmBu3ry5WPvGjRubo0aNCry+/fbbTcD8/vvvA+sOHz5sNm3a1GzSpInp9XqLfJbWrVubbrc70Hbq1KkmYK5evbrYsQp7/fXXi9S0d+9eMzw83Ozfv3/gGKZpmtOmTTMB87XXXjNN0zRXrlxpAuasWbNK3fdTTz1lAua+ffuOWYOISHWhU/VERKoJp9PJNddcU2x9REREYPnw4cPs37+fs88+m6ysLNavX1/mfkeMGEGNGjUCr88++2zAf6pYWfr27UuzZs0Crzt06EBsbGxgW6/Xy/z58xk2bBj169cPtGvevDmDBg0qtr81a9awbds2hgwZUqQ+j8fDxx9/HFg3b948UlNTGTFiRGBd4e/B4/Fw4MABmjdvTnx8PL/88kuZn6WwOXPmEBYWxk033RRYZ7fbueWWW4q1LXzcnJwc9u/fzxlnnAEQ9HELH7979+6cddZZgXXR0dHccMMNbNmyhXXr1hVpf8011xAeHh54HczPsLD58+eTm5vL7bffXmSyiuuvv57Y2NjAqYJxcXGA/3TJrKysEvdVMAHGp59+WukTb4iIVAUFJxGRaqJBgwZFfjkusHbtWi6++GLi4uKIjY2lTp06gYklCl9vUppGjRoVeV0Qog4dOhT0tgXbF2y7d+9esrOzad68ebF2Ja378ssvSUhIoGvXroF1HTt2pFWrVrz//vuBde+//z61a9fm/PPPD6zLzs7mgQceICkpCafTSe3atalTpw6pqanl+h4K27p1K/Xq1SM6OrrI+pYtWxZre/DgQW677TYSEhKIiIigTp06NG3aFCjf91/a8Us6VsHMilu3bi2y/kR+hkcfF4p/zvDwcE477bTA+02bNmXcuHG88sor1K5dmwEDBvDcc88V+bwjRozgzDPP5LrrriMhIYHLL7+cDz74QCFKRKotBScRkWqi8MhGgdTUVM4991x+/fVXHnroIT7//HOSk5N57LHHAMr1S6rdbi9xvWmalbptSebMmcPAgQOLTRoxYsQIvv32W/bv34/b7eazzz7j0ksvLTLT3y233MLDDz/MZZddxgcffMC8efNITk6mVq1alfrL+mWXXcbLL7/MjTfeyMcff8y8efMCE2RUVUio6J9DeTz55JP89ttv/Pvf/yY7O5tbb72Vtm3bsmPHDsDfXxctWsT8+fP5xz/+wW+//caIESPo169fsYlLRESqA00OISJSjS1cuJADBw7w8ccfc8455wTWb9682cKqjqhbty4ul6vEGd6OXpeamsrixYsZO3ZssbYjRoxg4sSJfPTRRyQkJJCens7ll19epM2HH37IqFGjePLJJwPrcnJyjuuGs40bN2bBggVkZGQUGXXasGFDkXaHDh1iwYIFTJw4kQceeCCwfuPGjcX2WdIMgsc6/tHHAgKnXjZu3Ljc+wpGwX43bNjAaaedFlifm5vL5s2b6du3b5H27du3p3379tx3330sXryYM888kxdeeIH//ve/ANhsNvr06UOfPn343//+xyOPPMJ//vMfvv3222L7EhEJdRpxEhGpxgpGGgqPLOTm5vL8889bVVIRdrudvn37Mnv2bHbt2hVYv2nTJr766qsibefNmwdA//79i+2ndevWtG/fnvfff5/333+fevXqFQmKBcc6eoTl2WefPa7RjcGDB5OXl1fkXlJer5dnn3222DGh+MjO008/XWyfUVFRAOUKcoMHD2bp0qUsWbIksC4zM5OXXnqJJk2a0KZNm/J+lKD07duX8PBwnnnmmSKf6dVXXyUtLS1w7Vl6ejp5eXlFtm3fvj02mw232w34T2E82umnnw4QaCMiUp1oxElEpBrr1asXNWrUYNSoUdx6660YhsFbb71VqadoBWvChAnMmzePM888k5tuugmv18u0adNo164dq1atCrT78ssvOeusswITDxxtxIgRPPDAA7hcLq699toikxcAXHDBBbz11lvExcXRpk0blixZwvz58wPTogdj6NChnHnmmdx7771s2bKFNm3a8PHHHxe7Zik2NpZzzjmHKVOm4PF4aNCgAfPmzStxxK9Lly4A/Oc//+Hyyy/H4XAwdOjQQKAq7N577+Xdd99l0KBB3HrrrdSsWZM33niDzZs389FHHxX77BWlTp06jB8/nokTJzJw4EAuvPBCNmzYwPPPP0+3bt0C18598803jB07luHDh/O3v/2NvLw83nrrLex2O5deeikADz30EIsWLWLIkCE0btyYvXv38vzzz9OwYcMik16IiFQXCk4iItVYrVq1+OKLL/i///s/7rvvPmrUqMHVV19Nnz59Avc3slqXLl346quvuPPOO7n//vtJSkrioYce4vfffw+cemaaJnPnzuXOO+8sdT8jRozgvvvuIysrq8hsegWmTp2K3W7nnXfeIScnhzPPPJP58+cf1/dgs9n47LPPuP3223n77bcxDIMLL7yQJ598kk6dOhVpO3PmTG655Raee+45TNOkf//+fPXVV0VmEQTo1q0bkyZN4oUXXmDu3Ln4fD42b95cYnBKSEhg8eLF3HPPPTz77LPk5OTQoUMHPv/88yIzDlaGCRMmUKdOHaZNm8Ydd9xBzZo1ueGGG3jkkUcC9/Xq2LEjAwYM4PPPP2fnzp1ERkbSsWNHvvrqq8CMghdeeCFbtmzhtddeY//+/dSuXZtzzz2XiRMnlhqORURCmWGG0p8lRUTklDFs2DDWrl3Lxo0bWbp0KT169GDt2rWVdhqaiIjIidA1TiIiUumys7OLvN64cSNz5syhd+/egXWPPPKIQpOIiIQsjTiJiEilq1evHqNHjw7cC2j69Om43W5WrlxJixYtrC5PRESkTLrGSUREKt3AgQN59913SUlJwel00rNnTx555BGFJhERqTY04iQiIiIiIlIGXeMkIiIiIiJSBgUnERERERGRMpxy1zj5fD527dpFTEwMhmFYXY6IiIiIiFjENE0OHz5M/fr1y7y5+CkXnHbt2kVSUpLVZYiIiIiISIjYvn07DRs2PGabUy44xcTEAP4vJzY21uJqwOPxMG/ePPr37x+4I7tIadRfJFjqMxIs9RkJlvqMBCuU+kx6ejpJSUmBjHAsp1xwKjg9LzY2NmSCU2RkJLGxsZZ3HAl96i8SLPUZCZb6jARLfUaCFYp9pjyX8GhyCBERERERkTIoOImIiIiIiJRBwUlERERERKQMp9w1TiIiIiIS+rxeLx6Px+oypBJ4PB7CwsLIycnB6/VW+vEcDgd2u/2E96PgJCIiIiIhJSMjgx07dmCaptWlSCUwTZPExES2b99eJfdVNQyDhg0bEh0dfUL7UXASERERkZDh9XrZsWMHkZGR1KlTp0p+sZaq5fP5yMjIIDo6usybzp4o0zTZt28fO3bsoEWLFic08qTgJCIiIiIhw+PxYJomderUISIiwupypBL4fD5yc3NxuVyVHpwA6tSpw5YtW/B4PCcUnDQ5hIiIiIiEHI00SUWpqL6k4CQiIiIiIlIGBScREREREZEyKDiJiIiIiISYJk2a8PTTT5e7/cKFCzEMg9TU1EqrCWDGjBnEx8dX6jFClSaHEBERERE5Qb179+b0008PKuwcy7Jly4iKiip3+169erF7927i4uIq5PhSXMiMOD366KMYhsHtt99+zHazZs2iVatWuFwu2rdvz5w5c6qmQBERERGRE2CaJnl5eeVqW6dOHSIjI8u97/DwcBITEzWpRiUKieC0bNkyXnzxRTp06HDMdosXL+aKK67g2muvZeXKlQwbNoxhw4axZs2aKqpURERERKqSaZpk5eZZ8ijvDXhHjx7Nd999x9SpUzEMA8Mw2LJlS+D0ua+++oouXbrgdDr54Ycf+PPPP7noootISEggOjqabt26MX/+/CL7PPpUPcMweOWVV7j44ouJjIykRYsWfPbZZ4H3jz5Vr+CUuq+//prWrVsTHR3NwIED2b17d2CbvLw8br31VuLj46lVqxb33HMPo0aNYtiwYUH9jKZPn06zZs0IDw+nZcuWvPXWW0V+fhMmTKBRo0Y4nU7q16/PbbfdFnj/+eefp0WLFrhcLhISEvj73/8e1LGrkuWn6mVkZHDVVVfx8ssv89///veYbadOncrAgQO56667AJg0aRLJyclMmzaNF154oSrKFREREZEqlO3x0uaBry059rqHBhAZXvavy1OnTuWPP/6gXbt2PPTQQ8CRewcB3HvvvTzxxBOcdtpp1KhRg+3btzN48GAefvhhnE4nb775JkOHDmXDhg00atSo1ONMnDiRKVOm8Pjjj/Pss89y1VVXsXXrVmrWrFli+6ysLJ544gneeustbDYbV199NXfeeSfvvPMOAI899hjvvPMOr7/+Oq1bt2bq1KnMnj2b8847r9zf0SeffMJtt93G008/Td++ffniiy+45ppraNiwIeeddx4fffQRTz31FO+99x5t27YlJSWFlStXArB8+XJuvfVW3nrrLXr16sXBgwf5/vvvy33sqmZ5cBozZgxDhgyhb9++ZQanJUuWMG7cuCLrBgwYwOzZs0vdxu1243a7A6/T09MB/83VPB7P8RdeQQpqCIVaJPSpv0iw1GckWOozEqyK7jMFN8D1+XyBh1XKe/yYmBjCw8OJiIigbt26RbYHmDBhAn369Amsj4+Pp3379oHXEydO5JNPPuHTTz9lzJgxgfUF30OBUaNGMWLECAD++9//8swzz/DTTz8xcODAQLvC35vH4+H555+nWbNmgP/37kmTJgXaPvvss9x7771cdNFFADzzzDPMmTOn2HGP/k4KPz/xxBOMGjWKG2+8EYDbb7+dJUuW8Pjjj3PuueeydetWEhMTOf/883E4HDRs2JAuXbpw+PBhtm3bRlRUFIMHDyYmJoakpCQ6duxY4T9zn8+HaZol3gA3mH5raXB67733+OWXX1i2bFm52qekpJCQkFBkXUJCAikpKaVuM3nyZCZOnFhs/bx584I6b7Qy7M6CvdkGtV2QnJxsaS1Svai/SLDUZyRY6jMSrIrqM2FhYSQmJpKRkUFubi6mabJk3BkVsu9gebIzSc8p3zVDeXl55ObmBv5ID/4RH4CWLVsWWZ+RkcFjjz3GvHnzSElJwev1kp2dzcaNGwPtfD4fOTk5RbZr3rx5kdcxMTFs27aN9PT0wLEOHz6MzWYjJyeHyMhI6tSpE9gmLi6OvXv3kp6eTlpaGnv27KFNmzZF9tmhQwfy8vKKrCssJycH0zQD769bt46rr766SPsuXbrwwgsvkJ6ezoABA3jqqac47bTT6Nu3L/369WPgwIGEhYXRo0cPGjZsSLNmzejTpw99+vThggsuqPDf0XNzc8nOzmbRokXFrjEr+N7Kw7LgtH37dm677TaSk5NxuVyVdpzx48cXGaVKT08nKSmJ/v37ExsbW2nHLY9H527gtV+3cn59H6OH9cHhcFhaj4Q+j8dDcnIy/fr1U3+RclGfkWCpz0iwKrrP5OTksH37dqKjowO/I1aHeeLCwsIIDw8v8vtlQQBITEwssv6ee+5h/vz5TJkyhebNmxMREcFll12GYRiBdjabDZfLVWS72NjYIq9tNlvgmAXHiomJITY2FpfLhcPhKFaPaZrExsYGrt+Kiooq0iYsLAyfz1fq78kul6tInYZhFKvT5XJhs9mIjY2lTZs2bNiwgfnz5zN//nzuuusunnvuOT777DPq16/PypUrWbhwIcnJyTz22GM8/vjj/PzzzxU65XlOTg4RERGcc845xXJHaQGxJJYFpxUrVrB37146d+4cWOf1elm0aBHTpk3D7XYXG0pLTExkz549Rdbt2bOHxMTEUo/jdDpxOp3F1jscDsv/hxDl9B/f4w2NeqT6UH+RYKnPSLDUZyRYFdVnvF4vhmFgs9mw2UJiHrNyCQ8Px+fzFam5YPnoz7J48WJGjx7NpZdeCvhHoLZs2ULv3r2LtCv4Hgrv7+jvpGDd0ccq/LqkemrUqEFCQgIrVqygd+/egP+7X7lyJaeffnqp3/3R+23dujVLlizhmmuuKfL52rRpE2gTFRXFRRddxEUXXcTYsWNp1aoV69at4+yzzyY8PJz+/fvTv39/JkyYQHx8PAsXLuSSSy459hceBJvNhmEYJfbRYPqsZcGpT58+rF69usi6a665hlatWnHPPfcUC00APXv2ZMGCBUWmLE9OTqZnz56VXW6lcIX7P2OudafuioiIiEgFaNKkCT///DNbtmwhOjq61AkbAFq0aMHHH3/M0KFDMQyD+++/35JruW655RYmT55M8+bNadWqFc8++yyHDh0Kakrzu+66i8suu4xOnTrRt29fPv/8cz7++OPALIEzZszA6/XSo0cPIiMjefvtt4mIiCApKYkvvviCLVu2cM4551CjRg3mzJmDz+ejZcuWlfWRT4hlwSkmJoZ27doVWRcVFUWtWrUC60eOHEmDBg2YPHkyALfddhvnnnsuTz75JEOGDOG9995j+fLlvPTSS1Vef0WIcCg4iYiIiJwM7rzzTkaNGkWbNm3Izs5m8+bNpbb93//+xz//+U969epF7dq1ueeee4I6Zayi3HPPPaSkpDBy5Ejsdjs33HADAwYMKHEAozTDhg1j6tSpPPHEE9x22200bdqU119/PTCKFR8fz6OPPsq4cePwer20b9+eTz/9lJo1axIfH8/HH3/MhAkTyMnJoUWLFrz77ru0bdu2kj7xiTHM8k5QXwWOvuNy7969adKkCTNmzAi0mTVrFvfddx9btmyhRYsWTJkyhcGDB5f7GOnp6cTFxZGWlmb5NU7vLt3G+I9X066Gj0/GDdQpEVImj8fDnDlzGDx4sPqLlIv6jARLfUaCVdF9Jicnh82bN9O0adNKvQ5eivP5fLRu3ZrLLruMSZMmVepx0tPTiY2NrZLTMY/Vp4LJBpZPR17YwoULj/kaYPjw4QwfPrxqCqpkGnESEREREats3bqVefPmce655+J2u5k2bRqbN2/myiuvtLq0kFR9rrg7Cbnyg5PHV/7zSEVEREREKoLNZmPGjBl069aNM888k9WrVzN//nxat25tdWkhKaRGnE41EQWTQ3gtLkRERERETjlJSUn8+OOPVpdRbWjEyUIRgREniwsREREREZFjUnCykMvh//p1jZOIiIiISGhTcLKQRpxERERERKoHBScLuTSrnoiIiIhItaDgZKGCySE8PgOfL2RupyUiIiIiIkdRcLJQwal6AO48DTuJiIiIiIQqBScLuQoFp2yP5iQXEREROZU1adKEp59+OvDaMAxmz55davstW7ZgGAarVq06oeNW1H7KMnr0aIYNG1apx6hMuo+Thew2A4fdwOM1NeIkIiIiIkXs3r2bGjVqVOg+R48eTWpqapFAlpSUxO7du6ldu3aFHutko+BksQiHHY83j2zdBVdERERECklMTKyS49jt9io7VnWmU/UsVnCdk07VExERESmBaUJupjUPs3yTd7300kvUr18fn6/oGUQXXXQR//znPwH4888/ueiii0hISCA6Oppu3boxf/78Y+736FP1li5dSqdOnXC5XHTt2pWVK1cWae/1ern22mtp2rQpERERtGzZkqlTpwbenzBhAm+88QaffvophmFgGAYLFy4s8VS97777ju7du+N0OqlXrx733nsveXl5gfd79+7Nrbfeyt13303NmjVJTExkwoQJ5fq+Crjdbm699Vbq1q2Ly+XirLPOYtmyZYH3Dx06xFVXXUWdOnWIiIigRYsWvP766wDk5uYyduxY6tWrh8vlonHjxkyePDmo4wdLI04WK7jOKUfBSURERKQ4TxY8Ut+aY/97F4RHldls+PDh3HLLLXz77bf06dMHgIMHDzJ37lzmzJkDQEZGBoMHD+bhhx/G6XTy5ptvMnToUDZs2ECjRo3KPEZGRgYXXHAB/fr14+2332bz5s3cdtttRdr4fD4aNmzIrFmzqFWrFosXL+aGG26gXr16XHbZZdx55538/vvvpKenBwJIzZo12bVrV5H97Ny5k8GDBzN69GjefPNN1q9fz/XXX4/L5SoSjt544w3GjRvHzz//zJIlSxg9ejRnnnkm/fr1K/PzANxzzz189NFHvPHGGzRu3JgpU6YwYMAANm3aRM2aNbn//vtZt24dX331FbVr12bTpk1kZ2cD8Mwzz/DZZ5/xwQcf0KhRI7Zv38727dvLddzjpeBksQiHf9AvW3fBFREREamWatSowaBBg5g5c2YgOH344YfUrl2b8847D4COHTvSsWPHwDaTJk3ik08+4bPPPmPs2LFlHmPmzJn4fD5effVVXC4Xbdu2ZceOHdx0002BNg6Hg4kTJwZeN23alCVLlvDBBx9w2WWXER0dTUREBG63+5in5j3//PMkJSUxbdo0DMOgVatW7Nq1i3vuuYcHHngAm83/+2uHDh148MEHAWjRogXTpk1jwYIF5QpOmZmZvPDCC8yYMYNBgwYB8PLLL5OcnMyrr77KXXfdxbZt2+jUqRNdu3YF/JNnFNi2bRstWrTgrLPOwjAMGjduXOYxT5SCk8Vc4RpxEhERESmVI9I/8mPVscvpqquu4vrrr+f555/H6XTyzjvvcPnllwdCRkZGBhMmTODLL79k9+7d5OXlkZ2dzbZt28q1/99//50OHTrgcrkC63r27Fms3XPPPcdrr73Gtm3byM7OJjc3l9NPP73cn6PgWD179sQwjMC6M888k4yMDHbs2BEYIevQoUOR7erVq8fevXvLdYzNmzfj8Xg488wzA+scDgfdu3fn999/B+Cmm27i0ksv5ZdffqF///4MGzaMXr16Af5JLvr160fLli0ZOHAgF1xwAf379w/qcwZL1zhZzBXm/xEoOImIiIiUwDD8p8tZ8SgUHMoydOhQTNPkyy+/ZPv27Xz//fdcddVVgffvvPNOPvnkEx555BG+//57Vq1aRfv27cnNza2wr+q9997jzjvv5Nprr2XevHmsWrWKa665pkKPUZjD4Sjy2jCMYtd5nYhBgwaxdetW7rjjDnbt2kWfPn248847AejcuTObN29m0qRJZGdnc9lll/H3v/+9wo5dEgUni7kCk0PoVD0RERGR6srlcnHJJZfwzjvv8O6779KyZUs6d+4ceP/HH39k9OjRXHzxxbRv357ExES2bNlS7v23bt2a3377jZycnMC6n376qUibH3/8kV69enHzzTfTqVMnmjdvzp9//lmkTXh4OF7vsf9g37p1a5YsWYJZaHKMH3/8kZiYGBo2bFjumo+ladOmhIeH8+OPPwbWeTweli1bRps2bQLr6tSpw6hRo3j77bd5+umneemllwLvxcbGMmLECF5++WXef/99PvroIw4ePFgh9ZVEwcliEZocQkREROSkcNVVV/Hll1/y2muvFRltAv81QB9//DGrVq3i119/5corrwxqdObKK6/EMAyuv/561q1bx5w5c3jiiSeKHWP58uV8/fXX/PHHH9x///1FZqkD/3VCv/32Gxs2bGD//v14PJ5ix7r55pvZvn07t9xyC+vXr+fTTz/lwQcfZNy4cYFTD09UVFQUN954I3fddRdz585l3bp1XH/99WRlZXHttdcC8MADD/Dpp5+yadMm1q5dyxdffEHr1q0B+N///se7777L+vXr+eOPP5g1axaJiYnEx8dXSH0lUXCyWME1TpqOXERERKR6O//886lZsyYbNmzgyiuvLPLe//73P2rUqEGvXr0YOnQoAwYMKDIiVZbo6Gg+//xzVq9eTadOnfjPf/7DY489VqTNv/71Ly655BJGjBhBjx49OHDgADfffHORNtdffz0tW7aka9eu1KlTp8iIT4EGDRowZ84cli5dSseOHbnxxhu59tprue+++4L4Nso2efJkLr30Uv7xj3/QuXNnNm3axNdffx246W94eDjjx4+nQ4cOnHPOOdjtdt577z0AYmJimDJlCl27dqVbt25s2bKFOXPmVFiwK4lhmuWcoP4kkZ6eTlxcHGlpacTGxlpdDv/++FdmLt3BLeedxv8NaG11ORLiPB4Pc+bMYfDgwcXOKxYpifqMBEt9RoJV0X0mJyeHzZs307Rp0yITIcjJw+fzkZ6eTmxsbKUGnQLH6lPBZAONOFksQtc4iYiIiIiEPAUniznD/MHJrVP1RERERERCloKTxXQDXBERERGR0KfgZDFNDiEiIiIiEvoUnCym6chFREREijvF5i+TSlRRfUnByWJHboCr4CQiIiJit/t/N8rNzbW4EjlZFPSlgr51vMIqohg5fgXXOOXoGicRERERwsLCiIyMZN++fTgcjiqZrlqqls/nIzc3l5ycnEr/+fp8Pvbt20dkZCRhYScWfRScLObSqXoiIiIiAYZhUK9ePTZv3szWrVutLkcqgWmaZGdnExERgWEYlX48m81Go0aNTvhYCk4WcwVGnBScRERERADCw8Np0aKFTtc7SXk8HhYtWsQ555xTJTfaDg8Pr5CRLQUni+kGuCIiIiLF2Ww2XC6X1WVIJbDb7eTl5eFyuaokOFUUnTRqMZ2qJyIiIiIS+hScLBahWfVEREREREKegpPFXIVm1dP9CkREREREQpOCk8UKTtUDcOfpOicRERERkVCk4GQxV9iRH0F2rk7XExEREREJRQpOFguz27Ab/lP0dJ2TiIiIiEhoUnAKAeH5PwUFJxERERGR0KTgFAICwUmn6omIiIiIhCQFpxCQP7Ge7uUkIiIiIhKiFJxCQHj+xHpZGnESEREREQlJCk4hwKngJCIiIiIS0hScQkC4zT+rXlZunsWViIiIiIhISSwNTtOnT6dDhw7ExsYSGxtLz549+eqrr0ptP2PGDAzDKPJwuVxVWHHl0IiTiIiIiEhoC7Py4A0bNuTRRx+lRYsWmKbJG2+8wUUXXcTKlStp27ZtidvExsayYcOGwGvDMKqq3ErjzI+vGnESEREREQlNlganoUOHFnn98MMPM336dH766adSg5NhGCQmJpb7GG63G7fbHXidnp4OgMfjwePxHEfVFcvj8QQmh8jIDo2aJHQV9A/1Eykv9RkJlvqMBEt9RoIVSn0mmBosDU6Feb1eZs2aRWZmJj179iy1XUZGBo0bN8bn89G5c2ceeeSRUkMWwOTJk5k4cWKx9fPmzSMyMrJCaj9RTpt/yGnN+o3MydlQRmsRSE5OtroEqWbUZyRY6jMSLPUZCVYo9JmsrKxytzVM0zQrsZYyrV69mp49e5KTk0N0dDQzZ85k8ODBJbZdsmQJGzdupEOHDqSlpfHEE0+waNEi1q5dS8OGDUvcpqQRp6SkJPbv309sbGylfKZgeDwexr22gLk7bFzZvSETh7axuiQJYR6Ph+TkZPr164fD4bC6HKkG1GckWOozEiz1GQlWKPWZ9PR0ateuTVpaWpnZwPIRp5YtW7Jq1SrS0tL48MMPGTVqFN999x1t2hQPED179iwyGtWrVy9at27Niy++yKRJk0rcv9PpxOl0FlvvcDgs/0EVcNr92TXHY4ZMTRLaQqn/SvWgPiPBUp+RYKnPSLBCoc8Ec3zLg1N4eDjNmzcHoEuXLixbtoypU6fy4osvlrmtw+GgU6dObNq0qbLLrFTh+ZNDZGpyCBERERGRkBRy93Hy+XxFTq07Fq/Xy+rVq6lXr14lV1W5NB25iIiIiEhos3TEafz48QwaNIhGjRpx+PBhZs6cycKFC/n6668BGDlyJA0aNGDy5MkAPPTQQ5xxxhk0b96c1NRUHn/8cbZu3cp1111n5cc4YeGB6cgVnEREREREQpGlwWnv3r2MHDmS3bt3ExcXR4cOHfj666/p168fANu2bcNmOzIodujQIa6//npSUlKoUaMGXbp0YfHixSVeD1WdaMRJRERERCS0WRqcXn311WO+v3DhwiKvn3rqKZ566qlKrMgaBZND6Aa4IiIiIiKhKeSucToV6VQ9EREREZHQpuAUAgKn6rk14iQiIiIiEooUnEJAYMTJ48Xi+xGLiIiIiEgJFJxCQMGIk2lCjsdnbTEiIiIiIlKMglMIcBT6KWiCCBERERGR0KPgFAJsBkTkpydNECEiIiIiEnoUnEJERLj/fD0FJxERERGR0KPgFCIiw/231MrUqXoiIiIiIiFHwSlERDr8I07ZGnESEREREQk5Ck4hIjJ/ar1M3ctJRERERCTkKDiFiMj8a5yyPRpxEhEREREJNQpOIaLgVL1Mt4KTiIiIiEioUXAKEQWTQ+g+TiIiIiIioUfBKURoOnIRERERkdCl4BQiovKDk6YjFxEREREJPQpOVvN5Mcy8wIiTpiMXEREREQk9Ck5W+vo/OCYn0Gr3x4FZ9TQ5hIiIiIhI6FFwslKYEwC7L7fQdOQ6VU9EREREJNQoOFnJEQFAmM+tEScRERERkRCm4GQlRxQAdq+baKd/OvJMt0acRERERERCjYKTlcIjAbCbbqLyg1OGgpOIiIiISMhRcLKSwx+cwgqNOB3OUXASEREREQk1Ck5WchSMOOUGgpNGnEREREREQo+Ck5UKTtXzuol2FkwOkYdpmlZWJSIiIiIiR1FwslLBiJPvyDVOeT4Td57PyqpEREREROQoCk5WKrjGyZdLpMOOYfhX6zonEREREZHQouBkpUIjTjabQXS4rnMSEREREQlFCk5WCj8SnDBNol26l5OIiIiISChScLJS/oiTDR/4PIHrnHSqnoiIiIhIaFFwslJ+cAIgN0tTkouIiIiIhCgFJyuFhWPa/GEJTxYxroLg5LGwKBEREREROZqCk9UKRp08hUecvBYWJCIiIiIiR1Nwspojwv/syQpc45Sha5xEREREREKKgpPV8kecDE92oREnnaonIiIiIhJKFJys5ojyPxe+xkkjTiIiIiIiIUXByWJmwal6hWbVO6xZ9UREREREQoqCk9Xyb4JL3pFrnHQDXBERERGR0KLgZLWwIyNOR6YjV3ASEREREQklCk5WCy+YHKLQdOS6xklEREREJKQoOFktcB+nbF3jJCIiIiISohScLGYWvgGuS9c4iYiIiIiEIkuD0/Tp0+nQoQOxsbHExsbSs2dPvvrqq2NuM2vWLFq1aoXL5aJ9+/bMmTOniqqtJIWDk07VExEREREJSZYGp4YNG/Loo4+yYsUKli9fzvnnn89FF13E2rVrS2y/ePFirrjiCq699lpWrlzJsGHDGDZsGGvWrKniyiuQo/g1Tpm5Xrw+08qqRERERESkEEuD09ChQxk8eDAtWrTgb3/7Gw8//DDR0dH89NNPJbafOnUqAwcO5K677qJ169ZMmjSJzp07M23atCquvAIV3Mep0Kl6oJn1RERERERCSVjZTaqG1+tl1qxZZGZm0rNnzxLbLFmyhHHjxhVZN2DAAGbPnl3qft1uN263O/A6PT0dAI/Hg8fjOfHCT5DP5sQO+NyZ2EwfzjAb7jwfhzKyiQyZn46EioI+Gwp9V6oH9RkJlvqMBEt9RoIVSn0mmBos/9V89erV9OzZk5ycHKKjo/nkk09o06ZNiW1TUlJISEgosi4hIYGUlJRS9z958mQmTpxYbP28efOIjIw8seIrQMODf9EFOLhnB0vmzMFp2HFj8GXytzSMsro6CVXJyclWlyDVjPqMBEt9RoKlPiPBCoU+k5WVVe62lgenli1bsmrVKtLS0vjwww8ZNWoU3333XanhKVjjx48vMkqVnp5OUlIS/fv3JzY2tkKOcSJ8az2w9QVqxUQwePBgntn0I+n7MunY9Qx6NK1pdXkSYjweD8nJyfTr1w+Hw2F1OVINqM9IsNRnJFjqMxKsUOozBWejlYflwSk8PJzmzZsD0KVLF5YtW8bUqVN58cUXi7VNTExkz549Rdbt2bOHxMTEUvfvdDpxOp3F1jscDst/UAB5Ef7wZsvLwe5wEBfhrykj1wyJ+iQ0hUr/lepDfUaCpT4jwVKfkWCFQp8J5vghdx8nn89X5Jqkwnr27MmCBQuKrEtOTi71mqhqITA5RCZAIDil51h/zqeIiIiIiPhZOuI0fvx4Bg0aRKNGjTh8+DAzZ85k4cKFfP311wCMHDmSBg0aMHnyZABuu+02zj33XJ588kmGDBnCe++9x/Lly3nppZes/BgnpPANcAFiC4JTtoKTiIiIiEiosDQ47d27l5EjR7J7927i4uLo0KEDX3/9Nf369QNg27Zt2GxHBsV69erFzJkzue+++/j3v/9NixYtmD17Nu3atbPqI5y4QHDKBgqNOCk4iYiIiIiEDEuD06uvvnrM9xcuXFhs3fDhwxk+fHglVWSBo0ecXP7glKbgJCIiIiISMkLuGqdTTn5wMnx5kJdb6Bon3QBXRERERCRUKDhZLbzQvaQ8WcRG+AcBNeIkIiIiIhI6FJysZnPgK/gxeLICp+rpGicRERERkdCh4GQ1w8Bry7/PVG5W4FQ9jTiJiIiIiIQOBacQEAhOnswj05HrPk4iIiIiIiFDwSkE5Nld/gV3hkacRERERERCkIJTCMiz5Qen3MzANU45Hh/uPK+FVYmIiIiISAEFpxAQGHHKPUyMKwzD8L88rCnJRURERERCgoJTCMgLTA6Ric1mEO3UlOQiIiIiIqFEwSkE5Nki/AvuDIAjN8FVcBIRERERCQkKTiHgyKl6mQCB65w04iQiIiIiEhoUnELAkVP1DgMQH+kPTqlZCk4iIiIiIqFAwSkE5NnzT9XLH3GqERkOwKGsXKtKEhERERGRQhScQkDgBrj51zjViPKPOB3KVHASEREREQkFCk4h4MiIkz841QyMOOlUPRERERGRUKDgFAKOXONUMOLkD04HdaqeiIiIiEhIUHAKAXm2orPq1cwPTjpVT0REREQkNCg4hYDAdOQF1zjln6p3UMFJRERERCQkKDiFgFJHnHSqnoiIiIhISFBwCgHeQHDy38epRuBUPQ+maVpVloiIiIiI5FNwCgEe+1EjTvmn6uV6fWTmeq0qS0RERERE8ik4hYDAqXreXMjLJSLcjsvh/9FogggREREREespOIUAb8GIExS7l5MmiBARERERsZ6CUwgwDTtmWMHperqXk4iIiIhIqFFwChXhUf5n3ctJRERERCTkKDiFivBo/7Pu5SQiIiIiEnIUnEJFYMQp/xqn/BGnAwpOIiIiIiKWU3AKEWbBiFN+cKod7Q9O+w+7rSpJRERERETyKTiFiqOucaob458sYq+Ck4iIiIiI5RScQkXgGqfDANSJcQKwT8FJRERERMRyCk6h4qgRp0BwylBwEhERERGxmoJTiDj6Gqe6+cHpQIYbr8+0qiwREREREUHBKXQcNR15rWgnNgN8JhzI1KiTiIiIiIiVFJxCxVHXONltBjWj/KNOe9MVnERERERErKTgFCqcsf5nd1pgVV1d5yQiIiIiEhIUnEKE6YrxL+SkB9ZpZj0RERERkdCg4BQqnHH+Z/eR4FRXwUlEREREJCQoOIUKV/6pehpxEhEREREJOQpOIcIMXONUfMRp7+EcK0oSEREREZF8Ck6hwll8xCkh1gVASpqCk4iIiIiIlRScQkVBcPK6weMPSvXjIwDYmZptVVUiIiIiIoKCU+hwRgOGfzn/dL0GNfzBae9hN7l5PosKExERERERS4PT5MmT6datGzExMdStW5dhw4axYcOGY24zY8YMDMMo8nC5XFVUcSUybOAsOiV5rahwwsNsmCbsSdfpeiIiIiIiVrE0OH333XeMGTOGn376ieTkZDweD/379yczM/OY28XGxrJ79+7AY+vWrVVUcSU76ia4hmHQIP90vR2HdLqeiIiIiIhVwqw8+Ny5c4u8njFjBnXr1mXFihWcc845pW5nGAaJiYmVXV7Vc8VCOkUmiGgQH8Hm/Zns0nVOIiIiIiKWsTQ4HS0tzT/SUrNmzWO2y8jIoHHjxvh8Pjp37swjjzxC27ZtS2zrdrtxu4/cByk93R9KPB4PHo+ngio/fgU1eDwe7OEx2IC8rEOY+esTY/1Tkm87kBES9Yq1CvcXkfJQn5Fgqc9IsNRnJFih1GeCqcEwTdOsxFrKzefzceGFF5KamsoPP/xQarslS5awceNGOnToQFpaGk888QSLFi1i7dq1NGzYsFj7CRMmMHHixGLrZ86cSWRkZIV+hhPV488nSUz/lZWNrmVbrXMB+Gq7wdwddnrW9XF5M00QISIiIiJSUbKysrjyyitJS0sjNjb2mG1DJjjddNNNfPXVV/zwww8lBqDSeDweWrduzRVXXMGkSZOKvV/SiFNSUhL79+8v88upCh6Ph+TkZPr164fryzHY1n6Mt+8kfD1uAuCjX3Zy7ydrOat5LV4f1cXiasVqhfuLw+GwuhypBtRnJFjqMxIs9RkJVij1mfT0dGrXrl2u4BQSp+qNHTuWL774gkWLFgUVmgAcDgedOnVi06ZNJb7vdDpxOp0lbmf1D6owh8OBLSIeALsnE3t+bY1qRQOwKzUnpOoVa4Va/5XQpz4jwVKfkWCpz0iwQqHPBHN8S2fVM02TsWPH8sknn/DNN9/QtGnToPfh9XpZvXo19erVq4QKq1hgVr0jk0M0rh0FwLaDWeR5daqeiIiIiIgVLA1OY8aM4e2332bmzJnExMSQkpJCSkoK2dlHZpAbOXIk48ePD7x+6KGHmDdvHn/99Re//PILV199NVu3buW6666z4iNULFd+cCo0q169WBfOMBt5PlNTkouIiIiIWMTS4DR9+nTS0tLo3bs39erVCzzef//9QJtt27axe/fuwOtDhw5x/fXX07p1awYPHkx6ejqLFy+mTZs2VnyEinXUfZwAbDaDpvmjTpv3H/v+ViIiIiIiUjksvcapPPNSLFy4sMjrp556iqeeeqqSKrKYK87/XGjECaBp7SjWpxzmr/2ZnGdBWSIiIiIipzpLR5zkKCVc4wQUGnHKqOqKREREREQEBafQUsI1ToBO1RMRERERsZiCUygJnKqXVmT1aXX8wemvfQpOIiIiIiJWUHAKJa54/3NOKhS6/qtFQgwAu9NySM3Krfq6REREREROcQpOoSSypv/Zlwe5R65ninU5aFQzEoB1u9NL2lJERERERCqRglMocURAmMu/nHWwyFtt6vmvf1q3S8FJRERERKSqKTiFmoga/ufsQ0VWt6mv4CQiIiIiYhUFp1BTWnAqGHHSqXoiIiIiIlVOwSnURORf53RUcGrXwD/j3sa9GWS686q6KhERERGRU5qCU6iJiPc/HxWcEuNcNKwRgddn8su2Q8W3ExERERGRSqPgFGoCp+odLPZW9yb+0ailm4u/JyIiIiIilUfBKdQEglNqsbe6N/UHp58VnEREREREqpSCU6iJLPkaJzgSnFZtSyVD1zmJiIiIiFQZBadQU8qsegBNa0fRtHYUuV4fCzfsreLCREREREROXQpOoaYgOGUVPx3PMAz6t00AYN7aPVVZlYiIiIjIKU3BKdSUMh15gf5tEgFY8Psena4nIiIiIlJFFJxCzTFO1QPo3Cie02pHkZnr5dNVO6uwMBERERGRU5eCU6gpHJxMs9jbhmFwZY9GAMz4cQteX/E2IiIiIiJSsRScQk1BcPJ5IDejxCbDuyYRF+Fg494MPvplRxUWJyIiIiJyalJwCjXhkRDm8i+XcrpeXISDMec1A2DynN/ZnZZdVdWJiIiIiJySFJxCUWBmvQOlNhnVqwntGsRyKMvDP2cs50CGu4qKExERERE59Sg4haKo2v7nzP2lNnGG2Xnuys7Ujnby++50Bj/zPR//soPcPF8VFSkiIiIicuoIs7oAKUFUXf9z5r5jNmtcK4r3bjiDG95azl/7Mhn3wa/cN3sNnRvVoEntSBJiXEQ5w4h2hhFmN7Db8h9GoWVb0fVhdgObYRBms2GzQZjNht0GdpvNv5295O3DbAXbGdhsRhV8SSIiIiIiVUfBKRRF1fE/lxGcAJrXjebLW87m1R/+4q2ftrIn3c0Pm/bzw6ZKrvEYIhx2IsPtRDrtRDrCiAi3E+W0E+EIIzYijIRYF/XiXNSLi6BenIsG8RHUiAq3rmARERERkTIoOIWi6PzglLG3XM0jwu2MPb8FN/duzu8p6azekca2g1kczMwlw51HpjuPPJ+JzzTJ8+Y/+0x8PhPvUeu8JT1ME683v23+dnnHmAY92+Ml2+PlQGb5P3JCrJN29ePo0qQG57WsS6vEGAxDI1ciIiIiEhoUnEJRYMSp9GucSmKzGbStH0fb+nGVUFRxBQGqcOjyeH1k53rJzM0jK9dLlttLVv5yZm4eadke9qa72ZWaTUp6DrtSc9if4WZPups96XtZsH4vU+Zu4G8J0VzRvRFXdG+Ey2Gvks8jIiIiIlIaBadQFLjGqXwjTlax2QzCK+B6pkx3Hr/vTue3HWks/nM/i/7Yzx97Mpj4+Tpe/WEz/x7cmkHtEjUCJSIiIiKWUXAKRUFc43QyiHKG0bVJTbo2qck/z2pKWraHz37dxfPfbmLHoWxufucXLjq9PlP+3gFnmEafRERERKTqaTryUFQwHXnGqRGcjhYX4eAfZzRmwf+dyy3nN8duM/h01S6ue2M5Wbl5VpcnIiIiIqcgBadQFJ1/ql7WfvCduvdligwP4//6t+SNa7oT4bDz/cb9jHx1Kek5HqtLExEREZFTjIJTKIrMH3Hy5UFOqqWlhIKzWtTm7et6EOsKY/nWQ9z67kq8x5jVT0RERESkoik4haKwcHDF+5dPkeucytKlcQ3evq4H4WE2Fm7Yx0uL/rK6JBERERE5hSg4hapTbIKI8ujQMJ7/DG4NwGNz17PkzwMWVyQiIiIipwoFp1BVcJ1TOW+Ce6oY2bMx/dokAHDDm8sxTZ2yJyIiIiKVT8EpVAWC0x5r6wgxhmEw8cK2ABx25zFj8RZrCxIRERGRU8JxBaft27ezY8eOwOulS5dy++2389JLL1VYYae82Ab+5/Sd1tYRgurHR/DABW0AeHLeH2Tnei2uSEREREROdscVnK688kq+/fZbAFJSUujXrx9Lly7lP//5Dw899FCFFnjKiq3vf07fZW0dIeofPRvTsEYEGe48Hpu73upyREREROQkd1zBac2aNXTv3h2ADz74gHbt2rF48WLeeecdZsyYUZH1nboUnI7JYbdxcSf/qNyMxVvI8WjUSUREREQqz3EFJ4/Hg9PpBGD+/PlceOGFALRq1Yrdu3dXXHWnshgFp7Lc3Lt5YHnqgo0WViIiIiIiJ7vjCk5t27blhRde4Pvvvyc5OZmBAwcCsGvXLmrVqlWhBZ6yCkacDu8Gn8/aWkJURLidHk1rAjB94Z94vPqeRERERKRyHFdweuyxx3jxxRfp3bs3V1xxBR07dgTgs88+C5zCJycoJhEwwJsLWbpfUWmmXt4psDxntUY7RURERKRyhB3PRr1792b//v2kp6dTo0aNwPobbriByMjICivulGZ3QHQCZKT4Z9aLrmN1RSEpMc5F7ehw9mfkctt7q7jo9AZWlyQiIiIiJ6HjGnHKzs7G7XYHQtPWrVt5+umn2bBhA3Xr1i33fiZPnky3bt2IiYmhbt26DBs2jA0bNpS53axZs2jVqhUul4v27dszZ86c4/kYoU8TRJTLY5d2CCx/u143DBYRERGRindcwemiiy7izTffBCA1NZUePXrw5JNPMmzYMKZPn17u/Xz33XeMGTOGn376ieTkZDweD/379yczM7PUbRYvXswVV1zBtddey8qVKxk2bBjDhg1jzZo1x/NRQlsgOOleTsfSp3VCYPmaGcssrERERERETlbHFZx++eUXzj77bAA+/PBDEhIS2Lp1K2+++SbPPPNMufczd+5cRo8eTdu2benYsSMzZsxg27ZtrFixotRtpk6dysCBA7nrrrto3bo1kyZNonPnzkybNu14PkpoK7gJbtqOY7cTYlxHzjrVJBEiIiIiUtGO6xqnrKwsYmJiAJg3bx6XXHIJNpuNM844g61btx53MWlpaQDUrFmz1DZLlixh3LhxRdYNGDCA2bNnl9je7XbjdrsDr9PT0wH/lOoej+e4a60oBTWUVIstLgk74DvwF94QqDWUzbmlF2c/vgiA/81bz7i+LSyuqHIcq7+IlER9RoKlPiPBUp+RYIVSnwmmhuMKTs2bN2f27NlcfPHFfP3119xxxx0A7N27l9jY2OPZJT6fj9tvv50zzzyTdu3aldouJSWFhISEIusSEhJISUkpsf3kyZOZOHFisfXz5s0LqYkskpOTi61LSDvAGUD61l/57mS9jqtC+bvz9O820yr35L6vU0n9ReRY1GckWOozEiz1GQlWKPSZrKyscrc9ruD0wAMPcOWVV3LHHXdw/vnn07NnT8AfRjp16lTG1iUbM2YMa9as4Ycffjiu7Uszfvz4IiNU6enpJCUl0b9//+MOeRXJ4/GQnJxMv379cDgcRd/c1wxeeoo430EGDxoEhmFNkdVEbv1d3PWR/1q31t3PpWntKIsrqnjH7C8iJVCfkWCpz0iw1GckWKHUZwrORiuP4wpOf//73znrrLPYvXt34B5OAH369OHiiy8Oen9jx47liy++YNGiRTRs2PCYbRMTE9mzZ0+RdXv27CExMbHE9k6nE6fTWWy9w+Gw/AdVWIn11GkGgOE+jMNzGKJ0c+Fj+XvXRoHgdN9nv/PBv3paXFHlCbX+K6FPfUaCpT4jwVKfkWCFQp8J5vjHNTkE+ANMp06d2LVrFzt2+Ccv6N69O61atSr3PkzTZOzYsXzyySd88803NG3atMxtevbsyYIFC4qsS05ODox6nVQcERCTP7Peoc3W1lINGIZB+wZxACzdfNDiakRERETkZHJcwcnn8/HQQw8RFxdH48aNady4MfHx8UyaNAmfr/wzmo0ZM4a3336bmTNnEhMTQ0pKCikpKWRnZwfajBw5kvHjxwde33bbbcydO5cnn3yS9evXM2HCBJYvX87YsWOP56OEvpr5YfKgglN5TL389MDyiq2HrCtERERERE4qxxWc/vOf/zBt2jQeffRRVq5cycqVK3nkkUd49tlnuf/++8u9n+nTp5OWlkbv3r2pV69e4PH+++8H2mzbto3du3cHXvfq1YuZM2fy0ksv0bFjRz788ENmz559zAklqrUaTfzPGnEql9PqRAeWr3l9qYWViIiIiMjJ5LiucXrjjTd45ZVXuPDCCwPrOnToQIMGDbj55pt5+OGHy7Uf0zTLbLNw4cJi64YPH87w4cPLXW+1Vst/nRP7T+5Z4ipS39Z1mf/7XtJz8tiVmk39+AirSxIRERGRau64RpwOHjxY4rVMrVq14uBBXVtSoeq28T/v/d3aOqqR567qHFge/sISCysRERERkZPFcQWnjh07Mm3atGLrp02bRocOHU64KCmkbmv/8/4N4M2ztpZqwhlmDyzvTM0+RksRERERkfI5rlP1pkyZwpAhQ5g/f35gNrslS5awfft25uhGrRUrrhE4osCTCQf/gjp/s7qiauGDf/Xkshf9o033z17DpGEn6TVwIiIiIlIljmvE6dxzz+WPP/7g4osvJjU1ldTUVC655BLWrl3LW2+9VdE1ntpsNqibf1rk3nXW1lKNdG9aM7D81k9bLaxERERERE4Gx30fp/r16/Pwww/z0Ucf8dFHH/Hf//6XQ4cO8eqrr1ZkfQJHTtdTcArKk8OP3Jx5+sI/LaxERERERKq74w5OUoUS8wPAzl+sraOauaRzg8DyY3PXW1iJiIiIiFR3Ck7VQVI3//OOZRDEDYZPdYZh0LtlncDrD5Ztt7AaEREREanOFJyqg4R2EBYBOalwYJPV1VQrL/2ja2D57o9+s7ASEREREanOgppV75JLLjnm+6mpqSdSi5TG7oD6nWDbYtixVDPrBSE8rOjfBlZtT+X0pHhrihERERGRaiuoEae4uLhjPho3bszIkSMrq9ZTW1J3//OWH6ytoxr67q7egeVhz/1oXSEiIiIiUm0FNeL0+uuvV1YdUpbmfeDHp2HTfP91TjadZVlejWtF0aVxDVZsPQTA8i0H6dqkZhlbiYiIiIgcod++q4ukMyA8BjL3we5VVldT7bxzXY/A8t9fWGJhJSIiIiJSHSk4VRdh4dCst3953aeWllIduRz2Iq+3Hsi0qBIRERERqY4UnKqT9sP9z7++B948a2uphubdcU5g+dzHF1pXiIiIiIhUOwpO1cnfBkFkLchIgT++srqaaudvCTFWlyAiIiIi1ZSCU3USFg6dR/mXFz6qm+Eeh/8OaxdYvnPWrxZWIiIiIiLViYJTddPrFnDGwp418NNzVldT7Vx9RuPA8ocrdlhYiYiIiIhUJ0FNRy4hILIm9JsIX9wByQ+CKx46XQ2GceztPDngToecNMhzgy8PfN785zwwvYDh349hy1+2HfW6hPftDv/DdtRzwbLNXnZtVeyxS9tzz0erAfj8110M7Vjf4opEREREJNQpOFVHXa6BnStg5dvw2VhY+hI0ORtcceB1+6csP5zif2TshexD/vVWsTnAHg6OCHDGgCvWP2rmjPHXHJMIsQ0gph7Uau5/2Cuva/69S1IgON3y7koFJxEREREpk4JTdWQYMPRZiG8Cix6HlN/8j7I39AeWMCfYwvIfdv+zkX/WpukDTP+zaRZaLvxewTof+DzgzX/4PPltjuLLf8+TCVn7yy7T7oR6HaB5X2jRH+p3qtBRK7ut6L5M08QIsVExEREREQktCk7Vlc0G594FXa+BDXNg3wbIzfSfIhdVB6IT/CM50Qn+mfhcsf4b6Noq+bI2n/dIiPJ6/KcBenP9y54scB/Of6RDTrp/NOzwbkjfBek7Yd8f/oC1Y5n/sXAy1P4bdL8BOv0DHK4KKfPXB/vTceI8AN75eVuRa59ERERERI6m4FTdRdWGziOtruIIm93/4DgDjs8HhzbD1h9h4zzYtAD2/wFz7oRFT8BZt0O360/4VL64CAeJsS5S0nO4b/YaBScREREROSbNqiehxWaDWs38YXDE2/B/G2DQ4xDb0H//qrn3wowhkLrthA9183nNAssHMiy8BkxEREREQp6Ck4Q2Vyz0uAFuXQlD/uc/3XD7TzD9LPjzmxPa9eXdGgWWv99YjmuvREREROSUpeAk1UNYOHS7Fm78Hhp0BXcazBwBv39+3LsMD7PRqVE8ALe/v6pi6hQRERGRk5KCk1QvNZvCNV9B6wv9k058MAp+ff+4d9ejaa3A8u607IqoUEREREROQgpOUv2EhcPfX4fTr/LfuPeTf8FvHxzXrq4/u2lg+azHvq2oCkVERETkJKPgJNWTPQwunOafphwTPrsV9qwLeje1op2BZa/PrMACRURERORkouAk1ZfNBgMfg2bnQ142zBoNeblB7+bO/n8LLC/bcrACCxQRERGRk4WCk1RvNhtc8rL/pr/7N8CvM4PexZjzmgeWh7+wpCKrExEREZGThIKTVH9RteGscf7lhY9CTnpQmxuGUQlFiYiIiMjJRMFJTg5d/wk1T4PDu/03yQ3SZ2PPDCyn53gqsjIREREROQkoOMnJweGCC58Fwwar3oGdK4LavEPD+MDy9IV/VnBxIiIiIlLdKTjJyaPJWdBhhH/528nHvRsFJxERERE5moKTnFzOuQsMO2xKhi0/BLVp39Z1A8uHMoOfnU9ERERETl4KTnJyqdUMOo/0L//8QlCbPndV58DyeU8urMCiRERERKS6U3CSk0/Xa/zPG5PBnVHuzZxh9sByapYmiBARERGRIxSc5OST2ME/w15eDvwxN6hNXxvdFYCkmhGVUZmIiIiIVFMKTnLyMQxofaF/ef0XQW3atUlNALYfzObX7akVXJiIiIiIVFcKTnJyKghOG5PBk1PuzWJdjsDyRc/9WNFViYiIiEg1peAkJ6f6nSAuCXIzYN2nVlcjIiIiItWcgpOcnGw26DLKv7zslaA2XXhn78ByWrYmiRARERERi4PTokWLGDp0KPXr18cwDGbPnn3M9gsXLsQwjGKPlJSUqilYqpdOI8EWBjuWwu5fy71Z41qRgeWOE+dVRmUiIiIiUs1YGpwyMzPp2LEjzz33XFDbbdiwgd27dwcedevWLXsjOfXEJEDrof7l1R+WezPDMCqpIBERERGprsKsPPigQYMYNGhQ0NvVrVuX+Pj4crV1u9243e7A6/T0dAA8Hg8ej/WnYRXUEAq1nIyMFgMJW/sJ5qYF5J33QLm3u71Pc55esAmA3NzckAlT6i8SLPUZCZb6jARLfUaCFUp9JpgaLA1Ox+v000/H7XbTrl07JkyYwJlnnllq28mTJzNx4sRi6+fNm0dkZGQJW1gjOTnZ6hJOSuF5eQzEwNi7lm8+fYccR41ybVczFwr+8/i/V+bSt4FZeUUeB/UXCZb6jARLfUaCpT4jwQqFPpOVlVXutoZpmiHxG6FhGHzyyScMGzas1DYbNmxg4cKFdO3aFbfbzSuvvMJbb73Fzz//TOfOnUvcpqQRp6SkJPbv309sbGxFf4ygeTwekpOT6devHw6Ho+wNJGj21/tj2/UL3gGP4et6bbm3a3H/keubNk7qXxmlBU39RYKlPiPBUp+RYKnPSLBCqc+kp6dTu3Zt0tLSyswG1WrEqWXLlrRs2TLwulevXvz555889dRTvPXWWyVu43Q6cTqdxdY7HA7Lf1CFhVo9J5V2l8KuX7Cv+wR7zxuPaxeh9rNRf5Fgqc9IsNRnJFjqMxKsUOgzwRy/2k9H3r17dzZt2mR1GRLK2l4MGLD9J0jdXu7Nxg9qFVjesj+zEgoTERERkeqi2genVatWUa9ePavLkFAW1wAa9/Ivr/243JuN6tUksDxnze4KLkpEREREqhNLg1NGRgarVq1i1apVAGzevJlVq1axbds2AMaPH8/IkSMD7Z9++mk+/fRTNm3axJo1a7j99tv55ptvGDNmjBXlS3XS7lL/cxDTkrsc9sDylLkbKroiEREREalGLL3Gafny5Zx33nmB1+PGjQNg1KhRzJgxg927dwdCFPinhf6///s/du7cSWRkJB06dGD+/PlF9iFSojbD4Ku7IeU32L8RarewuiIRERERqUYsDU69e/fmWJP6zZgxo8jru+++m7vvvruSq5KTUlQtOO082JTsH3U6b3y5Nnvjn90Z9dpSAP7cl0GzOtGVWaWIiIiIhKhqf42TSLm1/7v/ec1HUM5Z+M9qXjuw3OfJ7yqjKhERERGpBhSc5NTRcjCEueDARv8pe+VgtxmVXJSIiIiIVAcKTnLqcMVCi/wb2QYxSYSIiIiIiIKTnFoCp+t9DD5fuTaZdmWnwPLe9JzKqEpEREREQpyCk5xaWvSH8BhI3+G/IW45DGl/5D5hbyzZUkmFiYiIiEgoU3CSU4sjAtpe5F9eMaNcmxjGkeucnvv2z0ooSkRERERCnYKTnHq6/tP/vPYTyNxfrk2iwo/cDNfnK9+MfCIiIiJy8lBwklNPgy5QvxN4c2Hl2+XaZOrlR65z+nnzwcqqTERERERClIKTnJq6Xut/Xv5auSaJ6NO6bmB564HMyqpKREREREKUgpOcmtpdCq44SN0Km+aX2bzwdU73fry6MisTERERkRCk4CSnpvBIOP1q//LSl6ytRURERERCnoKTnLq6XwcYsCkZ9m8qs/n3d58XWP5zX0YlFiYiIiIioUbBSU5dNU+Dvw30L//0fJnNk2pGBpbHzlxZWVWJiIiISAhScJJTW88x/udV70DGvnJv9vvudDzesieVEBEREZGTg4KTnNqanOWfnjwvJ+hrnd5YvKVyahIRERGRkKPgJKc2w4Azb/MvL30J3Me+dqlXs1qB5dmrdlZmZSIiIiISQhScRFpdADWbQU4qrHzrmE3fua5HYPlQpqeSCxMRERGRUKHgJGKzQ69b/MtLngNv6YGo8P2cdqZmV3ZlIiIiIhIiFJxEADpeAVF1IW07rP2k3JuZplmJRYmIiIhIqFBwEgFwuOCMG/3LP06FYwSiW/u0CCx/s35vZVcmIiIiIiFAwUmkQNd/Qng07FkDmxaU2mxkz8aB5WvfWF4VlYmIiIiIxRScRApE1IAuo/3LPz5darMakeFVUo6IiIiIhA4FJ5HCzrgJbGGw5XvY+UuJTew2o8hrXeckIiIicvJTcBIpLK4htPu7f/kYo07dm9QMLLvzfJVclIiIiIhYTcFJ5Ghn3e5/XvcZ7PujxCbTr+4cWP5qze4qKEpERERErKTgJHK0uq2h5RDALHXUqfB1Tne8/2vV1CUiIiIillFwEinJ2eP8z7+9D6nbir1t03VOIiIiIqcUBSeRkjTsCk3PBV8eLH62xCbXndU0sDxj8ZYqKkxERERErKDgJFKas//P//zLm5BR/Ea3Y85rHlie+Pm6qqpKRERERCyg4CRSmqbnQIOukJcDS54r9naNKN3PSURERORUoeAkUhrDODLqtPx1cGdYW4+IiIiIWEbBSeRY/jYQajYDdxqsmlns7YFtEwPLHq/u5yQiIiJyslJwEjkWmw3OuMm//PN08BUNR5OGtQsst/jPV1VZmYiIiIhUIQUnkbJ0vAJccXDwL9j4dZG36sQ4LSpKRERERKqSgpNIWZzR0HmUf/nnF47ZVPdzEhERETk5KTiJlEe368CwwV8LYd+GUptluPOqriYRERERqTIKTiLlUaMx/G2Qf3npy0Xemnv72YHl0x9KrsqqRERERKSKKDiJlFePG/zPv74HuVmB1a0SYwPLXp9O1RMRERE5GSk4iZRXk3MgvjHkHob1X1hdjYiIiIhUIQUnkfKy2fwz7AH88mapzRb/ub+KChIRERGRqqLgJBKMTleBzQFbvoc/vw2s/te5pwWWr3z5ZysqExEREZFKZGlwWrRoEUOHDqV+/foYhsHs2bPL3GbhwoV07twZp9NJ8+bNmTFjRqXXKRIQ3wi6XetfTn4gcEPc2/q0sLAoEREREalslganzMxMOnbsyHPPPVeu9ps3b2bIkCGcd955rFq1ittvv53rrruOr7/+uuyNRSrKOXeBMxZSfoPVswCIDA+zuCgRERERqUyW/rY3aNAgBg0aVO72L7zwAk2bNuXJJ58EoHXr1vzwww889dRTDBgwoLLKFCkqqjaceSt8819YMg06XAaGUaTJ77vTaV0vtpQdiIiIiEh1U63+TL5kyRL69u1bZN2AAQO4/fbbS93G7XbjdrsDr9PT0wHweDx4PJ5KqTMYBTWEQi0ShI4jCfvucYyU38jbuhSzQWeGdazH7F93AzBo6vdsnNS/wg+r/iLBUp+RYKnPSLDUZyRYodRngqmhWgWnlJQUEhISiqxLSEggPT2d7OxsIiIiim0zefJkJk6cWGz9vHnziIyMrLRag5WcrBunVjedY7uSdOhHdn02iZWNr+dsF8wu9J/U51/OwW4cYwcnQP1FgqU+I8FSn5Fgqc9IsEKhz2RlZZXdKF+1Ck7HY/z48YwbNy7wOj09naSkJPr3709srPWnUnk8HpKTk+nXrx8Oh8PqciQIxo468MYgktKXUe+81yEinv/7eV7g/eadz6Z1vZgKPab6iwRLfUaCpT4jwVKfkWCFUp8pOButPKpVcEpMTGTPnj1F1u3Zs4fY2NgSR5sAnE4nTqez2HqHw2H5D6qwUKtHyqFJT0hoj7FnNY61s6DnzUXevvD5JWx5dEilHFr9RYKlPiPBUp+RYKnPSLBCoc8Ec/xqdR+nnj17smDBgiLrkpOT6dmzp0UVySnNMKDrNf7l5a+C18PUy0+3tCQRERERqRyWBqeMjAxWrVrFqlWrAP9046tWrWLbtm2A/zS7kSNHBtrfeOON/PXXX9x9992sX7+e559/ng8++IA77rjDivJF/DPqueLgwCb47jEuOr1BkbfzvD6LChMRERGRimRpcFq+fDmdOnWiU6dOAIwbN45OnTrxwAMPALB79+5AiAJo2rQpX375JcnJyXTs2JEnn3ySV155RVORi3WcMXDBU/7lxdMgJ40pl3YIvD3pi3UWFSYiIiIiFcnSa5x69+6NaZqlvj9jxowSt1m5cmUlViUSpLaXwHdTYN96WP0hA9qN5O6PfgPgjSVbue+CNjjs1eqsWBERERE5in6bEzlRhgGd/uFfXvYqcU57kbe/Wb/XgqJEREREpCIpOIlUhNOvBGcs7F0Lq2cVeevuD3+zqCgRERERqSgKTiIVIbImnHmbf/nr8cSREXgrLdv6u2KLiIiIyIlRcBKpKL1uhTqtIOsAr3f+y+pqRERERKQCKTiJVJSwcOgyGoDOh78t8tb2g1kWFCQiIiIiFUXBSaQitRkGGLD9Z+pxILD67CnfcjAz17KyREREROTEKDiJVKTYetD4TABuqLWqyFvXzFhmQUEiIiIiUhEUnEQqWofhAIyyzcWFO7D61+2pFhUkIiIiIidKwUmkonW4HGIbYju8k3vD3rW6GhERERGpAApOIhXN4YKLngXgavv8Itc6/bHnsFVViYiIiMgJUHASqQzNzofGZxFm+BgdNjewuv9TiywsSkRERESOl4KTSGXp/A8A/hX2JZ+EP4ATzaonIiIiUl0pOIlUlvaXsTvudAA62TYxyLYUgC37My0sSkRERESOh4KTSGWx2ahz7azAy7PtvwEw8fO1VlUkIiIiIsdJwUmkEoXF1mX5OTMAOMu2BjD5dsM+3HleS+sSERERkeAoOIlUsi5nDyTHdJBgpPI3YwcAz32zyeKqRERERCQYCk4ilcxwRLApogMA85z3EEkOzyg4iYiIiFQrCk4iVSA76dzA8nD7dxZWIiIiIiLHQ8FJpAqcftEtgeXetlXWFSIiIiIix0XBSaQKOKJrsuqCOQCcZ/+V4faF3PDmcg7neKwtTERERETKRcFJpIp06NSTzb4EAB4Le5mV69bz3Ld/WlyViIiIiJSHgpNIFbHZbVzjudu/bJjc53iHvYdzLK5KRERERMpDwUmkCm0x63FD7h0ADLAtIyMj0+KKRERERKQ8FJxEqtCy//Rlnq8ru82auAwPL20bDLt/s7osERERESmDgpNIFaoT4wQMFvvaBtateHeidQWJiIiISLkoOIlY4OW8IYFlV+pGCysRERERkfJQcBKpYr/c34/1ZiN6u58EoK1tK3z7CJimxZWJiIiISGkUnESqWM2ocAB2mnWOrPzuMdiYbFFFIiIiIlIWBScRC6ye0B8PYUXWeb+dDO4MiyoSERERkWNRcBKxQIzLAcC/8qcmB7Dv/gVeOhe8eVaVJSIiIiKlUHASsci8O87ha1832ua8So7pD1Ic2AQ7l1tbmIiIiIgUo+AkYpG/JcQAkEkE13ruPPLGtp8sqkhERERESqPgJBICfvS1Z5LnKv+L9V9ohj0RERGREKPgJGKhGOeRCSIW+9r5F3Ysg0cbwa6VFlUlIiIiIkdTcBKx0OLx5weWfzcb85jncv8Ldzq80heyDlpUmYiIiIgUpuAkYqGC2fUKTPdeyOFmF/hf+PJg5woLqhIRERGRoyk4iYSY9muvwPzbAP+LHZphT0RERCQUKDiJWOzFf3Q5ao3BE3829C9+9yjs/q3KaxIRERGRohScRCzWs1mtYuu+y2p65MWLZ8OX/wd5uVVYlYiIiIgUpuAkYrFYl4MV9/UlqWZEYN0asykbah2ZOIJlr8Dajy2oTkRERERAwUkkJNSKdvLwsPaF1hgM2Hkdvjqtj6z6Y26V1yUiIiIifgpOIiEiqtA9nQpcvOMK8mq19L/YvEg3xhURERGxSEgEp+eee44mTZrgcrno0aMHS5cuLbXtjBkzMAyjyMPlclVhtSKVo3Oj+GLrfjWb03bneEzDDlkHsH19D7UPr6v64kREREROcZYHp/fff59x48bx4IMP8ssvv9CxY0cGDBjA3r17S90mNjaW3bt3Bx5bt26twopFKodhGHx3V+9i692EkxPfHAD7itc4c9OjVVyZiIiIiFgenP73v/9x/fXXc80119CmTRteeOEFIiMjee2110rdxjAMEhMTA4+EhIQqrFik8jSuFVXi+g/N84u8DpveA/b+XhUliYiIiAhQ/KKKKpSbm8uKFSsYP358YJ3NZqNv374sWbKk1O0yMjJo3LgxPp+Pzp0788gjj9C2bdsS27rdbtxud+B1eno6AB6PB4/HU0Gf5PgV1BAKtUho+PBfPfj7iz8XWXd/ytm0H9Cd07+7BgDj4J94l76Cb4BGn+TY9G+MBEt9RoKlPiPBCqU+E0wNlgan/fv34/V6i40YJSQksH79+hK3admyJa+99hodOnQgLS2NJ554gl69erF27VoaNmxYrP3kyZOZOHFisfXz5s0jMjKyYj5IBUhOTra6BAkR/vkfiv+n+cQqBy+G1yUq138a6/4NS/nJO6dqi5NqS//GSLDUZyRY6jMSrFDoM1lZWeVua2lwOh49e/akZ8+egde9evWidevWvPjii0yaNKlY+/HjxzNu3LjA6/T0dJKSkujfvz+xsbFVUvOxeDwekpOT6devHw6Hw+pyJETUa5/KiJeLTpKy3RNNXuOzYKP/fk51o2Dw4MFWlCfViP6NkWCpz0iw1GckWKHUZwrORisPS4NT7dq1sdvt7Nmzp8j6PXv2kJiYWK59OBwOOnXqxKZNm0p83+l04nQ6S9zO6h9UYaFWj1irR7M63DekNf/98sh1TFsPZjHs0JnMiv+V2tl/YqT8huOZDjDmZ3BZ/0cACW36N0aCpT4jwVKfkWCFQp8J5viWTg4RHh5Oly5dWLBgQWCdz+djwYIFRUaVjsXr9bJ69Wrq1atXWWWKWOKaM5sWW7fZrEfXQw9huuL9Kw7vgscaw5Yfweer2gJFRERETiGWz6o3btw4Xn75Zd544w1+//13brrpJjIzM7nmGv9F8CNHjiwyecRDDz3EvHnz+Ouvv/jll1+4+uqr2bp1K9ddd51VH0GkUthtRinvGHzd5O4jL00fzBgMK0qfiVJERERETozl1ziNGDGCffv28cADD5CSksLpp5/O3LlzAxNGbNu2DZvtSL47dOgQ119/PSkpKdSoUYMuXbqwePFi2rRpY9VHEKk0ZzavxY+bDhRbf+OqJgxp/w3P/TUQvLn+lV/+H9TrBA27VHGVIiIiIic/y0ecAMaOHcvWrVtxu938/PPP9OjRI/DewoULmTFjRuD1U089FWibkpLCl19+SadOnSyoWqTyTb289L795eoUfK2GFl35yvmQm1nJVYmIiIicekIiOIlIyWpHO5k0rF2p71/6S4fiK9d9VokViYiIiJyaFJxEQtw/zmjM4nvPL/G9lWYLtt+6m0Nn3Htk5ewb4Y+vq6g6ERERkVODgpNINVA/PqLU986e8i2dFnYgudO0IytnXgaZxa+NEhEREZHjo+AkUk18eOOxp+i/fklNuOi5IysePw2WvVLJVYmIiIicGhScRKqJrk1qsvzf5x27UaerYcQ7R15/+X/wREvY/VvlFiciIiJyklNwEqlG4iKOfXfr1KxcaDUEuow+sjIjBWbfXLmFiYiIiJzkFJxEqpkp3fNoVieqxPcGPv09GAYMnQqXvXnkjT2rwTSrqEIRERGRk4+Ck0g147TDnLG9SnwvJT2H/83bQFq2B1pd4D91r8DEePjtg6opUkREROQko+AkUg3ZbAa/PtC/xPee+WYTnR6ax870XK5LHc3OVtccefPj62FSHfj5xSqqVEREROTkoOAkUk3FRTqoGRVe4ns+E8589Bvm/76XgavOLPqmNxe+uhu2L6uCKkVERERODgpOItXY1T0aldnmMJEwIQ3u2QJxSUfe+HIcJD8Iaz6uvAJFREREThIKTiLV2K19WpSr3Z70HHbnuuCONTDibf/KlN/gx6fho+sgZQ0c+LPyChURERGp5hScRKqxMLuNvx4ZTK1STtkr0OORBfSc/A1ZuXnQrE/RN00vvHAmvHAWZKdWXrEiIiIi1ZiCk0g1Z7MZLL+vb7na7k7LYeTba7in4TuYsQ2KvunJgqfbw7afYd2n8MU4yHNXQsUiIiIi1Y+Ck8hJwDAM1j00oMx2495fxaI/9vH+JoOMm3+FK94r2sCdDh/+Ez4YCctfheWvV1LFIiIiItWLgpPISSIyPIw//juIJ4Z3LLXNrzvSAssmkNG4D2bPW4o2St9xZHnuPbD6wwquVERERKT6UXASOYmEh9n4e5eG3NH3b2W2vfGtFbSbkMwVW4fAraugydklN/zoWnBnwOJnYfdvFVuwiIiISDWh4CRyErqtb9mz7S3+8wAAP/11EGo2hdFfwEXPldx4cgOYdx/MHAGmWZGlioiIiFQLCk4iJ6lJw9qVOdtegSfnbeCtJVtIazkC897t8GAq/P214g0P74KJ8fDXd/DulbDynQqtWURERCRUhVldgIhUjn+c0Zh/nNGYiZ+v5fUftxyz7bPfbALg/k/X0jIhhs9vOYvwdpfyR24tmv76PxyNu8Oqd49c//Tmhf7nDV/C1sVQ/3TodDU4IirvA4mIiIhYSCNOIie5B4e25a1ru9OmXmy52m/Yc5jFf+5n8ab99P8gk27bx8L598HI2SVvsOptmHMnPJwIO1ccWW+akLH3xD+AiIiISAhQcBI5BZzdog5zbjubtvXLF55ueXclX61JASA1y+NfWbsFTEgr+RS+Ai+fD5+O9d8LKvkBeKIF/PbBiZYvIiIiYjkFJ5FTSHlm2wM4nJPHWz9tDbzenZZ95M12l/oD1I0/Qq3mxTde+Ra81h8WP+N//fH1sG/DiZQtIiIiYjkFJ5FTSLcmNQFwhtlIiHWWe7uek78pvjKxHdyyIn8Uqowb5T7XHX6cCp6cYMoVERERCRmaHELkFBIX6eCX+/vhcthYtT2VK1/+udzbfrV6N7leH4Pa1SM87MjfXEzTxGh3CbS5CJa/BvVO948yHdpcdAfJD/gf7S71v77kZbDZK+BTiYiIiFQ+BSeRU0zN/CnKezWrzfL7+pKd6+XsKd+Wud1N7/wCwG2swm4zeO7Kzny9NoVPVu7k9Wu6cV7LutD9+vzGP8K3j8CSacV3tOYj/3PKGoiuC6dfBadfUSGfTURERKSy6FQ9kVNY7WgnSTUj2fLoEBb837nl3s7rM7nx7RV8snInANe8vqxog/AoGPAw3LkJhk2HGk2L72T/BtjyPcy+EXb+ciIfQ0RERKTSKTiJCACn1Y5iYNtE4iMdx7X9qNeW8tjc9UVXRteB06+E21bBv3dBs/NL3vjl82D6WfDlnbDlB3i1P2z+/rjqEBEREakMCk4iAoBhGLzwjy6seqA/l3ZuGPT23/2xj+kL/2TCZ2sD6/ZnuAHYlZqN6YiEf3wC/94N8Y38M/Kdf/+RHexZDctehhlDYPvP8MYF8NW9J/y5RERERCqCrnESkWKevKwjI7olcdmLS4LedsbiLcxYvKXY+lvPb864/i0hPBJuWQmY4MmCrT/CnyXM2gfw83T/6XzN+/qDVud/BF2PiIiISEVQcBKREnVvWpMtjw7BNE0e+mIdr/+45YT298w3m9h6MIvI8DBG9WpMq8RYvlibyXeuCTx84yOE/z4bti2BHcsgLsl/DRTAnjX+B8BfCyEnDXIzoG5rGPgouDMg+6D/Br0iIiIilUTBSUSOyTAMHhzalvuHtGFnana5ZuArzaerdgHw7tJtnPO3Oiz6Yx8As1bAnFvH0Oa88Ucab18Kr/YruoM1Hx5Z3rbEP/15geu+gfqdwPSC+zBE1jzuOkVERESOpmucRKRcbDYjMAPfhR3rn/D+CkJTgcHPfE/yuj18/MsO/thzGLNhN3jgIHQZXb4dvnI+PFQDJtWGKU1hwST/BBPuw/DXd7D7N8jYe8J1i4iIyKlJI04iErTHh3dgZM/G1I1xcdmLSziUlYs7z3fC+73+zeXF1l3R/VpuGvsIjXzb/JNKpO0gL3UHYXPvBns4pG7zn7p3tO+f8D8Ki20It66EsPATrlVEREROLQpOIhI0Z5idrk38p8L99O8+gfV703Po9eg35PnMCjvWu0u38+7S7fmv/qJzo3h+2ZYDPMSVPRoxoG8ii1et5dI1N/M3285j7yx9B/y3zpHXXUZDyyH+G/HWbQ1hzgqrW0RERE4uCk4iUmHqxrr447+D2J2eQ6TDTkp6Dlm5eVw6PfjZ+Urzy7bUwPLMn7cx8+dtALzCo0STzZMje3P/m19zQ9gXnBW7lxZZK0vf2YoZ/kcBRxR4c8EWBp2u9s/6506HBl2h5SCIqQeOCP8oV61mFfaZREREJPQpOIlIhbLZDBrERwBQI8p/StyWR4eQneslx+Ol06TkSjmuFztpRHPdm8uBWkzMGwUHIZ7DNDd20tO2jtNtf9LF9ge+sAhqevcX34kn0//s8/jvKVXg989h/oNF27YYAG2H+a+bynND+79DVG1wxVXK5xMRERFrKTiJSJWICLcTEW5ny6NDAPhtRyoXTvuRD/7Vk86N4nlx0V88/vWGCj9uKjEsN1ux3NsKvPkr3Ufer00aPWy/09zYSRvbVnJx0Oe0SOypW3Cm/Vn6jjd+7X8UWPiI//mCpyBlNaz7DOIa+Eer2lzof++03hX50URERKQKKTiJiCU6NIwPhCiAMec1Z8x5zUnP8bBmZxrPLNjI4Pb1eH/ZdtbuSq+0OvYTx5e+M/wvCoJVofzmII8Icuho+4vOxkaG1NrF39KPcerhF3ccWc7aD7t/heWvltw2sjY07gVeD/T4l/80wJ2/QKMeUKsFGAY4Y07o84mIiEjFUHASkZAS63LQq1ltejWrDcDInk1Yue0QdWKcbN6fyT9eXVql9XgIw0M03/s68D0dmLoX7NxMFNm48FDbSOO+sLfpZV/HbrMmmaaL5rZd5dt51n74/TP/8h9fFXvbh0Feu8sIr5EEkbX811Ud2gIRNTCbnEVueDw5PgdxkY6K+8AiIiJSIgUnEQl5nRrVAKBhjcgio1QAKWk51IwKxzDg67UpLN18kK/WpHBFtySe+WZTpdTjxU460aQDe80aXOm5DzxH3g8jj0TjEJfYvucgMbhxcI7tN9oaW3AZudQ3DgKQaTqJMtwlHwSwYRK+5v0S3zMAJ5BpRrPHVQt7Xg41fAfxOuPZGdOeOo1aEuZwkmaLp8m+zRi/ppLhtREdGYG39UXYD24CV7x/RMsZDcCUuev56a8D/O+y02lSOwoA0zQxDKPUGtfuSsMZZqd53ehgvkIREZFqR8FJRKq1xDhXYPmCDvW5oEN9HrqoHQDj+rcMvFcQAEzTZO2udD7+ZSe1osNZ/Od+ftx0oEJryiOMHWYdnvFeElg3y9u7xLZ1OYQbByaQTjRtjS30tK0l2sjGa9qINbJoZuwiDzuNjT3UMw76Tx80cgGoaWSA+8h9rOw5+2ia8w3s+wYAF5AAsOMNCqKNnWsD7d1mGDvN2sREuuid5aS9GcuOqVmsIo4UsxY7zVrsNeMZ2LEJrRvW4uEv13Jjaw/NW3VgdaqDKd9sZ4uZyPqHL8Rmt2GaJtsPZtOgRgR2m4HXZ/Lmki10a1KTdg1Knzhj8/5MPlyxnevOOi0wqYiIiEgoCYng9Nxzz/H444+TkpJCx44defbZZ+nevXup7WfNmsX999/Pli1baNGiBY899hiDBw+uwopFpLopGDUxDIN2DeICv8SPOa95qdukZXlwhBl48kz+2HuYP/YcZvvBbL5as5trz2rKzJ+3sT7l8AnVtZcaRV6vNZuw1tukjK1MnHiIJptaRjpJxl762Fbiw8BNOE5yqW8cwEMYcUYmqWY0zYxdtCjhPldOI4/TjBTIgTq2Yxzyd//jrXDgT/8jAeibf+ur7IfCycRFDuF4TAeriSTdjCSdSOJwsMKMYCl2fBh4seHDhhcbu20J7M2LJodw7Pi4ZmE0CbHhRIWZrDlowxEZT7tGtVi/z83NvRJp1qgRTlcE936yhvYN4rnu7KaE2W1EhoexIeUwLRKicTnsRUrP8/o4mJlLbIT/lEaXw86W/ZlEu8KoHX389+4yTf/9yo4ekcvN8xEedqwvU0REqiPLg9P777/PuHHjeOGFF+jRowdPP/00AwYMYMOGDdStW7dY+8WLF3PFFVcwefJkLrjgAmbOnMmwYcP45ZdfaNeunQWfQEROVoFrh8KhW5OadMu/6e+9g1oB/uuvSrM/w018hINMtxfDBjFO/z+37y7dzl/7Mnjlh80AXNG9Ee8u3RZkZf6A5CacA2Ycf5hJLPB1KdeWTnJJMA7hNW0kGIc4SAwNjP2YGNQ3DtDG2EokOTS1pZBpuog1srDhw0EeYXhx4C3xGq4II5cIcgvKC87RA0zu/IcT/4Qdm/PXzzvS5C3TwLMjjLCf89hLDdz4iDXD2YkdE4M87HixFX027eTlh7YS38eO17SVuD4PW+D9guUjz/62XmyBYxwgjuZJ9Vm57RB2m0GYL5dwI48c00GXpBjCazbgm/X7ue7MRqzfcQBnmMHqPR6a1nbx6450oqNjqR/vol6Mg4EdGrIj28mOQ1l8uGIHF3RI5LKuDYmJjGDP4Vxqx0Twx94sYlx2MnNyiXKFUzcmgv2ZuexOy6FL4xpk5ebx/rLt9GpWmxYJ0aRmeagdHV4k9Hl9JnabwaGsXLxl3MM6N8+Hx+sjymn5rxEiIlXGMAv+ZGaRHj160K1bN6ZNmwaAz+cjKSmJW265hXvvvbdY+xEjRpCZmckXX3wRWHfGGWdw+umn88ILL5R5vPT0dOLi4khLSyM2NrbiPshx8ng8zJkzh8GDB+Nw6AJvOTb1FylQeLTDNE2ycr0kr9tDeJiNPJ9JjsfLC9/9SU6ul11pOdgM8OX/a98yIYYNe45/pMyOlwjc5OIgkhzqGQfJJYwI3Njx4cJDjJFFDFnEGZm4yCXSyMGGiR1ffnQxCcfDacZuYowsXHhwkIfT8GCaBrmEUdtIIwI34YZ/ukOfaWAzLP1fVrXkM/3hyARMjPwH+esMyH9d8F5pbYNrd+y2BUyz5HaGYcPkSJ81MQiz28j1msXaFj5eLg5yCcNn2nCEGbjz/G0chpdcM4zYKBfZuT7cHn/cPVK7/2HHiys8jLDwCPZn5AaOERFuJ8Jh50Cmh9rRTvZl5JKXH55tmDSpGYGBj20Hs4hyhnPYnUd8hINYVxi5eV5yvT7yvD4y3XnUjHRwKMu/7/AwO9ERLnYfzqVWdAS1oxyY+Z/dxCDb42Pz/iwwoF2DeDLdeWw9mIU3P9nWi3PisBvEuBx4sbFmVwb14l3UjXWRlu3BnWeS6c7DZxqkZnsC32WzOlGE2e0YBmw7mI07z/+9Nq8bRXiYjUMZuaTneKgVFc7O1Cxy83x0SoonNSuXtGw3PuzUinYSEQYZuSZ/7s/CxKBVYjRgcCDDTUS4nbgIBzHOMDYfyMKT56VRzQj2Z/mIDLfhCrPhdISR6/WxfGsqpzeIISbCwZ6MPHI8PmJc4TjCDPYeyuC0OtFkuPNISXfTsGYULoednQcOk5qRSUJcJLVjI7HZ7GALw2vYyfaYHM7OpW5MOB6vj8M5ecRHhRNms5HhzsMRZic928O2g9lEucJoXieGbI+X8DA7dpuBO89HtsdHXKQDj9fEnefjx00HaVQzksQ4F1HOMCLCw3DneQmz2bDb4FBmLh6Pm7qxEZgmHHZ780e5DbLzTFyOsEJnPkBWrpesXC/RzrDACLVhgNfrw+szMUwvPp///oeR4Q58JnhNWJ+Szml1Yoh2OQgPs2GakO3xEWa3s/VAJhgGp9WJxmazBX7ePhN8PhO73eY/CP7X2bleDMM/Cu+wF/1vM/DfYgn/phz9r3DBMTxek/AwGzYDDAwwDEwTzPwtcjxenI4w//+PfD62bdvOeaMfIDquZglHqTrBZANL/1SUm5vLihUrGD9+fGCdzWajb9++LFlS8nS/S5YsYdy4cUXWDRgwgNmzZ5fY3u1243Yfufg6Pd0/rbHH48Hj8ZS4TVUqqCEUapHQp/4ipQm3wZB2RUfpL+6YiMfjITk5mX79+lV42Pb6TP//IA3DfzpclgfTNPH6/L9oFPzS6wyzEeW08+uONOasTmFfRi4D2iRw/2fruLpHEgczc5mzZg/ntqiN1zT5odg1ZyYOvORhI5ocwsgjDB9OIxfTNKhlpOPFjgs3BiZ2TGyGjzD/GBFh+I569mI3fNgpaFO8bVnvhxn+AFjSMRzkUcdIJTJ/4o+CIAgQTh4ANY30/FGqI798O/GQhx0bPiJx48XmDwz5xzteRcNmiAXPskYnC79vAsGcAWkC9qPW5eQ/H72+MC+QfVQbb/7DXsJ7AGn+p/Z2IC///dz8R2F2/KOpBdubQFah/WYXL6dbwW9qKfmvDY789pZ/z27y79jQMQzIyH8crfBvfIeOLJ4BR77nfUdtk1po291HvXfwyOJ5BfsufF/xnCN1tS1Yd/Q+8nUNA/Yc1TatUIOthZaz/E+Bc4wOUeTzFLG3lPWFuY86VinOcgCH8x/HUspnrCg9oOj3UUingoXyfO4Q0BHYcWgMzkhrb7sRzO9Ulgan/fv34/V6SUhIKLI+ISGB9evXl7hNSkpKie1TUlJKbD958mQmTpxYbP28efOIjIw8zsorXnJystUlSDWi/iLBCpU+0zsCiAD27WFqT4DNEAMDekLBb4bD65S2tQ//eX1Hn9tXo4S2VcPE/3tyHmCaR9btK/Q++P9SbEBg5M8Ewgzw+GB/Dtht/u3DbJCW6w/CceGQmgser5coIxevaZCWa3AoFyLsBqbpI9zmw45JlsfLvhw74XYbbq+P2i4fmw9DYgQcyIEIu8m6Q1A/yuRAjr+OMMPktBj/2EbNcJODblh5wEaiy0eDKP/6NQchzzSoH2ESF+6jptPk571H0kwdp4+oMNieCZ1q+dibDbuzjEJjOEe+qSbRPrZlGDSI9LEry6BFrL/G9jVMVhf6JdzApF0NH06bSUq2/7vYnmEQ7fARaTfZ7/bv1Y7PP5qEGbgFm4tcHOQRF26S4YFGkV52ZPpvK5Do9GCYPjw+k8w8G5789GLD9I+CGv5Rl8bRYPg87Mz/HABNok0Oe+Cg26C200dGnn9kwI4PHwZN8n/v+/OwPwQDxIab1HJCZh6kZNuo6YQD7sLfiBEI3zZMnDYfCZH+fmHDH5SzPCb7cgwMoFG0j+w8k/05tiL7AKjt8hFh87I7yyA23CTOAZl5JqlugyiHiQ2TzDwj0CPrunzsyzGICjPJyjMCo8Bx4XAo1yi2fxODOi6TQ27wYgPTh4FJVJiNjDwz/+pFf8sww99nIsIgKw/quvyfoWAUrWCkDyA+3P8fQ7rHf/uF2i6T1Bz/vmz4cNkh3RtGTadJng8yPBBuM4l3mOx2+785GyZ1Xfkj2ab/Dx2maZLhMYh0GBgGpLohKswk3GaS6/OPAPn7ml8tp49cn4HDdmQMNi0XIsPyR0pNk+y8I/3BaTeJCDPx+vx7sRsmqbn+03ijwvw1ZuaB3TCJsJt4fOAwTMLy/4hhAm4vuPP/HhJb6G9ahuH/Y0uqx4bdZsPt9e/PZ5rEhR+pI9dnEufwj+VkePz/jed4/bVH2Mn/LEX/UGJgYjNN8gehycwz8JoG0Q6KtQUw8v9RMwud0lusnelfZ+bvLzLMLPb3jYKtPfl/TXMUapDy8zLCXeuKHbsqZWVllbvtSX9y8vjx44uMUKWnp5OUlET//v1D5lS9yvprsJx81F8kWOozEiz1GQmW+owEq6DPDAmBPlNwNlp5WBqcateujd1uZ8+ePUXW79mzh8TExBK3SUxMDKq90+nE6Sw+a5LD4bD8B1VYqNUjoU39RYKlPiPBUp+RYKnPSLBCoc8Ec3xL50sNDw+nS5cuLFiwILDO5/OxYMECevbsWeI2PXv2LNIe/KeglNZeRERERETkRFl+qt64ceMYNWoUXbt2pXv37jz99NNkZmZyzTXXADBy5EgaNGjA5MmTAbjttts499xzefLJJxkyZAjvvfcey5cv56WXXrLyY4iIiIiIyEnM8uA0YsQI9u3bxwMPPEBKSgqnn346c+fODUwAsW3btsCUigC9evVi5syZ3Hffffz73/+mRYsWzJ49W/dwEhERERGRSmN5cAIYO3YsY8eOLfG9hQsXFls3fPhwhg8fXslViYiIiIiI+Fl6jZOIiIiIiEh1oOAkIiIiIiJSBgUnERERERGRMig4iYiIiIiIlEHBSUREREREpAwKTiIiIiIiImVQcBIRERERESmDgpOIiIiIiEgZFJxERERERETKoOAkIiIiIiJSBgUnERERERGRMig4iYiIiIiIlEHBSUREREREpAxhVhdQ1UzTBCA9Pd3iSvw8Hg9ZWVmkp6fjcDisLkdCnPqLBEt9RoKlPiPBUp+RYIVSnynIBAUZ4VhOueB0+PBhAJKSkiyuREREREREQsHhw4eJi4s7ZhvDLE+8Oon4fD527dpFTEwMhmFYXQ7p6ekkJSWxfft2YmNjrS5HQpz6iwRLfUaCpT4jwVKfkWCFUp8xTZPDhw9Tv359bLZjX8V0yo042Ww2GjZsaHUZxcTGxlrecaT6UH+RYKnPSLDUZyRY6jMSrFDpM2WNNBXQ5BAiIiIiIiJlUHASEREREREpg4KTxZxOJw8++CBOp9PqUqQaUH+RYKnPSLDUZyRY6jMSrOraZ065ySFERERERESCpREnERERERGRMig4iYiIiIiIlEHBSUREREREpAwKTiIiIiIiImVQcLLQc889R5MmTXC5XPTo0YOlS5daXZJUgcmTJ9OtWzdiYmKoW7cuw4YNY8OGDUXa5OTkMGbMGGrVqkV0dDSXXnope/bsKdJm27ZtDBkyhMjISOrWrctdd91FXl5ekTYLFy6kc+fOOJ1OmjdvzowZMyr740kVePTRRzEMg9tvvz2wTn1GjrZz506uvvpqatWqRUREBO3bt2f58uWB903T5IEHHqBevXpERETQt29fNm7cWGQfBw8e5KqrriI2Npb4+HiuvfZaMjIyirT57bffOPvss3G5XCQlJTFlypQq+XxSsbxeL/fffz9NmzYlIiKCZs2aMWnSJArPIaY+c2pbtGgRQ4cOpX79+hiGwezZs4u8X5X9Y9asWbRq1QqXy0X79u2ZM2dOhX/eEpliiffee88MDw83X3vtNXPt2rXm9ddfb8bHx5t79uyxujSpZAMGDDBff/11c82aNeaqVavMwYMHm40aNTIzMjICbW688UYzKSnJXLBggbl8+XLzjDPOMHv16hV4Py8vz2zXrp3Zt29fc+XKleacOXPM2rVrm+PHjw+0+euvv8zIyEhz3Lhx5rp168xnn33WtNvt5ty5c6v080rFWrp0qdmkSROzQ4cO5m233RZYrz4jhR08eNBs3LixOXr0aPPnn382//rrL/Prr782N23aFGjz6KOPmnFxcebs2bPNX3/91bzwwgvNpk2bmtnZ2YE2AwcONDt27Gj+9NNP5vfff282b97cvOKKKwLvp6WlmQkJCeZVV11lrlmzxnz33XfNiIgI88UXX6zSzysn7uGHHzZr1aplfvHFF+bmzZvNWbNmmdHR0ebUqVMDbdRnTm1z5swx//Of/5gff/yxCZiffPJJkferqn/8+OOPpt1uN6dMmWKuW7fOvO+++0yHw2GuXr260r8DBSeLdO/e3RwzZkzgtdfrNevXr29OnjzZwqrECnv37jUB87vvvjNN0zRTU1NNh8Nhzpo1K9Dm999/NwFzyZIlpmn6//Gy2WxmSkpKoM306dPN2NhY0+12m6ZpmnfffbfZtm3bIscaMWKEOWDAgMr+SFJJDh8+bLZo0cJMTk42zz333EBwUp+Ro91zzz3mWWedVer7Pp/PTExMNB9//PHAutTUVNPpdJrvvvuuaZqmuW7dOhMwly1bFmjz1VdfmYZhmDt37jRN0zSff/55s0aNGoE+VHDsli1bVvRHkko2ZMgQ85///GeRdZdccol51VVXmaapPiNFHR2cqrJ/XHbZZeaQIUOK1NOjRw/zX//6V4V+xpLoVD0L5ObmsmLFCvr27RtYZ7PZ6Nu3L0uWLLGwMrFCWloaADVr1gRgxYoVeDyeIv2jVatWNGrUKNA/lixZQvv27UlISAi0+f/27j8m6vqPA/jz8LjjDkWwgzuiUTIJEEuRKzvRtqIJp6t0VNPd2ME/DASFVpZZpq4y/3DaanVO568N9KYti0xlBJSDTSwFBD2xzZ+bnmTKIH9l3as/+vqJjyBX3+AO9PnYPtvd5/3ic6/PfV7jc6997vO+rKwsdHV14ejRo0pMz23cjmGNDV/FxcWYNWtWr+PKmqE7VVZWwmq14uWXX0ZMTAzS0tKwYcMGZfzUqVPwer2q4z169GhMmTJFVTORkZGwWq1KzHPPPYeQkBA0NjYqMU8//TR0Op0Sk5WVhfb2dly5cmWwd5MG0NSpU1FTU4MTJ04AAFpaWlBfXw+73Q6ANUP9C2R9BPNcxcYpCC5duoQ//vhD9QEGAMxmM7xeb5CyomDw+XwoKytDRkYGJkyYAADwer3Q6XSIjIxUxfasD6/X22f93B7rL6arqwvXr18fjN2hQeR2u3H48GF8+OGHvcZYM3SnkydPwuVyITExEVVVVSgqKsLChQuxdetWAH8f8/7OQ16vFzExMapxrVaLMWPG/Ku6ouFh8eLFmDt3LpKTkxEaGoq0tDSUlZXB4XAAYM1Q/wJZH3eLCUT9aAf9FYjoroqLi9HW1ob6+vpgp0JD2Llz51BaWorq6mqEhYUFOx0aBnw+H6xWK1auXAkASEtLQ1tbG9atWwen0xnk7Ggo2rFjByoqKrBt2zakpqaiubkZZWVlePDBB1kzRP/DK05BYDKZMGLEiF4zXl28eBEWiyVIWVGglZSUYPfu3airq8NDDz2krLdYLPjtt9/Q2dmpiu9ZHxaLpc/6uT3WX0xERAQMBsNA7w4NokOHDqGjowOTJ0+GVquFVqvF999/j48//hharRZms5k1QyqxsbEYP368al1KSgrOnj0L4O9j3t95yGKxoKOjQzX++++/4/Lly/+qrmh4WLRokXLV6bHHHkNubi5effVV5So3a4b6E8j6uFtMIOqHjVMQ6HQ6pKeno6amRlnn8/lQU1MDm80WxMwoEEQEJSUl2LVrF2prazF27FjVeHp6OkJDQ1X10d7ejrNnzyr1YbPZ0NraqvoHVF1djYiICOXDks1mU23jdgxrbPjJzMxEa2srmpublcVqtcLhcCiPWTPUU0ZGRq+fOThx4gQefvhhAMDYsWNhsVhUx7urqwuNjY2qmuns7MShQ4eUmNraWvh8PkyZMkWJ2b9/P27duqXEVFdXIykpCVFRUYO2fzTwrl27hpAQ9cfCESNGwOfzAWDNUP8CWR9BPVcN+vQT1Ce32y16vV62bNkix44dk4KCAomMjFTNeEX3pqKiIhk9erR89913cuHCBWW5du2aElNYWCjx8fFSW1srP/74o9hsNrHZbMr47amlZ8yYIc3NzbJv3z6Jjo7uc2rpRYsWicfjkU8//ZRTS99Des6qJ8KaIbWDBw+KVquVDz74QH766SepqKgQo9Eo5eXlSsyqVaskMjJSvvrqKzly5Ii8+OKLfU4dnJaWJo2NjVJfXy+JiYmqqYM7OzvFbDZLbm6utLW1idvtFqPRyKmlhyGn0ylxcXHKdORffPGFmEwmeeONN5QY1sz9rbu7W5qamqSpqUkAyJo1a6SpqUnOnDkjIoGrj4aGBtFqtbJ69WrxeDyybNkyTkd+P/jkk08kPj5edDqdPPnkk3LgwIFgp0QBAKDPZfPmzUrM9evXZf78+RIVFSVGo1HmzJkjFy5cUG3n9OnTYrfbxWAwiMlkktdee01u3bqliqmrq5NJkyaJTqeThIQE1WvQ8HZn48SaoTt9/fXXMmHCBNHr9ZKcnCzr169Xjft8Plm6dKmYzWbR6/WSmZkp7e3tqphffvlF5s2bJyNHjpSIiAjJz8+X7u5uVUxLS4tMmzZN9Hq9xMXFyapVqwZ932jgdXV1SWlpqcTHx0tYWJgkJCTI22+/rZoWmjVzf6urq+vz84vT6RSRwNbHjh075NFHHxWdTiepqanyzTffDNp+96QR6fGT0ERERERERNQL73EiIiIiIiLyg40TERERERGRH2yciIiIiIiI/GDjRERERERE5AcbJyIiIiIiIj/YOBEREREREfnBxomIiIiIiMgPNk5ERERERER+sHEiIiLqh0ajwZdffhnsNIiIKMjYOBER0ZCVl5cHjUbTa8nOzg52akREdJ/RBjsBIiKi/mRnZ2Pz5s2qdXq9PkjZEBHR/YpXnIiIaEjT6/WwWCyqJSoqCsBfX6NzuVyw2+0wGAxISEjA559/rvr71tZWPPvsszAYDHjggQdQUFCAX3/9VRWzadMmpKamQq/XIzY2FiUlJarxS5cuYc6cOTAajUhMTERlZaUyduXKFTgcDkRHR8NgMCAxMbFXo0dERMMfGyciIhrWli5dipycHLS0tMDhcGDu3LnweDwAgKtXryIrKwtRUVH44YcfsHPnTnz77beqxsjlcqG4uBgFBQVobW1FZWUlxo0bp3qNFStW4JVXXsGRI0cwc+ZMOBwOXL58WXn9Y8eOYe/evfB4PHC5XDCZTIF7A4iIKCA0IiLBToKIiKgveXl5KC8vR1hYmGr9kiVLsGTJEmg0GhQWFsLlciljTz31FCZPnozPPvsMGzZswJtvvolz584hPDwcALBnzx48//zzOH/+PMxmM+Li4pCfn4/333+/zxw0Gg3eeecdvPfeewD+asZGjhyJvXv3Ijs7Gy+88AJMJhM2bdo0SO8CERENBbzHiYiIhrRnnnlG1RgBwJgxY5THNptNNWaz2dDc3AwA8Hg8mDhxotI0AUBGRgZ8Ph/a29uh0Whw/vx5ZGZm9pvD448/rjwODw9HREQEOjo6AABFRUXIycnB4cOHMWPGDMyePRtTp079v/aViIiGLjZOREQ0pIWHh/f66txAMRgM/yguNDRU9Vyj0cDn8wEA7HY7zpw5gz179qC6uhqZmZkoLi7G6tWrBzxfIiIKHt7jREREw9qBAwd6PU9JSQEApKSkoKWlBVevXlXGGxoaEBISgqSkJIwaNQqPPPIIampq/lMO0dHRcDqdKC8vx0cffYT169f/p+0REdHQwytOREQ0pN28eRNer1e1TqvVKhMw7Ny5E1arFdOmTUNFRQUOHjyIjRs3AgAcDgeWLVsGp9OJ5cuX4+eff8aCBQuQm5sLs9kMAFi+fDkKCwsRExMDu92O7u5uNDQ0YMGCBf8ov3fffRfp6elITU3FzZs3sXv3bqVxIyKiewcbJyIiGtL27duH2NhY1bqkpCQcP34cwF8z3rndbsyfPx+xsbHYvn07xo8fDwAwGo2oqqpCaWkpnnjiCRiNRuTk5GDNmjXKtpxOJ27cuIG1a9fi9ddfh8lkwksvvfSP89PpdHjrrbdw+vRpGAwGTJ8+HW63ewD2nIiIhhLOqkdERMOWRqPBrl27MHv27GCnQkRE9zje40REREREROQHGyciIiIiIiI/eI8TERENW/y2ORERBQqvOBEREREREfnBxomIiIiIiMgPNk5ERERERER+sHEiIiIiIiLyg40TERERERGRH2yciIiIiIiI/GDjRERERERE5AcbJyIiIiIiIj/+BChXAROcykBmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_loss, label='training loss')\n",
    "plt.plot(validation_loss, label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training/validation loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('curve.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "x = np.arange(2, 4, 0.02)\n",
    "t = np.arange(1, 2, 0.02)\n",
    "ms_x, ms_t = np.meshgrid(x, t)\n",
    "# Just because meshgrid is used, we need to do the following adjustment\n",
    "x = np.ravel(ms_x).reshape(-1, 1)\n",
    "t = np.ravel(ms_t).reshape(-1, 1)\n",
    "u = 6 * np.exp(-3 * x - 2 * t)\n",
    "\n",
    "pt_x = Variable(torch.from_numpy(x).float(), requires_grad=True).to(device)\n",
    "pt_t = Variable(torch.from_numpy(t).float(), requires_grad=True).to(device)\n",
    "\n",
    "pt_uhat = net(pt_x, pt_t)\n",
    "uhat = pt_uhat.data.cpu().numpy()\n",
    "ms_uhat = uhat.reshape(ms_x.shape)\n",
    "ms_u = u.reshape(ms_x.shape)\n",
    "\n",
    "surf2 = ax.plot_surface(ms_x, ms_t, ms_uhat, cmap=cm.Reds,\n",
    "                        linewidth=2, antialiased=False, alpha=0.6, zorder=1)\n",
    "surf1 = ax.plot_surface(ms_x, ms_t, ms_u, cmap=cm.Greens,\n",
    "                        linewidth=2, antialiased=False, alpha=0.6, zorder=2)\n",
    "\n",
    "\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "fig.colorbar(surf1, shrink=0.5, aspect=5).set_label(\n",
    "    'Observation', labelpad=10, loc='top')\n",
    "fig.colorbar(surf2, shrink=0.5, aspect=5).set_label(\n",
    "    'Simulation', labelpad=10, loc='top')\n",
    "\n",
    "plt.savefig('inf.svg')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
