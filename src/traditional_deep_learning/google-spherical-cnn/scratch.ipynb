{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Any, Optional, Sequence, Union\n",
    "from flax import linen as nn\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "from spherical_cnn import layers\n",
    "from spherical_cnn import sphere_utils\n",
    "from spherical_cnn import spin_spherical_harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array = Union[np.ndarray, jnp.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinSphericalClassifier(nn.Module):\n",
    "    \"\"\"Construct a spin-weighted spherical CNN for classification.\n",
    "\n",
    "    Attributes:\n",
    "      num_classes: Number of nodes in the final layer.\n",
    "      resolutions: (n_layers,) list of resolutions at each layer. For consecutive\n",
    "        resolutions a, b, we must have either a == b or a == 2*b. The latter\n",
    "        triggers inclusion of a pooling layer.\n",
    "      spins: A (n_layers,) list of (n_spins,) lists of spin weights per layer.\n",
    "      widths: (n_layers,) list of width per layer (number of channels).\n",
    "      spectral_pooling: When True, use spectral instead of spatial pooling.\n",
    "      axis_name: Identifier for the mapped axis in parallel training.\n",
    "      num_filter_params: (n_layers,) the number of filter parameters per layer.\n",
    "      input_transformer: None, or SpinSphericalFourierTransformer\n",
    "        instance. Will be computed automatically if None.\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes: int\n",
    "    resolutions: Sequence[int]\n",
    "    spins: Sequence[Sequence[int]]\n",
    "    widths: Sequence[int]\n",
    "    spectral_pooling: bool\n",
    "    axis_name: Any\n",
    "    num_filter_params: Optional[Sequence[int]] = None\n",
    "    input_transformer: Optional[\n",
    "        spin_spherical_harmonics.SpinSphericalFourierTransformer\n",
    "    ] = None\n",
    "\n",
    "    def setup(self):\n",
    "        if self.input_transformer is None:\n",
    "            # Flatten spins.\n",
    "            all_spins = functools.reduce(operator.concat, self.spins)\n",
    "            self.transformer = spin_spherical_harmonics.SpinSphericalFourierTransformer(\n",
    "                resolutions=np.unique(self.resolutions), spins=np.unique(all_spins)\n",
    "            )\n",
    "        else:\n",
    "            self.transformer = self.input_transformer\n",
    "\n",
    "        num_layers = len(self.resolutions)\n",
    "        if len(self.spins) != num_layers or len(self.widths) != num_layers:\n",
    "            raise ValueError(\"resolutions, spins, and widths must be the same size!\")\n",
    "        model_layers = []\n",
    "        for layer_id in range(num_layers - 1):\n",
    "            resolution_in = self.resolutions[layer_id]\n",
    "            resolution_out = self.resolutions[layer_id + 1]\n",
    "            spins_in = self.spins[layer_id]\n",
    "            spins_out = self.spins[layer_id + 1]\n",
    "            if self.num_filter_params is None:\n",
    "                num_filter_params = None\n",
    "            else:\n",
    "                num_filter_params = self.num_filter_params[layer_id + 1]\n",
    "\n",
    "            num_channels = self.widths[layer_id + 1]\n",
    "\n",
    "            # We pool before conv to avoid expensive increase of number of channels at\n",
    "            # higher resolution.\n",
    "            if resolution_out == resolution_in // 2:\n",
    "                downsampling_factor = 2\n",
    "            elif resolution_out != resolution_in:\n",
    "                raise ValueError(\"Consecutive resolutions must be equal or halved.\")\n",
    "            else:\n",
    "                downsampling_factor = 1\n",
    "\n",
    "            model_layers.append(\n",
    "                layers.SpinSphericalBlock(\n",
    "                    num_channels=num_channels,\n",
    "                    spins_in=spins_in,\n",
    "                    spins_out=spins_out,\n",
    "                    downsampling_factor=downsampling_factor,\n",
    "                    spectral_pooling=self.spectral_pooling,\n",
    "                    num_filter_params=num_filter_params,\n",
    "                    axis_name=self.axis_name,\n",
    "                    transformer=self.transformer,\n",
    "                    name=f\"spin_block_{layer_id}\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.layers = model_layers\n",
    "\n",
    "        self.final_dense = nn.Dense(self.num_classes, name=\"final_dense\")\n",
    "\n",
    "    def __call__(self, inputs: Array, train: bool) -> jnp.ndarray:\n",
    "        \"\"\"Apply the network to `inputs`.\n",
    "\n",
    "        Args:\n",
    "          inputs: (batch_size, resolution, resolution, n_spins, n_channels) array of\n",
    "            spin-weighted spherical functions (SWSF) with equiangular sampling.\n",
    "          train: whether to run in training or inference mode.\n",
    "        Returns:\n",
    "          A (batch_size, num_classes) float32 array with per-class scores (logits).\n",
    "        \"\"\"\n",
    "        resolution, num_spins, num_channels = inputs.shape[2:]\n",
    "        if (\n",
    "            resolution != self.resolutions[0]\n",
    "            or num_spins != len(self.spins[0])\n",
    "            or num_channels != self.widths[0]\n",
    "        ):\n",
    "            raise ValueError(\"Incorrect input dimensions!\")\n",
    "\n",
    "        feature_maps = inputs\n",
    "        for layer in self.layers:\n",
    "            feature_maps = layer(feature_maps, train=train)\n",
    "\n",
    "        # Current feature maps are still spin spherical. Do final processing.\n",
    "        # Global pooling is not equivariant for spin != 0, so me must take the\n",
    "        # absolute values before.\n",
    "        mean_abs = sphere_utils.spin_spherical_mean(jnp.abs(feature_maps))\n",
    "        mean = sphere_utils.spin_spherical_mean(feature_maps).real\n",
    "        spins = jnp.expand_dims(jnp.array(self.spins[-1]), [0, 2])\n",
    "        feature_maps = jnp.where(spins == 0, mean, mean_abs)\n",
    "        # Shape is now (batch, spins, channel).\n",
    "        feature_maps = feature_maps.reshape((feature_maps.shape[0], -1))\n",
    "\n",
    "        return self.final_dense(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SMALL_CLASSIFIER_RESOLUTIONS = (64, 64, 64, 32, 32, 16, 16)\n",
    "num_layers = len(_SMALL_CLASSIFIER_RESOLUTIONS)\n",
    "widths = (1, 16, 16, 32, 32, 58, 58)\n",
    "num_filter_params_per_layer = tuple([8] * num_layers)\n",
    "# The difference between spherical and spin-weighted models is that spins are\n",
    "# zero in every layer for the spherical.\n",
    "spins = tuple([(0,)] * num_layers)\n",
    "model = SpinSphericalClassifier(\n",
    "    10,\n",
    "    resolutions=_SMALL_CLASSIFIER_RESOLUTIONS,\n",
    "    spins=spins,\n",
    "    widths=widths,\n",
    "    spectral_pooling=False,\n",
    "    num_filter_params=num_filter_params_per_layer,\n",
    "    axis_name='axis_1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpinSphericalClassifier(\n",
       "    # attributes\n",
       "    num_classes = 10\n",
       "    resolutions = (64, 64, 64, 32, 32, 16, 16)\n",
       "    spins = ((0,), (0,), (0,), (0,), (0,), (0,), (0,))\n",
       "    widths = (1, 16, 16, 32, 32, 58, 58)\n",
       "    spectral_pooling = False\n",
       "    axis_name = 'axis_1'\n",
       "    num_filter_params = (8, 8, 8, 8, 8, 8, 8)\n",
       "    input_transformer = None\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinSphericalAutoencoder(nn.Module):\n",
    "    \"\"\"Spin-weighted spherical CNN with an encoder-decoder structure.\n",
    "\n",
    "    Attributes:\n",
    "      resolutions: (n_layers,) list of resolutions at each layer.\n",
    "      spins: A (n_layers,) list of (n_spins,) lists of spin weights per layer.\n",
    "      widths: (n_layers,) list of width per layer (number of channels).\n",
    "      spectral_pooling: When True, use spectral instead of spatial pooling.\n",
    "      axis_name: Identifier for the mapped axis in parallel training.\n",
    "      num_filter_params: (n_layers,) the number of filter parameters per layer.\n",
    "      input_transformer: None, or SpinSphericalFourierTransformer instance.\n",
    "    \"\"\"\n",
    "\n",
    "    resolutions: Sequence[int]\n",
    "    spins: Sequence[Sequence[int]]\n",
    "    widths: Sequence[int]\n",
    "    spectral_pooling: bool\n",
    "    axis_name: Any\n",
    "    num_filter_params: Optional[Sequence[int]] = None\n",
    "    input_transformer: Optional[\n",
    "        spin_spherical_harmonics.SpinSphericalFourierTransformer\n",
    "    ] = None\n",
    "\n",
    "    def setup(self):\n",
    "        if self.input_transformer is None:\n",
    "            all_spins = functools.reduce(operator.concat, self.spins)\n",
    "            self.transformer = spin_spherical_harmonics.SpinSphericalFourierTransformer(\n",
    "                resolutions=np.unique(self.resolutions), spins=np.unique(all_spins)\n",
    "            )\n",
    "        else:\n",
    "            self.transformer = self.input_transformer\n",
    "\n",
    "        num_layers = len(self.resolutions)\n",
    "        if len(self.spins) != num_layers or len(self.widths) != num_layers:\n",
    "            raise ValueError(\"resolutions, spins, and widths must be the same size!\")\n",
    "\n",
    "        self.encoder_layers = list()\n",
    "        self.decoder_layers = list()\n",
    "\n",
    "        # Encoder (downsampling)\n",
    "        for layer_id in range(num_layers - 1):\n",
    "            resolution_in = self.resolutions[layer_id]\n",
    "            resolution_out = self.resolutions[layer_id + 1]\n",
    "            spins_in = self.spins[layer_id]\n",
    "            spins_out = self.spins[layer_id + 1]\n",
    "            num_channels = self.widths[layer_id + 1]\n",
    "\n",
    "            if self.num_filter_params is None:\n",
    "                num_filter_params = None\n",
    "            else:\n",
    "                num_filter_params = self.num_filter_params[layer_id + 1]\n",
    "\n",
    "            downsampling_factor = 2 if resolution_out == resolution_in // 2 else 1\n",
    "            if resolution_out != resolution_in and resolution_out != resolution_in // 2:\n",
    "                raise ValueError(\"Resolutions must be equal or halved.\")\n",
    "\n",
    "            print(self.encoder_layers)\n",
    "            self.encoder_layers.append(\n",
    "                layers.SpinSphericalBlock(\n",
    "                    num_channels=num_channels,\n",
    "                    spins_in=spins_in,\n",
    "                    spins_out=spins_out,\n",
    "                    downsampling_factor=downsampling_factor,\n",
    "                    spectral_pooling=self.spectral_pooling,\n",
    "                    num_filter_params=num_filter_params,\n",
    "                    axis_name=self.axis_name,\n",
    "                    transformer=self.transformer,\n",
    "                    name=f\"encoder_block_{layer_id}\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decoder (upsampling, symmetric to encoder)\n",
    "        for layer_id in reversed(range(num_layers - 1)):\n",
    "            resolution_in = self.resolutions[layer_id + 1]\n",
    "            resolution_out = self.resolutions[layer_id]\n",
    "            spins_in = self.spins[layer_id + 1]\n",
    "            spins_out = self.spins[layer_id]\n",
    "            num_channels = self.widths[layer_id]\n",
    "\n",
    "            upsampling_factor = 2 if resolution_out == resolution_in * 2 else 1\n",
    "            if resolution_out != resolution_in and resolution_out != resolution_in * 2:\n",
    "                raise ValueError(\"Resolutions must be equal or doubled.\")\n",
    "\n",
    "            self.decoder_layers.append(\n",
    "                layers.SpinSphericalBlock(\n",
    "                    num_channels=num_channels,\n",
    "                    spins_in=spins_in,\n",
    "                    spins_out=spins_out,\n",
    "                    downsampling_factor=1 / upsampling_factor,\n",
    "                    spectral_pooling=self.spectral_pooling,\n",
    "                    num_filter_params=num_filter_params,\n",
    "                    axis_name=self.axis_name,\n",
    "                    transformer=self.transformer,\n",
    "                    name=f\"decoder_block_{layer_id}\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.final_conv = nn.Conv(\n",
    "            features=self.widths[0],\n",
    "            kernel_size=(1, 1),\n",
    "            name=\"final_conv\"\n",
    "        )\n",
    "\n",
    "    def __call__(self, inputs: jnp.ndarray, train: bool) -> jnp.ndarray:\n",
    "        \"\"\"Apply the autoencoder network to `inputs`.\n",
    "\n",
    "        Args:\n",
    "          inputs: (batch_size, resolution, resolution, n_spins, n_channels) array.\n",
    "          train: whether to run in training or inference mode.\n",
    "\n",
    "        Returns:\n",
    "          Reconstructed tensor (same shape as input).\n",
    "        \"\"\"\n",
    "        feature_maps = inputs\n",
    "        skips = []\n",
    "\n",
    "        # Encoding Path\n",
    "        for layer in self.encoder_layers:\n",
    "            feature_maps = layer(feature_maps, train=train)\n",
    "            skips.append(feature_maps)  # Save for skip connections\n",
    "\n",
    "        # Decoding Path\n",
    "        for layer, skip in zip(self.decoder_layers, reversed(skips)):\n",
    "            feature_maps = layer(feature_maps, train=train) + skip  # Skip connection\n",
    "\n",
    "        return self.final_conv(feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpinSphericalAutoencoder(\n",
    "    resolutions=_SMALL_CLASSIFIER_RESOLUTIONS,\n",
    "    spins=spins,\n",
    "    widths=widths,\n",
    "    spectral_pooling=False,\n",
    "    axis_name='axis_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpinSphericalAutoencoder(\n",
       "    # attributes\n",
       "    resolutions = (64, 64, 64, 32, 32, 16, 16)\n",
       "    spins = ((0,), (0,), (0,), (0,), (0,), (0,), (0,))\n",
       "    widths = (1, 16, 16, 32, 32, 58, 58)\n",
       "    spectral_pooling = False\n",
       "    axis_name = 'axis_1'\n",
       "    num_filter_params = None\n",
       "    input_transformer = None\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  # For testing on a single slice, set batch size to 1\n",
    "n_spins = 0  # Adjust based on your data (e.g., spin-weighted spherical harmonics)\n",
    "n_channels = 3  # Adjust based on the number of channels\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "# Example: Generating random input tensor (replace with your actual slice)\n",
    "input_slice = jax.random.normal(key, (batch_size, 128, 110, n_spins, n_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'jaxlib.xla_extension.ArrayImpl' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# params = model.init(key, input_slice, train=False)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# # Get the model prediction for the 128x110 slice (which is input_slice here)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# # The predicted_output will now be the predicted slice(s) for all 141 shells\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(predicted_output.shape)\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Career/DMLab/SURROGATE/.venv/lib/python3.9/site-packages/flax/core/scope.py:1199\u001b[0m, in \u001b[0;36m_is_valid_variables\u001b[0;34m(variables)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_is_valid_variables\u001b[39m(variables: VariableDict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether the given variable dict is valid.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;124;03m    True if `variables` is a valid variable dict.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1199\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvariables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1201\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'jaxlib.xla_extension.ArrayImpl' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "yhat = model.apply(input_slice, train=True)\n",
    "# params = model.init(key, input_slice, train=False)\n",
    "\n",
    "# # Get the model prediction for the 128x110 slice (which is input_slice here)\n",
    "# predicted_output = model.apply(params, input_slice, train=False)\n",
    "\n",
    "# # The predicted_output will now be the predicted slice(s) for all 141 shells\n",
    "# print(predicted_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
