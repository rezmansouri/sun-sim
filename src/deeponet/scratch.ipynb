{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b99374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DDE_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import deepxde as dde\n",
    "from pyhdf.SD import SD, SDC\n",
    "from deepxde.nn import DeepONetCartesianProd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ea4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf(hdf_path, dataset_names):\n",
    "    f = SD(hdf_path, SDC.READ)\n",
    "    datasets = []\n",
    "    for dataset_name in dataset_names:\n",
    "        datasets.append(f.select(dataset_name).get())\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914cde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "br, phi, theta, rho = read_hdf('/Users/reza/Career/DMLab/SURROGATE/Data/psi_web_sample/train/cr1732/kpo_mas_mas_std_0101/br002.hdf', [\"Data-Set-2\", \"fakeDim0\", \"fakeDim1\", \"fakeDim2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0423f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 110, 141), (128,), (110,), (141,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.shape, phi.shape, theta.shape, rho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7123ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = br.transpose(2, 1, 0)\n",
    "br.shape\n",
    "br = np.zeros((2, 110, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad1d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.as_tensor(theta, dtype=torch.float32)  # [111]\n",
    "phi   = torch.as_tensor(phi,   dtype=torch.float32)  # [128]\n",
    "br    = torch.as_tensor(br,    dtype=torch.float32)  # [1, 111, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc712258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords shape: torch.Size([14080, 2])\n"
     ]
    }
   ],
   "source": [
    "Theta, Phi = torch.meshgrid(theta, phi, indexing=\"ij\")\n",
    "# Flatten => shape [111 * 128, 2] = [14208, 2]\n",
    "coords = torch.stack([Theta.flatten(), Phi.flatten()], dim=-1)\n",
    "print(\"coords shape:\", coords.shape)  # [14208, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c80ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch_input shape: torch.Size([2, 14080])\n"
     ]
    }
   ],
   "source": [
    "# br has shape [1, 111, 128]\n",
    "# Flatten => [1, 14208]\n",
    "branch_input = br.reshape(2, -1)\n",
    "print(\"branch_input shape:\", branch_input.shape)  # [1, 14208]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8acd9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepONetCartesianProd(\n",
    "    layer_sizes_branch=[14080, 256, 128],   # Branch final layer = 128\n",
    "    layer_sizes_trunk=[2, 256, 17920],      # Trunk final layer = 17920 = 128 * 140\n",
    "    activation=\"tanh\",\n",
    "    kernel_initializer=\"Glorot uniform\",\n",
    "    num_outputs=140,                        # produce 140 output channels\n",
    "    multi_output_strategy=\"split_trunk\",    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09ed48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: torch.Size([2, 14080, 140])\n"
     ]
    }
   ],
   "source": [
    "y_pred = model([branch_input, coords])\n",
    "print(\"Raw output:\", y_pred.shape)  # [1, 14208, 140]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eae5131f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: torch.Size([140, 110, 128])\n"
     ]
    }
   ],
   "source": [
    "# Permute to [1, 140, 14208]\n",
    "y_pred = y_pred.permute(0, 2, 1)\n",
    "\n",
    "# Reshape to [1, 140, 111, 128]\n",
    "y_pred = y_pred.reshape(1, 140, 110, 128)\n",
    "\n",
    "# Drop the batch dim => [140, 111, 128]\n",
    "y_pred = y_pred.squeeze(0)\n",
    "print(\"Final output:\", y_pred.shape)  # [140, 111, 128]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
